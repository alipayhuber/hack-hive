From 2df0f017e8a0fdc886a696e77a075ea47948b8a9 Mon Sep 17 00:00:00 2001
From: Brock Noland <brock@apache.org>
Date: Fri, 4 Oct 2013 14:51:38 +0000
Subject: [PATCH 064/375] HIVE-5395 - Various cleanup in ptf code (Edward Capriolo via Brock Noland)

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1529174 13f79535-47bb-0310-9956-ffa450edef68
---
 .../apache/hadoop/hive/ql/exec/PTFOperator.java    |   18 +-
 .../hive/ql/optimizer/ColumnPrunerProcFactory.java |    6 +-
 .../hadoop/hive/ql/parse/PTFInvocationSpec.java    |    7 +-
 .../apache/hadoop/hive/ql/parse/PTFTranslator.java |   54 +-
 .../hadoop/hive/ql/parse/SemanticAnalyzer.java     |   10 +-
 .../org/apache/hadoop/hive/ql/plan/PTFDesc.java    |  550 +-------------------
 .../hadoop/hive/ql/plan/PTFDeserializer.java       |   29 +-
 .../hadoop/hive/ql/plan/ptf/BoundaryDef.java       |   17 +
 .../hadoop/hive/ql/plan/ptf/CurrentRowDef.java     |   20 +
 .../apache/hadoop/hive/ql/plan/ptf/OrderDef.java   |   29 +
 .../hive/ql/plan/ptf/OrderExpressionDef.java       |   22 +
 .../hadoop/hive/ql/plan/ptf/PTFExpressionDef.java  |   58 ++
 .../hadoop/hive/ql/plan/ptf/PTFInputDef.java       |   32 ++
 .../hadoop/hive/ql/plan/ptf/PTFQueryInputDef.java  |   29 +
 .../hadoop/hive/ql/plan/ptf/PartitionDef.java      |   21 +
 .../ql/plan/ptf/PartitionedTableFunctionDef.java   |  111 ++++
 .../hadoop/hive/ql/plan/ptf/RangeBoundaryDef.java  |   24 +
 .../hadoop/hive/ql/plan/ptf/ShapeDetails.java      |   80 +++
 .../hadoop/hive/ql/plan/ptf/ValueBoundaryDef.java  |   48 ++
 .../hive/ql/plan/ptf/WindowExpressionDef.java      |   20 +
 .../hadoop/hive/ql/plan/ptf/WindowFrameDef.java    |   23 +
 .../hadoop/hive/ql/plan/ptf/WindowFunctionDef.java |   78 +++
 .../hive/ql/plan/ptf/WindowTableFunctionDef.java   |   15 +
 .../apache/hadoop/hive/ql/udf/ptf/MatchPath.java   |   26 +-
 .../org/apache/hadoop/hive/ql/udf/ptf/Noop.java    |   24 +-
 .../apache/hadoop/hive/ql/udf/ptf/NoopWithMap.java |    2 +-
 .../hive/ql/udf/ptf/TableFunctionEvaluator.java    |   59 +--
 .../hive/ql/udf/ptf/TableFunctionResolver.java     |   44 +-
 .../hive/ql/udf/ptf/WindowingTableFunction.java    |   14 +-
 29 files changed, 762 insertions(+), 708 deletions(-)
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/BoundaryDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/CurrentRowDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/OrderDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/OrderExpressionDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFExpressionDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFInputDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFQueryInputDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PartitionDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PartitionedTableFunctionDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/RangeBoundaryDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/ShapeDetails.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/ValueBoundaryDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowExpressionDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFrameDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFunctionDef.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowTableFunctionDef.java

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/PTFOperator.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/PTFOperator.java
index 8b0e3e0..a249d74 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/PTFOperator.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/PTFOperator.java
@@ -19,9 +19,9 @@
 package org.apache.hadoop.hive.ql.exec;
 
 import java.io.Serializable;
-import java.util.ArrayList;
+import java.util.ArrayDeque;
+import java.util.Deque;
 import java.util.List;
-import java.util.Stack;
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hive.conf.HiveConf;
@@ -30,12 +30,12 @@
 import org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc;
 import org.apache.hadoop.hive.ql.plan.OperatorDesc;
 import org.apache.hadoop.hive.ql.plan.PTFDesc;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFExpressionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFInputDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionedTableFunctionDef;
 import org.apache.hadoop.hive.ql.plan.PTFDeserializer;
 import org.apache.hadoop.hive.ql.plan.api.OperatorType;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFExpressionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFInputDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLeadLag;
 import org.apache.hadoop.hive.ql.udf.ptf.TableFunctionEvaluator;
 import org.apache.hadoop.hive.serde2.SerDe;
@@ -147,7 +147,7 @@ protected void reconstructQueryDef(HiveConf hiveConf) throws HiveException {
 
 	protected void setupKeysWrapper(ObjectInspector inputOI) throws HiveException {
 		PartitionDef pDef = conf.getStartOfChain().getPartition();
-		ArrayList<PTFExpressionDef> exprs = pDef.getExpressions();
+		List<PTFExpressionDef> exprs = pDef.getExpressions();
 		int numExprs = exprs.size();
 		ExprNodeEvaluator[] keyFields = new ExprNodeEvaluator[numExprs];
 		ObjectInspector[] keyOIs = new ObjectInspector[numExprs];
@@ -220,7 +220,7 @@ public OperatorType getType() {
    */
   private PTFPartition executeChain(PTFPartition part)
       throws HiveException {
-    Stack<PartitionedTableFunctionDef> fnDefs = new Stack<PartitionedTableFunctionDef>();
+    Deque<PartitionedTableFunctionDef> fnDefs = new ArrayDeque<PartitionedTableFunctionDef>();
     PTFInputDef iDef = conf.getFuncDef();
 
     while (iDef instanceof PartitionedTableFunctionDef) {
@@ -289,6 +289,4 @@ public static void connectLeadLagFunctionsToPartition(PTFDesc ptfDesc,
     }
   }
 
-
-
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java b/src/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
index 52c47d4..0798470 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
@@ -67,14 +67,14 @@
 import org.apache.hadoop.hive.ql.plan.MapJoinDesc;
 import org.apache.hadoop.hive.ql.plan.OperatorDesc;
 import org.apache.hadoop.hive.ql.plan.PTFDesc;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFExpressionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowFunctionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowTableFunctionDef;
 import org.apache.hadoop.hive.ql.plan.PlanUtils;
 import org.apache.hadoop.hive.ql.plan.ReduceSinkDesc;
 import org.apache.hadoop.hive.ql.plan.SelectDesc;
 import org.apache.hadoop.hive.ql.plan.TableDesc;
 import org.apache.hadoop.hive.ql.plan.TableScanDesc;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFExpressionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowTableFunctionDef;
 import org.apache.hadoop.hive.serde2.objectinspector.StructField;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFInvocationSpec.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFInvocationSpec.java
index 6f42c7d..06d3f4b 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFInvocationSpec.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFInvocationSpec.java
@@ -19,6 +19,7 @@
 package org.apache.hadoop.hive.ql.parse;
 
 import java.util.ArrayList;
+import java.util.List;
 
 import org.apache.hadoop.hive.ql.exec.PTFUtils;
 
@@ -124,7 +125,7 @@ public PTFQueryInputSpec getQueryInput() {
   public static class PartitionedTableFunctionSpec  extends PTFInputSpec {
     String name;
     String alias;
-    ArrayList<ASTNode> args;
+    List<ASTNode> args;
     PartitioningSpec partitioning;
     PTFInputSpec input;
     public String getName() {
@@ -139,10 +140,10 @@ public String getAlias() {
     public void setAlias(String alias) {
       this.alias = alias;
     }
-    public ArrayList<ASTNode> getArgs() {
+    public List<ASTNode> getArgs() {
       return args;
     }
-    public void setArgs(ArrayList<ASTNode> args) {
+    public void setArgs(List<ASTNode> args) {
       this.args = args;
     }
     public PartitioningSpec getPartitioning() {
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
index 4dac2e3..7a7f3ef 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
@@ -18,7 +18,9 @@
 
 package org.apache.hadoop.hive.ql.parse;
 
+import java.util.ArrayDeque;
 import java.util.ArrayList;
+import java.util.Deque;
 import java.util.HashMap;
 import java.util.LinkedHashMap;
 import java.util.List;
@@ -60,22 +62,22 @@
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc;
 import org.apache.hadoop.hive.ql.plan.PTFDesc;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.BoundaryDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.CurrentRowDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.OrderDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.OrderExpressionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFExpressionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFInputDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFQueryInputDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionedTableFunctionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.RangeBoundaryDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.ShapeDetails;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.ValueBoundaryDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowFrameDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowFunctionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowTableFunctionDef;
 import org.apache.hadoop.hive.ql.plan.PTFDeserializer;
+import org.apache.hadoop.hive.ql.plan.ptf.BoundaryDef;
+import org.apache.hadoop.hive.ql.plan.ptf.CurrentRowDef;
+import org.apache.hadoop.hive.ql.plan.ptf.OrderDef;
+import org.apache.hadoop.hive.ql.plan.ptf.OrderExpressionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFExpressionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFInputDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFQueryInputDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.RangeBoundaryDef;
+import org.apache.hadoop.hive.ql.plan.ptf.ShapeDetails;
+import org.apache.hadoop.hive.ql.plan.ptf.ValueBoundaryDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowTableFunctionDef;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLeadLag;
 import org.apache.hadoop.hive.ql.udf.ptf.TableFunctionEvaluator;
@@ -224,7 +226,7 @@ public PTFDesc translate(WindowingSpec wdwSpec, SemanticAnalyzer semAly, HiveCon
 
   private void translatePTFChain() throws SemanticException {
 
-    Stack<PTFInputSpec> ptfChain = new Stack<PTFInvocationSpec.PTFInputSpec>();
+    Deque<PTFInputSpec> ptfChain = new ArrayDeque<PTFInvocationSpec.PTFInputSpec>();
     PTFInputSpec currentSpec = ptfInvocation.getFunction();
     while (currentSpec != null) {
       ptfChain.push(currentSpec);
@@ -280,7 +282,7 @@ private PartitionedTableFunctionDef translate(PartitionedTableFunctionSpec spec,
     /*
      * translate args
      */
-    ArrayList<ASTNode> args = spec.getArgs();
+    List<ASTNode> args = spec.getArgs();
     if (args != null)
     {
       for (ASTNode expr : args)
@@ -303,7 +305,7 @@ private PartitionedTableFunctionDef translate(PartitionedTableFunctionSpec spec,
 
     if (tFn.transformsRawInput()) {
       StructObjectInspector rawInOutOI = tEval.getRawInputOI();
-      ArrayList<String> rawInOutColNames = tFn.getRawInputColumnNames();
+      List<String> rawInOutColNames = tFn.getRawInputColumnNames();
       RowResolver rawInRR = buildRowResolverForPTF(def.getName(),
           spec.getAlias(),
           rawInOutOI,
@@ -324,7 +326,7 @@ private PartitionedTableFunctionDef translate(PartitionedTableFunctionSpec spec,
     tFn.setupOutputOI();
 
     StructObjectInspector outputOI = tEval.getOutputOI();
-    ArrayList<String> outColNames = tFn.getOutputColumnNames();
+    List<String> outColNames = tFn.getOutputColumnNames();
     RowResolver outRR = buildRowResolverForPTF(def.getName(),
         spec.getAlias(),
         outputOI,
@@ -566,8 +568,8 @@ else if (bndSpec instanceof RangeBoundarySpec) {
   }
 
   static void setupWdwFnEvaluator(WindowFunctionDef def) throws HiveException {
-    ArrayList<PTFExpressionDef> args = def.getArgs();
-    ArrayList<ObjectInspector> argOIs = new ArrayList<ObjectInspector>();
+    List<PTFExpressionDef> args = def.getArgs();
+    List<ObjectInspector> argOIs = new ArrayList<ObjectInspector>();
     ObjectInspector[] funcArgOIs = null;
 
     if (args != null) {
@@ -619,7 +621,7 @@ private static void validateValueBoundaryExprType(ObjectInspector OI)
   }
 
   private ShapeDetails setupTableFnShape(String fnName, ShapeDetails inpShape,
-      StructObjectInspector OI, ArrayList<String> columnNames, RowResolver rr)
+      StructObjectInspector OI, List<String> columnNames, RowResolver rr)
       throws SemanticException {
     if (fnName.equals(FunctionRegistry.NOOP_TABLE_FUNCTION)
         || fnName.equals(
@@ -630,7 +632,7 @@ private ShapeDetails setupTableFnShape(String fnName, ShapeDetails inpShape,
   }
 
   private ShapeDetails setupShape(StructObjectInspector OI,
-      ArrayList<String> columnNames,
+      List<String> columnNames,
       RowResolver rr) throws SemanticException {
     Map<String, String> serdePropsMap = new LinkedHashMap<String, String>();
     SerDe serde = null;
@@ -672,7 +674,7 @@ private ShapeDetails copyShape(ShapeDetails src) {
 
   private ShapeDetails setupShapeForNoop(ShapeDetails inpShape,
       StructObjectInspector OI,
-      ArrayList<String> columnNames,
+      List<String> columnNames,
       RowResolver rr) throws SemanticException {
     ShapeDetails shp = new ShapeDetails();
 
@@ -738,7 +740,7 @@ private void setupRankingArgs(WindowTableFunctionDef wdwTFnDef,
       throw new SemanticException("Ranking Functions can take no arguments");
     }
     OrderDef oDef = wdwTFnDef.getOrder();
-    ArrayList<OrderExpressionDef> oExprs = oDef.getExpressions();
+    List<OrderExpressionDef> oExprs = oDef.getExpressions();
     for (OrderExpressionDef oExpr : oExprs) {
       wFnDef.addArg(oExpr);
     }
@@ -871,7 +873,7 @@ private static void addInputColumnsToList(ShapeDetails shape,
 
   protected static RowResolver buildRowResolverForPTF(String tbFnName, String tabAlias,
       StructObjectInspector rowObjectInspector,
-      ArrayList<String> outputColNames, RowResolver inputRR) throws SemanticException {
+      List<String> outputColNames, RowResolver inputRR) throws SemanticException {
 
     if (tbFnName.equals(FunctionRegistry.NOOP_TABLE_FUNCTION) ||
         tbFnName.equals(FunctionRegistry.NOOP_MAP_TABLE_FUNCTION)) {
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 8fae6ea..c34b261 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -139,9 +139,6 @@
 import org.apache.hadoop.hive.ql.plan.MapJoinDesc;
 import org.apache.hadoop.hive.ql.plan.OperatorDesc;
 import org.apache.hadoop.hive.ql.plan.PTFDesc;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.OrderExpressionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFExpressionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionedTableFunctionDef;
 import org.apache.hadoop.hive.ql.plan.PlanUtils;
 import org.apache.hadoop.hive.ql.plan.ReduceSinkDesc;
 import org.apache.hadoop.hive.ql.plan.ScriptDesc;
@@ -150,6 +147,9 @@
 import org.apache.hadoop.hive.ql.plan.TableScanDesc;
 import org.apache.hadoop.hive.ql.plan.UDTFDesc;
 import org.apache.hadoop.hive.ql.plan.UnionDesc;
+import org.apache.hadoop.hive.ql.plan.ptf.OrderExpressionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFExpressionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.hive.ql.session.SessionState.ResourceType;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;
@@ -9935,7 +9935,7 @@ void buildPTFReduceSinkDetails(PartitionedTableFunctionDef tabDef,
       RowResolver rsOpRR,
       RowResolver extractRR) throws SemanticException {
 
-    ArrayList<PTFExpressionDef> partColList = tabDef.getPartition().getExpressions();
+    List<PTFExpressionDef> partColList = tabDef.getPartition().getExpressions();
 
     for (PTFExpressionDef colDef : partColList) {
       partCols.add(colDef.getExprNode());
@@ -9950,7 +9950,7 @@ void buildPTFReduceSinkDetails(PartitionedTableFunctionDef tabDef,
      * we need to set includeKeyCols = false while creating the
      * ReduceSinkDesc
      */
-    ArrayList<OrderExpressionDef> orderColList = tabDef.getOrder().getExpressions();
+    List<OrderExpressionDef> orderColList = tabDef.getOrder().getExpressions();
     for (int i = 0; i < orderColList.size(); i++) {
       OrderExpressionDef colDef = orderColList.get(i);
       org.apache.hadoop.hive.ql.parse.PTFInvocationSpec.Order order = colDef.getOrder();
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java
index c1fbc62..95f38b6 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java
@@ -18,29 +18,19 @@
 
 package org.apache.hadoop.hive.ql.plan;
 
-import java.util.ArrayList;
-import java.util.Map;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hive.conf.HiveConf;
-import org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator;
 import org.apache.hadoop.hive.ql.exec.PTFUtils;
 import org.apache.hadoop.hive.ql.parse.LeadLagInfo;
 import org.apache.hadoop.hive.ql.parse.PTFInvocationSpec.Order;
 import org.apache.hadoop.hive.ql.parse.PTFInvocationSpec.PTFQueryInputType;
-import org.apache.hadoop.hive.ql.parse.RowResolver;
-import org.apache.hadoop.hive.ql.parse.TypeCheckCtx;
-import org.apache.hadoop.hive.ql.parse.WindowingSpec.Direction;
-import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;
-import org.apache.hadoop.hive.ql.udf.ptf.TableFunctionEvaluator;
-import org.apache.hadoop.hive.serde2.SerDe;
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowTableFunctionDef;
 
 @Explain(displayName = "PTF Operator")
-public class PTFDesc extends AbstractOperatorDesc
-{
+public class PTFDesc extends AbstractOperatorDesc {
   private static final long serialVersionUID = 1L;
   @SuppressWarnings("unused")
   private static final Log LOG = LogFactory.getLog(PTFDesc.class.getName());
@@ -99,538 +89,4 @@ public void setCfg(HiveConf cfg) {
     this.cfg = cfg;
   }
 
-  public abstract static class PTFInputDef {
-    String expressionTreeString;
-    ShapeDetails outputShape;
-    String alias;
-
-    public String getExpressionTreeString() {
-      return expressionTreeString;
-    }
-
-    public void setExpressionTreeString(String expressionTreeString) {
-      this.expressionTreeString = expressionTreeString;
-    }
-
-    public ShapeDetails getOutputShape() {
-      return outputShape;
-    }
-
-    public void setOutputShape(ShapeDetails outputShape) {
-      this.outputShape = outputShape;
-    }
-    public String getAlias() {
-      return alias;
-    }
-    public void setAlias(String alias) {
-      this.alias = alias;
-    }
-
-    public abstract PTFInputDef getInput();
-  }
-
-  public static class PTFQueryInputDef extends PTFInputDef {
-    String destination;
-    PTFQueryInputType type;
-    public String getDestination() {
-      return destination;
-    }
-    public void setDestination(String destination) {
-      this.destination = destination;
-    }
-    public PTFQueryInputType getType() {
-      return type;
-    }
-    public void setType(PTFQueryInputType type) {
-      this.type = type;
-    }
-
-    @Override
-    public PTFInputDef getInput() {
-      return null;
-    }
-  }
-
-  public static class PartitionedTableFunctionDef extends  PTFInputDef {
-    String name;
-    String resolverClassName;
-    ShapeDetails rawInputShape;
-    boolean carryForwardNames;
-    PTFInputDef input;
-    ArrayList<PTFExpressionDef> args;
-    PartitionDef partition;
-    OrderDef order;
-    TableFunctionEvaluator tFunction;
-    boolean transformsRawInput;
-    public String getName() {
-      return name;
-    }
-    public void setName(String name) {
-      this.name = name;
-    }
-    public ShapeDetails getRawInputShape() {
-      return rawInputShape;
-    }
-    public void setRawInputShape(ShapeDetails rawInputShape) {
-      this.rawInputShape = rawInputShape;
-    }
-    public boolean isCarryForwardNames() {
-      return carryForwardNames;
-    }
-    public void setCarryForwardNames(boolean carryForwardNames) {
-      this.carryForwardNames = carryForwardNames;
-    }
-    @Override
-    public PTFInputDef getInput() {
-      return input;
-    }
-    public void setInput(PTFInputDef input) {
-      this.input = input;
-    }
-    public PartitionDef getPartition() {
-      return partition;
-    }
-    public void setPartition(PartitionDef partition) {
-      this.partition = partition;
-    }
-    public OrderDef getOrder() {
-      return order;
-    }
-    public void setOrder(OrderDef order) {
-      this.order = order;
-    }
-    public TableFunctionEvaluator getTFunction() {
-      return tFunction;
-    }
-    public void setTFunction(TableFunctionEvaluator tFunction) {
-      this.tFunction = tFunction;
-    }
-    public ArrayList<PTFExpressionDef> getArgs() {
-      return args;
-    }
-
-    public void setArgs(ArrayList<PTFExpressionDef> args) {
-      this.args = args;
-    }
-
-    public void addArg(PTFExpressionDef arg) {
-      args = args == null ? new ArrayList<PTFExpressionDef>() : args;
-      args.add(arg);
-    }
-
-    public PartitionedTableFunctionDef getStartOfChain() {
-      if (input instanceof PartitionedTableFunctionDef ) {
-        return ((PartitionedTableFunctionDef)input).getStartOfChain();
-      }
-      return this;
-    }
-    public boolean isTransformsRawInput() {
-      return transformsRawInput;
-    }
-    public void setTransformsRawInput(boolean transformsRawInput) {
-      this.transformsRawInput = transformsRawInput;
-    }
-    public String getResolverClassName() {
-      return resolverClassName;
-    }
-    public void setResolverClassName(String resolverClassName) {
-      this.resolverClassName = resolverClassName;
-    }
-  }
-
-  public static class WindowTableFunctionDef extends PartitionedTableFunctionDef {
-    ArrayList<WindowFunctionDef> windowFunctions;
-
-    public ArrayList<WindowFunctionDef> getWindowFunctions() {
-      return windowFunctions;
-    }
-    public void setWindowFunctions(ArrayList<WindowFunctionDef> windowFunctions) {
-      this.windowFunctions = windowFunctions;
-    }
-  }
-
-  public static class ShapeDetails {
-    String serdeClassName;
-    Map<String, String> serdeProps;
-    ArrayList<String> columnNames;
-    transient StructObjectInspector OI;
-    transient SerDe serde;
-    transient RowResolver rr;
-    transient TypeCheckCtx typeCheckCtx;
-
-    static{
-      PTFUtils.makeTransient(ShapeDetails.class, "OI", "serde", "rr", "typeCheckCtx");
-    }
-
-    public String getSerdeClassName() {
-      return serdeClassName;
-    }
-
-    public void setSerdeClassName(String serdeClassName) {
-      this.serdeClassName = serdeClassName;
-    }
-
-    public Map<String, String> getSerdeProps() {
-      return serdeProps;
-    }
-
-    public void setSerdeProps(Map<String, String> serdeProps) {
-      this.serdeProps = serdeProps;
-    }
-
-    public ArrayList<String> getColumnNames() {
-      return columnNames;
-    }
-
-    public void setColumnNames(ArrayList<String> columnNames) {
-      this.columnNames = columnNames;
-    }
-
-    public StructObjectInspector getOI() {
-      return OI;
-    }
-
-    public void setOI(StructObjectInspector oI) {
-      OI = oI;
-    }
-
-    public SerDe getSerde() {
-      return serde;
-    }
-
-    public void setSerde(SerDe serde) {
-      this.serde = serde;
-    }
-
-    public RowResolver getRr() {
-      return rr;
-    }
-
-    public void setRr(RowResolver rr) {
-      this.rr = rr;
-    }
-
-    public TypeCheckCtx getTypeCheckCtx() {
-      return typeCheckCtx;
-    }
-
-    public void setTypeCheckCtx(TypeCheckCtx typeCheckCtx) {
-      this.typeCheckCtx = typeCheckCtx;
-    }
-  }
-
-  public static class PartitionDef {
-    ArrayList<PTFExpressionDef> expressions;
-
-    public ArrayList<PTFExpressionDef> getExpressions() {
-      return expressions;
-    }
-
-    public void setExpressions(ArrayList<PTFExpressionDef> expressions) {
-      this.expressions = expressions;
-    }
-    public void addExpression(PTFExpressionDef e) {
-      expressions = expressions == null ? new ArrayList<PTFExpressionDef>() : expressions;
-      expressions.add(e);
-    }
-  }
-
-  public static class OrderDef {
-    ArrayList<OrderExpressionDef> expressions;
-
-    public OrderDef() {}
-
-    public OrderDef(PartitionDef pDef) {
-      for(PTFExpressionDef eDef : pDef.getExpressions())
-      {
-        addExpression(new OrderExpressionDef(eDef));
-      }
-    }
-
-    public ArrayList<OrderExpressionDef> getExpressions() {
-      return expressions;
-    }
-
-    public void setExpressions(ArrayList<OrderExpressionDef> expressions) {
-      this.expressions = expressions;
-    }
-    public void addExpression(OrderExpressionDef e) {
-      expressions = expressions == null ? new ArrayList<OrderExpressionDef>() : expressions;
-      expressions.add(e);
-    }
-  }
-
-  public static class OrderExpressionDef extends PTFExpressionDef {
-    Order order;
-
-    public OrderExpressionDef() {}
-    public OrderExpressionDef(PTFExpressionDef e) {
-      super(e);
-      order = Order.ASC;
-    }
-
-    public Order getOrder() {
-      return order;
-    }
-
-    public void setOrder(Order order) {
-      this.order = order;
-    }
-  }
-
-  public static class WindowExpressionDef  extends PTFExpressionDef {
-    String alias;
-
-    public WindowExpressionDef() {}
-    public WindowExpressionDef(PTFExpressionDef eDef) {
-      super(eDef);
-    }
-    public String getAlias() {
-      return alias;
-    }
-
-    public void setAlias(String alias) {
-      this.alias = alias;
-    }
-  }
-
-  public static class WindowFunctionDef extends WindowExpressionDef
-  {
-    String name;
-    boolean isStar;
-    boolean isDistinct;
-    ArrayList<PTFExpressionDef> args;
-    WindowFrameDef windowFrame;
-    GenericUDAFEvaluator wFnEval;
-    boolean pivotResult;
-
-    public String getName() {
-      return name;
-    }
-
-    public void setName(String name) {
-      this.name = name;
-    }
-
-    public boolean isStar() {
-      return isStar;
-    }
-
-    public void setStar(boolean isStar) {
-      this.isStar = isStar;
-    }
-
-    public boolean isDistinct() {
-      return isDistinct;
-    }
-
-    public void setDistinct(boolean isDistinct) {
-      this.isDistinct = isDistinct;
-    }
-
-    public ArrayList<PTFExpressionDef> getArgs() {
-      return args;
-    }
-
-    public void setArgs(ArrayList<PTFExpressionDef> args) {
-      this.args = args;
-    }
-
-    public void addArg(PTFExpressionDef arg) {
-      args = args == null ? new ArrayList<PTFExpressionDef>() : args;
-      args.add(arg);
-    }
-
-    public WindowFrameDef getWindowFrame() {
-      return windowFrame;
-    }
-
-    public void setWindowFrame(WindowFrameDef windowFrame) {
-      this.windowFrame = windowFrame;
-    }
-
-    public GenericUDAFEvaluator getWFnEval() {
-      return wFnEval;
-    }
-
-    public void setWFnEval(GenericUDAFEvaluator wFnEval) {
-      this.wFnEval = wFnEval;
-    }
-
-    public boolean isPivotResult() {
-      return pivotResult;
-    }
-
-    public void setPivotResult(boolean pivotResult) {
-      this.pivotResult = pivotResult;
-    }
-
-  }
-
-  public static class WindowFrameDef
-  {
-    BoundaryDef start;
-    BoundaryDef end;
-    public BoundaryDef getStart() {
-      return start;
-    }
-    public void setStart(BoundaryDef start) {
-      this.start = start;
-    }
-    public BoundaryDef getEnd() {
-      return end;
-    }
-    public void setEnd(BoundaryDef end) {
-      this.end = end;
-    }
-  }
-
-  public static abstract class BoundaryDef {
-    Direction direction;
-
-    public Direction getDirection() {
-      return direction;
-    }
-
-    public void setDirection(Direction direction) {
-      this.direction = direction;
-    }
-
-    public abstract int getAmt();
-  }
-
-  public static class RangeBoundaryDef extends BoundaryDef {
-    int amt;
-
-    public int compareTo(BoundaryDef other)
-    {
-      int c = getDirection().compareTo(other.getDirection());
-      if ( c != 0) {
-        return c;
-      }
-      RangeBoundaryDef rb = (RangeBoundaryDef) other;
-      return getAmt() - rb.getAmt();
-    }
-
-    @Override
-    public int getAmt() {
-      return amt;
-    }
-
-    public void setAmt(int amt) {
-      this.amt = amt;
-    }
-  }
-
-  public static class CurrentRowDef extends BoundaryDef
-  {
-    public int compareTo(BoundaryDef other)
-    {
-      return getDirection().compareTo(other.getDirection());
-    }
-    @Override
-    public Direction getDirection() {
-      return Direction.CURRENT;
-    }
-
-    @Override
-    public int getAmt() { return 0; }
-  }
-
-  public static class ValueBoundaryDef extends BoundaryDef
-  {
-    PTFExpressionDef expressionDef;
-    int amt;
-
-    public int compareTo(BoundaryDef other) {
-      int c = getDirection().compareTo(other.getDirection());
-      if ( c != 0) {
-        return c;
-      }
-      ValueBoundaryDef vb = (ValueBoundaryDef) other;
-      return getAmt() - vb.getAmt();
-    }
-
-    public PTFExpressionDef getExpressionDef() {
-      return expressionDef;
-    }
-
-    public void setExpressionDef(PTFExpressionDef expressionDef) {
-      this.expressionDef = expressionDef;
-    }
-
-    public ExprNodeDesc getExprNode() {
-      return expressionDef == null ? null : expressionDef.getExprNode();
-    }
-
-    public ExprNodeEvaluator getExprEvaluator() {
-      return expressionDef == null ? null : expressionDef.getExprEvaluator();
-    }
-
-    public ObjectInspector getOI() {
-      return expressionDef == null ? null : expressionDef.getOI();
-    }
-
-    @Override
-    public int getAmt() {
-      return amt;
-    }
-
-    public void setAmt(int amt) {
-      this.amt = amt;
-    }
-  }
-
-  public static class PTFExpressionDef
-  {
-    String expressionTreeString;
-    ExprNodeDesc exprNode;
-    transient ExprNodeEvaluator exprEvaluator;
-    transient ObjectInspector OI;
-
-    static{
-      PTFUtils.makeTransient(PTFExpressionDef.class, "exprEvaluator", "OI");
-    }
-
-    public PTFExpressionDef() {}
-    public PTFExpressionDef(PTFExpressionDef e) {
-      expressionTreeString = e.getExpressionTreeString();
-      exprNode = e.getExprNode();
-      exprEvaluator = e.getExprEvaluator();
-      OI = e.getOI();
-    }
-
-    public String getExpressionTreeString() {
-      return expressionTreeString;
-    }
-
-    public void setExpressionTreeString(String expressionTreeString) {
-      this.expressionTreeString = expressionTreeString;
-    }
-
-    public ExprNodeDesc getExprNode() {
-      return exprNode;
-    }
-
-    public void setExprNode(ExprNodeDesc exprNode) {
-      this.exprNode = exprNode;
-    }
-
-    public ExprNodeEvaluator getExprEvaluator() {
-      return exprEvaluator;
-    }
-
-    public void setExprEvaluator(ExprNodeEvaluator exprEvaluator) {
-      this.exprEvaluator = exprEvaluator;
-    }
-
-    public ObjectInspector getOI() {
-      return OI;
-    }
-
-    public void setOI(ObjectInspector oI) {
-      OI = oI;
-    }
-  }
-
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDeserializer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDeserializer.java
index f4b47be..3a258e4 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDeserializer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDeserializer.java
@@ -18,12 +18,13 @@
 
 package org.apache.hadoop.hive.ql.plan;
 
+import java.util.ArrayDeque;
 import java.util.ArrayList;
+import java.util.Deque;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
-import java.util.Stack;
 
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator;
@@ -31,16 +32,16 @@
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.parse.LeadLagInfo;
 import org.apache.hadoop.hive.ql.parse.WindowingExprNodeEvaluatorFactory;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.BoundaryDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFExpressionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFInputDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFQueryInputDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionedTableFunctionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.ShapeDetails;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.ValueBoundaryDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowFrameDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowFunctionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.BoundaryDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFExpressionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFInputDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFQueryInputDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.ShapeDetails;
+import org.apache.hadoop.hive.ql.plan.ptf.ValueBoundaryDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowTableFunctionDef;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLeadLag;
 import org.apache.hadoop.hive.ql.udf.ptf.TableFunctionEvaluator;
@@ -76,7 +77,7 @@ public PTFDeserializer(PTFDesc ptfDesc, StructObjectInspector inputOI, HiveConf 
   }
 
   public void initializePTFChain(PartitionedTableFunctionDef tblFnDef) throws HiveException {
-    Stack<PTFInputDef> ptfChain = new Stack<PTFInputDef>();
+    Deque<PTFInputDef> ptfChain = new ArrayDeque<PTFInputDef>();
     PTFInputDef currentDef = tblFnDef;
     while (currentDef != null) {
       ptfChain.push(currentDef);
@@ -188,8 +189,8 @@ protected void initialize(PartitionedTableFunctionDef def) throws HiveException 
   }
 
   static void setupWdwFnEvaluator(WindowFunctionDef def) throws HiveException {
-    ArrayList<PTFExpressionDef> args = def.getArgs();
-    ArrayList<ObjectInspector> argOIs = new ArrayList<ObjectInspector>();
+    List<PTFExpressionDef> args = def.getArgs();
+    List<ObjectInspector> argOIs = new ArrayList<ObjectInspector>();
     ObjectInspector[] funcArgOIs = null;
 
     if (args != null) {
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/BoundaryDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/BoundaryDef.java
new file mode 100644
index 0000000..62a652e
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/BoundaryDef.java
@@ -0,0 +1,17 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import org.apache.hadoop.hive.ql.parse.WindowingSpec.Direction;
+
+public abstract class BoundaryDef {
+  Direction direction;
+
+  public Direction getDirection() {
+    return direction;
+  }
+
+  public void setDirection(Direction direction) {
+    this.direction = direction;
+  }
+
+  public abstract int getAmt();
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/CurrentRowDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/CurrentRowDef.java
new file mode 100644
index 0000000..eec6a1b
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/CurrentRowDef.java
@@ -0,0 +1,20 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import org.apache.hadoop.hive.ql.parse.WindowingSpec.Direction;
+
+public class CurrentRowDef extends BoundaryDef {
+
+  public int compareTo(BoundaryDef other) {
+    return getDirection().compareTo(other.getDirection());
+  }
+
+  @Override
+  public Direction getDirection() {
+    return Direction.CURRENT;
+  }
+
+  @Override
+  public int getAmt() {
+    return 0;
+  }
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/OrderDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/OrderDef.java
new file mode 100644
index 0000000..3f3b79e
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/OrderDef.java
@@ -0,0 +1,29 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import java.util.ArrayList;
+import java.util.List;
+
+public class OrderDef {
+  List<OrderExpressionDef> expressions;
+
+  public OrderDef() {}
+
+  public OrderDef(PartitionDef pDef) {
+    for(PTFExpressionDef eDef : pDef.getExpressions()) {
+      addExpression(new OrderExpressionDef(eDef));
+    }
+  }
+
+  public List<OrderExpressionDef> getExpressions() {
+    return expressions;
+  }
+
+  public void setExpressions(ArrayList<OrderExpressionDef> expressions) {
+    this.expressions = expressions;
+  }
+  public void addExpression(OrderExpressionDef e) {
+    expressions = expressions == null ? new ArrayList<OrderExpressionDef>() : expressions;
+    expressions.add(e);
+  }
+}
+
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/OrderExpressionDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/OrderExpressionDef.java
new file mode 100644
index 0000000..9ea8f23
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/OrderExpressionDef.java
@@ -0,0 +1,22 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import org.apache.hadoop.hive.ql.parse.PTFInvocationSpec.Order;
+
+public class OrderExpressionDef extends PTFExpressionDef {
+  private Order order;
+
+  public OrderExpressionDef() {}
+  public OrderExpressionDef(PTFExpressionDef e) {
+    super(e);
+    order = Order.ASC;
+  }
+
+  public Order getOrder() {
+    return order;
+  }
+
+  public void setOrder(Order order) {
+    this.order = order;
+  }
+}
+
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFExpressionDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFExpressionDef.java
new file mode 100644
index 0000000..647115e
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFExpressionDef.java
@@ -0,0 +1,58 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator;
+import org.apache.hadoop.hive.ql.exec.PTFUtils;
+import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+
+public class PTFExpressionDef {
+  String expressionTreeString;
+  ExprNodeDesc exprNode;
+  transient ExprNodeEvaluator exprEvaluator;
+  transient ObjectInspector OI;
+
+  static{
+    PTFUtils.makeTransient(PTFExpressionDef.class, "exprEvaluator", "OI");
+  }
+
+  public PTFExpressionDef() {}
+
+  public PTFExpressionDef(PTFExpressionDef e) {
+    expressionTreeString = e.getExpressionTreeString();
+    exprNode = e.getExprNode();
+    exprEvaluator = e.getExprEvaluator();
+    OI = e.getOI();
+  }
+
+  public String getExpressionTreeString() {
+    return expressionTreeString;
+  }
+
+  public void setExpressionTreeString(String expressionTreeString) {
+    this.expressionTreeString = expressionTreeString;
+  }
+
+  public ExprNodeDesc getExprNode() {
+    return exprNode;
+  }
+
+  public void setExprNode(ExprNodeDesc exprNode) {
+    this.exprNode = exprNode;
+  }
+
+  public ExprNodeEvaluator getExprEvaluator() {
+    return exprEvaluator;
+  }
+
+  public void setExprEvaluator(ExprNodeEvaluator exprEvaluator) {
+    this.exprEvaluator = exprEvaluator;
+  }
+
+  public ObjectInspector getOI() {
+    return OI;
+  }
+
+  public void setOI(ObjectInspector oI) {
+    OI = oI;
+  }
+}
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFInputDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFInputDef.java
new file mode 100644
index 0000000..6d425c7
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFInputDef.java
@@ -0,0 +1,32 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+
+public abstract class PTFInputDef {
+  private String expressionTreeString;
+  private ShapeDetails outputShape;
+  private String alias;
+
+  public String getExpressionTreeString() {
+    return expressionTreeString;
+  }
+
+  public void setExpressionTreeString(String expressionTreeString) {
+    this.expressionTreeString = expressionTreeString;
+  }
+
+  public ShapeDetails getOutputShape() {
+    return outputShape;
+  }
+
+  public void setOutputShape(ShapeDetails outputShape) {
+    this.outputShape = outputShape;
+  }
+  public String getAlias() {
+    return alias;
+  }
+  public void setAlias(String alias) {
+    this.alias = alias;
+  }
+
+  public abstract PTFInputDef getInput();
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFQueryInputDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFQueryInputDef.java
new file mode 100644
index 0000000..c03c3c0
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PTFQueryInputDef.java
@@ -0,0 +1,29 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import org.apache.hadoop.hive.ql.parse.PTFInvocationSpec.PTFQueryInputType;
+
+public class PTFQueryInputDef extends PTFInputDef {
+  private String destination;
+  private PTFQueryInputType type;
+
+  public String getDestination() {
+    return destination;
+  }
+
+  public void setDestination(String destination) {
+    this.destination = destination;
+  }
+
+  public PTFQueryInputType getType() {
+    return type;
+  }
+
+  public void setType(PTFQueryInputType type) {
+    this.type = type;
+  }
+
+  @Override
+  public PTFInputDef getInput() {
+    return null;
+  }
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PartitionDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PartitionDef.java
new file mode 100644
index 0000000..afd6b8d
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PartitionDef.java
@@ -0,0 +1,21 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import java.util.ArrayList;
+import java.util.List;
+
+
+public class PartitionDef {
+  private List<PTFExpressionDef> expressions;
+
+  public List<PTFExpressionDef> getExpressions() {
+    return expressions;
+  }
+
+  public void setExpressions(List<PTFExpressionDef> expressions) {
+    this.expressions = expressions;
+  }
+  public void addExpression(PTFExpressionDef e) {
+    expressions = expressions == null ? new ArrayList<PTFExpressionDef>() : expressions;
+    expressions.add(e);
+  }
+}
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PartitionedTableFunctionDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PartitionedTableFunctionDef.java
new file mode 100644
index 0000000..f617da6
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/PartitionedTableFunctionDef.java
@@ -0,0 +1,111 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.hadoop.hive.ql.udf.ptf.TableFunctionEvaluator;
+
+public class PartitionedTableFunctionDef extends PTFInputDef {
+  private String name;
+  private String resolverClassName;
+  private ShapeDetails rawInputShape;
+  private boolean carryForwardNames;
+  private PTFInputDef input;
+  private List<PTFExpressionDef> args;
+  private PartitionDef partition;
+  private OrderDef order;
+  private TableFunctionEvaluator tFunction;
+  boolean transformsRawInput;
+
+  public String getName() {
+    return name;
+  }
+
+  public void setName(String name) {
+    this.name = name;
+  }
+
+  public ShapeDetails getRawInputShape() {
+    return rawInputShape;
+  }
+
+  public void setRawInputShape(ShapeDetails rawInputShape) {
+    this.rawInputShape = rawInputShape;
+  }
+
+  public boolean isCarryForwardNames() {
+    return carryForwardNames;
+  }
+
+  public void setCarryForwardNames(boolean carryForwardNames) {
+    this.carryForwardNames = carryForwardNames;
+  }
+
+  @Override
+  public PTFInputDef getInput() {
+    return input;
+  }
+
+  public void setInput(PTFInputDef input) {
+    this.input = input;
+  }
+
+  public PartitionDef getPartition() {
+    return partition;
+  }
+
+  public void setPartition(PartitionDef partition) {
+    this.partition = partition;
+  }
+
+  public OrderDef getOrder() {
+    return order;
+  }
+
+  public void setOrder(OrderDef order) {
+    this.order = order;
+  }
+
+  public TableFunctionEvaluator getTFunction() {
+    return tFunction;
+  }
+  public void setTFunction(TableFunctionEvaluator tFunction) {
+    this.tFunction = tFunction;
+  }
+
+  public List<PTFExpressionDef> getArgs() {
+    return args;
+  }
+
+  public void setArgs(List<PTFExpressionDef> args) {
+    this.args = args;
+  }
+
+  public void addArg(PTFExpressionDef arg) {
+    args = args == null ? new ArrayList<PTFExpressionDef>() : args;
+    args.add(arg);
+  }
+
+  public PartitionedTableFunctionDef getStartOfChain() {
+    if (input instanceof PartitionedTableFunctionDef ) {
+      return ((PartitionedTableFunctionDef)input).getStartOfChain();
+    }
+    return this;
+  }
+
+  public boolean isTransformsRawInput() {
+    return transformsRawInput;
+  }
+
+  public void setTransformsRawInput(boolean transformsRawInput) {
+    this.transformsRawInput = transformsRawInput;
+  }
+
+  public String getResolverClassName() {
+    return resolverClassName;
+  }
+
+  public void setResolverClassName(String resolverClassName) {
+    this.resolverClassName = resolverClassName;
+  }
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/RangeBoundaryDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/RangeBoundaryDef.java
new file mode 100644
index 0000000..64dcbc5
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/RangeBoundaryDef.java
@@ -0,0 +1,24 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+
+public class RangeBoundaryDef extends BoundaryDef {
+  private int amt;
+
+  public int compareTo(BoundaryDef other) {
+    int c = getDirection().compareTo(other.getDirection());
+    if (c != 0) {
+      return c;
+    }
+    RangeBoundaryDef rb = (RangeBoundaryDef) other;
+    return getAmt() - rb.getAmt();
+  }
+
+  @Override
+  public int getAmt() {
+    return amt;
+  }
+
+  public void setAmt(int amt) {
+    this.amt = amt;
+  }
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/ShapeDetails.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/ShapeDetails.java
new file mode 100644
index 0000000..c7e6d54
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/ShapeDetails.java
@@ -0,0 +1,80 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import java.util.List;
+import java.util.Map;
+
+import org.apache.hadoop.hive.ql.exec.PTFUtils;
+import org.apache.hadoop.hive.ql.parse.RowResolver;
+import org.apache.hadoop.hive.ql.parse.TypeCheckCtx;
+import org.apache.hadoop.hive.serde2.SerDe;
+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
+
+public class ShapeDetails {
+  String serdeClassName;
+  Map<String, String> serdeProps;
+  List<String> columnNames;
+  transient StructObjectInspector OI;
+  transient SerDe serde;
+  transient RowResolver rr;
+  transient TypeCheckCtx typeCheckCtx;
+
+  static {
+    PTFUtils.makeTransient(ShapeDetails.class, "OI", "serde", "rr", "typeCheckCtx");
+  }
+
+  public String getSerdeClassName() {
+    return serdeClassName;
+  }
+
+  public void setSerdeClassName(String serdeClassName) {
+    this.serdeClassName = serdeClassName;
+  }
+
+  public Map<String, String> getSerdeProps() {
+    return serdeProps;
+  }
+
+  public void setSerdeProps(Map<String, String> serdeProps) {
+    this.serdeProps = serdeProps;
+  }
+
+  public List<String> getColumnNames() {
+    return columnNames;
+  }
+
+  public void setColumnNames(List<String> columnNames) {
+    this.columnNames = columnNames;
+  }
+
+  public StructObjectInspector getOI() {
+    return OI;
+  }
+
+  public void setOI(StructObjectInspector oI) {
+    OI = oI;
+  }
+
+  public SerDe getSerde() {
+    return serde;
+  }
+
+  public void setSerde(SerDe serde) {
+    this.serde = serde;
+  }
+
+  public RowResolver getRr() {
+    return rr;
+  }
+
+  public void setRr(RowResolver rr) {
+    this.rr = rr;
+  }
+
+  public TypeCheckCtx getTypeCheckCtx() {
+    return typeCheckCtx;
+  }
+
+  public void setTypeCheckCtx(TypeCheckCtx typeCheckCtx) {
+    this.typeCheckCtx = typeCheckCtx;
+  }
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/ValueBoundaryDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/ValueBoundaryDef.java
new file mode 100644
index 0000000..8b6ed30
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/ValueBoundaryDef.java
@@ -0,0 +1,48 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator;
+import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+
+public class ValueBoundaryDef extends BoundaryDef {
+  private PTFExpressionDef expressionDef;
+  private int amt;
+
+  public int compareTo(BoundaryDef other) {
+    int c = getDirection().compareTo(other.getDirection());
+    if (c != 0) {
+      return c;
+    }
+    ValueBoundaryDef vb = (ValueBoundaryDef) other;
+    return getAmt() - vb.getAmt();
+  }
+
+  public PTFExpressionDef getExpressionDef() {
+    return expressionDef;
+  }
+
+  public void setExpressionDef(PTFExpressionDef expressionDef) {
+    this.expressionDef = expressionDef;
+  }
+
+  public ExprNodeDesc getExprNode() {
+    return expressionDef == null ? null : expressionDef.getExprNode();
+  }
+
+  public ExprNodeEvaluator getExprEvaluator() {
+    return expressionDef == null ? null : expressionDef.getExprEvaluator();
+  }
+
+  public ObjectInspector getOI() {
+    return expressionDef == null ? null : expressionDef.getOI();
+  }
+
+  @Override
+  public int getAmt() {
+    return amt;
+  }
+
+  public void setAmt(int amt) {
+    this.amt = amt;
+  }
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowExpressionDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowExpressionDef.java
new file mode 100644
index 0000000..50253ae
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowExpressionDef.java
@@ -0,0 +1,20 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+
+public class WindowExpressionDef extends PTFExpressionDef {
+  private String alias;
+
+  public WindowExpressionDef() {}
+
+  public WindowExpressionDef(PTFExpressionDef eDef) {
+    super(eDef);
+  }
+
+  public String getAlias() {
+    return alias;
+  }
+
+  public void setAlias(String alias) {
+    this.alias = alias;
+  }
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFrameDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFrameDef.java
new file mode 100644
index 0000000..ca6e709
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFrameDef.java
@@ -0,0 +1,23 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+
+public class WindowFrameDef {
+  private BoundaryDef start;
+  private BoundaryDef end;
+
+  public BoundaryDef getStart() {
+    return start;
+  }
+
+  public void setStart(BoundaryDef start) {
+    this.start = start;
+  }
+
+  public BoundaryDef getEnd() {
+    return end;
+  }
+
+  public void setEnd(BoundaryDef end) {
+    this.end = end;
+  }
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFunctionDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFunctionDef.java
new file mode 100644
index 0000000..231165a
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFunctionDef.java
@@ -0,0 +1,78 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;
+
+public class WindowFunctionDef extends WindowExpressionDef {
+  String name;
+  boolean isStar;
+  boolean isDistinct;
+  List<PTFExpressionDef> args;
+  WindowFrameDef windowFrame;
+  GenericUDAFEvaluator wFnEval;
+  boolean pivotResult;
+
+  public String getName() {
+    return name;
+  }
+
+  public void setName(String name) {
+    this.name = name;
+  }
+
+  public boolean isStar() {
+    return isStar;
+  }
+
+  public void setStar(boolean isStar) {
+    this.isStar = isStar;
+  }
+
+  public boolean isDistinct() {
+    return isDistinct;
+  }
+
+  public void setDistinct(boolean isDistinct) {
+    this.isDistinct = isDistinct;
+  }
+
+  public List<PTFExpressionDef> getArgs() {
+    return args;
+  }
+
+  public void setArgs(List<PTFExpressionDef> args) {
+    this.args = args;
+  }
+
+  public void addArg(PTFExpressionDef arg) {
+    args = args == null ? new ArrayList<PTFExpressionDef>() : args;
+    args.add(arg);
+  }
+
+  public WindowFrameDef getWindowFrame() {
+    return windowFrame;
+  }
+
+  public void setWindowFrame(WindowFrameDef windowFrame) {
+    this.windowFrame = windowFrame;
+  }
+
+  public GenericUDAFEvaluator getWFnEval() {
+    return wFnEval;
+  }
+
+  public void setWFnEval(GenericUDAFEvaluator wFnEval) {
+    this.wFnEval = wFnEval;
+  }
+
+  public boolean isPivotResult() {
+    return pivotResult;
+  }
+
+  public void setPivotResult(boolean pivotResult) {
+    this.pivotResult = pivotResult;
+  }
+
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowTableFunctionDef.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowTableFunctionDef.java
new file mode 100644
index 0000000..a0faf9f
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowTableFunctionDef.java
@@ -0,0 +1,15 @@
+package org.apache.hadoop.hive.ql.plan.ptf;
+
+import java.util.List;
+
+
+public class WindowTableFunctionDef extends PartitionedTableFunctionDef {
+  List<WindowFunctionDef> windowFunctions;
+
+  public List<WindowFunctionDef> getWindowFunctions() {
+    return windowFunctions;
+  }
+  public void setWindowFunctions(List<WindowFunctionDef> windowFunctions) {
+    this.windowFunctions = windowFunctions;
+  }
+}
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/MatchPath.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/MatchPath.java
index 31fa5e3..b81370e 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/MatchPath.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/MatchPath.java
@@ -40,9 +40,9 @@
 import org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.PTFDesc;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFExpressionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFInputDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionedTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFExpressionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFInputDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
 import org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters;
@@ -100,8 +100,8 @@ public void execute(PTFPartitionIterator<Object> pItr, PTFPartition outP) throws
       if (syFnRes.matches )
       {
         int sz = syFnRes.nextRow - (pItr.getIndex() - 1);
-        Object selectListInput = MatchPath.getSelectListInput(iRow,
-            tDef.getInput().getOutputShape().getOI(), pItr, sz);
+        Object selectListInput = NPath.getSelectListInput(iRow,
+            tableDef.getInput().getOutputShape().getOI(), pItr, sz);
         ArrayList<Object> oRow = new ArrayList<Object>();
         for(ExprNodeEvaluator resExprEval : resultExprInfo.resultExprEvals)
         {
@@ -161,7 +161,7 @@ public void setupOutputOI() throws SemanticException
       MatchPath evaluator = (MatchPath) getEvaluator();
       PartitionedTableFunctionDef tDef = evaluator.getTableDef();
 
-      ArrayList<PTFExpressionDef> args = tDef.getArgs();
+      List<PTFExpressionDef> args = tDef.getArgs();
       int argsNum = args == null ? 0 : args.size();
 
       if ( argsNum < 4 )
@@ -198,8 +198,8 @@ public void setupOutputOI() throws SemanticException
     /*
      * validate and setup patternStr
      */
-    private void validateAndSetupPatternStr(MatchPath evaluator,
-        ArrayList<PTFExpressionDef> args) throws SemanticException {
+    private void validateAndSetupPatternStr(NPath evaluator,
+        List<PTFExpressionDef> args) throws SemanticException {
       PTFExpressionDef symboPatternArg = args.get(0);
       ObjectInspector symbolPatternArgOI = symboPatternArg.getOI();
 
@@ -218,8 +218,8 @@ private void validateAndSetupPatternStr(MatchPath evaluator,
     /*
      * validate and setup SymbolInfo
      */
-    private void validateAndSetupSymbolInfo(MatchPath evaluator,
-        ArrayList<PTFExpressionDef> args,
+    private void validateAndSetupSymbolInfo(NPath evaluator,
+        List<PTFExpressionDef> args,
         int argsNum) throws SemanticException {
       int symbolArgsSz = argsNum - 2;
       if ( symbolArgsSz % 2 != 0)
@@ -262,8 +262,8 @@ private void validateAndSetupSymbolInfo(MatchPath evaluator,
     /*
      * validate and setup resultExprStr
      */
-    private void validateAndSetupResultExprStr(MatchPath evaluator,
-        ArrayList<PTFExpressionDef> args,
+    private void validateAndSetupResultExprStr(NPath evaluator,
+        List<PTFExpressionDef> args,
         int argsNum) throws SemanticException {
       PTFExpressionDef resultExprArg = args.get(argsNum - 1);
       ObjectInspector resultExprArgOI = resultExprArg.getOI();
@@ -303,7 +303,7 @@ public void initializeOutputOI() throws HiveException {
         MatchPath evaluator = (MatchPath) getEvaluator();
         PartitionedTableFunctionDef tDef = evaluator.getTableDef();
 
-        ArrayList<PTFExpressionDef> args = tDef.getArgs();
+        List<PTFExpressionDef> args = tDef.getArgs();
         int argsNum = args.size();
 
         validateAndSetupPatternStr(evaluator, args);
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/Noop.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/Noop.java
index 727195a..fcf6afd 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/Noop.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/Noop.java
@@ -18,43 +18,37 @@
 
 package org.apache.hadoop.hive.ql.udf.ptf;
 
-import java.util.ArrayList;
+import java.util.List;
 
 import org.apache.hadoop.hive.ql.exec.PTFPartition;
 import org.apache.hadoop.hive.ql.exec.PTFPartition.PTFPartitionIterator;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.parse.SemanticException;
 import org.apache.hadoop.hive.ql.plan.PTFDesc;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionedTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 
-public class Noop extends TableFunctionEvaluator
-{
+public class Noop extends TableFunctionEvaluator {
 
   @Override
-  public PTFPartition execute(PTFPartition iPart) throws HiveException
-  {
+  public PTFPartition execute(PTFPartition iPart) throws HiveException {
     return iPart;
   }
 
   @Override
-  protected void execute(PTFPartitionIterator<Object> pItr, PTFPartition oPart)
-  {
+  protected void execute(PTFPartitionIterator<Object> pItr, PTFPartition oPart) {
     throw new UnsupportedOperationException();
   }
 
-  public static class NoopResolver extends TableFunctionResolver
-  {
+  public static class NoopResolver extends TableFunctionResolver {
 
     @Override
-    protected TableFunctionEvaluator createEvaluator(PTFDesc ptfDesc, PartitionedTableFunctionDef tDef)
-    {
+    protected TableFunctionEvaluator createEvaluator(PTFDesc ptfDesc, PartitionedTableFunctionDef tDef) {
       return new Noop();
     }
 
     @Override
-    public void setupOutputOI() throws SemanticException
-    {
+    public void setupOutputOI() throws SemanticException {
       StructObjectInspector OI = getEvaluator().getTableDef().getInput().getOutputShape().getOI();
       setOutputOI(OI);
     }
@@ -75,7 +69,7 @@ public boolean carryForwardNames() {
      * Set to null only because carryForwardNames is true.
      */
     @Override
-    public ArrayList<String> getOutputColumnNames() {
+    public List<String> getOutputColumnNames() {
       return null;
     }
 
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/NoopWithMap.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/NoopWithMap.java
index 8cbb030..0b090a9 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/NoopWithMap.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/NoopWithMap.java
@@ -24,7 +24,7 @@
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.parse.SemanticException;
 import org.apache.hadoop.hive.ql.plan.PTFDesc;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionedTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 
 public class NoopWithMap extends Noop
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/TableFunctionEvaluator.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/TableFunctionEvaluator.java
index db1ecb2..32e78ac 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/TableFunctionEvaluator.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/TableFunctionEvaluator.java
@@ -24,7 +24,7 @@
 import org.apache.hadoop.hive.ql.exec.PTFUtils;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.plan.PTFDesc;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionedTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 
@@ -46,8 +46,7 @@
  * </ol>
  *
  */
-public abstract class TableFunctionEvaluator
-{
+public abstract class TableFunctionEvaluator {
   /*
    * how is this different from the OutpuShape set on the TableDef.
    * This is the OI of the object coming out of the PTF.
@@ -59,52 +58,45 @@
    * same comment as OI applies here.
    */
   transient protected StructObjectInspector rawInputOI;
-  protected PartitionedTableFunctionDef tDef;
+  protected PartitionedTableFunctionDef tableDef;
   protected PTFDesc ptfDesc;
   boolean transformsRawInput;
   transient protected PTFPartition outputPartition;
 
-  static{
+  static {
+    //TODO is this a bug? The field is not named outputOI it is named OI
     PTFUtils.makeTransient(TableFunctionEvaluator.class, "outputOI", "rawInputOI");
   }
 
-  public StructObjectInspector getOutputOI()
-  {
+  public StructObjectInspector getOutputOI() {
     return OI;
   }
 
-  protected void setOutputOI(StructObjectInspector outputOI)
-  {
+  protected void setOutputOI(StructObjectInspector outputOI) {
     OI = outputOI;
   }
 
-  public PartitionedTableFunctionDef getTableDef()
-  {
-    return tDef;
+  public PartitionedTableFunctionDef getTableDef() {
+    return tableDef;
   }
 
-  public void setTableDef(PartitionedTableFunctionDef tDef)
-  {
-    this.tDef = tDef;
+  public void setTableDef(PartitionedTableFunctionDef tDef) {
+    this.tableDef = tDef;
   }
 
-  protected PTFDesc getQueryDef()
-  {
+  protected PTFDesc getQueryDef() {
     return ptfDesc;
   }
 
-  protected void setQueryDef(PTFDesc ptfDesc)
-  {
+  protected void setQueryDef(PTFDesc ptfDesc) {
     this.ptfDesc = ptfDesc;
   }
 
-  public StructObjectInspector getRawInputOI()
-  {
+  public StructObjectInspector getRawInputOI() {
     return rawInputOI;
   }
 
-  protected void setRawInputOI(StructObjectInspector rawInputOI)
-  {
+  protected void setRawInputOI(StructObjectInspector rawInputOI) {
     this.rawInputOI = rawInputOI;
   }
 
@@ -117,17 +109,15 @@ public void setTransformsRawInput(boolean transformsRawInput) {
   }
 
   public PTFPartition execute(PTFPartition iPart)
-      throws HiveException
-  {
+      throws HiveException {
     PTFPartitionIterator<Object> pItr = iPart.iterator();
     PTFOperator.connectLeadLagFunctionsToPartition(ptfDesc, pItr);
 
     if ( outputPartition == null ) {
       outputPartition = PTFPartition.create(ptfDesc.getCfg(),
-          tDef.getOutputShape().getSerde(),
-          OI, tDef.getOutputShape().getOI());
-    }
-    else {
+          tableDef.getOutputShape().getSerde(),
+          OI, tableDef.getOutputShape().getOI());
+    } else {
       outputPartition.reset();
     }
 
@@ -137,17 +127,14 @@ public PTFPartition execute(PTFPartition iPart)
 
   protected abstract void execute(PTFPartitionIterator<Object> pItr, PTFPartition oPart) throws HiveException;
 
-  public PTFPartition transformRawInput(PTFPartition iPart) throws HiveException
-  {
-    if ( !isTransformsRawInput())
-    {
-      throw new HiveException(String.format("Internal Error: mapExecute called on function (%s)that has no Map Phase", tDef.getName()));
+  public PTFPartition transformRawInput(PTFPartition iPart) throws HiveException {
+    if (!isTransformsRawInput()) {
+      throw new HiveException(String.format("Internal Error: mapExecute called on function (%s)that has no Map Phase", tableDef.getName()));
     }
     return _transformRawInput(iPart);
   }
 
-  protected PTFPartition _transformRawInput(PTFPartition iPart) throws HiveException
-  {
+  protected PTFPartition _transformRawInput(PTFPartition iPart) throws HiveException {
     return null;
   }
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/TableFunctionResolver.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/TableFunctionResolver.java
index 1aa8e04..969013c 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/TableFunctionResolver.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/TableFunctionResolver.java
@@ -18,7 +18,7 @@
 
 package org.apache.hadoop.hive.ql.udf.ptf;
 
-import java.util.ArrayList;
+import java.util.List;
 
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator;
@@ -27,7 +27,7 @@
 import org.apache.hadoop.hive.ql.parse.SemanticException;
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.PTFDesc;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionedTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFResolver;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 
@@ -53,8 +53,7 @@
  * </ol>
  */
 @SuppressWarnings("deprecation")
-public abstract class TableFunctionResolver
-{
+public abstract class TableFunctionResolver {
   TableFunctionEvaluator evaluator;
   PTFDesc ptfDesc;
 
@@ -65,8 +64,7 @@
    *   the transformsRawInput boolean.
    */
   public void initialize(HiveConf cfg, PTFDesc ptfDesc, PartitionedTableFunctionDef tDef)
-      throws SemanticException
-  {
+      throws SemanticException {
     this.ptfDesc = ptfDesc;
 
     evaluator = createEvaluator(ptfDesc, tDef);
@@ -79,16 +77,14 @@ public void initialize(HiveConf cfg, PTFDesc ptfDesc, PartitionedTableFunctionDe
    * called during deserialization of a QueryDef during runtime.
    */
   public void initialize(PTFDesc ptfDesc, PartitionedTableFunctionDef tDef, TableFunctionEvaluator evaluator)
-      throws HiveException
-  {
+      throws HiveException {
     this.evaluator = evaluator;
     this.ptfDesc = ptfDesc;
     evaluator.setTableDef(tDef);
     evaluator.setQueryDef(ptfDesc);
   }
 
-  public TableFunctionEvaluator getEvaluator()
-  {
+  public TableFunctionEvaluator getEvaluator() {
     return evaluator;
   }
 
@@ -105,7 +101,7 @@ public TableFunctionEvaluator getEvaluator()
    * A PTF Function must provide the 'external' names of the columns in its Output.
    *
    */
-  public abstract ArrayList<String> getOutputColumnNames() throws SemanticException;
+  public abstract List<String> getOutputColumnNames() throws SemanticException;
 
 
   /**
@@ -127,10 +123,8 @@ public TableFunctionEvaluator getEvaluator()
    * - subsequent to this call, a call to getRawInputOI call on the {@link TableFunctionEvaluator} must return the OI
    *   of the output of this function.
    */
-  public void setupRawInputOI() throws SemanticException
-  {
-    if (!transformsRawInput())
-    {
+  public void setupRawInputOI() throws SemanticException {
+    if (!transformsRawInput()) {
       return;
     }
     throw new SemanticException(
@@ -141,9 +135,8 @@ public void setupRawInputOI() throws SemanticException
    * A PTF Function must provide the 'external' names of the columns in the transformed Raw Input.
    *
    */
-  public ArrayList<String> getRawInputColumnNames() throws SemanticException {
-    if (!transformsRawInput())
-    {
+  public List<String> getRawInputColumnNames() throws SemanticException {
+    if (!transformsRawInput()) {
       return null;
     }
     throw new SemanticException(
@@ -153,10 +146,8 @@ public void setupRawInputOI() throws SemanticException
   /*
    * Same responsibility as initializeOI, but for the RawInput.
    */
-  public void initializeRawInputOI() throws HiveException
-  {
-    if (!transformsRawInput())
-    {
+  public void initializeRawInputOI() throws HiveException {
+    if (!transformsRawInput()) {
       return;
     }
     throw new HiveException(
@@ -166,21 +157,18 @@ public void initializeRawInputOI() throws HiveException
   /*
    * callback method used by subclasses to set the RawInputOI on the Evaluator.
    */
-  protected void setRawInputOI(StructObjectInspector rawInputOI)
-  {
+  protected void setRawInputOI(StructObjectInspector rawInputOI) {
     evaluator.setRawInputOI(rawInputOI);
   }
 
   /*
    * callback method used by subclasses to set the OutputOI on the Evaluator.
    */
-  protected void setOutputOI(StructObjectInspector outputOI)
-  {
+  protected void setOutputOI(StructObjectInspector outputOI) {
     evaluator.setOutputOI(outputOI);
   }
 
-  public PTFDesc getPtfDesc()
-  {
+  public PTFDesc getPtfDesc() {
     return ptfDesc;
   }
 
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/WindowingTableFunction.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/WindowingTableFunction.java
index 358c63e..110ef27 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/WindowingTableFunction.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/WindowingTableFunction.java
@@ -31,13 +31,13 @@
 import org.apache.hadoop.hive.ql.parse.WindowingSpec.BoundarySpec;
 import org.apache.hadoop.hive.ql.parse.WindowingSpec.Direction;
 import org.apache.hadoop.hive.ql.plan.PTFDesc;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.BoundaryDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PTFExpressionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.PartitionedTableFunctionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.ValueBoundaryDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowFrameDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowFunctionDef;
-import org.apache.hadoop.hive.ql.plan.PTFDesc.WindowTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.BoundaryDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PTFExpressionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.PartitionedTableFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.ValueBoundaryDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowFunctionDef;
+import org.apache.hadoop.hive.ql.plan.ptf.WindowTableFunctionDef;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.AggregationBuffer;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
-- 
1.7.0.4

