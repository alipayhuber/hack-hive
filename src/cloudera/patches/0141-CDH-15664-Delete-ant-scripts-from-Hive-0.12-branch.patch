From 2e10dd8652bd5a6fbee470161703eff981133fab Mon Sep 17 00:00:00 2001
From: Brock Noland <brock@cloudera.com>
Date: Tue, 12 Nov 2013 14:12:12 -0600
Subject: [PATCH 141/375] CDH-15664: Delete ant scripts from Hive 0.12 branch

---
 ant/build.xml                                      |   54 -
 ant/ivy.xml                                        |   32 -
 beeline/build.xml                                  |   52 -
 beeline/ivy.xml                                    |   55 -
 build-common.xml                                   |  584 --------
 build-offline.xml                                  |   37 -
 build.properties                                   |  171 ---
 build.xml                                          | 1488 --------------------
 cli/build.xml                                      |   52 -
 cli/ivy.xml                                        |   39 -
 common/build.xml                                   |   57 -
 common/ivy.xml                                     |   48 -
 contrib/build.xml                                  |  102 --
 contrib/ivy.xml                                    |   32 -
 data/conf/hive-log4j-old.properties                |   82 --
 data/conf/hive-site-old.xml                        |  197 ---
 eclipse-templates/.classpath                       |  131 --
 eclipse-templates/.classpath._hbase                |   76 -
 .../.externalToolBuilders/Hive_Ant_Builder.launch  |   40 -
 eclipse-templates/.project                         |   45 -
 .../.settings/org.eclipse.jdt.core.prefs           |  276 ----
 .../.settings/org.eclipse.jdt.ui.prefs             |  126 --
 eclipse-templates/BeeLine.launchtemplate           |   51 -
 eclipse-templates/HiveCLI.launchtemplate           |   50 -
 eclipse-templates/HiveServer.launchtemplate        |   50 -
 eclipse-templates/HiveServer2.launchtemplate       |   50 -
 eclipse-templates/TestBeeLineDriver.launchtemplate |   43 -
 eclipse-templates/TestCliDriver.launchtemplate     |   43 -
 .../TestEmbeddedHiveMetaStore.launchtemplate       |   43 -
 .../TestEmbeddedThriftCLIService.launchtemplate    |   43 -
 .../TestHBaseCliDriver.launchtemplate              |   43 -
 eclipse-templates/TestHive.launchtemplate          |   43 -
 .../TestHiveMetaStoreChecker.launchtemplate        |   43 -
 eclipse-templates/TestHiveMetaTool.launchtemplate  |   43 -
 eclipse-templates/TestHiveServer.launchtemplate    |   43 -
 eclipse-templates/TestJdbc.launchtemplate          |   44 -
 eclipse-templates/TestJdbc2.launchtemplate         |   44 -
 eclipse-templates/TestMTQueries.launchtemplate     |   43 -
 .../TestRemoteHiveMetaStore.launchtemplate         |   43 -
 .../TestRemoteThriftCLIService.launchtemplate      |   43 -
 eclipse-templates/TestTruncate.launchtemplate      |   43 -
 hbase-handler/build.xml                            |   82 --
 hbase-handler/ivy.xml                              |   45 -
 hcatalog/build-support/ant/deploy.xml              |  154 --
 hcatalog/build-support/ant/test.xml                |  111 --
 hcatalog/build.xml                                 |  529 -------
 hcatalog/core/build.xml                            |   42 -
 hcatalog/core/pom-old.xml                          |   85 --
 hcatalog/hcatalog-pig-adapter/build.xml            |   42 -
 hcatalog/hcatalog-pig-adapter/pom-old.xml          |   45 -
 hcatalog/ivy.xml                                   |   34 -
 hcatalog/pom-old.xml                               |  251 ----
 hcatalog/server-extensions/build.xml               |   41 -
 hcatalog/server-extensions/pom-old.xml             |   77 -
 hcatalog/src/test/e2e/hcatalog/build.xml           |  350 -----
 .../e2e/hcatalog/tools/generate/java/build.xml     |   76 -
 hcatalog/src/test/e2e/hcatalog/udfs/java/build.xml |   60 -
 hcatalog/src/test/e2e/templeton/build.xml          |  197 ---
 hcatalog/storage-handlers/hbase/build.xml          |  224 ---
 hcatalog/storage-handlers/hbase/pom-old.xml        |  115 --
 hcatalog/webhcat/java-client/build.xml             |   42 -
 hcatalog/webhcat/java-client/pom-old.xml           |   45 -
 hcatalog/webhcat/svr/build.xml                     |   63 -
 hcatalog/webhcat/svr/pom-old.xml                   |  110 --
 hwi/build.xml                                      |   75 -
 hwi/ivy.xml                                        |   40 -
 ivy.xml                                            |   54 -
 ivy/common-configurations.xml                      |   33 -
 ivy/ivysettings.xml                                |  106 --
 ivy/libraries.properties                           |   73 -
 jdbc/build.xml                                     |   63 -
 jdbc/ivy.xml                                       |   38 -
 maven-delete-ant.sh                                |   66 -
 maven-rollback.sh                                  |  149 --
 maven-rollforward.sh                               |  153 --
 metastore/build.xml                                |  134 --
 metastore/ivy.xml                                  |   53 -
 odbc/build.xml                                     |  122 --
 odbc/ivy.xml                                       |   34 -
 ql/build.xml                                       |  349 -----
 ql/ivy.xml                                         |   90 --
 serde/build.xml                                    |   69 -
 serde/ivy.xml                                      |   47 -
 service/build.xml                                  |   45 -
 service/ivy.xml                                    |   35 -
 shims/build.xml                                    |  184 ---
 shims/ivy.xml                                      |  195 ---
 testutils/build.xml                                |   24 -
 testutils/ivy.xml                                  |   34 -
 89 files changed, 0 insertions(+), 9709 deletions(-)
 delete mode 100644 ant/build.xml
 delete mode 100644 ant/ivy.xml
 delete mode 100644 beeline/build.xml
 delete mode 100644 beeline/ivy.xml
 delete mode 100644 build-common.xml
 delete mode 100644 build-offline.xml
 delete mode 100644 build.properties
 delete mode 100644 build.xml
 delete mode 100755 cli/build.xml
 delete mode 100644 cli/ivy.xml
 delete mode 100755 common/build.xml
 delete mode 100644 common/ivy.xml
 delete mode 100644 contrib/build.xml
 delete mode 100644 contrib/ivy.xml
 delete mode 100644 data/conf/hive-log4j-old.properties
 delete mode 100644 data/conf/hive-site-old.xml
 delete mode 100644 eclipse-templates/.classpath
 delete mode 100644 eclipse-templates/.classpath._hbase
 delete mode 100644 eclipse-templates/.externalToolBuilders/Hive_Ant_Builder.launch
 delete mode 100644 eclipse-templates/.project
 delete mode 100644 eclipse-templates/.settings/org.eclipse.jdt.core.prefs
 delete mode 100644 eclipse-templates/.settings/org.eclipse.jdt.ui.prefs
 delete mode 100644 eclipse-templates/BeeLine.launchtemplate
 delete mode 100644 eclipse-templates/HiveCLI.launchtemplate
 delete mode 100644 eclipse-templates/HiveServer.launchtemplate
 delete mode 100644 eclipse-templates/HiveServer2.launchtemplate
 delete mode 100644 eclipse-templates/TestBeeLineDriver.launchtemplate
 delete mode 100644 eclipse-templates/TestCliDriver.launchtemplate
 delete mode 100644 eclipse-templates/TestEmbeddedHiveMetaStore.launchtemplate
 delete mode 100644 eclipse-templates/TestEmbeddedThriftCLIService.launchtemplate
 delete mode 100644 eclipse-templates/TestHBaseCliDriver.launchtemplate
 delete mode 100644 eclipse-templates/TestHive.launchtemplate
 delete mode 100644 eclipse-templates/TestHiveMetaStoreChecker.launchtemplate
 delete mode 100644 eclipse-templates/TestHiveMetaTool.launchtemplate
 delete mode 100644 eclipse-templates/TestHiveServer.launchtemplate
 delete mode 100644 eclipse-templates/TestJdbc.launchtemplate
 delete mode 100644 eclipse-templates/TestJdbc2.launchtemplate
 delete mode 100644 eclipse-templates/TestMTQueries.launchtemplate
 delete mode 100644 eclipse-templates/TestRemoteHiveMetaStore.launchtemplate
 delete mode 100644 eclipse-templates/TestRemoteThriftCLIService.launchtemplate
 delete mode 100644 eclipse-templates/TestTruncate.launchtemplate
 delete mode 100644 hbase-handler/build.xml
 delete mode 100644 hbase-handler/ivy.xml
 delete mode 100644 hcatalog/build-support/ant/deploy.xml
 delete mode 100644 hcatalog/build-support/ant/test.xml
 delete mode 100644 hcatalog/build.xml
 delete mode 100644 hcatalog/core/build.xml
 delete mode 100644 hcatalog/core/pom-old.xml
 delete mode 100644 hcatalog/hcatalog-pig-adapter/build.xml
 delete mode 100644 hcatalog/hcatalog-pig-adapter/pom-old.xml
 delete mode 100644 hcatalog/ivy.xml
 delete mode 100644 hcatalog/pom-old.xml
 delete mode 100644 hcatalog/server-extensions/build.xml
 delete mode 100644 hcatalog/server-extensions/pom-old.xml
 delete mode 100644 hcatalog/src/test/e2e/hcatalog/build.xml
 delete mode 100644 hcatalog/src/test/e2e/hcatalog/tools/generate/java/build.xml
 delete mode 100644 hcatalog/src/test/e2e/hcatalog/udfs/java/build.xml
 delete mode 100644 hcatalog/src/test/e2e/templeton/build.xml
 delete mode 100644 hcatalog/storage-handlers/hbase/build.xml
 delete mode 100644 hcatalog/storage-handlers/hbase/pom-old.xml
 delete mode 100644 hcatalog/webhcat/java-client/build.xml
 delete mode 100644 hcatalog/webhcat/java-client/pom-old.xml
 delete mode 100644 hcatalog/webhcat/svr/build.xml
 delete mode 100644 hcatalog/webhcat/svr/pom-old.xml
 delete mode 100644 hwi/build.xml
 delete mode 100644 hwi/ivy.xml
 delete mode 100644 ivy.xml
 delete mode 100644 ivy/common-configurations.xml
 delete mode 100644 ivy/ivysettings.xml
 delete mode 100644 ivy/libraries.properties
 delete mode 100644 jdbc/build.xml
 delete mode 100644 jdbc/ivy.xml
 delete mode 100644 maven-delete-ant.sh
 delete mode 100644 maven-rollback.sh
 delete mode 100644 maven-rollforward.sh
 delete mode 100755 metastore/build.xml
 delete mode 100644 metastore/ivy.xml
 delete mode 100644 odbc/build.xml
 delete mode 100644 odbc/ivy.xml
 delete mode 100644 ql/build.xml
 delete mode 100644 ql/ivy.xml
 delete mode 100644 serde/build.xml
 delete mode 100644 serde/ivy.xml
 delete mode 100644 service/build.xml
 delete mode 100644 service/ivy.xml
 delete mode 100644 shims/build.xml
 delete mode 100644 shims/ivy.xml
 delete mode 100644 testutils/build.xml
 delete mode 100644 testutils/ivy.xml

diff --git a/src/ant/build.xml b/src/ant/build.xml
deleted file mode 100644
index e982e3d..0000000
--- a/src/ant/build.xml
+++ /dev/null
@@ -1,54 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-
-<!--
-Before you can run these subtargets directly, you need
-to call at top-level: ant deploy-contrib compile-core-test
--->
-<project name="anttasks" default="jar">
-
-  <property name="src.dir"  location="${basedir}/src"/>
-  <import file="../build-common.xml"/>
-
-  <target name="compile" depends="init,ivy-retrieve">
-    <echo message="${ant.project.name}"/>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${src.dir}"
-     includes="**/*.java"
-     destdir="${build.classes}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     debug="${javac.debug}"
-     deprecation="${javac.deprecation}">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="classpath"/>
-    </javac>
-  </target>
-
-  <target name="jar" depends="compile">
-    <echo message="${ant.project.name}"/>
-    <copy file="${src.dir}/org/apache/hadoop/hive/ant/antlib.xml"
-          todir="${build.dir}/classes/org/apache/hadoop/hive/ant"/>
-    <jar destfile="${build.dir}/hive-anttasks-${version}.jar">
-      <fileset dir="${build.dir}/classes"/>
-    </jar>
-  </target>
-</project>
diff --git a/src/ant/ivy.xml b/src/ant/ivy.xml
deleted file mode 100644
index 0fe0a23..0000000
--- a/src/ant/ivy.xml
+++ /dev/null
@@ -1,32 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-anttasks" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <dependency org="commons-lang" name="commons-lang" rev="${commons-lang.version}"/>
-    <dependency org="velocity" name="velocity" rev="${velocity.version}" transitive="false"/>
-  </dependencies>
-</ivy-module>
diff --git a/src/beeline/build.xml b/src/beeline/build.xml
deleted file mode 100644
index b356204..0000000
--- a/src/beeline/build.xml
+++ /dev/null
@@ -1,52 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-
-<!-- 
-Before you can run these subtargets directly, you need 
-to call at top-level: ant deploy-contrib compile-core-test
--->
-<project name="beeline" default="jar">
-
-  <property name="src.dir"  location="${basedir}/src/java"/>
-  <import file="../build-common.xml"/>
-
-  <target name="compile" depends="init, setup, ivy-retrieve">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${src.dir}"
-     includes="**/*.java"
-     destdir="${build.classes}"
-     debug="${javac.debug}"
-     deprecation="${javac.deprecation}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     includeantruntime="false">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="classpath"/>
-    </javac>
-    <copy todir="${build.classes}" failonerror="false">
-      <fileset dir="${src.dir}">
-        <include name="**/*.properties"/>
-      </fileset>
-    </copy>
-  </target>
-
-</project>
diff --git a/src/beeline/ivy.xml b/src/beeline/ivy.xml
deleted file mode 100644
index cdded26..0000000
--- a/src/beeline/ivy.xml
+++ /dev/null
@@ -1,55 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-beeline" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <!-- Runtime Dependencies -->
-
-    <dependency org="commons-cli" name="commons-cli" rev="${commons-cli.version}"/>
-    <dependency org="commons-io" name="commons-io" rev="${commons-io.version}" />
-    <dependency org="commons-lang" name="commons-lang" rev="${commons-lang.version}"/>
-    <dependency org="commons-logging" name="commons-logging" rev="${commons-logging.version}"
-                transitive="false"/>
-    <dependency org="commons-logging" name="commons-logging-api" rev="${commons-logging-api.version}"
-                transitive="false"/>
-    <dependency org="jline" name="jline" rev="${jline.version}"
-                transitive="false"/>
-    <dependency org="org.apache.thrift" name="libthrift" rev="${libthrift.version}"
-                transitive="false"/>
-
-    <dependency org="org.apache.hive" name="hive-service" rev="${version}"
-                conf="compile->default" />
-    <dependency org="org.apache.hive" name="hive-shims" rev="${version}"
-                conf="runtime" transitive="false"/>
-    
-    <!-- Test Dependencies -->
-    <dependency org="junit" name="junit"
-                rev="${junit.version}" conf="test->default" />
-    <dependency org="org.mockito" name="mockito-all"
-                rev="${mockito-all.version}" conf="test->default" />
-  </dependencies>
-</ivy-module>
diff --git a/src/build-common.xml b/src/build-common.xml
deleted file mode 100644
index 3aaa9b0..0000000
--- a/src/build-common.xml
+++ /dev/null
@@ -1,584 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-
-<project xmlns:ivy="antlib:org.apache.ivy.ant"
-         xmlns:artifact="urn:maven-artifact-ant"
-         name="hivecommon" default="jar">
-
-  <property name="hive.root" location="${basedir}/.."/>
-  <property file="${hive.root}/build.properties"/>
-  <property file="${user.home}/build.properties" />
-  <property file="${basedir}/build.properties" />
-
-  <property environment="env"/>
-
-  <property name="hive.conf.dir" value="${hive.root}/conf"/>
-  <property name="dist.dir" location="${hive.root}"/>
-
-  <property name="build.dir.hive" location="${hive.root}/build"/>
-  <property name="build.dir.hadoop" location="${build.dir.hive}/hadoopcore"/>
-  <property name="build.dir" location="${build.dir.hive}/${ant.project.name}"/>
-  <property name="build.classes" location="${build.dir}/classes"/>
-  <property name="build.encoding" value="ISO-8859-1"/>
-
-  <!-- Thrift codegen properties -->
-  <property name="thrift.args" value="-I ${thrift.home} --gen java:beans,hashcode --gen cpp --gen php --gen py --gen rb"/>
-  <property name="thrift.gen.dir" value="${basedir}/src/gen/thrift"/>
-
-  <property name="hadoop.conf.dir" location="${hadoop.root}/conf"/>
-
-  <!-- configuration needed for tests -->
-  <property name="test.src.dir" value="${basedir}/src/test"/>
-  <property name="test.src.data.dir" value="${hive.root}/data"/>
-  <property name="test.resources.dir" value="${basedir}/src/test/resources"/>
-  <property name="test.build.dir" value="${build.dir}/test"/>
-  <property name="test.log.dir" value="${test.build.dir}/logs"/>
-  <property name="test.data.dir" value="${test.build.dir}/data"/>
-  <property name="test.build.src" value="${test.build.dir}/src"/>
-  <property name="test.build.classes" value="${test.build.dir}/classes"/>
-  <property name="test.build.resources" value="${test.build.dir}/resources"/>
-  <property name="test.include" value="Test*"/>
-  <property name="test.classpath.id" value="test.classpath"/>
-  <property name="test.output" value="true"/>
-  <property name="test.junit.output.format" value="xml"/>
-  <property name="test.junit.output.usefile" value="true"/>
-  <property name="minimr.query.files" value="list_bucket_dml_10.q,input16_cc.q,scriptfile1.q,scriptfile1_win.q,bucket4.q,bucketmapjoin6.q,disable_merge_for_bucketing.q,reduce_deduplicate.q,smb_mapjoin_8.q,join1.q,groupby2.q,bucketizedhiveinputformat.q,bucketmapjoin7.q,optrstat_groupby.q,bucket_num_reducers.q,bucket5.q,load_fs2.q,bucket_num_reducers2.q,infer_bucket_sort_merge.q,infer_bucket_sort_reducers_power_two.q,infer_bucket_sort_dyn_part.q,infer_bucket_sort_bucketed_table.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_num_buckets.q,leftsemijoin_mr.q,schemeAuthority.q,schemeAuthority2.q,truncate_column_buckets.q,remote_script.q,,load_hdfs_file_with_space_in_the_name.q,parallel_orderby.q,import_exported_table.q"/>
-  <property name="minimr.query.negative.files" value="cluster_tasklog_retrieval.q,minimr_broken_pipe.q,mapreduce_stack_trace.q,mapreduce_stack_trace_turnoff.q,mapreduce_stack_trace_hadoop20.q,mapreduce_stack_trace_turnoff_hadoop20.q" />
-  <property name="test.silent" value="true"/>
-  <property name="hadoopVersion" value="${hadoop.version.ant-internal}"/>
-  <property name="test.serialize.qplan" value="false"/>
-  <property name="test.print.classpath" value="false"/>
-  <property name="test.lang" value="en_US.UTF-8"/>
-
-  <property name="hadoop.opts.23" value="-D mapreduce.framework.name=local" />
-  <property name="hadoop.opts.20" value="" />
-
-  <condition property="test.halt.on.failure" value="no" else="yes">
-    <equals arg1="${test.continue.on.failure}" arg2="true"/>
-  </condition>
-
-  <target name="set-test-classpath">
-    <typedef name="distinctelementsclasspath" classname="org.apache.hadoop.hive.ant.DistinctElementsClassPath"
-      classpath="${build.dir.hive}/anttasks/hive-anttasks-${version}.jar:${build.ivy.lib.dir}/default/commons-collections-${commons-collections.version}.jar:${build.ivy.lib.dir}/default/commons-lang-${commons-lang.version}.jar"/>
-    <distinctelementsclasspath id="test.classpath">
-      <pathelement location="${test.build.classes}" />
-      <pathelement location="${test.build.resources}" />
-      <pathelement location="" />
-      <pathelement location="${test.src.data.dir}/conf"/>
-      <pathelement location="${hive.conf.dir}"/>
-      <pathelement location="${build.dir.hive}/beeline/test/classes"/>
-      <pathelement location="${build.dir.hive}/cli/test/classes"/>
-      <pathelement location="${build.dir.hive}/common/test/classes"/>
-      <pathelement location="${build.dir.hive}/hbase-handler/test/classes"/>
-      <pathelement location="${build.dir.hive}/hwi/test/classes"/>
-      <pathelement location="${build.dir.hive}/jdbc/test/classes"/>
-      <pathelement location="${build.dir.hive}/metastore/test/classes"/>
-      <pathelement location="${build.dir.hive}/hcatalog/test/classes"/>
-      <pathelement location="${build.dir.hive}/ql/test/classes"/>
-      <pathelement location="${build.dir.hive}/serde/test/classes"/>
-      <pathelement location="${build.dir.hive}/service/test/classes"/>
-      <pathelement location="${build.dir.hive}/shims/test/classes"/>
-
-      <!-- Include build/dist/lib on the classpath before Ivy and exclude hive jars from Ivy to make sure we get the local changes when we test Hive -->
-      <fileset dir="${build.dir.hive}/dist/lib" includes="*.jar" erroronmissingdir="false" excludes="**/hive_contrib*.jar,**/hive-contrib*.jar,**/lib*.jar"/>
-      <fileset dir="${hive.root}/testlibs" includes="*.jar"/>
-      <fileset dir="${build.ivy.lib.dir}/hadoop0.${hadoop.mr.rev}.shim" includes="*.jar" erroronmissingdir="false" />
-      <pathelement location="${build.classes}" />
-
-      <!-- test directory may contain hadoop jars used by tests only (e.g. mini cluster) -->
-      <fileset dir="${hive.root}/build/ivy/lib/test" includes="*.jar" erroronmissingdir="false"
-               excludes="**/hive_*.jar,**/hive-*.jar"/>
-      <fileset dir="${hive.root}/build/ivy/lib/test" includes="hive-testutils*.jar" Erroronmissingdir="false"/>
-
-      <!-- we strip out hadoop jars present in places other than the hadoop shimmed dir-->
-      <fileset dir="${hive.root}/build/ivy/lib/default" includes="*.jar" erroronmissingdir="false"
-               excludes="**/hive_*.jar,**/hive-*.jar,**/hadoop-*.jar" />
-    </distinctelementsclasspath>
-  </target>
-
-  <!-- include contrib on local classpath, but not on cluster -->
-  <!-- https://reviews.facebook.net/D2133#comment-47 -->
-  <path id="test.local.classpath">
-    <path refid="${test.classpath.id}"/>
-    <fileset dir="${hive.root}/build/ivy/lib/test" includes="hive-contrib*.jar" erroronmissingdir="false"/>
-  </path>
-
-
-  <loadproperties srcfile="${ivy.conf.dir}/libraries.properties"/>
-
-  <osfamily property="os.family"/>
-
-  <condition property="offline">
-    <istrue value="${is-offline}"/>
-  </condition>
-  <import file="build-offline.xml"/>
-
-  <!--this is the naming policy for artifacts we want pulled down-->
-  <property name="ivy.artifact.retrieve.pattern" value="[conf]/[artifact]-[revision](-[classifier]).[ext]"/>
-
-  <target name="ivy-init-settings">
-    <!--Configure Ivy by reading in the settings file
-        If anyone has already read in a settings file into this settings ID, it gets priority
-    -->
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:settings id="${ant.project.name}.ivy.settings" file="${ivysettings.xml}"/>
-  </target>
-
-  <target name="ivy-resolve" depends="ivy-init-settings" unless="offline">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings"
-      conf="default" log="${ivyresolvelog}"/>
-    <ivy:report todir="${build.ivy.report.dir}" settingsRef="${ant.project.name}.ivy.settings"
-                graph="false" />
-  </target>
-
-  <target name="ivy-retrieve" depends="ivy-resolve"
-    description="Retrieve Ivy-managed artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
-      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"
-      log="${ivyresolvelog}"/>
-  </target>
-
-  <target name="ivy-resolve-test" depends="ivy-init-settings" unless="offline">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings"
-      conf="test" log="${ivyresolvelog}"/>
-  </target>
-
-  <target name="ivy-retrieve-test" depends="ivy-resolve-test"
-    description="Retrieve Ivy-managed artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
-      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"
-      log="${ivyresolvelog}" conf="test"/>
-  </target>
-
-  <target name="ivy-resolve-hadoop-shim" depends="ivy-init-settings" unless="offline">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings"
-      conf="${ivy.hadoop.shim.conf}" log="${ivyresolvelog}"/>
-  </target>
-
-  <target name="ivy-retrieve-hadoop-shim" depends="ivy-resolve-hadoop-shim"
-    description="Retrieve Ivy-managed artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
-      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"
-      log="${ivyresolvelog}" conf="${ivy.hadoop.shim.conf}"/>
-  </target>
-
-  <!-- the normal classpath -->
-  <path id="common-classpath">
-    <pathelement location="${build.dir.hive}/classes"/>
-    <fileset dir="${build.dir.hive}" includes="*/*.jar"/>
-    <fileset dir="${hive.root}/lib" includes="*.jar"/>
-    <fileset dir="${build.ivy.lib.dir}/default" includes="junit*.jar" />
-    <fileset dir="${build.ivy.lib.dir}/hadoop0.${hadoop.mr.rev}.shim" includes="*.jar" erroronmissingdir="false" />
-    <fileset dir="${build.ivy.lib.dir}/default" includes="*.jar"
-             excludes="**/hadoop-*.jar"
-             erroronmissingdir="false"/>
-  </path>
-
-  <path id="classpath">
-    <pathelement location="${build.dir.hive}/service/classes"/>
-    <pathelement location="${build.dir.hive}/common/classes"/>
-    <pathelement location="${build.dir.hive}/serde/classes"/>
-    <pathelement location="${build.dir.hive}/metastore/classes"/>
-    <pathelement location="${build.dir.hive}/hcatalog/classes"/>
-    <pathelement location="${build.dir.hive}/ql/classes"/>
-    <pathelement location="${build.dir.hive}/beeline/classes"/>
-    <pathelement location="${build.dir.hive}/cli/classes"/>
-    <pathelement location="${build.dir.hive}/shims/classes"/>
-    <pathelement location="${build.dir.hive}/hwi/classes"/>
-    <pathelement location="${build.dir.hive}/jdbc/classes"/>
-    <pathelement location="${build.dir.hive}/hbase-handler/classes"/>
-    <fileset dir="${basedir}" includes="lib/*.jar"/>
-    <path refid="common-classpath"/>
-  </path>
-
-  <target name="create-dirs">
-    <echo message="Project: ${ant.project.name}"/>
-    <mkdir dir="${build.dir.hive}"/>
-    <mkdir dir="${build.dir}"/>
-    <mkdir dir="${build.classes}"/>
-    <mkdir dir="${build.dir.hive}/jexl/classes"/>
-    <mkdir dir="${build.dir.hadoop}"/>
-    <mkdir dir="${test.build.dir}"/>
-    <mkdir dir="${test.build.src}"/>
-    <mkdir dir="${test.build.classes}"/>
-    <mkdir dir="${test.build.resources}"/>
-    <copy todir="${test.build.resources}" failonerror="false">
-      <fileset dir="${test.resources.dir}"/>
-    </copy>
-  </target>
-
-  <target name="init" depends="create-dirs">
-    <echo message="Project: ${ant.project.name}"/>
-  </target>
-
-  <target name="test-init" depends="set-test-classpath">
-    <echo message="Project: ${ant.project.name}"/>
-    <mkdir dir="${test.data.dir}"/>
-    <mkdir dir="${test.log.dir}/clientpositive"/>
-    <mkdir dir="${test.log.dir}/beelinepositive"/>
-    <mkdir dir="${test.log.dir}/clientnegative"/>
-    <mkdir dir="${test.log.dir}/positive"/>
-    <mkdir dir="${test.log.dir}/negative"/>
-    <mkdir dir="${test.data.dir}/warehouse"/>
-    <mkdir dir="${test.data.dir}/metadb"/>
-  </target>
-
-  <target name="setup">
-    <echo message="Project: ${ant.project.name}"/>
-  </target>
-
-  <target name="compile" depends="init, setup, ivy-retrieve">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${src.dir}"
-     includes="**/*.java"
-     destdir="${build.classes}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     debug="${javac.debug}"
-     deprecation="${javac.deprecation}"
-     includeantruntime="false">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="classpath"/>
-    </javac>
-    <copy todir="${build.classes}" failonerror="false">
-      <fileset dir="${src.dir}/conf"/>
-    </copy>
-  </target>
-
-  <target name="jar" depends="make-pom,compile">
-    <echo message="Project: ${ant.project.name}" />
-    <jar
-      jarfile="${build.dir}/hive-${ant.project.name}-${version}.jar"
-      basedir="${build.classes}">
-      <manifest>
-        <!-- Not putting these in their own manifest section, since that inserts
-        a new-line, which breaks the reading of the attributes. -->
-        <attribute name="Implementation-Title" value="Hive"/>
-        <attribute name="Implementation-Version" value="${version}"/>
-        <attribute name="Implementation-Vendor" value="Apache"/>
-      </manifest>
-      <metainf dir="${hive.root}" includes="LICENSE,NOTICE"/>
-    </jar>
-    <ivy:publish settingsRef="${ant.project.name}.ivy.settings"
-                 resolver="local" pubrevision="${version}" overwrite="true"
-                 artifactspattern="${build.dir}/${ivy.publish.pattern}"/>
-  </target>
-
-  <!-- target to compile tests -->
-  <target name="compile-test" depends="compile,ivy-retrieve-test,set-test-classpath">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${test.src.dir}"
-     includes="org/apache/**/hive/**/*.java"
-     destdir="${test.build.classes}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     debug="${javac.debug}"
-     optimize="${javac.optimize}"
-     deprecation="${javac.deprecation}"
-     includeantruntime="false">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="test.classpath"/>
-    </javac>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${test.build.src}"
-     includes="org/apache/**/hive/**/*.java"
-     destdir="${test.build.classes}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     debug="${javac.debug}"
-     optimize="${javac.optimize}"
-     deprecation="${javac.deprecation}"
-     includeantruntime="false">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="test.classpath"/>
-    </javac>
-    <!-- Generate a classpath to have YARN use downloaded dependencies. -->
-    <property name="mrapp-classpath" refid="test.classpath" />
-    <echo file="${test.build.classes}/mrapp-generated-classpath" message="${mrapp-classpath}" />
-  </target>
-
-  <target name="test-jar" depends="compile-test">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete file="${test.build.dir}/test-udfs.jar"/>
-    <jar jarfile="${test.build.dir}/test-udfs.jar">
-        <fileset dir="${test.build.classes}" includes="**/udf/*.class"/>
-        <fileset dir="${test.build.classes}" includes="**/udf/generic/*.class"/>
-    </jar>
-    <delete file="${test.build.dir}/test-serdes.jar"/>
-    <jar jarfile="${test.build.dir}/test-serdes.jar">
-        <fileset dir="${test.build.classes}" includes="**/serde2/*.class" excludes="**/serde2/TestSerDe.class"/>
-    </jar>  	
-    <delete file="${test.build.dir}/TestSerDe.jar"/>
-    <jar jarfile="${test.build.dir}/TestSerDe.jar">
-        <fileset dir="${test.build.classes}" includes="**/serde2/TestSerDe.class"/>
-    </jar>
-    <delete file="${test.build.classes}/org/apache/hadoop/hive/serde2/TestSerDe.class"/> 
-  </target>
-
-  <target name="test-conditions">
-    <echo message="Project: ${ant.project.name}"/>
-    <condition property="qfile" value="">
-      <not>
-        <isset property="qfile"/>
-      </not>
-    </condition>
-
-    <condition property="qfile_regex" value="">
-      <not>
-        <isset property="qfile_regex"/>
-      </not>
-    </condition>
-
-    <condition property="qfile_negative_regex" value="">
-      <not>
-        <isset property="qfile_negative_regex"/>
-      </not>
-    </condition>
-
-    <condition property="overwrite" value="false">
-      <not>
-        <isset property="overwrite"/>
-      </not>
-    </condition>
-
-    <condition property="standalone" value="false">
-      <not>
-        <isset property="standalone"/>
-      </not>
-    </condition>
-
-    <condition property="disableserver" value="false">
-      <not>
-        <isset property="disableserver"/>
-      </not>
-    </condition>
-    
-    <condition property="clustermode" value="">
-      <not>
-        <isset property="clustermode"/>
-      </not>
-    </condition>
-
-    <condition property="run_disabled" value="false">
-      <not>
-        <isset property="run_disabled"/>
-      </not>
-    </condition>
-
-  </target>
-
-
-  <target name="gen-test">
-    <echo message="Project: ${ant.project.name}"/>
-  </target>
-
-  <!-- use pfile:/// as warehouse file system in 20 for non miniMR runs -->
-  <condition property="test.warehouse.scheme" value="pfile://" else="">
-    <not>
-      <equals arg1="${clustermode}" arg2="miniMR" />
-    </not>
-  </condition>
-
-  <property name="test.warehouse.dir" value="${test.warehouse.scheme}${build.dir}/test/data/warehouse"/>
-  <property name="mapred.job.tracker" value="local"/>
-  <property name="fs.default.name" value="file:///"/>
-
-  <!-- target to run the tests -->
-  <target name="test"
-    depends="test-conditions,gen-test,compile-test,test-jar,test-init">
-    <antcall target="testonly" />
-  </target>
-
-  <target name="testonly" depends="test-conditions,test-init">
-    <echo message="Project: ${ant.project.name}"/>
-    <property name="hadoop.testcp" refid="test.classpath"/>
-    <if>
-      <equals arg1="${hadoop.mr.rev}" arg2="23" />
-      <then>
-        <property name="hadoop.opts" value="${hadoop.opts.23}" />
-        <property name="test.dfs.mkdir" value="-mkdir -p"/>
-      </then>
-      <else>
-        <property name="hadoop.opts" value="${hadoop.opts.20}" />
-        <property name="test.dfs.mkdir" value="-mkdir"/>
-      </else>
-    </if>
-    <!-- Set the OS specific settings to run junit tests on unix as well as on windows -->
-    <if>
-      <equals arg1="windows" arg2="${os.family}"/>
-      <then>
-        <property name="junit.script.extension" value=".cmd"/>
-      </then>
-      <else>
-        <property name="junit.script.extension" value=""/>
-      </else>
-    </if>
-    <if>
-      <equals arg1="${test.print.classpath}" arg2="true" />
-      <then>
-        <echo message="Test Classpath: ${hadoop.testcp}"/>
-      </then>
-    </if>
-
-    <junit showoutput="${test.output}" printsummary="yes" haltonfailure="${test.halt.on.failure}"
-           fork="yes" maxmemory="${test.junit.maxmemory}" dir="${basedir}" timeout="${test.junit.timeout}"
-           errorProperty="tests.failed" failureProperty="tests.failed" filtertrace="off">
-      <jvmarg value="-XX:+HeapDumpOnOutOfMemoryError"/>
-      <jvmarg value="-XX:HeapDumpPath=${hive.root}"/>
-      <env key="LANG" value="${test.lang}"/>
-      <env key="HIVE_HADOOP_TEST_CLASSPATH" value="${hadoop.testcp}"/>
-      <env key="HADOOP_HOME" value="${hadoop.root}"/>
-      <env key="HADOOP_CLASSPATH" path="${test.src.data.dir}/conf:${build.dir.hive}/dist/lib/derby-${derby.version}.jar:${build.dir.hive}/dist/lib/JavaEWAH-${javaewah.version}.jar:${hadoop.root}/modules/*"/> <!-- Modules needed for Hadoop 0.23 -->
-      <env key="TZ" value="US/Pacific"/>
-      <sysproperty key="test.output.overwrite" value="${overwrite}"/>
-      <sysproperty key="test.dfs.mkdir" value="${test.dfs.mkdir}"/>
-      <sysproperty key="test.service.standalone.server" value="${standalone}"/>
-      <sysproperty key="test.service.disable.server" value="${disableserver}"/>
-      <sysproperty key="log4j.configuration" value="file:///${test.src.data.dir}/conf/hive-log4j.properties"/>
-      <sysproperty key="derby.stream.error.file" value="${test.build.dir}/derby.log"/>
-      <sysproperty key="hive.aux.jars.path" value="file:///${test.build.dir}/test-udfs.jar"/>
-      <sysproperty key="ql.test.query.clientpositive.dir" value="${ql.test.query.clientpositive.dir}"/>
-      <sysproperty key="ql.test.results.clientpositive.dir" value="${ql.test.results.clientpositive.dir}"/>
-      <sysproperty key="test.log.dir" value="${test.log.dir}"/>
-      <sysproperty key="hadoop.log.dir" value="${test.log.dir}"/>
-      <sysproperty key="test.silent" value="${test.silent}"/>
-      <sysproperty key="test.tmp.dir" value="${build.dir}/tmp"/>
-      <sysproperty key="test.src.data.dir" value="${test.src.data.dir}"/>
-      <sysproperty key="test.warehouse.dir" value="${test.warehouse.dir}"/>
-      <sysproperty key="test.build.resources" value="${test.build.resources}"/>
-      <sysproperty key="mapred.job.tracker" value="${mapred.job.tracker}"/>
-      <sysproperty key="fs.default.name" value="${fs.default.name}"/>
-      <sysproperty key="build.dir" value="${build.dir}"/>
-      <sysproperty key="build.dir.hive" value="${build.dir.hive}"/>
-      <sysproperty key="build.ivy.lib.dir" value="${build.ivy.lib.dir}"/>
-      <sysproperty key="derby.version" value="${derby.version}"/>
-      <sysproperty key="hive.root" value="${hive.root}"/>
-      <sysproperty key="hive.version" value="${version}"/>
-      <sysproperty key="java.net.preferIPv4Stack" value="${java.net.preferIPv4Stack}"/>
-      <sysproperty key="hadoop.bin.path" value="${test.hadoop.bin.path}${junit.script.extension}"/>
-      <sysproperty key="test.concurrency.num.threads" value="${test.concurrency.num.threads}"/>
-      <sysproperty key="hive.home" value="${hive.root}/build/dist"/>
-      <sysproperty key="qfile" value="${qfile}"/>
-      <jvmarg line="${junit.jvm.args}"/>
-
-      <classpath refid="test.local.classpath"/>
-      <formatter type="${test.junit.output.format}" usefile="${test.junit.output.usefile}" />
-      <batchtest todir="${test.build.dir}" unless="testcase">
-        <fileset dir="${test.build.classes}"
-                 includes="**/${test.include}.class"
-                 excludes="**/TestSerDe.class,**/TestHiveMetaStore.class,**/TestBeeLineDriver.class,**/TestHiveServer2Concurrency.class,**/*$*.class,${test.junit.exclude}" />
-      </batchtest>
-      <batchtest todir="${test.build.dir}" if="testcase">
-        <fileset dir="${test.build.classes}" includes="**/${testcase}.class"/>
-      </batchtest>
-      <assertions>
-        <enable />
-      </assertions>
-    </junit>
-    <fail if="tests.failed">Tests failed!</fail>
-  </target>
-
-  <target name="clean-test">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete dir="${test.build.dir}"/>
-    <delete dir="${build.dir.hive}/ql/tmp"/>
-    <delete dir="${build.dir.hive}/test"/>
-  </target>
-
-  <target name="clean">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete dir="${build.dir}"/>
-  </target>
-
-  <target name="check-thrift-home">
-    <echo message="Project: ${ant.project.name}"/>
-    <condition property="thrift.home.defined">
-      <or>
-        <not>
-          <isset property="thrift.home"/>
-        </not>
-        <equals arg1="${thrift.home}" arg2="$${thrift.home}" trim="true"/>
-      </or>
-    </condition>
-  </target>
-
-  <target name="thriftif" depends="check-thrift-home">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete dir="${thrift.gen.dir}"/>
-    <mkdir dir="${thrift.gen.dir}"/>
-    <for param="thrift.file">
-      <path>
-        <fileset dir="." includes="if/*.thrift,if/test/*.thrift" />
-      </path>
-      <sequential>
-        <echo message="Generating Thrift code for @{thrift.file}"/>
-        <exec executable="${thrift.home}/bin/thrift"  failonerror="true" dir=".">
-          <arg line="${thrift.args} -I ${basedir}/include -I ${basedir}/.. -o ${thrift.gen.dir} @{thrift.file} " />
-        </exec>
-      </sequential>
-    </for>
-  </target>
-  
-  <target name="check-ivy" depends="ivy-init-settings">
-    <echo message="Project: ${ant.project.name}"/>
-    <available file="${basedir}/ivy.xml" property="ivy.present"/>
-  </target>
-
-  <target name="make-pom" if="ivy.present" depends="check-ivy,ivy-resolve">
-    <echo message="Project: ${ant.project.name}"/>
-    <echo> Writing POM to ${build.dir}/pom.xml</echo>
-
-    <ivy:makepom ivyfile="${basedir}/ivy.xml" pomfile="${build.dir}/pom.xml">
-      <mapping conf="default" scope="compile" />
-      <mapping conf="runtime" scope="compile" />
-      <mapping conf="compile" scope="compile" />
-    </ivy:makepom>
-    <replace file="${build.dir}/pom.xml">
-      <replacetoken>&lt;dependencies&gt;</replacetoken>
-      <replacevalue>
-        &lt;description&gt;Hive is a data warehouse infrastructure built on top of Hadoop see
-        http://wiki.apache.org/hadoop/Hive &lt;/description&gt;
-        &lt;licenses&gt;
-        &lt;license&gt;
-        &lt;name&gt;The Apache Software License, Version 2.0&lt;/name&gt;
-        &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt;
-        &lt;distribution&gt;repo&lt;/distribution&gt;
-        &lt;/license&gt;
-        &lt;/licenses&gt;
-        &lt;scm&gt;
-        &lt;url&gt;http://svn.apache.org/repos/asf/hive/&lt;/url&gt;
-        &lt;/scm&gt;
-        &lt;dependencies&gt;
-      </replacevalue>
-    </replace>
-  </target>
-
-</project>
diff --git a/src/build-offline.xml b/src/build-offline.xml
deleted file mode 100644
index e3bfad7..0000000
--- a/src/build-offline.xml
+++ /dev/null
@@ -1,37 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-<!-- common imports for ivy offline mode -->
-<project name="hiveoffline">
-  <condition property="ivy.cache.name" value="offline" else="online">
-    <isset property="offline"/>
-  </condition>
-  <condition property="ivy.checkmodified" value="false" else="true">
-    <isset property="offline"/>
-  </condition>
-  <condition property="ivy.changingPattern" value="" else=".*SNAPSHOT">
-    <isset property="offline"/>
-  </condition>
-  <condition property="ivy.skip">
-    <and>
-      <isset property="offline"/>
-      <available file="${build.dir.hadoop}/hadoop-${hadoop.version.ant-internal}.installed"/>
-    </and>
-  </condition>
-</project>
diff --git a/src/build.properties b/src/build.properties
deleted file mode 100644
index 9b404a9..0000000
--- a/src/build.properties
+++ /dev/null
@@ -1,171 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one
-# or more contributor license agreements.  See the NOTICE file
-# distributed with this work for additional information
-# regarding copyright ownership.  The ASF licenses this file
-# to you under the Apache License, Version 2.0 (the
-# "License"); you may not use this file except in compliance
-# with the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-Name=Hive
-name=hive
-shortversion=0.12.0-cdh5.0.0
-version=${shortversion}-SNAPSHOT
-hcatalog.version=${version}
-year=2012
-
-javac.debug=on
-javac.version=1.6
-javac.optimize=on
-javac.deprecation=off
-javac.args=
-javac.args.warnings=
-
-hadoop-0.20.version=0.20.2
-hadoop-0.20S.version=1.1.2
-hadoop-0.23.version=2.1.0-beta
-hadoop.version=${hadoop-0.20.version}
-hadoop.security.version=${hadoop-0.20S.version}
-# Used to determine which set of Hadoop artifacts we depend on.
-# - 20: hadoop-core, hadoop-test
-# - 23: hadoop-common, hadoop-mapreduce-*, etc
-hadoop.mr.rev=20S
-
-build.dir.hive=${hive.root}/build
-build.dir.hadoop=${build.dir.hive}/hadoopcore
-
-
-hadoop.version.ant-internal=${hadoop.version}
-hadoop.root.default=${build.dir.hadoop}/hadoop-${hadoop.version.ant-internal}
-hadoop.root=${hadoop.root.default}
-test.hadoop.bin.path=${hive.root}/testutils/hadoop
-java.net.preferIPv4Stack=true
-
-# Newer versions of Hadoop name the jar as hadoop-{core,test}-VERSION instead of hadoop-VERSION-{core,test}
-# We will add both styles to the classpath and it will pick up whichever is there
-hadoop.oldstyle-name.jar=${hadoop.root}/hadoop-${hadoop.version.ant-internal}-core.jar
-hadoop.oldstyle-name.tools.jar=${hadoop.root}/hadoop-${hadoop.version.ant-internal}-tools.jar
-hadoop.oldstyle-name.test.jar=${hadoop.root}/hadoop-${hadoop.version.ant-internal}-test.jar
-hadoop.newstyle-name.jar=${hadoop.root}/hadoop-core-${hadoop.version.ant-internal}.jar
-hadoop.newstyle-name.test.jar=${hadoop.root}/hadoop-test-${hadoop.version.ant-internal}.jar
-hadoop.newstyle-name.tools.jar=${hadoop.root}/hadoop-tools-${hadoop.version.ant-internal}.jar
-# The following are used for versions of Hadoop that are broken into separate jars
-# They are ignored if not present
-hadoop.common.jar=${hadoop.root}/share/hadoop/common/hadoop-common-${hadoop.version.ant-internal}.jar
-hadoop.common.test.jar=${hadoop.root}/share/hadoop/common/hadoop-common-${hadoop.version.ant-internal}-tests.jar
-hadoop.hdfs.jar=${hadoop.root}/share/hadoop/hdfs/hadoop-hdfs-${hadoop.version.ant-internal}.jar
-hadoop.hdfs.test.jar=${hadoop.root}/share/hadoop/hdfs/hadoop-hdfs-${hadoop.version.ant-internal}-tests.jar
-hadoop.mapreduce.jar=${hadoop.root}/modules/hadoop-mapreduce-client-core-${hadoop.version.ant-internal}.jar
-hadoop.mapreduce.test.jar=${hadoop.root}/hadoop-mapreduce-test-${hadoop.version.ant-internal}.jar
-hadoop.mapreduce.tools.jar=${hadoop.root}/hadoop-mapreduce-tools-${hadoop.version.ant-internal}.jar
-
-jetty.test.jar=${hadoop.root}/lib/jetty-5.1.4.jar
-servlet.test.jar=${hadoop.root}/lib/servlet-api.jar
-jasper.test.jar=${hadoop.root}/lib/jetty-ext/jasper-runtime.jar
-jasperc.test.jar=${hadoop.root}/lib/jetty-ext/jasper-compiler.jar
-jsp.test.jar=${hadoop.root}/lib/jetty-ext/jsp-api.jar
-common.jar=${hadoop.root}/lib/commons-httpclient-3.0.1.jar
-
-# module names needed for build process
-
-# full profile
-iterate.hive.full.all=ant,shims,common,serde,metastore,ql,contrib,service,cli,jdbc,beeline,hwi,hbase-handler,testutils,hcatalog
-iterate.hive.full.modules=shims,common,serde,metastore,ql,contrib,service,cli,jdbc,beeline,hwi,hbase-handler,testutils,hcatalog
-iterate.hive.full.tests=common,ql,contrib,hbase-handler,hwi,jdbc,beeline,metastore,odbc,serde,service,hcatalog
-iterate.hive.full.thrift=ql,service,metastore,serde
-iterate.hive.full.protobuf=ql
-iterate.hive.full.cpp=odbc
-
-# no hcatalog profile
-iterate.hive.nohcat.all=ant,shims,common,serde,metastore,ql,contrib,service,cli,jdbc,beeline,hwi,hbase-handler,testutils
-iterate.hive.nohcat.modules=shims,common,serde,metastore,ql,contrib,service,cli,jdbc,beeline,hwi,hbase-handler,testutils
-iterate.hive.nohcat.tests=ql,contrib,hbase-handler,hwi,jdbc,beeline,metastore,odbc,serde,service
-iterate.hive.nohcat.thrift=common,ql,service,metastore,serde
-iterate.hive.nohcat.protobuf=ql
-iterate.hive.nohcat.cpp=odbc
-
-# core profile
-iterate.hive.core.all=ant,shims,common,serde,metastore,ql,cli
-iterate.hive.core.modules=shims,common,serde,metastore,ql,cli
-iterate.hive.core.tests=ql
-iterate.hive.core.thrift=ql
-iterate.hive.core.protobuf=ql
-iterate.hive.core.cpp=
-
-#
-# Test Properties
-#
-
-# Cancel the individual tests if they don't finish in the given time
-# (measured in milliseconds). Ignored if fork is disabled. When running
-# multiple tests inside the same Java VM (see forkMode), timeout
-# applies to the time that all tests use together, not to an individual test.
-test.junit.timeout=86400000
-
-# Use this property to selectively disable tests from the command line:
-# ant test -Dtest.junit.exclude="**/TestCliDriver.class"
-# ant test -Dtest.junit.exclude="**/Test*CliDriver.class,**/TestPartitions.class"
-test.junit.exclude=
-
-test.continue.on.failure=true
-
-test.submodule.exclude=
-test.junit.maxmemory=512m
-
-test.concurrency.num.threads=1
-#test.beelinepositive.exclude=add_part_exist.q,alter1.q,alter2.q,alter4.q,alter5.q,alter_rename_partition.q,alter_rename_partition_authorization.q,archive.q,archive_corrupt.q,archive_multi.q,archive_mr_1806.q,archive_multi_mr_1806.q,authorization_1.q,authorization_2.q,authorization_4.q,authorization_5.q,authorization_6.q,authorization_7.q,ba_table1.q,ba_table2.q,ba_table3.q,ba_table_udfs.q,binary_table_bincolserde.q,binary_table_colserde.q,cluster.q,columnarserde_create_shortcut.q,combine2.q,constant_prop.q,create_nested_type.q,create_or_replace_view.q,create_struct_table.q,create_union_table.q,database.q,database_location.q,database_properties.q,ddltime.q,describe_database_json.q,drop_database_removes_partition_dirs.q,escape1.q,escape2.q,exim_00_nonpart_empty.q,exim_01_nonpart.q,exim_02_00_part_empty.q,exim_02_part.q,exim_03_nonpart_over_compat.q,exim_04_all_part.q,exim_04_evolved_parts.q,exim_05_some_part.q,exim_06_one_part.q,exim_07_all_part_over_nonoverlap.q,exim_08_nonpart_rename.q,exim_09_part_spec_nonoverlap.q,exim_10_external_managed.q,exim_11_managed_external.q,exim_12_external_location.q,exim_13_managed_location.q,exim_14_managed_location_over_existing.q,exim_15_external_part.q,exim_16_part_external.q,exim_17_part_managed.q,exim_18_part_external.q,exim_19_00_part_external_location.q,exim_19_part_external_location.q,exim_20_part_managed_location.q,exim_21_export_authsuccess.q,exim_22_import_exist_authsuccess.q,exim_23_import_part_authsuccess.q,exim_24_import_nonexist_authsuccess.q,global_limit.q,groupby_complex_types.q,groupby_complex_types_multi_single_reducer.q,index_auth.q,index_auto.q,index_auto_empty.q,index_bitmap.q,index_bitmap1.q,index_bitmap2.q,index_bitmap3.q,index_bitmap_auto.q,index_bitmap_rc.q,index_compact.q,index_compact_1.q,index_compact_2.q,index_compact_3.q,index_stale_partitioned.q,init_file.q,input16.q,input16_cc.q,input46.q,input_columnarserde.q,input_dynamicserde.q,input_lazyserde.q,input_testxpath3.q,input_testxpath4.q,insert2_overwrite_partitions.q,insertexternal1.q,join_thrift.q,lateral_view.q,load_binary_data.q,load_exist_part_authsuccess.q,load_nonpart_authsuccess.q,load_part_authsuccess.q,loadpart_err.q,lock1.q,lock2.q,lock3.q,lock4.q,merge_dynamic_partition.q,multi_insert.q,multi_insert_move_tasks_share_dependencies.q,null_column.q,ppd_clusterby.q,query_with_semi.q,rename_column.q,sample6.q,sample_islocalmode_hook.q,set_processor_namespaces.q,show_tables.q,source.q,split_sample.q,str_to_map.q,transform1.q,udaf_collect_set.q,udaf_context_ngrams.q,udaf_histogram_numeric.q,udaf_ngrams.q,udaf_percentile_approx.q,udf_array.q,udf_bitmap_and.q,udf_bitmap_or.q,udf_explode.q,udf_format_number.q,udf_map.q,udf_map_keys.q,udf_map_values.q,udf_max.q,udf_min.q,udf_named_struct.q,udf_percentile.q,udf_printf.q,udf_sentences.q,udf_sort_array.q,udf_split.q,udf_struct.q,udf_substr.q,udf_translate.q,udf_union.q,udf_xpath.q,udtf_stack.q,view.q,virtual_column.q
-
-
-
-#
-# Ivy Properties
-#
-build.ivy.dir=${build.dir.hive}/ivy
-build.ivy.lib.dir=${build.ivy.dir}/lib
-build.ivy.report.dir=${build.ivy.dir}/report
-build.ivy.maven.dir=${build.ivy.dir}/maven
-ivy.conf.dir=${hive.root}/ivy
-ivy.version=2.3.0
-ivy.jar=${build.ivy.lib.dir}/ivy-${ivy.version}.jar
-ivy.changingPattern=.*SNAPSHOT
-ivy.publish.pattern=[artifact]-[revision].[ext]
-ivy.artifact.retrieve.pattern=[conf]/[artifact]-[revision](-[classifier]).[ext]
-ivysettings.xml=${ivy.conf.dir}/ivysettings.xml
-ivyresolvelog=default
-ivy.mvn.repo=http://repo2.maven.org/maven2
-ivy_repo_url=${ivy.mvn.repo}/org/apache/ivy/ivy/${ivy.version}/ivy-${ivy.version}.jar
-hive.ivy.org=org.apache.hive
-mvn.publish.repo=snapshots
-mvn.jar.dir=${build.dir.hive}/maven/jars
-mvn.pom.dir=${build.dir.hive}/maven/poms
-mvn.license.dir=${build.dir.hive}/maven/licenses
-mvn.deploy.id=apache.snapshots.https
-mvn.deploy.url=https://repository.apache.org/content/repositories/snapshots
-mvn.staging.repo.id=apache.staging.https
-mvn.staging.repo.url=https://repository.apache.org/service/local/staging/deploy/maven2
-
-#
-# Data nucleus repository - needed for jdo2-api-2.3-ec.jar download
-#
-datanucleus.repo=http://www.datanucleus.org/downloads/maven2
-
-# JVM arguments
-jvm.args=-XX:-UseSplitVerifier
-
-# junit jvm args
-junit.jvm.args=-XX:-UseSplitVerifier -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=128M
-
-#
-# Eclipse Properties
-#
-
-# JVM arguments for Eclipse launch configurations
-eclipse.launch.jvm.args=-Xms256m -Xmx1024m ${jvm.args}
-
diff --git a/src/build.xml b/src/build.xml
deleted file mode 100644
index d846ee3..0000000
--- a/src/build.xml
+++ /dev/null
@@ -1,1488 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-
-<project name="hive" default="jar"
-         xmlns:ivy="antlib:org.apache.ivy.ant"
-         xmlns:artifact="urn:maven-artifact-ant"
-         xmlns:rat="antlib:org.apache.rat.anttasks"
-         xmlns:maven="antlib:org.apache.maven.artifact.ant">
-
-  <property name="hive.root" location="${basedir}"/>
-  <property file="${hive.root}/build.properties"/>
-  <property file="${user.home}/build.properties" />
-  <property file="${basedir}/build.properties" />
-  <loadproperties srcfile="${ivy.conf.dir}/libraries.properties"/>
-
-  <property environment="env"/>
-
-  <property name="target.dir" location="${build.dir.hive}/dist"/>
-  <property name="target.lib.dir" location="${target.dir}/lib"/>
-  <property name="target.conf.dir" location="${target.dir}/conf"/>
-  <property name="target.bin.dir" location="${target.dir}/bin"/>
-  <property name="target.scripts.dir" location="${target.dir}/scripts"/>
-  <property name="target.example.dir" location="${target.dir}/examples"/>
-  <property name="ql.test.query.dir" location="${basedir}/ql/src/test/queries"/>
-  <property name="test.data.dir" location="${basedir}/data"/>
-  <property name="test.build.dir" value="${build.dir.hive}/test"/>
-  <property name="test.continue.on.failure" value="true"/>
-  <property name="build.docs" value="${target.dir}/docs"/>
-  <property name="build.javadoc" value="${build.docs}/api"/>
-  <property name="docs.src" value="${hive.root}/docs"/>
-  <property name="anakia.docs.src" value="${docs.src}/xdocs"/>
-  <property name="anakia.docs.dest" value="${target.dir}/docs"/>
-  <property name="images.src" value="${docs.src}/images"/>
-  <property name="javadoc.link.java"
-            value="http://java.sun.com/javase/6/docs/api/"/>
-  <property name="sourceJavaVersion" value="${javac.version}" />
-  <property name="targetJavaVersion" value="${javac.version}" />
-  <property name="final.name" value="${name}-${version}"/>
-  <property name="tar.final.name" value="${final.name}"/>
-  <property name="bin.final.name" value="${final.name}-bin"/>
-  <property name="vcs.excludes" value="**/.svn,**/.svn/**,**/.git,**/.git/**"/>
-  <property name="checkstyle.conf.dir" location="${hive.root}/checkstyle"/>
-  <property name="checkstyle.build.dir" location="${build.dir.hive}/checkstyle"/>
-  <property name="rat.build.dir" location="${build.dir.hive}/rat"/>
-  <property name="md5sum.format" value="{0}  {1}"/>
-
-  <taskdef resource="net/sf/antcontrib/antcontrib.properties">
-    <classpath>
-      <pathelement location="${hive.root}/testlibs/ant-contrib-1.0b3.jar"/>
-    </classpath>
-  </taskdef>
-
-  <if>
-    <equals arg1="${build.profile}" arg2="core"/>
-    <then>
-      <property name="iterate.hive.all" value="${iterate.hive.core.all}"/>
-      <property name="iterate.hive.modules" value="${iterate.hive.core.modules}"/>
-      <property name="iterate.hive.tests" value="${iterate.hive.core.tests}"/>
-      <property name="iterate.hive.thrift" value="${iterate.hive.core.thrift}"/>
-      <property name="iterate.hive.protobuf" value="${iterate.hive.core.protobuf}"/>
-      <property name="iterate.hive.cpp" value="${iterate.hive.core.cpp}"/>
-    </then>
-  </if>
-
-  <if>
-    <equals arg1="${build.profile}" arg2="nohcat"/>
-    <then>
-      <property name="iterate.hive.all" value="${iterate.hive.nohcat.all}"/>
-      <property name="iterate.hive.modules" value="${iterate.hive.nohcat.modules}"/>
-      <property name="iterate.hive.tests" value="${iterate.hive.nohcat.tests}"/>
-      <property name="iterate.hive.thrift" value="${iterate.hive.nohcat.thrift}"/>
-      <property name="iterate.hive.protobuf" value="${iterate.hive.nohcat.protobuf}"/>
-      <property name="iterate.hive.cpp" value="${iterate.hive.nohcat.cpp}"/>
-    </then>
-  </if>
-
-  <if>
-    <or>
-      <equals arg1="${build.profile}" arg2="full"/>
-      <not><isset property="build.profile"/></not>
-    </or>
-    <then>
-      <property name="iterate.hive.all" value="${iterate.hive.full.all}"/>
-      <property name="iterate.hive.modules" value="${iterate.hive.full.modules}"/>
-      <property name="iterate.hive.tests" value="${iterate.hive.full.tests}"/>
-      <property name="iterate.hive.thrift" value="${iterate.hive.full.thrift}"/>
-      <property name="iterate.hive.protobuf" value="${iterate.hive.full.protobuf}"/>
-      <property name="iterate.hive.cpp" value="${iterate.hive.full.cpp}"/>
-    </then>
-  </if>
-
-  <!-- Check minimum ant version required -->
-  <fail message="Please use ant version 1.8.0 or greater for building hive.">
-    <condition>
-      <not>
-        <antversion atleast="1.8.0"/>
-      </not>
-    </condition>
-  </fail>
-
-  <condition property="is-offline" value="true" else="false">
-    <isset property="offline"/>
-  </condition>
-
-  <import file="build-offline.xml"/>
-
-  <condition property="staging">
-    <equals arg1="${mvn.publish.repo}" arg2="staging"/>
-  </condition>
-
-  <condition property="test.halt.on.failure" value="no" else="yes">
-    <equals arg1="${test.continue.on.failure}" arg2="true"/>
-  </condition>
-
-  <taskdef resource="net/sf/antcontrib/antcontrib.properties">
-    <classpath>
-      <pathelement location="${hive.root}/testlibs/ant-contrib-1.0b3.jar"/>
-    </classpath>
-  </taskdef>
-
-  <!-- ForTask is not defined in net/sf/antcontrib/antcontrib.properties! -->
-  <taskdef name="for" classname="net.sf.antcontrib.logic.ForTask">
-    <classpath>
-      <pathelement location="${hive.root}/testlibs/ant-contrib-1.0b3.jar"/>
-    </classpath>
-  </taskdef>
-  
-  <!-- ====================================================== -->
-  <!-- Macro definitions                                      -->
-  <!-- ====================================================== -->
-  <macrodef name="macro_tar" description="Worker Macro for tar">
-    <attribute name="param.destfile"/>
-    <element name="param.listofitems"/>
-    <sequential>
-      <tar compression="gzip" longfile="gnu" destfile="@{param.destfile}">
-      <param.listofitems/>
-      </tar>
-      <checksum file="@{param.destfile}" algorithm="md5" pattern="${md5sum.format}"/>
-    </sequential>
-  </macrodef>
-
-  <macrodef name="iterate">
-    <attribute name="target"/>
-    <attribute name="iterate"/>
-    <sequential>
-      <if>
-        <isset property="module"/>
-        <then> <var name="target.module" value="${module}"/>  </then>
-        <else> <var name="target.module" value="@{iterate}"/> </else>
-      </if>
-      <for list="${target.module}" param="module">
-        <sequential>
-          <subant buildpath="@{module}/build.xml" target="@{target}">
-            <property name="is-offline" value="${is-offline}"/>
-            <property name="thrift.home" value="${thrift.home}"/>
-            <property name="build.dir.hive" location="${build.dir.hive}"/>
-            <property name="sourceJavaVersion" value="${sourceJavaVersion}" />
-            <property name="targetJavaVersion" value="${targetJavaVersion}" />
-          </subant>
-        </sequential>
-      </for>
-    </sequential>
-  </macrodef>
-
-  <!-- the normal classpath -->
-  <path id="common-classpath">
-    <pathelement location="${hadoop.oldstyle-name.jar}"/>
-    <pathelement location="${hadoop.newstyle-name.jar}"/>
-    <pathelement location="${hadoop.common.jar}"/>
-    <pathelement location="${hadoop.hdfs.jar}"/>
-    <pathelement location="${hadoop.mapreduce.jar}"/>
-    <pathelement location="${build.dir.hive}/classes"/>
-    <fileset dir="${hive.root}" includes="hive-*.jar"/>
-    <fileset dir="${hive.root}/lib" includes="*.jar"/>
-    <fileset dir="${build.dir.hive}/ivy/lib/default" includes="*.jar"
-	excludes="*hadoop*.jar" erroronmissingdir="false"/>
-  </path>
-
-  <path id="classpath">
-    <pathelement location="${build.dir.hive}/common/classes"/>
-    <pathelement location="${build.dir.hive}/serde/classes"/>
-    <pathelement location="${build.dir.hive}/metastore/classes"/>
-    <pathelement location="${build.dir.hive}/hcatalog/classes"/>
-    <pathelement location="${build.dir.hive}/ql/classes"/>
-    <pathelement location="${build.dir.hive}/cli/classes"/>
-    <pathelement location="${build.dir.hive}/beeline/classes"/>
-    <fileset dir="${hive.root}/data" includes="files/*.jar"/>
-    <fileset dir="${hive.root}/ql" includes="lib/*.jar"/>
-    <fileset dir="${hive.root}/cli" includes="lib/*.jar"/>
-    <fileset dir="${hive.root}/service" includes="lib/*.jar"/>
-    <path refid="common-classpath"/>
-  </path>
-
-  <target name="ivy-init-settings">
-    <!--Configure Ivy by reading in the settings file
-        If anyone has already read in a settings file into this settings ID, it gets priority
-    -->
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:settings id="${ant.project.name}.ivy.settings" file="${ivysettings.xml}"/>
-  </target>
-  
-  <target name="ivy-init-dirs">
-    <echo message="Project: ${ant.project.name}"/>
-    <mkdir dir="${build.ivy.dir}" />
-    <mkdir dir="${build.ivy.lib.dir}" />
-    <mkdir dir="${build.ivy.report.dir}" />
-    <mkdir dir="${build.ivy.maven.dir}" />
-  </target>
-
-  <target name="ivy-probe-antlib" >
-    <echo message="Project: ${ant.project.name}"/>
-    <condition property="ivy.found">
-      <typefound uri="antlib:org.apache.ivy.ant" name="cleancache"/>
-    </condition>
-  </target>
-
-  <target name="ivy-download" depends="ivy-init-dirs"
-          description="To download ivy" unless="offline">
-    <echo message="Project: ${ant.project.name}"/>
-    <get src="${ivy_repo_url}" dest="${ivy.jar}" usetimestamp="true"/>
-  </target>
-  
-  <!--
-  To avoid Ivy leaking things across big projects, always load Ivy in the same classloader.
-  Also note how we skip loading Ivy if it is already there, just to make sure all is well.
-  -->
-  <target name="ivy-init-antlib" depends="ivy-download,ivy-init-dirs,ivy-probe-antlib" unless="ivy.found">
-    <echo message="Project: ${ant.project.name}"/>
-    <typedef uri="antlib:org.apache.ivy.ant" onerror="fail" loaderRef="ivyLoader" resource="org/apache/ivy/ant/antlib.xml">
-      <classpath>
-        <pathelement location="${ivy.jar}"/>
-      </classpath>
-    </typedef>
-    <fail>
-      <condition>
-        <not>
-          <typefound uri="antlib:org.apache.ivy.ant" name="cleancache"/>
-        </not>
-      </condition>
-      You need Apache Ivy 2.1 or later from http://ant.apache.org/
-      It could not be loaded from ${ivy_repo_url}
-    </fail>
-  </target>
-
-  <target name="ivy-clean-cache" depends="ivy-init-antlib"
-          description="Clean the Ivy cache">
-    <ivy:cleancache />
-  </target>
-
-  <target name="init" depends="ivy-init-antlib,deploy-ant-tasks">
-    <echo message="Project: ${ant.project.name}"/>
-    <iterate target="init" iterate="${iterate.hive.all}"/>
-  </target>
-
-  <target name="test-init">
-    <echo message="Project: ${ant.project.name}"/>
-    <iterate target="test-init" iterate="${iterate.hive.all}"/>
-  </target>
-
-  <!-- target to deploy anttasks -->
-  <target name="compile-ant-tasks">
-    <echo message="Project: ${ant.project.name}"/>
-    <subant target="compile">
-      <fileset dir="." includes="ant/build.xml"/>
-      <property name="sourceJavaVersion" value="${sourceJavaVersion}"/>
-      <property name="targetJavaVersion" value="${targetJavaVersion}"/>
-    </subant>
-  </target>
-
-  <target name="deploy-ant-tasks" depends="compile-ant-tasks">
-    <echo message="Project: ${ant.project.name}"/>
-    <subant target="jar">
-      <fileset dir="." includes="ant/build.xml"/>
-    </subant>
-    <taskdef name="getversionpref" classname="org.apache.hadoop.hive.ant.GetVersionPref"
-             classpath="${build.dir.hive}/anttasks/hive-anttasks-${version}.jar"/>
-  </target>
-
-  
-  <target name="compile-cpp"
-          depends="init"
-          description="Build CPP artifacts" >
-    <echo message="Project: ${ant.project.name}"/>
-    <fail unless="thrift.home">
-      You must set thrift.home to the absolute path of your
-      local Thrift installation.
-    </fail>
-    <iterate target="compile-cpp" iterate="${iterate.hive.cpp}"/>
-  </target>
-
-  <target name="compile-cpp-clean"
-          description="Clean CPP artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <iterate target="clean" iterate="${iterate.hive.cpp}"/>
-  </target>
-
-  <target name="compile" depends="compile-cpp">
-    <echo message="Project: ${ant.project.name}"/>
-    <iterate target="compile" iterate="${iterate.hive.modules}"/>
-  </target>
-
-  <target name="thriftif">
-    <echo message="Project: ${ant.project.name}"/>
-    <iterate target="thriftif" iterate="${iterate.hive.thrift}"/>
-  </target>
-
-  <target name="protobuf">
-    <echo message="Project: ${ant.project.name}"/>
-    <iterate target="protobuf" iterate="${iterate.hive.protobuf}"/>
-  </target>
-
-  <target name="jar"
-          depends="init"
-          description="Build JAR artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <iterate target="jar" iterate="${iterate.hive.modules}"/>
-  </target>
-
-  <target name="gen-test" depends="jar" description="Generate tests">
-    <iterate target="gen-test" iterate="${iterate.hive.tests}"/>
-  </target>
-  
-  <target name="jar-test" depends="gen-test"
-          description="Build Java test artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <iterate target="compile-test" iterate="${iterate.hive.tests}"/>
-  </target>
-
-  <target name="test" depends="clean-test,jar-test" description="Run tests">
-    <property name="test.target.name" value="test"/>
-    <antcall target="testonly" />
-  </target>
-
-
-
-  <!-- target to run the tests -->
-  <target name="testonly">
-    <if>
-      <not><isset property="test.target.name"/></not>
-      <then><property name="test.target.name" value="testonly"/></then>
-    </if>
-    <echo message="Project: ${ant.project.name}"/>
-    <if>
-      <or>
-      <isset property="module"/>
-      <equals arg1="${test.target.name}" arg2="testonly"/>
-      </or>
-      <else>
-        <antcall target="test-shims">
-          <param name="hadoop.version.ant-internal" value="${hadoop.security.version}" />
-        </antcall>
-      </else>
-    </if>
-    <condition property="target.module" value="${module}" else="${iterate.hive.tests}">
-      <isset property="module"/>
-    </condition>
-    <for keepgoing="${test.continue.on.failure}" list="${target.module}" param="module">
-      <sequential>
-        <ant antfile="@{module}/build.xml" target="${test.target.name}" inheritAll="false" inheritRefs="true">
-          <property name="build.dir.hive" location="${build.dir.hive}"/>
-          <property name="is-offline" value="${is-offline}"/>
-          <property name="sourceJavaVersion" value="${sourceJavaVersion}" />
-          <property name="targetJavaVersion" value="${targetJavaVersion}" />
-        </ant>
-      </sequential>
-    </for>
-  </target>
-
-  <target name="test-shims">
-    <echo message="Project: ${ant.project.name}"/>
-    <subant target="test" failonerror="${test.halt.on.failure}">
-      <property name="hadoop.version" value="${hadoop.security.version}"/>
-      <property name="hadoop.security.version" value="${hadoop.security.version}"/>
-      <fileset dir="${hive.root}/shims" includes="build.xml"/>
-    </subant>
-  </target>
-
-  <!-- create an html report from junit output files -->
-  <target name="testreport"
-          description="Generate JUnit HTML test report">
-    <echo message="Project: ${ant.project.name}"/>
-    <mkdir dir="${test.build.dir}"/>
-    <junitreport todir="${test.build.dir}">
-      <fileset dir="${build.dir.hive}">
-        <include name="**/TEST-*.xml"/>
-      </fileset>
-      <report format="noframes" todir="${test.build.dir}"/>
-    </junitreport>
-  </target>
-
-  <target name="clean-test"
-          description="Clean test results">
-    <echo message="Project: ${ant.project.name}"/>
-    <iterate target="clean-test" iterate="${iterate.hive.modules}"/>
-    <delete dir="${build.dir.hive}/test"/>
-    <delete dir="${hive.root}/ql/TempStatsStore"/>
-  </target>
-
-  <target name="clean"
-          description="Clean build artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <iterate target="clean" iterate="${iterate.hive.all}"/>
-    <iterate target="clean" iterate="${iterate.hive.cpp}"/>
-    <delete dir="${target.dir}"/>
-    <antcall target="clean-online"/>
-    <antcall target="clean-offline"/>
-  </target>
-
-  <target name="clean-online" unless="offline">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete dir="${build.dir.hive}"/>
-  </target>
-
-  <target name="clean-offline" if="offline">
-    <echo message="Project: ${ant.project.name}"/>
-    <!-- preserve the downloaded ivy .jar  -->
-    <delete quiet="true" includeemptydirs="true">
-      <fileset dir="${build.dir.hive}" excludes="ivy/**/ivy*.jar"/>
-    </delete>
-  </target>
-
-  <target name="very-clean" unless="offline" depends="clean,ivy-clean-cache"
-          description="Clean build artifacts and flush Ivy cache" />
-
-
-  <target name="package-cpp"
-          depends="package,compile-cpp"
-          description="Deploy CPP artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <mkdir dir="${target.dir}/include"/>
-    <copy todir="${target.dir}/include" preservelastmodified="true" flatten="true">
-      <fileset file="${build.dir.hive}/odbc/include/*"/>
-    </copy>
-    <copy todir="${target.lib.dir}" preservelastmodified="true" flatten="true">
-      <fileset file="${build.dir.hive}/odbc/lib/*" excludes="*.so"/>
-    </copy>
-    <symlink link="${target.lib.dir}/libhiveclient.so" resource="libhiveclient.so.1.0.0"/>
-
-  </target>
-
-  <target name="package"
-          depends="jar"
-          description="Deploy JAR artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <echo message="Deploying Hive jars to ${target.dir}"/>
-    <mkdir dir="${target.dir}"/>
-    <mkdir dir="${target.lib.dir}"/>
-    <mkdir dir="${target.conf.dir}"/>
-    <mkdir dir="${target.bin.dir}"/>
-    <mkdir dir="${target.scripts.dir}/metastore/upgrade"/>
-    <mkdir dir="${target.example.dir}"/>
-    <mkdir dir="${target.example.dir}/files"/>
-    <mkdir dir="${target.example.dir}/queries"/>
-    <mkdir dir="${target.lib.dir}/py"/>
-    <mkdir dir="${target.lib.dir}/php"/>
-    <copy file="${hive.root}/bin/hive" todir="${target.bin.dir}"/>
-    <copy file="${hive.root}/bin/metatool" todir="${target.bin.dir}"/>
-    <copy file="${hive.root}/bin/schematool" todir="${target.bin.dir}"/>
-    <copy file="${hive.root}/bin/beeline" todir="${target.bin.dir}"/>
-    <copy file="${hive.root}/bin/hiveserver2" todir="${target.bin.dir}"/>
-    <copy file="${hive.root}/bin/hive-config.sh" todir="${target.bin.dir}"/>
-    <copy todir="${target.bin.dir}/ext">
-      <fileset dir="${hive.root}/bin/ext" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy todir="${target.scripts.dir}/metastore/upgrade">
-      <fileset dir="${hive.root}/metastore/scripts/upgrade" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy file="${basedir}/conf/hive-default.xml.template" todir="${target.conf.dir}">
-      <filterset>
-        <filter token="VERSION" value="${version}"/>
-      </filterset>
-    </copy>
-    <copy todir="${target.conf.dir}">
-     <fileset dir="${basedir}/conf">
-       <include name="*.template"/>
-     </fileset>
-    </copy>
-    <copy file="${basedir}/common/src/java/conf/hive-log4j.properties"
-          tofile="${target.conf.dir}/hive-log4j.properties.template"/>
-    <copy file="${basedir}/ql/src/java/conf/hive-exec-log4j.properties"
-          tofile="${target.conf.dir}/hive-exec-log4j.properties.template"/>
-      
-    <!-- Create php thrift package -->
-    <copy todir="${target.lib.dir}/php">
-     <fileset dir="${hive.root}/service/lib/php" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy todir="${target.lib.dir}/php/packages/serde">
-      <fileset dir="${hive.root}/serde/src/gen/thrift/gen-php" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy todir="${target.lib.dir}/php/packages/hive_metastore">
-      <fileset dir="${hive.root}/metastore/src/gen/thrift/gen-php" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy todir="${target.lib.dir}/php/packages/hive_service">
-      <fileset dir="${hive.root}/service/src/gen/thrift/gen-php" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy todir="${target.lib.dir}/php/packages/queryplan">
-      <fileset dir="${hive.root}/ql/src/gen/thrift/gen-php" excludes="${vcs.excludes}"/>
-    </copy>
-
-
-    <!-- Create the python thrift package -->
-    <copy todir="${target.lib.dir}/py">
-      <fileset dir="${hive.root}/service/lib/py" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy todir="${target.lib.dir}/py/hive_serde">
-      <fileset dir="${hive.root}/serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy todir="${target.lib.dir}/py/hive_metastore">
-      <fileset dir="${hive.root}/metastore/src/gen/thrift/gen-py/hive_metastore" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy todir="${target.lib.dir}/py/hive_service">
-      <fileset dir="${hive.root}/service/src/gen/thrift/gen-py/hive_service" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy todir="${target.lib.dir}/py/TCLIService">
-      <fileset dir="${hive.root}/service/src/gen/thrift/gen-py/TCLIService" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy todir="${target.lib.dir}/py/queryplan">
-      <fileset dir="${hive.root}/ql/src/gen/thrift/gen-py/queryplan" excludes="${vcs.excludes}"/>
-    </copy>
-
-    <!-- copy jar files -->
-    <copy todir="${target.lib.dir}" preservelastmodified="true" flatten="true">
-      <fileset dir="${hive.root}"  >
-        <include name="*/*.jar"/>
-        <include name="*/*/*.jar"/>
-        <exclude name="**/TestSerDe.jar"/>
-        <exclude name="build/hadoopcore/*.jar"/>
-        <exclude name="**/ant-contrib*.jar"/>
-        <exclude name="**/hive-anttasks*.jar"/>
-        <exclude name="**/hive-testutils*.jar"/>
-      </fileset>
-      <fileset file="${build.dir.hive}/beeline/hive-beeline-${version}.jar" erroronmissingdir="false"/>
-      <fileset file="${build.dir.hive}/cli/hive-cli-${version}.jar" erroronmissingdir="false"/>
-      <fileset file="${build.dir.hive}/common/hive-common-${version}.jar" erroronmissingdir="false"/>
-      <fileset file="${build.dir.hive}/ql/hive-exec-${version}.jar" erroronmissingdir="false"/>
-      <fileset file="${build.dir.hive}/metastore/hive-metastore-${version}.jar" erroronmissingdir="false"/>
-      <fileset file="${build.dir.hive}/hwi/hive-hwi-${version}.war" erroronmissingdir="false"/>
-      <fileset file="${build.dir.hive}/contrib/hive-contrib-${version}.jar" erroronmissingdir="false"/>
-      <fileset dir="${build.dir.hive}/ivy/lib/default">
-        <include name="*.jar"/>
-        <exclude name="*.tar.gz"/>
-        <exclude name="hadoop-*.jar" />
-        <exclude name="**/*high-scale-lib-*"/>
-        <exclude name="**/hamcrest-core-*jar"/>
-        <exclude name="**/junit*.jar"/>
-        <exclude name="**/kryo*.jar"/>
-        <exclude name="**/asm*.jar"/>
-        <exclude name="**/mockito*.jar"/>
-        <exclude name="**/velocity*.jar"/>
-        <exclude name="**/antlr-3*.jar"/>
-      </fileset>
-    </copy>
-    <copy todir="${target.example.dir}/files" preservelastmodified="true" flatten="true">
-      <fileset dir="${test.data.dir}/files" includes="*.*" excludes="${vcs.excludes}"/>
-    </copy>
-    <copy file="${basedir}/README.txt" todir="${target.dir}">
-      <filterset>
-        <filter token="VERSION" value="${version}"/>
-      </filterset>
-    </copy>
-    <copy file="${basedir}/NOTICE" todir="${target.dir}"/>
-    <copy file="${basedir}/LICENSE" todir="${target.dir}"/>
-    <copy file="${basedir}/RELEASE_NOTES.txt" todir="${target.dir}"/>
-    <copy todir="${target.example.dir}/queries" preservelastmodified="true" flatten="true">
-      <fileset dir="${ql.test.query.dir}/positive" includes="*.q" excludes="${vcs.excludes}"/>
-    </copy>
-    <chmod perm="ugo+x" type="file" parallel="false">
-      <fileset dir="${target.bin.dir}"/>
-    </chmod>
-
-    <!-- Package the hcat stuff and pull it up into Hive's build dir -->
-    <if>
-      <matches string="${iterate.hive.all}" pattern="hcatalog"/>
-      <then>
-        <ant antfile="${hive.root}/hcatalog/build.xml" target="package"
-          inheritAll="false"/>
-        <mkdir dir="${target.dir}/hcatalog"/>
-        <copy todir="${target.dir}/hcatalog">
-          <fileset dir="${hive.root}/hcatalog/build/hcatalog-${hcatalog.version}"/>
-        </copy>
-      </then>
-    </if>
-    <!--fix permissions since 'copy' looses them (known ant/Java issue)-->
-    <if>
-      <matches string="${iterate.hive.all}" pattern="hcatalog"/>
-      <then>
-        <chmod perm="ugo+x" type="file">
-          <fileset dir="${target.dir}/hcatalog/bin"/>
-          <fileset dir="${target.dir}/hcatalog/sbin"/>
-        </chmod>
-      </then>
-    </if>
-  </target>
-
-
-  <!-- ====================================================== -->
-  <!-- Generate files for eclipse.                            -->
-  <!-- ====================================================== -->
-  <target name="eclipse-files" depends="gen-test"
-          description="Generate files for Eclipse">
-    <echo message="Project: ${ant.project.name}"/>
-    <condition property="hadoop.version.ant-internal" value="0.20">
-      <not>
-        <isset property="hadoop.version.ant-internal"/>
-      </not>
-    </condition>
-    <echo message="Using hadoop version ${hadoop.version.ant-internal}"/>
-
-    <taskdef name="getversionpref" classname="org.apache.hadoop.hive.ant.GetVersionPref"
-             classpath="${build.dir.hive}/anttasks/hive-anttasks-${version}.jar"/>
-
-    <getversionpref property="hadoop.version.ant-internal.prefix" input="${hadoop.version.ant-internal}"/>
-
-    <condition property="jetty.jar" value="jetty-6.1.14.jar" else="jetty-5.1.4.jar">
-      <matches string="${hadoop.version.ant-internal}" pattern="^0\.20\..*" />
-    </condition>
-
-    <condition property="jetty.util.jar" value="jetty-util-6.1.14.jar" else="jetty-ext/jsp-api.jar">
-      <!-- hadoop 0.19 and earlier does not have jetty-util.jar, so we just load another jar -->
-      <matches string="${hadoop.version.ant-internal}" pattern="^0\.20\..*" />
-    </condition>
-
-    <condition property="servlet-api.jar" value="servlet-api-2.5-6.1.14.jar" else="servlet-api.jar">
-      <matches string="${hadoop.version.ant-internal}" pattern="^0\.20\..*" />
-    </condition>
-
-
-    <!-- Construct the classpath needed for testutils/hadoop launch script -->
-    <path id="hive.hadoop.test.classpath">
-      <fileset dir="${hive.root}/build/ivy/lib/hadoop0.${hadoop.mr.rev}.shim" includes="*.jar" />
-      <fileset dir="${hive.root}/build/ivy/lib/default" includes="*.jar" excludes="hive*.jar" />
-    </path>
-    <property name="hive.hadoop.test.classpath" refid="hive.hadoop.test.classpath"/>
-    
-    <pathconvert property="eclipse.project">
-      <path path="${basedir}"/>
-      <regexpmapper from="^.*/([^/]+)$$" to="\1" handledirsep="yes"/>
-    </pathconvert>
-    <copy todir="." overwrite="true">
-      <fileset dir="eclipse-templates">
-        <exclude name="**/README.txt"/>
-        <exclude name="${vcs.excludes}"/>
-      </fileset>
-      <filterset>
-        <filtersfile file="${hive.root}/ivy/libraries.properties"/>
-        <filter token="PROJECT" value="${eclipse.project}"/>
-        <filter token="HADOOPVER" value="${hadoop.version.ant-internal}"/>
-        <filter token="HADOOPVERPREF" value="${hadoop.version.ant-internal.prefix}"/>
-        <filter token="JETTYJAR" value="${jetty.jar}"/>
-        <filter token="JETTYUTILJAR" value="${jetty.util.jar}"/>
-        <filter token="SERVLETAPIJAR" value="${servlet-api.jar}"/>
-        <filter token="HIVE_VERSION" value="${version}"/>
-        <filter token="HIVE_HADOOP_TEST_CLASSPATH" value="${hive.hadoop.test.classpath}"/>
-        <filter token="HADOOP_BIN_PATH" value="${hive.root}/testutils/hadoop"/>
-        <filter token="JVM_ARGS" value="${eclipse.launch.jvm.args}"/>
-      </filterset>
-    </copy>
-    <move todir="." includeemptydirs="false">
-      <fileset dir=".">
-        <include name="*.launchtemplate"/>
-      </fileset>
-      <mapper type="glob" from="*.launchtemplate" to="*.launch"/>
-    </move>
-  </target>
-
-  <target name="clean-eclipse-files"
-          description="Delete files for Eclipse">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete includeemptydirs="true">
-      <fileset dir="." includes=".classpath .project .settings/ .externalToolBuilders/"/>
-    </delete>
-  </target>
-
-  <!-- ====================================================== -->
-  <!-- Get Arc-JIRA library.                                  -->
-  <!-- ====================================================== -->
-  
-  <target name="arc-setup" description="Get Arc-JIRA library" depends="init">
-    <get
-      dest="${build.dir.hive}/arc-jira.tar.gz"
-      src="https://github.com/facebook/arc-jira/tarball/master"/>
-    <untar src="${build.dir.hive}/arc-jira.tar.gz" compression="gzip"
- 		dest="${build.dir.hive}">
-      <patternset>
-        <include name="facebook-arc-jira-*/arc_jira_lib/**"/>
-      </patternset>
-    </untar>
-    <move todir="${hive.root}">
-      <fileset dir="${build.dir.hive}">
-        <include name="facebook-arc-jira-*/arc_jira_lib/**"/>
-       </fileset>
-      <mapper type="regexp" from="^facebook-arc-jira-([^/])*/(.*)" to="\.\2"/>
-    </move>
-    <delete includeemptydirs="true">
-      <fileset dir="${build.dir.hive}">
-        <include name="facebook-arc-jira-*"/>
-        <include name="arc-jira.tar.gz"/>
-      </fileset>
-    </delete> 
-  </target>
-
-  <!-- ================================================================== -->
-  <!-- Documentation                                                      -->
-  <!-- ================================================================== -->
-
-  <target name="docs" description="Generate documentation" depends="ivy-init-antlib">
-    <echo message="Project: ${ant.project.name}"/>
-    <antcall target="docs-anakia"/>
-  </target>
-
-  <target name="javadoc" depends="package" description="Generate Javadoc" unless="skip.javadoc">
-    <echo message="Project: ${ant.project.name}"/>
-    <mkdir dir="${build.javadoc}"/>
-    <javadoc
-      maxmemory="1024m"
-      packagenames="org.apache.hadoop.hive.*"
-      destdir="${build.javadoc}"
-      author="true"
-      version="true"
-      use="true"
-      windowtitle="${Name} ${version} API"
-      doctitle="${Name} ${version} API"
-      bottom="Copyright &amp;copy; ${year} The Apache Software Foundation"
-      useexternalfile="yes"
-      >
-
-      <packageset dir="ant/src"/>
-      <packageset dir="hwi/src/java"/>
-      <packageset dir="hwi/src/test"/>
-      <packageset dir="common/src/java"/>
-      <packageset dir="service/src/java"/>
-      <packageset dir="service/src/test"/>
-      <packageset dir="service/src/gen/thrift/gen-javabean"/>
-      <packageset dir="serde/src/java"/>
-      <packageset dir="serde/src/test"/>
-      <packageset dir="serde/src/gen/thrift/gen-javabean"/>
-      <packageset dir="serde/src/gen/protobuf/gen-java"/>
-      <packageset dir="jdbc/src/java"/>
-      <packageset dir="jdbc/src/test"/>
-      <packageset dir="metastore/src/java"/>
-      <packageset dir="metastore/src/test"/>
-      <packageset dir="metastore/src/gen/thrift/gen-javabean"/>
-      <packageset dir="metastore/src/model"/>
-      <packageset dir="hcatalog/src/java"/>
-      <packageset dir="cli/src/java"/>
-      <packageset dir="beeline/src/java"/>
-      <packageset dir="beeline/src/test"/>
-      <packageset dir="ql/src/java"/>
-      <packageset dir="ql/src/test"/>
-      <packageset dir="ql/src/gen/thrift/gen-javabean"/>
-      <packageset dir="${build.dir.hive}/ql/gen/antlr/gen-java"/>
-      <packageset dir="shims/src/common/java"/>
-
-      <link href="${javadoc.link.java}"/>
-
-      <classpath >
-        <path refid="classpath" />
-        <pathelement path="${java.class.path}"/>
-        <pathelement 
-           path="${build.ivy.lib.dir}/default/hadoop-core-${hadoop-0.20.version}.jar"/>
-        <pathelement 
-           path="${build.ivy.lib.dir}/default/hadoop-test-${hadoop-0.20.version}.jar"/>
-      </classpath>
-
-      <group title="Hive" packages="org.apache.*"/>
-  </javadoc>
-
-  </target>
-
-  <!-- ================================================================== -->
-  <!-- Make release tarball                                               -->
-  <!-- ================================================================== -->
-
-  <target name="tar" depends="package, docs, javadoc" description="Make release tarball">
-    <echo message="Project: ${ant.project.name}"/>
-    <macro_tar param.destfile="${build.dir.hive}/${tar.final.name}.tar.gz">
-      <param.listofitems>
-        <tarfileset dir="${build.dir.hive}/dist" mode="755" prefix="${tar.final.name}"
-                    excludes="${vcs.excludes}">
-          <include name="bin/**"/>
-        </tarfileset>
-        <tarfileset dir="${build.dir.hive}/dist" mode="755" prefix="${tar.final.name}"
-                    excludes="${vcs.excludes}">
-          <include name="lib/py/**/*-remote"/>
-        </tarfileset>
-        <tarfileset dir="${build.dir.hive}/dist" mode="664" prefix="${tar.final.name}"
-                    excludes="${vcs.excludes}">
-          <include name="**"/>
-          <exclude name="bin/**"/>
-          <exclude name="lib/py/**/*-remote"/>
-        </tarfileset>
-        <tarfileset dir="${hive.root}" mode="664" prefix="${tar.final.name}/src"
-                    excludes="${vcs.excludes}">
-          <exclude name="build/**" />
-          <exclude name="hcatalog/**/build/**" />
-          <exclude name="bin/**" />
-          <exclude name="**/py/**/*-remote" />
-          <exclude name="data/scripts/**" />
-          <exclude name="metastore/scripts/**" />
-          <exclude name="ql/src/test/scripts/**" />
-        </tarfileset>
-        <tarfileset dir="${hive.root}" mode="755" prefix="${tar.final.name}/src"
-                    excludes="${vcs.excludes}">
-          <exclude name="build/**" />
-          <exclude name="hcatalog/**/build/**" />
-          <include name="bin/**" />
-          <include name="**/py/**/*-remote" />
-          <include name="data/scripts/**" />
-          <include name="metastore/scripts/**" />
-          <include name="ql/src/test/scripts/**" />
-        </tarfileset>
-      </param.listofitems>
-    </macro_tar>
-  </target>
-
-  <target name="binary" depends="package, docs, javadoc"
-          description="Make release tarball without source and documentation">
-    <echo message="Project: ${ant.project.name}"/>
-    <macro_tar param.destfile="${build.dir.hive}/${bin.final.name}.tar.gz">
-      <param.listofitems>
-        <tarfileset dir="${build.dir.hive}/dist" mode="755" prefix="${bin.final.name}"
-                    excludes="${vcs.excludes}">
-          <include name="bin/**"/>
-          <include name="hcatalog/bin/*"/>
-          <include name="hcatalog/sbin/*"/>
-        </tarfileset>
-        <tarfileset dir="${build.dir.hive}/dist" mode="755" prefix="${bin.final.name}"
-                    excludes="${vcs.excludes}">
-          <include name="lib/py/**/*-remote"/>
-        </tarfileset>
-        <tarfileset dir="${build.dir.hive}/dist" mode="664" prefix="${bin.final.name}"
-                    excludes="${vcs.excludes}">
-          <include name="**"/>
-          <exclude name="bin/**"/>
-          <exclude name="docs/**"/>
-          <exclude name="lib/py/**/*-remote"/>
-          <exclude name="hcatalog/bin/*"/>
-          <exclude name="hcatalog/sbin/*"/>
-        </tarfileset>
-      </param.listofitems>
-    </macro_tar>
-  </target>
-
-
-  <!-- ================================================================== -->
-  <!-- RAT                                                                -->
-  <!-- ================================================================== -->
-
-
-  <target name="ivy-resolve-rat" depends="ivy-init-settings">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="rat"
-                 log="${ivyresolvelog}"/>
-  </target>
-  
-  <target name="ivy-retrieve-rat" depends="ivy-resolve-rat"
-    description="Retrieve Ivy-managed artifacts for RAT">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
-      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"
-      log="${ivyresolvelog}"/>
-    <ivy:cachepath pathid="rat-classpath" conf="rat"/>
-  </target>
-
-  <target name="rat" depends="init,ivy-retrieve-rat,check-for-rat"
-          if="rat.present"
-          description="Run RAT on source files">
-    <echo message="Project: ${ant.project.name}"/>
-    <taskdef uri="antlib:org.apache.rat.anttasks"
-             resource="org/apache/rat/anttasks/antlib.xml">
-      <classpath refid="rat-classpath"/>
-    </taskdef>
-
-    <mkdir dir="${rat.build.dir}"/>
-
-    <rat:report reportFile="${rat.build.dir}/hive-rat.txt">
-       <fileset dir=".">
-         <patternset id="non.build.files">
-           <exclude name="**/build/**"/>
-           <exclude name="**/src/gen/**"/>
-           <exclude name=".arcconfig*"/>
-           <exclude name=".arc_jira_lib/**"/>
-           <exclude name="**/*.deflate"/>
-           <exclude name="**/*.m"/>
-           <exclude name="**/*.m.out"/>
-           <exclude name="**/*.q"/>
-           <exclude name="**/*.q.out"/>
-           <exclude name="data/files/*.rc"/>
-           <exclude name="**/test/data/**/*.rc"/>
-           <exclude name="data/files/*.seq"/>
-	   <exclude name="**/data/files/*.log"/>
-           <exclude name="**/*.txt"/>
-           <exclude name="**/test/results/**/*.out"/>
-           <exclude name="**/test/results/**/*.xml"/>
-           <exclude name="**/testdata/*.input"/>
-
-           <!-- Ignore recordio generated file -->
-	   <exclude name="ql/src/test/org/apache/hadoop/hive/ql/io/RecordTestObj.java"/>
-
-           <!-- Ignore thrift generated files -->
-           <exclude name="service/lib/php/packages/fb303/FacebookService.php"/>
-           <exclude name="service/lib/php/packages/fb303/fb303_types.php"/>
-           <exclude name="service/lib/py/fb303/FacebookService-remote"/>
-           <exclude name="service/lib/py/fb303/FacebookService.py"/>
-           <exclude name="service/lib/py/fb303/constants.py"/>
-           <exclude name="service/lib/py/fb303/ttypes.py"/>
-           <exclude name="service/lib/py/thrift/reflection/limited/constants.py"/>
-           <exclude name="service/lib/py/thrift/reflection/limited/ttypes.py"/>
-         </patternset>
-       </fileset>
-    </rat:report>
-  </target>
-
-  <target name="check-for-rat">
-    <echo message="Project: ${ant.project.name}"/>
-    <available property="rat.present" 
-	       resource="org/apache/rat/anttasks/antlib.xml">
-      <classpath refid="rat-classpath"/>
-    </available>
-  </target>
-
-  <!-- ================================================================== -->
-  <!-- Checkstyle                                                         -->
-  <!-- ================================================================== -->
-
-
-  <target name="ivy-resolve-checkstyle" depends="ivy-init-settings">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="checkstyle"
-                 log="${ivyresolvelog}"/>
-  </target>
-  
-  <target name="ivy-retrieve-checkstyle" depends="ivy-resolve-checkstyle"
-    description="Retrieve Ivy-managed artifacts for the checkstyle configurations">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
-      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"
-      log="${ivyresolvelog}"/>
-    <ivy:cachepath pathid="checkstyle-classpath" conf="checkstyle"/>
-  </target>
-
-  <target name="checkstyle" depends="init,ivy-retrieve-checkstyle,check-for-checkstyle"
-          if="checkstyle.present"
-          description="Run Checkstyle on source files">
-    <echo message="Project: ${ant.project.name}"/>
-    <taskdef resource="checkstyletask.properties">
-      <classpath refid="checkstyle-classpath"/>
-    </taskdef>
-
-    <mkdir dir="${checkstyle.build.dir}"/>
-
-    <checkstyle config="${checkstyle.conf.dir}/checkstyle.xml"
-  		failOnViolation="false">
-      <fileset dir="${hive.root}">
-        <exclude name="build/**"/>
-        <exclude name="ant/**"/>
-        <include name="**/*.java"/>
-      </fileset>
-      <formatter type="plain" toFile="${checkstyle.build.dir}/checkstyle-errors.txt"/>
-      <formatter type="xml" toFile="${checkstyle.build.dir}/checkstyle-errors.xml"/>
-    </checkstyle>
-
-    <xslt style="${checkstyle.conf.dir}/checkstyle-noframes-sorted.xsl"
-          in="${checkstyle.build.dir}/checkstyle-errors.xml"
-          out="${checkstyle.build.dir}/checkstyle-errors.html"/>
-
-  </target>
-
-  <target name="check-for-checkstyle">
-    <echo message="Project: ${ant.project.name}"/>
-    <available property="checkstyle.present" resource="checkstyletask.properties">
-      <classpath refid="checkstyle-classpath"/>
-    </available>
-  </target>
-
-  <!-- ================================================================== -->
-  <!-- Findbugs                                                         -->
-  <!-- ================================================================== -->
-  
-
-  <target name="ivy-resolve-findbugs" depends="ivy-init-settings">
-    <echo message="Project: ${ant.project.name}" />
-    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="findbugs" log="${ivyresolvelog}" />
-  </target>
-  
-  <property name="ivy.findbugs.retrieve.pattern" value="[conf]/[artifact].[ext]" />
-  
-  <target name="ivy-retrieve-findbugs" depends="ivy-resolve-findbugs" description="Retrieve Ivy-managed artifacts for the checkstyle configurations">
-    <echo message="Project: ${ant.project.name}" />
-    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings" pattern="${build.ivy.lib.dir}/${ivy.findbugs.retrieve.pattern}" log="${ivyresolvelog}" />
-  </target>
-  
-  <target name="check-for-findbugs">
-    <echo message="Project: ${ant.project.name}" />
-    <path id="findbugs.classpath">
-      <fileset dir="${build.ivy.lib.dir}/findbugs">
-	<include name="*.jar" />
-      </fileset>
-    </path>
-    <pathconvert property="findbugs.classpath" refid="findbugs.classpath" />
-  </target>
-  
-  <target name="findbugs" depends="init,ivy-retrieve-findbugs,check-for-findbugs" description="Run findbugs on source files">
-    <echo message="Project: ${ant.project.name}" />
-    
-    <property name="findbugs.conf.dir" location="${hive.root}/findbugs" />
-    <property name="findbugs.build.dir" location="${build.dir.hive}/findbugs" />
-    <property name="findbugs.exclude.file" value="${findbugs.conf.dir}/findbugs-exclude.xml"/>
-    <property name="findbugs.report.htmlfile" value="${findbugs.build.dir}/findbugs-report.html"/>
-    <property name="findbugs.report.xmlfile" value="${findbugs.build.dir}/findbugs-report.xml"/>
-    
-    <mkdir dir="${findbugs.build.dir}" />
-    <taskdef name="findbugs" classname="edu.umd.cs.findbugs.anttask.FindBugsTask" classpath="${build.ivy.lib.dir}/findbugs/findbugs-ant.jar" />
-    
-    <findbugs classpath="${findbugs.classpath}" pluginList="" effort="max" output="xml" outputFile="${findbugs.report.xmlfile}" excludeFilter="${findbugs.exclude.file}">
-      
-      <auxClasspath>
-	<fileset dir="${build.dir.hive}">
-	  <include name="**/*.jar" />
-	</fileset>
-      </auxClasspath>
-      
-      <sourcePath path="${hive.root}/ant" />
-      <sourcePath path="${hive.root}/beeline" />
-      <sourcePath path="${hive.root}/cli" />
-      <sourcePath path="${hive.root}/common" />
-      <sourcePath path="${hive.root}/contrib" />
-      <sourcePath path="${hive.root}/hbase-handler" />
-      <sourcePath path="${hive.root}/hwi" />
-      <sourcePath path="${hive.root}/jdbc" />
-      <sourcePath path="${hive.root}/metastore" />
-      <sourcePath path="${hive.root}/hcatalog" />
-      <sourcePath path="${hive.root}/odbc" />
-      <sourcePath path="${hive.root}/ql" />
-      <sourcePath path="${hive.root}/serde" />
-      <sourcePath path="${hive.root}/service" />
-      <sourcePath path="${hive.root}/shims" />
-      <class location="${build.dir.hive}/anttasks/classes" />
-      <class location="${build.dir.hive}/beeline/classes" />
-      <class location="${build.dir.hive}/cli/classes" />
-      <class location="${build.dir.hive}/common/classes" />
-      <class location="${build.dir.hive}/contrib/classes" />
-      <class location="${build.dir.hive}/hbase-handler/classes" />
-      <class location="${build.dir.hive}/hwi/classes" />
-      <class location="${build.dir.hive}/jdbc/classes" />
-      <class location="${build.dir.hive}/metastore/classes" />
-      <class location="${build.dir.hive}/hcatalog/classes" />
-      <class location="${build.dir.hive}/ql/classes" />
-      <class location="${build.dir.hive}/serde/classes" />
-      <class location="${build.dir.hive}/service/classes" />
-      <class location="${build.dir.hive}/shims/classes" />
-    </findbugs>
-    <!--
-        <xslt style="${findbugs.conf.dir}/default.xsl" in="${findbugs.report.xmlfile}"  out="${findbugs.report.htmlfile}"/>
-        -->
-  </target>
-  <target name="ivy-docs" depends="ivy-init-settings"
-          description="Resolve, Retrieve Ivy-managed artifacts for docs configuration">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="docs"/>
-    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
-                  pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}" conf="docs"/>
-    <ivy:cachepath pathid="docs-classpath" conf="docs"/>
-  </target>
-  
-  <target name="docs-anakia" depends="ivy-docs">
-    <echo message="Project: ${ant.project.name}"/>
-    <echo message="Building xdocs with anakia"/>
-    <mkdir dir="${build.dir.hive}/docs"/>
-    <taskdef name="anakia" classname="org.apache.velocity.anakia.AnakiaTask">
-      <classpath refid="common-classpath"/>
-      <classpath refid="docs-classpath"/>
-    </taskdef>
-    <anakia basedir="${anakia.docs.src}" destdir="${anakia.docs.dest}"
-      extension=".html" style="./docs/stylesheets/site.vsl"
-      projectFile="../stylesheets/project.xml"
-      excludes="**/stylesheets/**"
-      includes="**/*.xml"
-      lastModifiedCheck="false"
-      velocityPropertiesFile="${docs.src}/velocity.properties">
-    </anakia>
-    <copy todir="${anakia.docs.dest}/images" filtering="no">
-      <fileset dir="${docs.src}/images">
-        <include name="**/*.gif"/>
-        <include name="**/*.jpeg"/>
-        <include name="**/*.jpg"/>
-        <include name="**/*.png"/>
-      </fileset>
-    </copy>
-    <copy file="${docs.src}/site.css" tofile="${anakia.docs.dest}/site.css" />
-  </target>
-
-  <!-- Prepare for maven deploy i.e. jars, poms, and licence -->
-
-  <target name="ivy-resolve-maven-ant-tasks" depends="ivy-init-settings">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="maven"
-      log="${ivyresolvelog}"/>
-  </target>
-
-  <target name="ivy-retrieve-maven-ant-tasks" depends="ivy-resolve-maven-ant-tasks"
-    description="Retrieve Ivy-managed artifacts for the maven-ant-tasks configurations">
-    <echo message="Project: ${ant.project.name}"/>
-    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
-      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"
-      log="${ivyresolvelog}"/>
-    <ivy:cachepath pathid="maven-ant-tasks.classpath" conf="maven"/>
-  </target>
-
-  
-  <target name="mvn-taskdef" depends="ivy-retrieve-maven-ant-tasks">
-    <echo message="Project: ${ant.project.name}"/>
-    <typedef resource="org/apache/maven/artifact/ant/antlib.xml"
-	     uri="urn:maven-artifact-ant" classpathref="maven-ant-tasks.classpath" />
-  </target>
-  
-  <target name="maven-build" depends="package" description="Build Maven artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <!-- create jars, poms licences directory -->
-    <mkdir dir="${mvn.jar.dir}" />
-    <mkdir dir="${mvn.pom.dir}" />
-    <mkdir dir="${mvn.license.dir}" />
-
-    <!-- call make pom on all projects that have ivy.xml -->
-    <iterate target="make-pom" iterate="${iterate.hive.all}"/>
-
-    <!-- copy the jars  -->
-    <copy file="${build.dir.hive}/anttasks/hive-anttasks-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/beeline/hive-beeline-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/cli/hive-cli-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/common/hive-common-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/contrib/hive-contrib-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/hbase-handler/hive-hbase-handler-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/hwi/hive-hwi-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/jdbc/hive-jdbc-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/metastore/hive-metastore-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/ql/hive-exec-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/serde/hive-serde-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/service/hive-service-${version}.jar"
-          todir="${mvn.jar.dir}" />
-    <copy file="${build.dir.hive}/shims/hive-shims-${version}.jar"
-          todir="${mvn.jar.dir}" />
-
-    <!-- copy over maven pom files created using the make-pom target and rename to maven convention -->
-    <copy file="${build.dir.hive}/anttasks/pom.xml"
-          tofile="${mvn.pom.dir}/hive-anttasks-${version}.pom" />
-    <copy file="${build.dir.hive}/beeline/pom.xml"
-          tofile="${mvn.pom.dir}/hive-beeline-${version}.pom" />
-    <copy file="${build.dir.hive}/cli/pom.xml"
-          tofile="${mvn.pom.dir}/hive-cli-${version}.pom" />
-    <copy file="${build.dir.hive}/common/pom.xml"
-          tofile="${mvn.pom.dir}/hive-common-${version}.pom" />
-    <copy file="${build.dir.hive}/contrib/pom.xml"
-          tofile="${mvn.pom.dir}/hive-contrib-${version}.pom" />
-    <copy file="${build.dir.hive}/hbase-handler/pom.xml"
-          tofile="${mvn.pom.dir}/hive-hbase-handler-${version}.pom" />
-    <copy file="${build.dir.hive}/hwi/pom.xml"
-          tofile="${mvn.pom.dir}/hive-hwi-${version}.pom" />
-    <copy file="${build.dir.hive}/jdbc/pom.xml"
-          tofile="${mvn.pom.dir}/hive-jdbc-${version}.pom" />
-    <copy file="${build.dir.hive}/metastore/pom.xml"
-          tofile="${mvn.pom.dir}/hive-metastore-${version}.pom" />
-    <copy file="${build.dir.hive}/ql/pom.xml"
-          tofile="${mvn.pom.dir}/hive-exec-${version}.pom" />
-    <copy file="${build.dir.hive}/serde/pom.xml"
-          tofile="${mvn.pom.dir}/hive-serde-${version}.pom" />
-    <copy file="${build.dir.hive}/service/pom.xml"
-          tofile="${mvn.pom.dir}/hive-service-${version}.pom" />
-    <copy file="${build.dir.hive}/shims/pom.xml"
-          tofile="${mvn.pom.dir}/hive-shims-${version}.pom" />
-
-
-
-    <!-- copy over licence -->
-    <copy file="${hive.root}/LICENSE" todir="${mvn.license.dir}" />
-
-    <!-- checksum files -->
-    <checksum forceOverwrite="yes" algorithm="MD5" fileext=".md5">
-      <fileset dir="${mvn.jar.dir}" excludes="**/*.sha1,**/*.md5" />
-      <fileset dir="${mvn.pom.dir}" excludes="**/*.sha1,**/*.md5" />
-      <fileset dir="${mvn.license.dir}" excludes="**/*.sha1,**/*.md5" />
-    </checksum>
-
-    <checksum forceOverwrite="yes" algorithm="SHA" fileext=".sha1">
-      <fileset dir="${mvn.jar.dir}" excludes="**/*.sha1,**/*.md5" />
-      <fileset dir="${mvn.pom.dir}" excludes="**/*.sha1,**/*.md5" />
-      <fileset dir="${mvn.license.dir}" excludes="**/*.sha1,**/*.md5" />
-    </checksum>
-
-    <echo>
-      Please consult the HowToRelease page on the Hive Wiki for
-      a description of the remaining steps required to publish
-      Maven artifacts to the ASF repository:
-
-      https://cwiki.apache.org/confluence/display/Hive/HowToRelease
-    </echo>
-  </target>
-
-  <!-- Deploy a single artifact to the maven repository -->
-  <target name="maven-publish-artifact">
-    <echo message="Project: ${ant.project.name}"/>
-    <artifact:pom
-       file="${mvn.pom.dir}/hive-${hive.project}-${version}.pom"
-       id="hive.project.pom" />
-    <artifact:install-provider artifactId="wagon-http" version="1.0-beta-2" />
-    <if>
-      <equals arg1="${mvn.publish.repo}" arg2="staging" />
-      <then>
-        <artifact:deploy
-            file="${mvn.jar.dir}/hive-${hive.project}-${version}.jar">
-          <pom refid="hive.project.pom" />
-          <remoteRepository
-              id="${mvn.staging.repo.id}" url="${mvn.staging.repo.url}"/>
-          <attach file="${mvn.jar.dir}/hive-${hive.project}-${version}.jar.asc"
-                  type="jar.asc"/>
-          <attach file="${mvn.pom.dir}/hive-${hive.project}-${version}.pom.asc"
-                  type="pom.asc"/>
-        </artifact:deploy>
-      </then>
-      <elseif>
-        <equals arg1="${mvn.publish.repo}" arg2="local"/>
-        <then>
-          <artifact:install 
-              file="${mvn.jar.dir}/hive-${hive.project}-${version}.jar">
-            <pom refid="hive.project.pom" />
-          </artifact:install>
-        </then>
-      </elseif>
-      <else>
-        <artifact:deploy
-            file="${mvn.jar.dir}/hive-${hive.project}-${version}.jar">
-          <pom refid="hive.project.pom" />
-          <remoteRepository id="${mvn.deploy.id}" url="${mvn.deploy.url}"/>
-        </artifact:deploy>
-      </else>
-    </if>
-  </target>
-
-  
-  <target name="maven-publish" depends="init,mvn-taskdef,maven-sign"
-          description="Publish Maven artifacts">
-    <echo message="Project: ${ant.project.name}"/>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="anttasks" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="beeline" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="cli" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="common" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="contrib" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="exec" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="hbase-handler" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="hwi" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="jdbc" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="metastore" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="serde" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="service" />
-    </antcall>
-    <antcall target="maven-publish-artifact">
-      <param name="hive.project" value="shims" />
-    </antcall>
-    <!-- Handle HCat separately; matches maven-publish-artifact-->
-    <if>
-      <equals arg1="${mvn.publish.repo}" arg2="staging" />
-      <then>
-        <ant dir="hcatalog" target="mvn-deploy-signed">
-          <property name="mvn.deploy.repo.id" value="${mvn.staging.repo.id}"/>
-          <property name="mvn.deploy.repo.url" value="${mvn.staging.repo.url}"/>
-        </ant>
-      </then>
-      <elseif>
-        <equals arg1="${mvn.publish.repo}" arg2="local"/>
-          <then>
-            <!-- NOP, HCat always publishes to the local repo in jar target-->
-          </then>
-      </elseif>
-      <else>
-        <ant dir="hcatalog" target="mvn-deploy">
-          <property name="mvn.deploy.repo.id" value="${mvn.deploy.id}"/>
-          <property name="mvn.deploy.repo.url" value="${mvn.deploy.url}"/>
-        </ant>
-      </else>
-    </if>
-  </target>
-
-  <target name="maven-sign" if="staging">
-    <echo message="Project: ${ant.project.name}"/>
-    <input message="password:>" addproperty="gpg.passphrase">
-      <handler classname="org.apache.tools.ant.input.SecureInputHandler" />
-    </input>
-    <macrodef name="sign-artifact" description="Signs the artifact">
-      <attribute name="input.file"/>
-      <attribute name="output.file" default="@{input.file}.asc"/>
-      <attribute name="gpg.passphrase"/>
-      <sequential>
-        <echo>Signing @{input.file} Sig File: @{output.file}</echo>
-        <exec executable="gpg" >
-          <arg value="--armor"/>
-          <arg value="--output"/>
-          <arg value="@{output.file}"/>
-          <arg value="--passphrase"/>
-          <arg value="@{gpg.passphrase}"/>
-          <arg value="--detach-sig"/>
-          <arg value="@{input.file}"/>
-        </exec>
-      </sequential>
-    </macrodef>
-
-    <!-- hive-anttasks -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-anttasks-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-anttasks-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-anttasks-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-anttasks-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-beeline -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-beeline-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-beeline-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-beeline-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-beeline-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-cli -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-cli-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-cli-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-cli-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-cli-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-common -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-common-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-common-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-common-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-common-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-contrib -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-contrib-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-contrib-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-contrib-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-contrib-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-exec -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-exec-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-exec-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-exec-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-exec-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-hbase-handler -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-hbase-handler-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-hbase-handler-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-hbase-handler-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-hbase-handler-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-hwi -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-hwi-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-hwi-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-hwi-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-hwi-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-jdbc -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-jdbc-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-jdbc-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-jdbc-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-jdbc-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-metastore -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-metastore-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-metastore-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-metastore-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-metastore-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-serde -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-serde-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-serde-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-serde-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-serde-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-service -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-service-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-service-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-service-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-service-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-
-    <!-- hive-shims -->
-    <sign-artifact
-        input.file="${mvn.jar.dir}/hive-shims-${version}.jar"
-        output.file="${mvn.jar.dir}/hive-shims-${version}.jar.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-    <sign-artifact
-        input.file="${mvn.pom.dir}/hive-shims-${version}.pom"
-        output.file="${mvn.pom.dir}/hive-shims-${version}.pom.asc"
-        gpg.passphrase="${gpg.passphrase}"/>
-  </target>  
-  
-</project>
diff --git a/src/cli/build.xml b/src/cli/build.xml
deleted file mode 100755
index 4a8cd02..0000000
--- a/src/cli/build.xml
+++ /dev/null
@@ -1,52 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-
-<!-- 
-Before you can run these subtargets directly, you need 
-to call at top-level: ant deploy-contrib compile-core-test
--->
-<project name="cli" default="jar">
-
-  <property name="src.dir"  location="${basedir}/src/java"/>
-  <import file="../build-common.xml"/>
-
-  <target name="compile" depends="init, setup, ivy-retrieve">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${src.dir}"
-     includes="**/*.java"
-     destdir="${build.classes}"
-     debug="${javac.debug}"
-     deprecation="${javac.deprecation}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     includeantruntime="false">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="classpath"/>
-    </javac>
-    <copy todir="${build.classes}" failonerror="false">
-      <fileset dir="${src.dir}">
-        <include name="**/*.properties"/>
-      </fileset>
-    </copy>
-  </target>
-
-</project>
diff --git a/src/cli/ivy.xml b/src/cli/ivy.xml
deleted file mode 100644
index f7e86df..0000000
--- a/src/cli/ivy.xml
+++ /dev/null
@@ -1,39 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-cli" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <!-- Runtime Dependencies -->
-
-    <dependency org="jline" name="jline" rev="${jline.version}"
-                transitive="false"/>
-    <dependency org="org.apache.hive" name="hive-service" rev="${version}"
-                conf="compile->default" />
-    <dependency org="org.apache.hive" name="hive-shims" rev="${version}"
-                conf="runtime" transitive="false"/>
-  </dependencies>
-</ivy-module>
diff --git a/src/common/build.xml b/src/common/build.xml
deleted file mode 100755
index ad66efa..0000000
--- a/src/common/build.xml
+++ /dev/null
@@ -1,57 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-
-<!-- 
-Before you can run these subtargets directly, you need 
-to call at top-level: ant deploy-contrib compile-core-test
--->
-<project name="common" default="jar">
-
-  <property name="src.dir"  location="${basedir}/src/java"/>
-  <property name="src.gen.dir"  location="${basedir}/src/gen"/>
-  <import file="../build-common.xml"/>
-
-  <target name="compile" depends="init, setup, ivy-retrieve">
-    <echo message="Project: ${ant.project.name}"/>
-    <exec executable="bash" failonerror="true">
-      <arg value="${basedir}/src/scripts/saveVersion.sh"/>
-      <arg value="${version}"/>
-      <arg value="${shortversion}"/>
-      <arg value="${basedir}/src"/>
-    </exec>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${src.dir}:${src.gen.dir}"
-     includes="**/*.java"
-     destdir="${build.classes}"
-     debug="${javac.debug}"
-     deprecation="${javac.deprecation}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     includeantruntime="false">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="classpath"/>
-    </javac>
-    <copy todir="${build.classes}" failonerror="false">
-      <fileset dir="${src.dir}/conf"/>
-    </copy>
-  </target>
-
-</project>
diff --git a/src/common/ivy.xml b/src/common/ivy.xml
deleted file mode 100644
index 95cee84..0000000
--- a/src/common/ivy.xml
+++ /dev/null
@@ -1,48 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-common" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <dependency org="org.apache.hadoop" name="hadoop-auth"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop23.compile->default" transitive="false">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.avro" name="avro" rev="${avro.version}"
-                conf="hadoop23.compile->default" transitive="false" />
-
-    <dependency org="org.apache.hive" name="hive-shims" rev="${version}"
-                conf="compile->default" transitive="false" />
-    <dependency org="commons-cli" name="commons-cli" rev="${commons-cli.version}"/>
-    <dependency org="org.apache.commons" name="commons-compress" rev="${commons-compress.version}"/>
-    <dependency org="commons-lang" name="commons-lang" rev="${commons-lang.version}"/>
-    <dependency org="log4j" name="log4j" rev="${log4j.version}"
-                transitive="false"/>
-  </dependencies>
-</ivy-module>
diff --git a/src/contrib/build.xml b/src/contrib/build.xml
deleted file mode 100644
index 5d33d83..0000000
--- a/src/contrib/build.xml
+++ /dev/null
@@ -1,102 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-
-<project name="contrib" default="jar">
-
-  <property name="contrib.lib.dir" value="${basedir}/lib"/>
-  <property name="src.dir"  location="${basedir}/src/java"/>
-  <property name="contrib.test.query.dir" location="${basedir}/src/test/queries"/>
-  <property name="ql.test.template.dir" location="${basedir}/../ql/src/test/templates"/>
-  <property name="contrib.test.results.dir" location="${basedir}/src/test/results"/>
-
-  <import file="../build-common.xml"/>
-
-  <target name="test-jar" depends="compile-test, jar">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete file="${test.build.dir}/test-udfs.jar"/>
-    <jar jarfile="${test.build.dir}/test-udfs.jar">
-        <fileset dir="${test.build.classes}" includes="**/udf/*.class"/>
-        <fileset dir="${test.build.classes}" includes="**/udf/generic/*.class"/>
-    </jar>
-  </target>
-
-  <target name="gen-test" depends="test-conditions, test-init" >
-    <echo message="Project: ${ant.project.name}"/>
-    <taskdef name="qtestgen" classname="org.apache.hadoop.hive.ant.QTestGenTask"
-             classpath="${build.dir.hive}/anttasks/hive-anttasks-${version}.jar:${build.ivy.lib.dir}/default/velocity-${velocity.version}.jar:${build.ivy.lib.dir}/default/commons-collections-${commons-collections.version}.jar:${build.ivy.lib.dir}/default/commons-lang-${commons-lang.version}.jar"/>
-    
-    <mkdir dir="${test.build.src}/org/apache/hadoop/hive/ql/parse"/>
-    <mkdir dir="${test.build.src}/org/apache/hadoop/hive/cli"/>
-    <mkdir dir="${test.log.dir}/contribpositive"/>
-    <mkdir dir="${test.log.dir}/contribnegative"/>
-    <mkdir dir="${test.log.dir}/contribclientpositive"/>
-    <mkdir dir="${test.log.dir}/contribclientnegative"/>
-
-    <qtestgen hiveRootDirectory="${hive.root}"
-              outputDirectory="${test.build.src}/org/apache/hadoop/hive/ql/parse" 
-              templatePath="${ql.test.template.dir}" template="TestParse.vm" 
-              queryDirectory="${contrib.test.query.dir}/positive"
-              queryFile="${qfile}"
-              queryFileRegex="${qfile_regex}"
-              runDisabled="${run_disabled}"
-              resultsDirectory="${contrib.test.results.dir}/compiler" className="TestContribParse"
-              logFile="${test.log.dir}/testcontribparsegen.log"
-              logDirectory="${test.log.dir}/contribpositive"/>
-    
- <!-- the TestContribParseNegative.java got removed? 
-    <qtestgen outputDirectory="${test.build.src}/org/apache/hadoop/hive/ql/parse" 
-              templatePath="${ql.test.template.dir}" template="TestParseNegative.vm" 
-              queryDirectory="${contrib.test.query.dir}/negative" 
-              queryFile="${qfile}"
-              queryFileRegex="${qfile_regex}"
-              runDisabled="${run_disabled}"
-              resultsDirectory="${contrib.test.results.dir}/compiler/errors" className="TestContribParseNegative"
-              logFile="${test.log.dir}/testcontribparseneggen.log"
-              logDirectory="${test.log.dir}/contribnegative"/>
-   -->
-
-    <qtestgen hiveRootDirectory="${hive.root}"
-              outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli" 
-              templatePath="${ql.test.template.dir}" template="TestCliDriver.vm" 
-              queryDirectory="${contrib.test.query.dir}/clientpositive" 
-              queryFile="${qfile}"
-              queryFileRegex="${qfile_regex}"
-              runDisabled="${run_disabled}"
-              clusterMode="${clustermode}"
-              resultsDirectory="${contrib.test.results.dir}/clientpositive" className="TestContribCliDriver"
-              logFile="${test.log.dir}/testcontribclidrivergen.log"
-              logDirectory="${test.log.dir}/contribclientpositive"
-              hadoopVersion="${hadoopVersion}"
-    />
-
-    <qtestgen hiveRootDirectory="${hive.root}"
-              outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli" 
-              templatePath="${ql.test.template.dir}" template="TestNegativeCliDriver.vm" 
-              queryDirectory="${contrib.test.query.dir}/clientnegative" 
-              queryFile="${qfile}"
-              queryFileRegex="${qfile_regex}"
-              runDisabled="${run_disabled}"
-              resultsDirectory="${contrib.test.results.dir}/clientnegative" className="TestContribNegativeCliDriver"
-              logFile="${test.log.dir}/testcontribnegclidrivergen.log"
-              logDirectory="${test.log.dir}/contribclientnegative"/>
-
-  </target>
-
-</project>
diff --git a/src/contrib/ivy.xml b/src/contrib/ivy.xml
deleted file mode 100644
index 4216106..0000000
--- a/src/contrib/ivy.xml
+++ /dev/null
@@ -1,32 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-contrib" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>  
-  <dependencies>
-    <dependency org="org.apache.hive" name="hive-exec" rev="${version}"
-                conf="compile->default" />
-  </dependencies>
-</ivy-module>
diff --git a/src/data/conf/hive-log4j-old.properties b/src/data/conf/hive-log4j-old.properties
deleted file mode 100644
index f274b8c..0000000
--- a/src/data/conf/hive-log4j-old.properties
+++ /dev/null
@@ -1,82 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one
-# or more contributor license agreements.  See the NOTICE file
-# distributed with this work for additional information
-# regarding copyright ownership.  The ASF licenses this file
-# to you under the Apache License, Version 2.0 (the
-# "License"); you may not use this file except in compliance
-# with the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-# Define some default values that can be overridden by system properties
-hive.root.logger=DEBUG,DRFA
-hive.log.dir=${build.dir.hive}/ql/tmp/
-hive.log.file=hive.log
-
-# Define the root logger to the system property "hadoop.root.logger".
-log4j.rootLogger=${hive.root.logger}, EventCounter
-
-# Logging Threshold
-log4j.threshhold=WARN
-
-#
-# Daily Rolling File Appender
-#
-
-log4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppender
-log4j.appender.DRFA.File=${hive.log.dir}/${hive.log.file}
-
-# Rollver at midnight
-log4j.appender.DRFA.DatePattern=.yyyy-MM-dd
-
-# 30-day backup
-#log4j.appender.DRFA.MaxBackupIndex=30
-log4j.appender.DRFA.layout=org.apache.log4j.PatternLayout
-
-# Pattern format: Date LogLevel LoggerName LogMessage
-#log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
-# Debugging Pattern format
-log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %-5p %c{2} (%F:%M(%L)) - %m%n
-
-
-#
-# console
-# Add "console" to rootlogger above if you want to use this
-#
-
-log4j.appender.console=org.apache.log4j.ConsoleAppender
-log4j.appender.console.target=System.err
-log4j.appender.console.layout=org.apache.log4j.PatternLayout
-log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{2}: %m%n
-
-#custom logging levels
-#log4j.logger.xxx=DEBUG
-
-#
-# Event Counter Appender
-# Sends counts of logging messages at different severity levels to Hadoop Metrics.
-#
-log4j.appender.EventCounter=org.apache.hadoop.hive.shims.HiveEventCounter
-
-
-log4j.category.DataNucleus=ERROR,DRFA
-log4j.category.Datastore=ERROR,DRFA
-log4j.category.Datastore.Schema=ERROR,DRFA
-log4j.category.JPOX.Datastore=ERROR,DRFA
-log4j.category.JPOX.Plugin=ERROR,DRFA
-log4j.category.JPOX.MetaData=ERROR,DRFA
-log4j.category.JPOX.Query=ERROR,DRFA
-log4j.category.JPOX.General=ERROR,DRFA
-log4j.category.JPOX.Enhancer=ERROR,DRFA
-log4j.logger.org.apache.hadoop.conf.Configuration=ERROR,DRFA
-
-
-# Silence useless ZK logs
-log4j.logger.org.apache.zookeeper.server.NIOServerCnxn=WARN,DRFA
-log4j.logger.org.apache.zookeeper.ClientCnxnSocketNIO=WARN,DRFA
diff --git a/src/data/conf/hive-site-old.xml b/src/data/conf/hive-site-old.xml
deleted file mode 100644
index 4e6ff16..0000000
--- a/src/data/conf/hive-site-old.xml
+++ /dev/null
@@ -1,197 +0,0 @@
-<?xml version="1.0"?>
-<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-<configuration>
-
-<!-- Hive Configuration can either be stored in this file or in the hadoop configuration files  -->
-<!-- that are implied by Hadoop setup variables.                                                -->
-<!-- Aside from Hadoop setup variables - this file is provided as a convenience so that Hive    -->
-<!-- users do not have to edit hadoop configuration files (that may be managed as a centralized -->
-<!-- resource).                                                                                 -->
-
-<!-- Hive Execution Parameters -->
-<property>
-  <name>hadoop.tmp.dir</name>
-  <value>${build.dir.hive}/test/hadoop-${user.name}</value>
-  <description>A base for other temporary directories.</description>
-</property>
-
-<!--
-<property>
-  <name>hive.exec.reducers.max</name>
-  <value>1</value>
-  <description>maximum number of reducers</description>
-</property>
--->
-
-<property>
-  <name>hive.exec.scratchdir</name>
-  <value>${build.dir}/scratchdir</value>
-  <description>Scratch space for Hive jobs</description>
-</property>
-
-<property>
-  <name>hive.exec.local.scratchdir</name>
-  <value>${build.dir}/localscratchdir/</value>
-  <description>Local scratch space for Hive jobs</description>
-</property>
-
-<property>
-  <name>javax.jdo.option.ConnectionURL</name>
-  <!-- note: variable substituion not working here because it's loaded by jdo, not Hive -->
-  <value>jdbc:derby:;databaseName=../build/test/junit_metastore_db;create=true</value>
-</property>
-
-<property>
-  <name>javax.jdo.option.ConnectionDriverName</name>
-  <value>org.apache.derby.jdbc.EmbeddedDriver</value>
-</property>
-
-<property>
-  <name>javax.jdo.option.ConnectionUserName</name>
-  <value>APP</value>
-</property>
-
-<property>
-  <name>javax.jdo.option.ConnectionPassword</name>
-  <value>mine</value>
-</property>
-
-<property>
-  <!--  this should eventually be deprecated since the metastore should supply this -->
-  <name>hive.metastore.warehouse.dir</name>
-  <value>${test.warehouse.dir}</value>
-  <description></description>
-</property>
-
-<property>
-  <name>hive.metastore.metadb.dir</name>
-  <value>file://${build.dir}/test/data/metadb/</value>
-  <description>
-  Required by metastore server or if the uris argument below is not supplied
-  </description>
-</property>
-
-<property>
-  <name>test.log.dir</name>
-  <value>${build.dir}/test/logs</value>
-  <description></description>
-</property>
-
-<property>
-  <name>test.src.dir</name>
-  <value>file://${build.dir}/src/test</value>
-  <description></description>
-</property>
-
-<property>
-  <name>test.data.files</name>
-  <value>${user.dir}/../data/files</value>
-  <description></description>
-</property>
-
-<property>
-  <name>test.query.file1</name>
-  <value>file://${user.dir}/../ql/src/test/org/apache/hadoop/hive/ql/input2.q</value>
-  <value></value>
-  <description></description>
-</property>
-
-<property>
-  <name>hive.jar.path</name>
-  <value>${build.dir.hive}/ql/hive-exec-${version}.jar</value>
-  <description></description>
-</property>
-
-<property>
-  <name>hive.metastore.rawstore.impl</name>
-  <value>org.apache.hadoop.hive.metastore.ObjectStore</value>
-  <description>Name of the class that implements org.apache.hadoop.hive.metastore.rawstore interface. This class is used to store and retrieval of raw metadata objects such as table, database</description>
-</property>
-
-<property>
-  <name>hive.querylog.location</name>
-  <value>${build.dir}/tmp</value>
-  <description>Location of the structured hive logs</description>
-</property>
-
-<property>
-  <name>hive.exec.pre.hooks</name>
-  <value>org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables</value>
-  <description>Pre Execute Hook for Tests</description>
-</property>
-
-<property>
-  <name>hive.exec.post.hooks</name>
-  <value>org.apache.hadoop.hive.ql.hooks.PostExecutePrinter</value>
-  <description>Post Execute Hook for Tests</description>
-</property>
-
-<property>
-  <name>hive.task.progress</name>
-  <value>false</value>
-  <description>Track progress of a task</description>
-</property>
-
-<property>
-  <name>hive.support.concurrency</name>
-  <value>true</value>
-  <description>Whether hive supports concurrency or not. A zookeeper instance must be up and running for the default hive lock manager to support read-write locks.</description>
-</property>
-
-<property>
-  <name>fs.pfile.impl</name>
-  <value>org.apache.hadoop.fs.ProxyLocalFileSystem</value>
-  <description>A proxy for local file system used for cross file system testing</description>
-</property>
-
-<property>
-  <name>hive.exec.mode.local.auto</name>
-  <value>false</value>
-  <description>
-    Let hive determine whether to run in local mode automatically
-    Disabling this for tests so that minimr is not affected
-  </description>
-</property>
-
-<property>
-  <name>hive.auto.convert.join</name>
-  <value>false</value>
-  <description>Whether Hive enable the optimization about converting common join into mapjoin based on the input file size</description>
-</property>
-
-<property>
-  <name>hive.ignore.mapjoin.hint</name>
-  <value>false</value>
-  <description>Whether Hive ignores the mapjoin hint</description>
-</property>
-
-<property>
-  <name>hive.input.format</name>
-  <value>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</value>
-  <description>The default input format, if it is not specified, the system assigns it. It is set to HiveInputFormat for hadoop versions 17, 18 and 19, whereas it is set to CombineHiveInputFormat for hadoop 20. The user can always overwrite it - if there is a bug in CombineHiveInputFormat, it can always be manually set to HiveInputFormat. </description>
-</property>
-
-<property>
-  <name>hive.default.rcfile.serde</name>
-  <value>org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe</value>
-  <description>The default SerDe hive will use for the rcfile format</description>
-</property>
-
-</configuration>
diff --git a/src/eclipse-templates/.classpath b/src/eclipse-templates/.classpath
deleted file mode 100644
index 08de081..0000000
--- a/src/eclipse-templates/.classpath
+++ /dev/null
@@ -1,131 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<classpath>
-  <classpathentry kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/ant-1.6.5.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/commons-cli-1.2.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/commons-codec-1.4.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/commons-el-1.0.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/commons-httpclient-3.0.1.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/commons-logging-1.1.1.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/commons-net-1.4.1.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/core-3.1.1.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/ftplet-api-1.0.0.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/ftpserver-core-1.0.0.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/ftpserver-deprecated-1.0.0-M2.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/hadoop-core-@HADOOPVER@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/hadoop-test-@HADOOPVER@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/hadoop-tools-@HADOOPVER@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/hsqldb-1.8.0.10.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/jasper-compiler-5.5.12.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/jasper-runtime-5.5.12.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/jets3t-0.7.1.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/jetty-6.1.14.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/jetty-util-6.1.14.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/jsp-2.1-6.1.14.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/jsp-api-2.1-6.1.14.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/kfs-0.3.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/mina-core-2.0.0-M5.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/oro-2.0.8.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/servlet-api-2.5-6.1.14.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/hadoop0.20.shim/xmlenc-0.52.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/avro-@avro.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/avro-mapred-@avro.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/jline-@jline.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/json-@json.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/commons-compress-@commons-compress.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/commons-lang-@commons-lang.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/commons-logging-@commons-logging.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/commons-logging-api-@commons-logging-api.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/commons-io-@commons-io.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/derby-@derby.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/hbase-@hbase.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/hbase-@hbase.version@-tests.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/guava-@guava.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/libfb303-@libfb303.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/libthrift-@libthrift.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/protobuf-java-@protobuf.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/zookeeper-@zookeeper.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/log4j-@log4j.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/antlr-@antlr.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/antlr-runtime-@antlr-runtime.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/junit-@junit.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/jdo-api-@jdo-api.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/kryo-@kryo.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/datanucleus-api-jdo-@datanucleus-api-jdo.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/datanucleus-core-@datanucleus-core.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/datanucleus-rdbms-@datanucleus-rdbms.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/commons-cli-@commons-cli.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/commons-collections-@commons-collections.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/bonecp-@BoneCP.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/commons-pool-@commons-pool.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/httpcore-@httpcore.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/httpclient-@httpclient.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/slf4j-api-@slf4j-api.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/slf4j-log4j12-@slf4j-log4j12.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/JavaEWAH-@javaewah.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/javolution-@javolution.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/jackson-core-asl-1.8.8.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/jackson-jaxrs-1.8.8.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/jackson-xc-1.8.8.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/mockito-all-@mockito-all.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/ST4-@ST4.version@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/snappy-@snappy.version@.jar"/>
-  <classpathentry kind="lib" path="build/beeline/hive-beeline-@HIVE_VERSION@.jar"/>
-  <classpathentry kind="lib" path="build/ivy/lib/default/tempus-fugit-@tempus-fugit.version@.jar"/>
-  <classpathentry kind="src" path="build/contrib/test/src"/>
-  <classpathentry kind="src" path="build/metastore/gen/antlr/gen-java"/>
-  <classpathentry kind="lib" path="build/testutils/hive-testutils-@HIVE_VERSION@.jar"/>
-  <classpathentry kind="src" path="build/ql/test/src"/>
-  <classpathentry kind="src" path="build/ql/gen/antlr/gen-java"/>
-  <classpathentry kind="src" path="beeline/src/java"/>
-  <classpathentry kind="src" path="beeline/src/test"/>
-  <classpathentry kind="src" path="cli/src/java"/>
-  <classpathentry kind="src" path="cli/src/test"/>
-  <classpathentry kind="src" path="common/src/java"/>
-  <classpathentry kind="src" path="common/src/test"/>
-  <classpathentry kind="src" path="contrib/src/java"/>
-  <classpathentry kind="src" path="contrib/src/test"/>
-  <classpathentry kind="src" path="hbase-handler/src/java"/>
-  <classpathentry kind="src" path="hwi/src/java"/>
-  <classpathentry kind="src" path="hwi/src/test"/>
-  <classpathentry kind="src" path="jdbc/src/java"/>
-  <classpathentry kind="src" path="jdbc/src/test"/>
-  <classpathentry kind="src" path="metastore/src/gen/thrift/gen-javabean"/>
-  <classpathentry kind="src" path="metastore/src/java"/>
-  <classpathentry kind="src" path="metastore/src/model"/>
-  <classpathentry kind="src" path="metastore/src/test"/>
-  <classpathentry kind="src" path="ql/src/gen/thrift/gen-javabean"/>
-  <classpathentry kind="src" path="ql/src/gen/protobuf/gen-java"/>
-  <classpathentry kind="src" path="ql/src/java"/>
-  <classpathentry kind="src" path="ql/src/test"/>
-  <classpathentry kind="src" path="serde/src/gen/thrift/gen-javabean"/>
-  <classpathentry kind="src" path="serde/src/gen/protobuf/gen-java"/>
-  <classpathentry kind="src" path="serde/src/java"/>
-  <classpathentry kind="src" path="serde/src/test"/>
-  <classpathentry kind="src" path="service/src/gen/thrift/gen-javabean"/>
-  <classpathentry kind="src" path="service/src/java"/>
-  <classpathentry kind="src" path="service/src/test"/>
-  <classpathentry kind="src" path="shims/src/@HADOOPVERPREF@/java"/>
-  <classpathentry kind="src" path="shims/src/common/java"/>
-  <classpathentry excluding="queries/|results/|templates/" kind="src" path="hbase-handler/src/test"/>
-  <classpathentry kind="src" path="testutils/src/java"/>
-  <classpathentry kind="output" path="build/eclipse-classes"/>
-</classpath>
diff --git a/src/eclipse-templates/.classpath._hbase b/src/eclipse-templates/.classpath._hbase
deleted file mode 100644
index 758ce95..0000000
--- a/src/eclipse-templates/.classpath._hbase
+++ /dev/null
@@ -1,76 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<classpath>
-	<classpathentry exported="true" kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER"/>
-	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/hadoop-@HADOOPVER@-core.jar"/>
-	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/hadoop-@HADOOPVER@-test.jar"/>
-	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/lib/@SERVLETAPIJAR@"/>
-	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/lib/@JETTYJAR@"/>
-	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/lib/@JETTYUTILJAR@"/>
-	<classpathentry exported="true" kind="lib" path="cli/lib/jline-@jline.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/json.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/commons-cli-@commons-cli.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/commons-codec-@commons-code.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/commons-lang-@commons-lang.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/commons-logging-@commons-logging.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/commons-logging-api-@commons-logging-api.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/derby.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/jdo-api-@jdo-api.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/datanucleus-api-jdo-@datanucleus-api-jdo.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/datanucleus-core-@datanucleus-core.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/datanucleus-rdbms-@datanucleus-rdbms.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/thrift-fb303-@thrift-fb303.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/thrift-@thrift.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="lib/log4j-@log4j.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="ql/lib/antlr-@antlr.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="ql/lib/antlr-runtime-@antlr-runtime.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="testlibs/junit-@junit.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="stats/lib/hbase-@hbase.version@.jar"/>
-	<classpathentry exported="true" kind="lib" path="stats/lib/hbase-@hbase-test.version@-test.jar"/>
-	<classpathentry exported="true" kind="lib" path="stats/lib/zookeeper-@zookeeper.version@.jar"/>
-	<classpathentry kind="src" path="build/ql/gen-javabean"/>
-	<classpathentry kind="src" path="build/contrib/test/src"/>
-	<classpathentry kind="src" path="build/ql/test/src"/>
-	<classpathentry kind="src" path="cli/src/java"/>
-	<classpathentry kind="src" path="common/src/java"/>
-	<classpathentry kind="src" path="contrib/src/java"/>
-	<classpathentry kind="src" path="contrib/src/test"/>
-	<classpathentry kind="src" path="metastore/src/gen-javabean"/>
-	<classpathentry kind="src" path="metastore/src/java"/>
-	<classpathentry kind="src" path="metastore/src/model"/>
-	<classpathentry kind="src" path="metastore/src/test"/>
-	<classpathentry kind="src" path="ql/src/gen-javabean"/>
-	<classpathentry kind="src" path="ql/src/java"/>
-	<classpathentry kind="src" path="ql/src/test"/>
-	<classpathentry kind="src" path="serde/src/gen-javabean"/>
-        <classpathentry kind="src" path="serde/src/gen-java"/>
-	<classpathentry kind="src" path="serde/src/java"/>
-	<classpathentry kind="src" path="serde/src/test"/>
-	<classpathentry kind="src" path="service/src/gen-javabean"/>
-	<classpathentry kind="src" path="service/src/java"/>
-	<classpathentry kind="src" path="service/src/test"/>
-	<classpathentry kind="src" path="jdbc/src/java"/>
-	<classpathentry kind="src" path="jdbc/src/test"/>
-	<classpathentry kind="src" path="shims/src/@HADOOPVERPREF@/java"/>
-	<classpathentry kind="src" path="shims/src/common/java"/>
-	<classpathentry kind="src" path="hbase-handler/src/java"/>
-        <classpathentry kind="src" path="hwi/src/java"/>
-	<classpathentry kind="src" path="hwi/src/test"/>
-        <classpathentry kind="output" path="build/eclipse-classes"/>
-</classpath>
diff --git a/src/eclipse-templates/.externalToolBuilders/Hive_Ant_Builder.launch b/src/eclipse-templates/.externalToolBuilders/Hive_Ant_Builder.launch
deleted file mode 100644
index b9b711d..0000000
--- a/src/eclipse-templates/.externalToolBuilders/Hive_Ant_Builder.launch
+++ /dev/null
@@ -1,40 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" standalone="no"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.ant.AntBuilderLaunchConfigurationType">
-<stringAttribute key="org.eclipse.ant.ui.ATTR_ANT_AUTO_TARGETS" value="package,"/>
-<stringAttribute key="org.eclipse.ant.ui.ATTR_ANT_CLEAN_TARGETS" value="clean-test,clean,"/>
-<stringAttribute key="org.eclipse.ant.ui.ATTR_ANT_MANUAL_TARGETS" value="package,"/>
-<booleanAttribute key="org.eclipse.ant.ui.ATTR_TARGETS_UPDATED" value="true"/>
-<booleanAttribute key="org.eclipse.ant.ui.DEFAULT_VM_INSTALL" value="false"/>
-<stringAttribute key="org.eclipse.debug.core.ATTR_REFRESH_SCOPE" value="${project}"/>
-<listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_PATHS">
-<listEntry value="/@PROJECT@/build.xml"/>
-</listAttribute>
-<listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_TYPES">
-<listEntry value="1"/>
-</listAttribute>
-<booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="true"/>
-<booleanAttribute key="org.eclipse.debug.ui.ATTR_LAUNCH_IN_BACKGROUND" value="false"/>
-<stringAttribute key="org.eclipse.jdt.launching.CLASSPATH_PROVIDER" value="org.eclipse.ant.ui.AntClasspathProvider"/>
-<booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="true"/>
-<stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-<stringAttribute key="org.eclipse.ui.externaltools.ATTR_LOCATION" value="${workspace_loc:/@PROJECT@/build.xml}"/>
-<stringAttribute key="org.eclipse.ui.externaltools.ATTR_RUN_BUILD_KINDS" value="incremental,auto,clean"/>
-<booleanAttribute key="org.eclipse.ui.externaltools.ATTR_TRIGGERS_CONFIGURED" value="true"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/.project b/src/eclipse-templates/.project
deleted file mode 100644
index b47323c..0000000
--- a/src/eclipse-templates/.project
+++ /dev/null
@@ -1,45 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<projectDescription>
-	<name>@PROJECT@</name>
-	<comment></comment>
-	<projects>
-	</projects>
-	<buildSpec>
-		<buildCommand>
-			<name>org.eclipse.jdt.core.javabuilder</name>
-			<arguments>
-			</arguments>
-		</buildCommand>
-		<buildCommand>
-			<name>org.eclipse.ui.externaltools.ExternalToolBuilder</name>
-			<triggers>auto,clean,incremental,</triggers>
-			<arguments>
-				<dictionary>
-					<key>LaunchConfigHandle</key>
-					<value>&lt;project&gt;/.externalToolBuilders/Hive_Ant_Builder.launch</value>
-				</dictionary>
-			</arguments>
-		</buildCommand>
-
-	</buildSpec>
-	<natures>
-		<nature>org.eclipse.jdt.core.javanature</nature>
-	</natures>
-</projectDescription>
diff --git a/src/eclipse-templates/.settings/org.eclipse.jdt.core.prefs b/src/eclipse-templates/.settings/org.eclipse.jdt.core.prefs
deleted file mode 100644
index c345ec8..0000000
--- a/src/eclipse-templates/.settings/org.eclipse.jdt.core.prefs
+++ /dev/null
@@ -1,276 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one
-# or more contributor license agreements.  See the NOTICE file
-# distributed with this work for additional information
-# regarding copyright ownership.  The ASF licenses this file
-# to you under the Apache License, Version 2.0 (the
-# "License"); you may not use this file except in compliance
-# with the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
-#Sat Feb 13 22:33:52 PST 2010
-eclipse.preferences.version=1
-org.eclipse.jdt.core.formatter.align_type_members_on_columns=false
-org.eclipse.jdt.core.formatter.alignment_for_arguments_in_allocation_expression=16
-org.eclipse.jdt.core.formatter.alignment_for_arguments_in_enum_constant=16
-org.eclipse.jdt.core.formatter.alignment_for_arguments_in_explicit_constructor_call=16
-org.eclipse.jdt.core.formatter.alignment_for_arguments_in_method_invocation=16
-org.eclipse.jdt.core.formatter.alignment_for_arguments_in_qualified_allocation_expression=16
-org.eclipse.jdt.core.formatter.alignment_for_assignment=0
-org.eclipse.jdt.core.formatter.alignment_for_binary_expression=16
-org.eclipse.jdt.core.formatter.alignment_for_compact_if=16
-org.eclipse.jdt.core.formatter.alignment_for_conditional_expression=80
-org.eclipse.jdt.core.formatter.alignment_for_enum_constants=0
-org.eclipse.jdt.core.formatter.alignment_for_expressions_in_array_initializer=16
-org.eclipse.jdt.core.formatter.alignment_for_multiple_fields=16
-org.eclipse.jdt.core.formatter.alignment_for_parameters_in_constructor_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_parameters_in_method_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_selector_in_method_invocation=16
-org.eclipse.jdt.core.formatter.alignment_for_superclass_in_type_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_superinterfaces_in_enum_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_superinterfaces_in_type_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_throws_clause_in_constructor_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_throws_clause_in_method_declaration=16
-org.eclipse.jdt.core.formatter.blank_lines_after_imports=1
-org.eclipse.jdt.core.formatter.blank_lines_after_package=1
-org.eclipse.jdt.core.formatter.blank_lines_before_field=0
-org.eclipse.jdt.core.formatter.blank_lines_before_first_class_body_declaration=0
-org.eclipse.jdt.core.formatter.blank_lines_before_imports=1
-org.eclipse.jdt.core.formatter.blank_lines_before_member_type=1
-org.eclipse.jdt.core.formatter.blank_lines_before_method=1
-org.eclipse.jdt.core.formatter.blank_lines_before_new_chunk=1
-org.eclipse.jdt.core.formatter.blank_lines_before_package=0
-org.eclipse.jdt.core.formatter.blank_lines_between_import_groups=1
-org.eclipse.jdt.core.formatter.blank_lines_between_type_declarations=1
-org.eclipse.jdt.core.formatter.brace_position_for_annotation_type_declaration=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_anonymous_type_declaration=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_array_initializer=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_block=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_block_in_case=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_constructor_declaration=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_enum_constant=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_enum_declaration=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_method_declaration=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_switch=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_type_declaration=end_of_line
-org.eclipse.jdt.core.formatter.comment.clear_blank_lines_in_block_comment=false
-org.eclipse.jdt.core.formatter.comment.clear_blank_lines_in_javadoc_comment=false
-org.eclipse.jdt.core.formatter.comment.format_block_comments=true
-org.eclipse.jdt.core.formatter.comment.format_header=false
-org.eclipse.jdt.core.formatter.comment.format_html=true
-org.eclipse.jdt.core.formatter.comment.format_javadoc_comments=true
-org.eclipse.jdt.core.formatter.comment.format_line_comments=true
-org.eclipse.jdt.core.formatter.comment.format_source_code=true
-org.eclipse.jdt.core.formatter.comment.indent_parameter_description=true
-org.eclipse.jdt.core.formatter.comment.indent_root_tags=true
-org.eclipse.jdt.core.formatter.comment.insert_new_line_before_root_tags=insert
-org.eclipse.jdt.core.formatter.comment.insert_new_line_for_parameter=insert
-org.eclipse.jdt.core.formatter.comment.line_length=100
-org.eclipse.jdt.core.formatter.compact_else_if=true
-org.eclipse.jdt.core.formatter.continuation_indentation=2
-org.eclipse.jdt.core.formatter.continuation_indentation_for_array_initializer=2
-org.eclipse.jdt.core.formatter.format_guardian_clause_on_one_line=false
-org.eclipse.jdt.core.formatter.indent_body_declarations_compare_to_annotation_declaration_header=true
-org.eclipse.jdt.core.formatter.indent_body_declarations_compare_to_enum_constant_header=true
-org.eclipse.jdt.core.formatter.indent_body_declarations_compare_to_enum_declaration_header=true
-org.eclipse.jdt.core.formatter.indent_body_declarations_compare_to_type_header=true
-org.eclipse.jdt.core.formatter.indent_breaks_compare_to_cases=true
-org.eclipse.jdt.core.formatter.indent_empty_lines=false
-org.eclipse.jdt.core.formatter.indent_statements_compare_to_block=true
-org.eclipse.jdt.core.formatter.indent_statements_compare_to_body=true
-org.eclipse.jdt.core.formatter.indent_switchstatements_compare_to_cases=true
-org.eclipse.jdt.core.formatter.indent_switchstatements_compare_to_switch=false
-org.eclipse.jdt.core.formatter.indentation.size=2
-org.eclipse.jdt.core.formatter.insert_new_line_after_annotation_on_local_variable=insert
-org.eclipse.jdt.core.formatter.insert_new_line_after_annotation_on_member=insert
-org.eclipse.jdt.core.formatter.insert_new_line_after_annotation_on_parameter=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_after_opening_brace_in_array_initializer=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_at_end_of_file_if_missing=insert
-org.eclipse.jdt.core.formatter.insert_new_line_before_catch_in_try_statement=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_before_closing_brace_in_array_initializer=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_before_else_in_if_statement=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_before_finally_in_try_statement=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_before_while_in_do_statement=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_annotation_declaration=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_anonymous_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_block=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_enum_constant=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_enum_declaration=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_method_body=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_after_and_in_type_parameter=insert
-org.eclipse.jdt.core.formatter.insert_space_after_assignment_operator=insert
-org.eclipse.jdt.core.formatter.insert_space_after_at_in_annotation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_at_in_annotation_type_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_binary_operator=insert
-org.eclipse.jdt.core.formatter.insert_space_after_closing_angle_bracket_in_type_arguments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_closing_angle_bracket_in_type_parameters=insert
-org.eclipse.jdt.core.formatter.insert_space_after_closing_brace_in_block=insert
-org.eclipse.jdt.core.formatter.insert_space_after_closing_paren_in_cast=insert
-org.eclipse.jdt.core.formatter.insert_space_after_colon_in_assert=insert
-org.eclipse.jdt.core.formatter.insert_space_after_colon_in_case=insert
-org.eclipse.jdt.core.formatter.insert_space_after_colon_in_conditional=insert
-org.eclipse.jdt.core.formatter.insert_space_after_colon_in_for=insert
-org.eclipse.jdt.core.formatter.insert_space_after_colon_in_labeled_statement=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_allocation_expression=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_annotation=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_array_initializer=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_constructor_declaration_parameters=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_constructor_declaration_throws=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_enum_constant_arguments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_enum_declarations=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_explicitconstructorcall_arguments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_for_increments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_for_inits=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_method_declaration_parameters=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_method_declaration_throws=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_method_invocation_arguments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_multiple_field_declarations=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_multiple_local_declarations=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_parameterized_type_reference=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_superinterfaces=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_type_arguments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_type_parameters=insert
-org.eclipse.jdt.core.formatter.insert_space_after_ellipsis=insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_angle_bracket_in_parameterized_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_angle_bracket_in_type_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_angle_bracket_in_type_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_brace_in_array_initializer=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_bracket_in_array_allocation_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_bracket_in_array_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_annotation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_cast=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_catch=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_constructor_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_enum_constant=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_for=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_if=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_method_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_method_invocation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_parenthesized_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_switch=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_synchronized=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_while=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_postfix_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_prefix_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_question_in_conditional=insert
-org.eclipse.jdt.core.formatter.insert_space_after_question_in_wildcard=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_semicolon_in_for=insert
-org.eclipse.jdt.core.formatter.insert_space_after_unary_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_and_in_type_parameter=insert
-org.eclipse.jdt.core.formatter.insert_space_before_assignment_operator=insert
-org.eclipse.jdt.core.formatter.insert_space_before_at_in_annotation_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_binary_operator=insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_angle_bracket_in_parameterized_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_angle_bracket_in_type_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_angle_bracket_in_type_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_brace_in_array_initializer=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_bracket_in_array_allocation_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_bracket_in_array_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_annotation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_cast=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_catch=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_constructor_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_enum_constant=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_for=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_if=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_method_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_method_invocation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_parenthesized_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_switch=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_synchronized=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_while=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_assert=insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_case=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_conditional=insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_default=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_for=insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_labeled_statement=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_allocation_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_annotation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_array_initializer=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_constructor_declaration_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_constructor_declaration_throws=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_enum_constant_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_enum_declarations=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_explicitconstructorcall_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_for_increments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_for_inits=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_method_declaration_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_method_declaration_throws=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_method_invocation_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_multiple_field_declarations=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_multiple_local_declarations=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_parameterized_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_superinterfaces=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_type_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_type_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_ellipsis=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_angle_bracket_in_parameterized_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_angle_bracket_in_type_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_angle_bracket_in_type_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_annotation_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_anonymous_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_array_initializer=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_block=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_constructor_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_enum_constant=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_enum_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_method_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_switch=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_bracket_in_array_allocation_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_bracket_in_array_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_bracket_in_array_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_annotation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_annotation_type_member_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_catch=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_constructor_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_enum_constant=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_for=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_if=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_method_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_method_invocation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_parenthesized_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_switch=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_synchronized=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_while=insert
-org.eclipse.jdt.core.formatter.insert_space_before_parenthesized_expression_in_return=insert
-org.eclipse.jdt.core.formatter.insert_space_before_parenthesized_expression_in_throw=insert
-org.eclipse.jdt.core.formatter.insert_space_before_postfix_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_prefix_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_question_in_conditional=insert
-org.eclipse.jdt.core.formatter.insert_space_before_question_in_wildcard=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_semicolon=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_semicolon_in_for=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_unary_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_brackets_in_array_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_braces_in_array_initializer=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_brackets_in_array_allocation_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_parens_in_annotation_type_member_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_parens_in_constructor_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_parens_in_enum_constant=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_parens_in_method_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_parens_in_method_invocation=do not insert
-org.eclipse.jdt.core.formatter.join_lines_in_comments=false
-org.eclipse.jdt.core.formatter.join_wrapped_lines=false
-org.eclipse.jdt.core.formatter.keep_else_statement_on_same_line=false
-org.eclipse.jdt.core.formatter.keep_empty_array_initializer_on_one_line=false
-org.eclipse.jdt.core.formatter.keep_imple_if_on_one_line=false
-org.eclipse.jdt.core.formatter.keep_then_statement_on_same_line=false
-org.eclipse.jdt.core.formatter.lineSplit=100
-org.eclipse.jdt.core.formatter.never_indent_block_comments_on_first_column=false
-org.eclipse.jdt.core.formatter.never_indent_line_comments_on_first_column=false
-org.eclipse.jdt.core.formatter.number_of_blank_lines_at_beginning_of_method_body=0
-org.eclipse.jdt.core.formatter.number_of_empty_lines_to_preserve=30
-org.eclipse.jdt.core.formatter.put_empty_statement_on_new_line=true
-org.eclipse.jdt.core.formatter.tabulation.char=space
-org.eclipse.jdt.core.formatter.tabulation.size=2
-org.eclipse.jdt.core.formatter.use_tabs_only_for_leading_indentations=false
-org.eclipse.jdt.core.formatter.wrap_before_binary_operator=true
diff --git a/src/eclipse-templates/.settings/org.eclipse.jdt.ui.prefs b/src/eclipse-templates/.settings/org.eclipse.jdt.ui.prefs
deleted file mode 100644
index 12c3600..0000000
--- a/src/eclipse-templates/.settings/org.eclipse.jdt.ui.prefs
+++ /dev/null
@@ -1,126 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one
-# or more contributor license agreements.  See the NOTICE file
-# distributed with this work for additional information
-# regarding copyright ownership.  The ASF licenses this file
-# to you under the Apache License, Version 2.0 (the
-# "License"); you may not use this file except in compliance
-# with the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
-#Sat Feb 13 22:33:52 PST 2010
-cleanup.add_default_serial_version_id=true
-cleanup.add_generated_serial_version_id=false
-cleanup.add_missing_annotations=true
-cleanup.add_missing_deprecated_annotations=true
-cleanup.add_missing_methods=false
-cleanup.add_missing_nls_tags=false
-cleanup.add_missing_override_annotations=true
-cleanup.add_serial_version_id=false
-cleanup.always_use_blocks=true
-cleanup.always_use_parentheses_in_expressions=false
-cleanup.always_use_this_for_non_static_field_access=false
-cleanup.always_use_this_for_non_static_method_access=false
-cleanup.convert_to_enhanced_for_loop=true
-cleanup.correct_indentation=true
-cleanup.format_source_code=true
-cleanup.format_source_code_changes_only=false
-cleanup.make_local_variable_final=true
-cleanup.make_parameters_final=false
-cleanup.make_private_fields_final=true
-cleanup.make_type_abstract_if_missing_method=false
-cleanup.make_variable_declarations_final=false
-cleanup.never_use_blocks=false
-cleanup.never_use_parentheses_in_expressions=true
-cleanup.organize_imports=true
-cleanup.qualify_static_field_accesses_with_declaring_class=false
-cleanup.qualify_static_member_accesses_through_instances_with_declaring_class=true
-cleanup.qualify_static_member_accesses_through_subtypes_with_declaring_class=true
-cleanup.qualify_static_member_accesses_with_declaring_class=true
-cleanup.qualify_static_method_accesses_with_declaring_class=false
-cleanup.remove_private_constructors=true
-cleanup.remove_trailing_whitespaces=true
-cleanup.remove_trailing_whitespaces_all=true
-cleanup.remove_trailing_whitespaces_ignore_empty=false
-cleanup.remove_unnecessary_casts=false
-cleanup.remove_unnecessary_nls_tags=true
-cleanup.remove_unused_imports=true
-cleanup.remove_unused_local_variables=true
-cleanup.remove_unused_private_fields=true
-cleanup.remove_unused_private_members=false
-cleanup.remove_unused_private_methods=true
-cleanup.remove_unused_private_types=true
-cleanup.sort_members=false
-cleanup.sort_members_all=false
-cleanup.use_blocks=true
-cleanup.use_blocks_only_for_return_and_throw=false
-cleanup.use_parentheses_in_expressions=false
-cleanup.use_this_for_non_static_field_access=true
-cleanup.use_this_for_non_static_field_access_only_if_necessary=true
-cleanup.use_this_for_non_static_method_access=true
-cleanup.use_this_for_non_static_method_access_only_if_necessary=true
-cleanup_profile=_Apache Hive Cleanup
-cleanup_settings_version=2
-eclipse.preferences.version=1
-editor_save_participant_org.eclipse.jdt.ui.postsavelistener.cleanup=true
-formatter_profile=_Apache Hive Formatter
-formatter_settings_version=11
-org.eclipse.jdt.ui.javadoc=false
-org.eclipse.jdt.ui.text.custom_code_templates=<?xml version\="1.0" encoding\="UTF-8" standalone\="no"?><templates><template autoinsert\="true" context\="gettercomment_context" deleted\="false" description\="Comment for getter method" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.gettercomment" name\="gettercomment">/**\n * @return the ${bare_field_name}\n */</template><template autoinsert\="true" context\="settercomment_context" deleted\="false" description\="Comment for setter method" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.settercomment" name\="settercomment">/**\n * @param ${param} the ${bare_field_name} to set\n */</template><template autoinsert\="true" context\="constructorcomment_context" deleted\="false" description\="Comment for created constructors" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.constructorcomment" name\="constructorcomment">/**\n * ${tags}\n */</template><template autoinsert\="false" context\="filecomment_context" deleted\="false" description\="Comment for created Java files" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.filecomment" name\="filecomment">/**\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * "License"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http\://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an "AS IS" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n</template><template autoinsert\="false" context\="typecomment_context" deleted\="false" description\="Comment for created types" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.typecomment" name\="typecomment">/**\n * ${type_name}.\n *\n * ${tags}\n */</template><template autoinsert\="true" context\="fieldcomment_context" deleted\="false" description\="Comment for fields" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.fieldcomment" name\="fieldcomment">/**\n * \n */</template><template autoinsert\="true" context\="methodcomment_context" deleted\="false" description\="Comment for non-overriding methods" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.methodcomment" name\="methodcomment">/**\n * ${tags}\n */</template><template autoinsert\="true" context\="overridecomment_context" deleted\="false" description\="Comment for overriding methods" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.overridecomment" name\="overridecomment">/* (non-Javadoc)\n * ${see_to_overridden}\n */</template><template autoinsert\="true" context\="delegatecomment_context" deleted\="false" description\="Comment for delegate methods" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.delegatecomment" name\="delegatecomment">/**\n * ${tags}\n * ${see_to_target}\n */</template><template autoinsert\="true" context\="newtype_context" deleted\="false" description\="Newly created files" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.newtype" name\="newtype">${filecomment}\n${package_declaration}\n\n${typecomment}\n${type_declaration}</template><template autoinsert\="true" context\="classbody_context" deleted\="false" description\="Code in new class type bodies" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.classbody" name\="classbody">\n</template><template autoinsert\="true" context\="interfacebody_context" deleted\="false" description\="Code in new interface type bodies" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.interfacebody" name\="interfacebody">\n</template><template autoinsert\="true" context\="enumbody_context" deleted\="false" description\="Code in new enum type bodies" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.enumbody" name\="enumbody">\n</template><template autoinsert\="true" context\="annotationbody_context" deleted\="false" description\="Code in new annotation type bodies" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.annotationbody" name\="annotationbody">\n</template><template autoinsert\="true" context\="catchblock_context" deleted\="false" description\="Code in new catch blocks" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.catchblock" name\="catchblock">// ${todo} Auto-generated catch block\n${exception_var}.printStackTrace();</template><template autoinsert\="true" context\="methodbody_context" deleted\="false" description\="Code in created method stubs" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.methodbody" name\="methodbody">// ${todo} Auto-generated method stub\n${body_statement}</template><template autoinsert\="true" context\="constructorbody_context" deleted\="false" description\="Code in created constructor stubs" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.constructorbody" name\="constructorbody">${body_statement}\n// ${todo} Auto-generated constructor stub</template><template autoinsert\="true" context\="getterbody_context" deleted\="false" description\="Code in created getters" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.getterbody" name\="getterbody">return ${field};</template><template autoinsert\="true" context\="setterbody_context" deleted\="false" description\="Code in created setters" enabled\="true" id\="org.eclipse.jdt.ui.text.codetemplates.setterbody" name\="setterbody">${field} \= ${param};</template></templates>
-sp_cleanup.add_default_serial_version_id=true
-sp_cleanup.add_generated_serial_version_id=false
-sp_cleanup.add_missing_annotations=true
-sp_cleanup.add_missing_deprecated_annotations=true
-sp_cleanup.add_missing_methods=false
-sp_cleanup.add_missing_nls_tags=false
-sp_cleanup.add_missing_override_annotations=true
-sp_cleanup.add_serial_version_id=false
-sp_cleanup.always_use_blocks=true
-sp_cleanup.always_use_parentheses_in_expressions=false
-sp_cleanup.always_use_this_for_non_static_field_access=false
-sp_cleanup.always_use_this_for_non_static_method_access=false
-sp_cleanup.convert_to_enhanced_for_loop=false
-sp_cleanup.correct_indentation=false
-sp_cleanup.format_source_code=false
-sp_cleanup.format_source_code_changes_only=false
-sp_cleanup.make_local_variable_final=false
-sp_cleanup.make_parameters_final=false
-sp_cleanup.make_private_fields_final=true
-sp_cleanup.make_type_abstract_if_missing_method=false
-sp_cleanup.make_variable_declarations_final=true
-sp_cleanup.never_use_blocks=false
-sp_cleanup.never_use_parentheses_in_expressions=true
-sp_cleanup.on_save_use_additional_actions=true
-sp_cleanup.organize_imports=true
-sp_cleanup.qualify_static_field_accesses_with_declaring_class=false
-sp_cleanup.qualify_static_member_accesses_through_instances_with_declaring_class=true
-sp_cleanup.qualify_static_member_accesses_through_subtypes_with_declaring_class=true
-sp_cleanup.qualify_static_member_accesses_with_declaring_class=false
-sp_cleanup.qualify_static_method_accesses_with_declaring_class=false
-sp_cleanup.remove_private_constructors=true
-sp_cleanup.remove_trailing_whitespaces=true
-sp_cleanup.remove_trailing_whitespaces_all=true
-sp_cleanup.remove_trailing_whitespaces_ignore_empty=false
-sp_cleanup.remove_unnecessary_casts=false
-sp_cleanup.remove_unnecessary_nls_tags=false
-sp_cleanup.remove_unused_imports=true
-sp_cleanup.remove_unused_local_variables=false
-sp_cleanup.remove_unused_private_fields=true
-sp_cleanup.remove_unused_private_members=false
-sp_cleanup.remove_unused_private_methods=true
-sp_cleanup.remove_unused_private_types=true
-sp_cleanup.sort_members=false
-sp_cleanup.sort_members_all=false
-sp_cleanup.use_blocks=true
-sp_cleanup.use_blocks_only_for_return_and_throw=false
-sp_cleanup.use_parentheses_in_expressions=false
-sp_cleanup.use_this_for_non_static_field_access=false
-sp_cleanup.use_this_for_non_static_field_access_only_if_necessary=true
-sp_cleanup.use_this_for_non_static_method_access=false
-sp_cleanup.use_this_for_non_static_method_access_only_if_necessary=true
diff --git a/src/eclipse-templates/BeeLine.launchtemplate b/src/eclipse-templates/BeeLine.launchtemplate
deleted file mode 100644
index 799b1e2..0000000
--- a/src/eclipse-templates/BeeLine.launchtemplate
+++ /dev/null
@@ -1,51 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" standalone="no"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.launching.localJavaApplication">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-
-  <listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_PATHS">
-    <listEntry value="/hive/jdbc/src/java/org/apache/hive/cli/beeline/BeeLine.java"/>
-  </listAttribute>
-
-  <listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_TYPES">
-    <listEntry value="1"/>
-  </listAttribute>
-
-    <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/common/src/java/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/cli/hive-cli-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/ql/hive-exec-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-
-
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hive.cli.beeline.BeeLine"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-    value="-Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@"/>
-
-</launchConfiguration>
diff --git a/src/eclipse-templates/HiveCLI.launchtemplate b/src/eclipse-templates/HiveCLI.launchtemplate
deleted file mode 100644
index 507a225..0000000
--- a/src/eclipse-templates/HiveCLI.launchtemplate
+++ /dev/null
@@ -1,50 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" standalone="no"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.launching.localJavaApplication">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-
-  <listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_PATHS">
-    <listEntry value="/hive/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java"/>
-  </listAttribute>
-
-  <listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_TYPES">
-    <listEntry value="1"/>
-  </listAttribute>
-
-    <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/common/src/java/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/ql/hive-exec-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-
-
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.cli.CliDriver"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-    value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@"/>
-
-</launchConfiguration>
diff --git a/src/eclipse-templates/HiveServer.launchtemplate b/src/eclipse-templates/HiveServer.launchtemplate
deleted file mode 100644
index a550c6f..0000000
--- a/src/eclipse-templates/HiveServer.launchtemplate
+++ /dev/null
@@ -1,50 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" standalone="no"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.launching.localJavaApplication">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-
-  <listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_PATHS">
-    <listEntry value="/hive/service/src/java/org/apache/hadoop/hive/service/HiveServer.java"/>
-  </listAttribute>
-
-  <listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_TYPES">
-    <listEntry value="1"/>
-  </listAttribute>
-
-    <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/common/src/java/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/ql/hive-exec-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-
-
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.service.HiveServer"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-    value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@"/>
-
-</launchConfiguration>
diff --git a/src/eclipse-templates/HiveServer2.launchtemplate b/src/eclipse-templates/HiveServer2.launchtemplate
deleted file mode 100644
index 10f04ab..0000000
--- a/src/eclipse-templates/HiveServer2.launchtemplate
+++ /dev/null
@@ -1,50 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" standalone="no"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.launching.localJavaApplication">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-
-  <listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_PATHS">
-    <listEntry value="/hive/service/src/java/org/apache/hive/service/server/HiveServer2.java"/>
-  </listAttribute>
-
-  <listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_TYPES">
-    <listEntry value="1"/>
-  </listAttribute>
-
-    <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/common/src/java/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/ql/hive-exec-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-
-
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hive.service.server.HiveServer2"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-    value="-Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@"/>
-
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestBeeLineDriver.launchtemplate b/src/eclipse-templates/TestBeeLineDriver.launchtemplate
deleted file mode 100644
index 36842fd..0000000
--- a/src/eclipse-templates/TestBeeLineDriver.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hive.cli.beeline.TestBeeLineDriver"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dtest.warehouse.dir=&quot;pfile://${workspace_loc:@PROJECT@}/build/test/data/warehouse&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestCliDriver.launchtemplate b/src/eclipse-templates/TestCliDriver.launchtemplate
deleted file mode 100644
index 2db3456..0000000
--- a/src/eclipse-templates/TestCliDriver.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.cli.TestCliDriver"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dtest.warehouse.dir=&quot;pfile://${workspace_loc:@PROJECT@}/build/test/data/warehouse&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestEmbeddedHiveMetaStore.launchtemplate b/src/eclipse-templates/TestEmbeddedHiveMetaStore.launchtemplate
deleted file mode 100644
index 3dc1010..0000000
--- a/src/eclipse-templates/TestEmbeddedHiveMetaStore.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dtest.warehouse.dir=&quot;pfile://${workspace_loc:@PROJECT@}/build/test/data/warehouse&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestEmbeddedThriftCLIService.launchtemplate b/src/eclipse-templates/TestEmbeddedThriftCLIService.launchtemplate
deleted file mode 100644
index 2e63e0a..0000000
--- a/src/eclipse-templates/TestEmbeddedThriftCLIService.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit4"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hive.service.cli.TestEmbeddedThriftCLIService"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/service/tmp&quot; -Dtest.warehouse.dir=&quot;pfile://${workspace_loc:@PROJECT@}/build/test/data/warehouse&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/service&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/service"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestHBaseCliDriver.launchtemplate b/src/eclipse-templates/TestHBaseCliDriver.launchtemplate
deleted file mode 100644
index ab02c4d..0000000
--- a/src/eclipse-templates/TestHBaseCliDriver.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-0.6.0.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.cli.TestHBaseCliDriver"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestHive.launchtemplate b/src/eclipse-templates/TestHive.launchtemplate
deleted file mode 100644
index 5e68c21..0000000
--- a/src/eclipse-templates/TestHive.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.ql.metadata.TestHive"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dtest.warehouse.dir=&quot;pfile://${workspace_loc:@PROJECT@}/build/test/data/warehouse&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestHiveMetaStoreChecker.launchtemplate b/src/eclipse-templates/TestHiveMetaStoreChecker.launchtemplate
deleted file mode 100644
index 2bb9268..0000000
--- a/src/eclipse-templates/TestHiveMetaStoreChecker.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dtest.warehouse.dir=&quot;pfile://${workspace_loc:@PROJECT@}/build/test/data/warehouse&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestHiveMetaTool.launchtemplate b/src/eclipse-templates/TestHiveMetaTool.launchtemplate
deleted file mode 100644
index f6429af..0000000
--- a/src/eclipse-templates/TestHiveMetaTool.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.metastore.TestHiveMetaTool"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dtest.warehouse.dir=&quot;pfile://${workspace_loc:@PROJECT@}/build/test/data/warehouse&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestHiveServer.launchtemplate b/src/eclipse-templates/TestHiveServer.launchtemplate
deleted file mode 100644
index a930aa3..0000000
--- a/src/eclipse-templates/TestHiveServer.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.service.TestHiveServer"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="-Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dtest.warehouse.dir=&quot;pfile://${workspace_loc:@PROJECT@}/build/test/data/warehouse&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/service"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestJdbc.launchtemplate b/src/eclipse-templates/TestJdbc.launchtemplate
deleted file mode 100644
index 267f58a..0000000
--- a/src/eclipse-templates/TestJdbc.launchtemplate
+++ /dev/null
@@ -1,44 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.jdbc.TestJdbcDriver"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot; -Dtest.warehouse.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/test/data/warehouse&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
-
diff --git a/src/eclipse-templates/TestJdbc2.launchtemplate b/src/eclipse-templates/TestJdbc2.launchtemplate
deleted file mode 100644
index cacd7fd..0000000
--- a/src/eclipse-templates/TestJdbc2.launchtemplate
+++ /dev/null
@@ -1,44 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hive.jdbc.TestJdbcDriver2"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot; -Dtest.warehouse.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/test/data/warehouse&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
-
diff --git a/src/eclipse-templates/TestMTQueries.launchtemplate b/src/eclipse-templates/TestMTQueries.launchtemplate
deleted file mode 100644
index 172692e..0000000
--- a/src/eclipse-templates/TestMTQueries.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.ql.TestMTQueries"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestRemoteHiveMetaStore.launchtemplate b/src/eclipse-templates/TestRemoteHiveMetaStore.launchtemplate
deleted file mode 100644
index 81e3877..0000000
--- a/src/eclipse-templates/TestRemoteHiveMetaStore.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.metastore.TestRemoteHiveMetaStore"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dtest.warehouse.dir=&quot;pfile://${workspace_loc:@PROJECT@}/build/test/data/warehouse&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestRemoteThriftCLIService.launchtemplate b/src/eclipse-templates/TestRemoteThriftCLIService.launchtemplate
deleted file mode 100644
index d9411a5..0000000
--- a/src/eclipse-templates/TestRemoteThriftCLIService.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit4"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hive.service.cli.TestRemoteThriftCLIService"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/service/tmp&quot; -Dtest.warehouse.dir=&quot;pfile://${workspace_loc:@PROJECT@}/build/test/data/warehouse&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/service&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/service"/>
-</launchConfiguration>
diff --git a/src/eclipse-templates/TestTruncate.launchtemplate b/src/eclipse-templates/TestTruncate.launchtemplate
deleted file mode 100644
index 38513a5..0000000
--- a/src/eclipse-templates/TestTruncate.launchtemplate
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
- 
-      http://www.apache.org/licenses/LICENSE-2.0
- 
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
---> 
-<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
-  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
-  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
-    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
-    <mapEntry key="HIVE_HADOOP_TEST_CLASSPATH" value="@HIVE_HADOOP_TEST_CLASSPATH@"/>
-  </mapAttribute>
-  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
-  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
-  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
-  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-metastore-@HIVE_VERSION@.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
-    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
-  </listAttribute>
-  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
-  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.metastore.TestTruncate"/>
-  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
-  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS"
-                   value="@JVM_ARGS@ -Dhive.root.logger=INFO,console -Dhadoop.bin.path=@HADOOP_BIN_PATH@ -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
-  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
-</launchConfiguration>
diff --git a/src/hbase-handler/build.xml b/src/hbase-handler/build.xml
deleted file mode 100644
index 8e23a09..0000000
--- a/src/hbase-handler/build.xml
+++ /dev/null
@@ -1,82 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-
-<project name="hbase-handler" default="jar">
-
-  <property name="hbase-handler.lib.dir" value="${basedir}/lib"/>
-  <property name="src.dir"  location="${basedir}/src/java"/>
-  <property name="hbase-handler.test.query.dir" location="${basedir}/src/test/queries"/>
-  <property name="ql.test.template.dir" location="${basedir}/../ql/src/test/templates"/>
-  <property name="ql.hbase.test.template.dir" location="${basedir}/src/test/templates"/>
-  <property name="hbase-handler.test.results.dir" location="${basedir}/src/test/results"/>
-
-  <import file="../build-common.xml"/>
-
-  <target name="test-jar" depends="compile-test, jar">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete file="${test.build.dir}/test-udfs.jar"/>
-    <jar jarfile="${test.build.dir}/test-udfs.jar">
-        <fileset dir="${test.build.classes}" includes="**/udf/*.class"/>
-        <fileset dir="${test.build.classes}" includes="**/udf/generic/*.class"/>
-    </jar>
-  </target>
-
-  <target name="gen-test" depends="test-conditions, test-init" >
-    <echo message="Project: ${ant.project.name}"/>
-    <taskdef name="qtestgen" classname="org.apache.hadoop.hive.ant.QTestGenTask"
-             classpath="${build.dir.hive}/anttasks/hive-anttasks-${version}.jar:${build.ivy.lib.dir}/default/velocity-${velocity.version}.jar:${build.ivy.lib.dir}/default/commons-collections-${commons-collections.version}.jar:${build.ivy.lib.dir}/default/commons-lang-${commons-lang.version}.jar"/>
-    
-    <mkdir dir="${test.build.src}/org/apache/hadoop/hive/cli"/>
-    <mkdir dir="${test.log.dir}/hbase-handler"/>
-    <mkdir dir="${hbase-handler.test.results.dir}"/>
-
-    <qtestgen hiveRootDirectory="${hive.root}"
-              outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli" 
-              templatePath="${ql.hbase.test.template.dir}" template="TestHBaseCliDriver.vm" 
-              queryDirectory="${hbase-handler.test.query.dir}/positive" 
-              queryFile="${qfile}"
-              runDisabled="${run_disabled}"
-              clusterMode="${clustermode}"
-              resultsDirectory="${hbase-handler.test.results.dir}/positive" className="TestHBaseCliDriver"
-              logFile="${test.log.dir}/testhbaseclidrivergen.log"
-              logDirectory="${test.log.dir}/hbase-handler"/>
-    <qtestgen hiveRootDirectory="${hive.root}"
-              outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli" 
-              templatePath="${ql.hbase.test.template.dir}" template="TestHBaseCliDriver.vm" 
-              queryDirectory="${hbase-handler.test.query.dir}/positive" 
-              queryFile="hbase_bulk.m"
-              runDisabled="${run_disabled}"
-              clusterMode="miniMR"
-              resultsDirectory="${hbase-handler.test.results.dir}/positive" className="TestHBaseMinimrCliDriver"
-              logFile="${test.log.dir}/testhbaseminimrclidrivergen.log"
-              logDirectory="${test.log.dir}/hbase-handler"/>
-   <qtestgen  hiveRootDirectory="${hive.root}"
-              outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli"
-              templatePath="${ql.hbase.test.template.dir}" template="TestHBaseNegativeCliDriver.vm"
-              queryDirectory="${hbase-handler.test.query.dir}/negative"
-              queryFile="${qfile}"
-              runDisabled="${run_disabled}"
-              clusterMode="${clustermode}"
-              resultsDirectory="${hbase-handler.test.results.dir}/negative" className="TestHBaseNegativeCliDriver"
-              logFile="${test.log.dir}/testhbasenegativeclidrivergen.log"
-              logDirectory="${test.log.dir}/hbase-handler"/>
-  </target>
-
-</project>
diff --git a/src/hbase-handler/ivy.xml b/src/hbase-handler/ivy.xml
deleted file mode 100644
index 7be8649..0000000
--- a/src/hbase-handler/ivy.xml
+++ /dev/null
@@ -1,45 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0" xmlns:m="http://ant.apache.org/ivy/maven">
-  <info organisation="${hive.ivy.org}" module="hive-hbase-handler" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>  
-  <dependencies>
-    <dependency org="org.apache.hive" name="hive-exec" rev="${version}"
-                conf="compile->default" />
-    <dependency org="org.apache.hbase" name="hbase" rev="${hbase.version}"
-                transitive="false">
-      <artifact name="hbase" type="jar"/>
-      <artifact name="hbase" type="test-jar" ext="jar"
-                m:classifier="tests"/>
-    </dependency>
-    <dependency org="com.github.stephenc.high-scale-lib" name="high-scale-lib" rev="1.1.1"
-                transitive="false"/>
-    <dependency org="com.yammer.metrics" name="metrics-core" rev="${metrics-core.version}">
-      <exclude org="org.slf4j" module="slf4j-api"/><!--causes a dual slf4j presence otherwise-->
-    </dependency>
-    <dependency org="org.codehaus.jackson" name="jackson-jaxrs" rev="${jackson.version}"/>
-    <dependency org="org.codehaus.jackson" name="jackson-xc" rev="${jackson.version}"/>
-  </dependencies>
-</ivy-module>
diff --git a/src/hcatalog/build-support/ant/deploy.xml b/src/hcatalog/build-support/ant/deploy.xml
deleted file mode 100644
index 1e44178..0000000
--- a/src/hcatalog/build-support/ant/deploy.xml
+++ /dev/null
@@ -1,154 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project xmlns:artifact="artifact:org.apache.maven.artifact.ant">
-
-    <loadproperties srcfile="${path.to.basedir}/build.properties"/>
-
-    <macrodef name="_sign">
-        <attribute name="inputFile"/>
-        <sequential>
-            <echo>Signing @{inputFile}</echo>
-            <delete file="@{inputFile}.asc"/>
-            <exec executable="gpg">
-                <arg value="--armor"/>
-                <arg value="--output"/>
-                <arg value="@{inputFile}.asc"/>
-                <arg value="--passphrase"/>
-                <arg value="${gpg.passphrase}"/>
-                <arg value="--detach-sig"/>
-                <arg value="@{inputFile}"/>
-            </exec>
-        </sequential>
-    </macrodef>
-
-    <macrodef name="_mvnpublish">
-      <attribute name="module"/>
-      <attribute name="jarname" default="@{module}"/>
-      <sequential>
-        <echo message="Installing local artifact for maven : @{module}" />
-        <artifact:install file="${path.to.basedir}/../build/@{module}/hive-@{jarname}-${hive.version}.jar">
-          <artifact:pom file="${path.to.basedir}/../build/@{module}/pom.xml"/>
-          <artifact:localRepository path="${mvn.local.repo}"/>
-        </artifact:install>
-      </sequential>
-    </macrodef>
-
-    <target name="hive-mvn-publish">
-      <!-- Pick built jars for all the hive artifacts and install them to local maven cache -->
-      <_mvnpublish module="shims" />
-      <_mvnpublish module="common" />
-      <_mvnpublish module="serde" />
-      <_mvnpublish module="metastore" />
-      <_mvnpublish module="ql" jarname="exec"/>
-      <_mvnpublish module="contrib" />
-      <_mvnpublish module="service" />
-      <_mvnpublish module="cli" />
-      <_mvnpublish module="jdbc" />
-      <_mvnpublish module="beeline" />
-      <_mvnpublish module="hwi" />
-      <_mvnpublish module="hbase-handler" />
-      <_mvnpublish module="testutils" />
-    </target>
-
-    <target name="mvn-init" unless="mvn-init.complete" description="Get Maven Ant Tasks jar and deploy all Hive jars to local Maven repo">
-        <echo message="${ant.project.name}"/>
-        <get src="${mvnrepo}/org/apache/maven/maven-ant-tasks/${maven-ant-tasks.version}/maven-ant-tasks-${maven-ant-tasks.version}.jar"
-             dest="${path.to.basedir}/build/maven-ant-tasks-${maven-ant-tasks.version}.jar"
-             usetimestamp="true"
-             skipexisting="true"/>
-        <taskdef resource="org/apache/maven/artifact/ant/antlib.xml"
-                 uri="artifact:org.apache.maven.artifact.ant"
-                 classpath="${path.to.basedir}/build/maven-ant-tasks-${maven-ant-tasks.version}.jar"/>
-        <antcall target="hive-mvn-publish" />
-        <artifact:dependencies>
-            <dependency groupId="org.apache.hive.hcatalog" artifactId="hcatalog" version="${hcatalog.version}" scope="system" systemPath="${path.to.basedir}/pom.xml"/>
-            <artifact:localRepository path="${mvn.local.repo}"/>
-        </artifact:dependencies>
-        <artifact:pom id="mvn.pom" file="pom.xml">
-            <profile id="${_mvn.hadoop.profile}"/>
-            <artifact:localRepository path="${mvn.local.repo}"/>
-        </artifact:pom>
-        <property name="mvn-init.complete" value="true"/>
-    </target>
-
-    <target name="_check-mvn-dependencies" unless="mvn-dependencies.complete">
-        <available property="mvn-dependencies.complete"
-                   file="${build.dir}/lib/.mvn-dependencies.complete"/>
-    </target>
-
-    <target name="mvn-dependencies"
-            depends="mvn-init,_check-mvn-dependencies"
-            unless="mvn-dependencies.complete">
-        <echo message="${ant.project.name}"/>
-
-        <artifact:dependencies pathId="mvn.compile.classpath"
-          scopes="compile" pomRefId="mvn.pom">
-            <localRepository path="${mvn.local.repo}"/>
-        </artifact:dependencies>
-        <mkdir dir="${build.dir}/lib/compile"/>
-        <copy todir="${build.dir}/lib/compile">
-            <path refid="mvn.compile.classpath"/>
-        </copy>
-
-        <artifact:dependencies pathId="mvn.provided.classpath"
-          scopes="provided" pomRefId="mvn.pom">
-            <localRepository path="${mvn.local.repo}"/>
-        </artifact:dependencies>
-        <mkdir dir="${build.dir}/lib/provided"/>
-        <copy todir="${build.dir}/lib/provided">
-            <path refid="mvn.provided.classpath"/>
-        </copy>
-
-        <artifact:dependencies pathId="mvn.test.classpath"
-          scopes="compile, test" pomRefId="mvn.pom">
-            <localRepository path="${mvn.local.repo}"/>
-        </artifact:dependencies>
-        <mkdir dir="${build.dir}/lib/test"/>
-        <copy todir="${build.dir}/lib/test">
-            <path refid="mvn.test.classpath"/>
-        </copy>
-
-        <touch file="${build.dir}/lib/.mvn-dependencies.complete"/>
-    </target>
-
-    <target name="mvn-deploy" depends="mvn-init" description="Deploy artifacts to a Maven repository.">
-        <echo message="${ant.project.name}"/>
-        <artifact:deploy file="${build.dir}/${ant.project.name}-${hcatalog.version}.jar"
-          pomRefId="mvn.pom">
-            <remoteRepository id="${mvn.deploy.repo.id}" url="${mvn.deploy.repo.url}"/>
-        </artifact:deploy>
-    </target>
-
-    <target name="mvn-deploy-signed" depends="mvn-init"
-            description="Sign and deploy artifacts to a Maven repository.">
-        <echo message="${ant.project.name}"/>
-        <_sign inputFile="${build.dir}/${ant.project.name}-${hcatalog.version}.jar"/>
-        <_sign inputFile="${pom.file}"/>
-        <artifact:deploy file="${build.dir}/${ant.project.name}-${hcatalog.version}.jar"
-          pomRefId="mvn.pom">
-            <attach file="${build.dir}/${ant.project.name}-${hcatalog.version}.jar.asc" type="jar.asc"/>
-            <attach file="${pom.file}.asc" type="pom.asc"/>
-            <remoteRepository id="${mvn.deploy.repo.id}" url="${mvn.deploy.repo.url}"/>
-        </artifact:deploy>
-    </target>
-
-</project>
diff --git a/src/hcatalog/build-support/ant/test.xml b/src/hcatalog/build-support/ant/test.xml
deleted file mode 100644
index 28a6e8d..0000000
--- a/src/hcatalog/build-support/ant/test.xml
+++ /dev/null
@@ -1,111 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project>
-
-  <!-- By default all tests are run. To run one test define -Dtestcase=X on the command line -->
-  <macrodef name="_junit">
-    <attribute name="srcDir"/>
-    <sequential>
-      <!-- If anyone knows how to set umask inside ant please do so -->
-      <exec executable="${path.to.basedir}/build-support/scripts/umaskcheck.sh"
-            failonerror="true"/>
-
-      <delete dir="${test.logs}"/>
-      <delete dir="${test.warehouse.dir}"/>
-      <delete dir="${test.data.dir}"/>
-      <mkdir dir="${test.logs}"/>
-      <mkdir dir="${test.warehouse.dir}"/>
-      <mkdir dir="${test.data.dir}"/>
-
-      <junit showoutput="${test.output}"
-             printsummary="yes"
-             haltonfailure="no"
-             fork="yes"
-             maxmemory="512m"
-             dir="${test.dir}"
-             timeout="${test.timeout}"
-             errorProperty="tests.failed"
-             failureProperty="tests.failed">
-        <sysproperty key="hadoop.log.dir" value="${test.logs}"/>
-        <sysproperty key="hive.metastore.warehouse.dir" value="${test.warehouse.dir}"/>
-        <sysproperty key="test.data.dir" value="${test.data.dir}"/>
-        <sysproperty key="java.security.krb5.realm" value=""/> <!-- HADOOP-7489 -->
-        <sysproperty key="java.security.krb5.kdc" value=""/> <!-- HADOOP-7489 -->
-        <!--HCAT_PREFIX, HIVE_HOME are needed by WebHCat tests-->
-        <env key="HCAT_PREFIX" value="${env.HCAT_PREFIX}"/>
-        <env key="HIVE_HOME" value="${env.HIVE_HOME}"/>
-        <classpath>
-          <path refid="test.class.path"/>
-          <pathelement location="${clover.jar}"/>
-        </classpath>
-        <jvmarg line="${junit.jvm.args}"/>
-        <formatter type="${test.junit.output.format}"/>
-        <batchtest fork="yes" todir="${test.logs}" unless="testcase">
-          <fileset dir="@{srcDir}" includes="**/Test*.java"/>
-        </batchtest>
-        <batchtest fork="yes" todir="${test.logs}" if="testcase">
-          <fileset dir="@{srcDir}" includes="**/${testcase}.java"/>
-        </batchtest>
-        <assertions>
-          <enable/>
-        </assertions>
-      </junit>
-      <copy todir="${test.result.dir}">
-        <!--make sure hive's 'ant testreport' includes them-->
-        <fileset dir="${test.logs}">
-          <include name="**/TEST-*.xml"/>
-        </fileset>
-      </copy>
-      <fail if="tests.failed">Tests failed!</fail>
-    </sequential>
-  </macrodef>
-
-  <target name="clover-init">
-    <echo message="${ant.project.name}"/>
-    <available property="clover.present" file="${clover.jar}"/>
-    <fail message="'clover.home' is not defined. Please pass -Dclover.home=/path/to/clover to ant on the command-line." unless="clover.present"/>
-    <taskdef resource="cloverlib.xml" classpath="${clover.jar}"/>
-    <mkdir dir="${clover.db.dir}"/>
-    <clover-setup initString="${clover.db.dir}/hcat_coverage.db">
-      <fileset dir="src" includes="${src.dir}" excludes="**/NoExitSecurityManager.java"/>
-    </clover-setup>
-  </target>
-
-  <target name="_test-with-clover" depends="clover-init, test"
-          description="run unit tests and generate code coverage reports">
-    <echo message="${ant.project.name}"/>
-    <mkdir dir="${clover.report.dir}"/>
-      <clover-report>
-      <current outfile="${clover.report.dir}" title="${final.name}">
-        <format type="html"/>
-      </current>
-      </clover-report>
-    <clover-report>
-      <current outfile="${clover.report.dir}/clover.xml" title="${final.name}">
-        <format type="xml"/>
-      </current>
-    </clover-report>
-    <mkdir dir="${clover.pdf.report.dir}"/>
-    <clover-pdf-report outfile="${clover.pdf.report.dir}/clover_coverage.pdf" />
-  </target>
-
-</project>
diff --git a/src/hcatalog/build.xml b/src/hcatalog/build.xml
deleted file mode 100644
index af20f1a..0000000
--- a/src/hcatalog/build.xml
+++ /dev/null
@@ -1,529 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="hcatalog" default="jar"
-    xmlns:artifact="artifact:org.apache.maven.artifact.ant">
-  <!-- This build file doesn't match the Hive pattern yet so don't use their
-       definitions yet. -->
-  <!-- <import file="../build-common.xml"/> -->
-
-    <property name="path.to.basedir" location="${basedir}"/>
-    <property name="test.result.dir" location="${build.dir.hive}/hcatalog/test"
-              description="location to place TEST-*.xml files so that hive's testreport includes them"/>
-    <property name="hive.dist.dir" location="${build.dir.hive}/dist"
-            description="where all hive build artifacts are placed to make binary tar ball"/>
-    <loadproperties srcfile="${basedir}/build.properties"/>
-
-    <!--
-    ================================================================================
-    Properties and Classpaths Section
-    ================================================================================
-    -->
-
-    <condition property="staging">
-        <equals arg1="${repo}" arg2="staging"/>
-    </condition>
-
-    <!-- e2e test properties -->
-    <property name="test.e2e.dir" value="${basedir}/src/test/e2e/hcatalog"/>
-
-    <!-- packaging properties -->
-    <property name="package.prefix" value="/usr"/>
-    <property name="package.conf.dir" value="/etc/hcatalog"/>
-    <property name="package.log.dir" value="/var/log/hcatalog"/>
-    <property name="package.pid.dir" value="/var/run/hcatalog"/>
-    <property name="package.var.dir" value="/var/lib/hcatalog"/>
-    <property name="package.share.dir" value="/share/hcatalog/${module}"/>
-    <property name="package.buildroot" value="${build.dir}/rpm/hcatalog_package_build_${user.name}"/>
-    <property name="package.build.dir" value="${build.dir}/rpm/hcatalog_package_build_${user.name}/BUILD"/>
-
-    <target name="init">
-        <mkdir dir="${dist.dir}"/>
-    </target>
-
-    <!--
-    ================================================================================
-    Build all jars
-    ================================================================================
-    -->
-    <target name="jar" depends="init" description="build all jars">
-        <ant target="jar" dir="core" inheritAll="false">
-          <property name="_mvn.hadoop.profile" value="${mvn.hadoop.profile}"/>
-        </ant>
-        <ant target="jar" dir="hcatalog-pig-adapter" inheritAll="false">
-          <property name="_mvn.hadoop.profile" value="${mvn.hadoop.profile}"/>
-        </ant>
-        <ant target="jar" dir="server-extensions" inheritAll="false">
-          <property name="_mvn.hadoop.profile" value="${mvn.hadoop.profile}"/>
-        </ant>
-        <ant target="jar" dir="webhcat/svr" inheritAll="false">
-          <property name="_mvn.hadoop.profile" value="${mvn.hadoop.profile}"/>
-        </ant>
-        <ant target="jar" dir="webhcat/java-client" inheritAll="false">
-          <property name="_mvn.hadoop.profile" value="${mvn.hadoop.profile}"/>
-        </ant>
-        <ant target="jar" dir="storage-handlers/hbase" inheritAll="false">
-          <property name="_mvn.hadoop.profile" value="${mvn.hadoop.profile}"/>
-        </ant>
-    </target>
-
-    <!--
-    ================================================================================
-    Test Section
-    ================================================================================
-    -->
-
-    <target name="gen-test" description="Generate tests, a no-op for hcat"/>
-    <target name="test" depends="jar" description="run unit tests">
-      <property name="test.target.name" value="test"/>
-      <antcall target="testonly" />
-      <!-- One checkstyle run for the whole repo. Runs after junit tests
-      to piggyback on resolved jars. -->
-      <path id="checkstyle.class.path">
-          <fileset dir="core/build/lib/test"/>
-      </path>
-      <antcall target="checkstyle" inheritRefs="true"/>
-    </target>
-
-    <target name="testonly">
-        <if>
-          <not><isset property="test.target.name"/></not>
-          <then><property name="test.target.name" value="testonly"/></then>
-        </if>
-        <mkdir dir="${test.result.dir}"/>
-        <!-- Placed in a parallel structure so that the tests keep going
-             even if some fail.  Otherwise a failure in one of the earlier ant
-             call terminates the target and the rest do not run.  -->
-        <parallel threadCount="1">
-            <ant target="${test.target.name}" dir="core" inheritAll="false">
-                <property name="test.result.dir" location="${test.result.dir}"/>
-            </ant>
-            <ant target="${test.target.name}" dir="hcatalog-pig-adapter" inheritAll="false">
-                <property name="test.result.dir" location="${test.result.dir}"/>
-            </ant>
-            <ant target="${test.target.name}" dir="server-extensions" inheritAll="false">
-                <property name="test.result.dir" location="${test.result.dir}"/>
-            </ant>
-            <ant target="${test.target.name}" dir="webhcat/svr" inheritAll="false">
-                <property name="test.result.dir" location="${test.result.dir}"/>
-                <property name="env.HIVE_HOME" value="${hive.dist.dir}"/>
-                <property name="env.HCAT_PREFIX" value="${hive.dist.dir}/hcatalog"/>
-            </ant>
-            <ant target="${test.target.name}" dir="webhcat/java-client" inheritAll="false">
-                <property name="test.result.dir" location="${test.result.dir}"/>
-            </ant>
-            <ant target="${test.target.name}" dir="storage-handlers/hbase" inheritAll="false">
-                <property name="test.result.dir" location="${test.result.dir}"/>
-            </ant>
-        </parallel>
-    </target>
-
-    <target name="compile-test" depends="jar" description="compile unit tests">
-        <ant target="compile-test" dir="core" inheritAll="false"/>
-        <ant target="compile-test" dir="hcatalog-pig-adapter" inheritAll="false"/>
-        <ant target="compile-test" dir="server-extensions" inheritAll="false"/>
-        <ant target="compile-test" dir="webhcat/svr" inheritAll="false"/>
-        <ant target="compile-test" dir="webhcat/java-client" inheritAll="false"/>
-        <ant target="compile-test" dir="storage-handlers/hbase" inheritAll="false"/>
-    </target>
-
-    <target name="test-with-clover" depends="clover-init"
-            description="run unit tests and generate code coverage reports">
-        <ant target="_test-with-clover" dir="core" inheritAll="false"/>
-        <ant target="_test-with-clover" dir="hcatalog-pig-adapter" inheritAll="false"/>
-        <ant target="_test-with-clover" dir="server-extensions" inheritAll="false"/>
-        <ant target="_test-with-clover" dir="webhcat/svr" inheritAll="false"/>
-        <ant target="_test-with-clover" dir="webhcat/java-client" inheritAll="false"/>
-        <!-- storage-handlers do not have coverage as they have not
-             yet been migrated to the new build files. -->
-        <ant target="test" dir="storage-handlers/hbase" inheritAll="false"/>
-    </target>
-
-
-    <!--
-    ================================================================================
-    Findbugs Section
-    ================================================================================
-    -->
-
-    <target name="findbugs" depends="init-findbugs,jar">
-        <property name="findbugs.out.dir" value="${test.dir}/findbugs"/>
-        <property name="findbugs.exclude.file" value="${test.src.dir}/findbugsExcludeFile.xml"/>
-        <property name="findbugs.report.htmlfile"
-                  value="${findbugs.out.dir}/hcat-findbugs-report.html"/>
-        <property name="findbugs.report.xmlfile"
-                  value="${findbugs.out.dir}/hcat-findbugs-report.xml"/>
-
-        <ant target="findbugs" dir="core" inheritAll="false"/>
-        <ant target="findbugs" dir="hcatalog-pig-adapter" inheritAll="false"/>
-        <ant target="findbugs" dir="server-extensions" inheritAll="false"/>
-        <ant target="findbugs" dir="webhcat/svr" inheritAll="false"/>
-        <ant target="findbugs" dir="webhcat/java-client" inheritAll="false"/>
-    </target>
-
-    <!--
-    ================================================================================
-    Clean Section
-    ================================================================================
-    -->
-    <!-- Clean up children -->
-    <target name="clean" description="Cleanup all build artifacts">
-        <echo message="${ant.project.name}"/>
-        <delete dir="${build.dir}"/>
-        <ant target="clean" dir="core" inheritAll="false"/>
-        <ant target="clean" dir="hcatalog-pig-adapter" inheritAll="false"/>
-        <ant target="clean" dir="server-extensions" inheritAll="false"/>
-        <ant target="clean" dir="webhcat/svr" inheritAll="false"/>
-        <ant target="clean" dir="webhcat/java-client" inheritAll="false"/>
-        <ant target="clean" dir="storage-handlers/hbase" inheritAll="false"/>
-    </target>
-
-    <!-- Clean up children -->
-    <target name="clean-test" description="Cleanup test artifacts">
-        <echo message="${ant.project.name}"/>
-        <delete dir="${test.result.dir}"/>
-        <delete dir="${build.dir}"/>
-        <ant target="clean-test" dir="core" inheritAll="false"/>
-        <ant target="clean-test" dir="hcatalog-pig-adapter" inheritAll="false"/>
-        <ant target="clean-test" dir="server-extensions" inheritAll="false"/>
-        <ant target="clean-test" dir="webhcat/svr" inheritAll="false"/>
-        <ant target="clean-test" dir="webhcat/java-client" inheritAll="false"/>
-        <ant target="clean-test" dir="storage-handlers/hbase" inheritAll="false"/>
-    </target>
-
-    <!--
-    ================================================================================
-    Docs Section
-    ================================================================================
-    -->
-    <target name="docs" depends="forrest, javadoc"
-            description="Generate Javadoc and Forrest documentation">
-    </target>
-
-    <target name="forrest" if="forrest.home"
-            description="Generate forrest-based documentation. To use, specify -Dforrest.home=&lt;base of Apache Forrest installation&gt; on the command line.">
-        <exec dir="${docs.src}" executable="${forrest.home}/bin/forrest"
-              failonerror="true">
-        </exec>
-        <copy todir="${build.docs}/">
-            <fileset dir="${docs.src}/build/site/"/>
-        </copy>
-    </target>
-
-    <target name="javadoc" depends="jar" description="Generate Javadoc documentation" unless="skip.javadoc">
-        <mkdir dir="${build.javadoc}"/>
-        <record name="${build.dir}/javadoc.log" action="start"/>
-        <!--NOTE: old org.apache.hcatalog is intentionally excluded since 0.11 
-        version of the JavaDocs is available online-->
-        <javadoc overview="${src.dir}/../docs/overview.html"
-                 packagenames="org.apache.hive.hcatalog.*" 
-                 destdir="${build.javadoc}"
-                 author="true"
-                 version="true"
-                 use="true"
-                 noqualifier="all"
-                 windowtitle="HCatalog ${hcatalog.version} API"
-                 doctitle="HCatalog ${hcatalog.version} API"
-                 failonerror="true"
-                 useexternalfile="yes">
-            <packageset dir="core/src/main/java"/>
-            <packageset dir="hcatalog-pig-adapter/src/main/java"/>
-            <packageset dir="server-extensions/src/main/java"/>
-            <packageset dir="storage-handlers/hbase/src/gen-java"/>
-            <packageset dir="storage-handlers/hbase/src/java"/>
-            <packageset dir="webhcat/svr/src/main/java"/>
-            <packageset dir="webhcat/java-client/src/main/java"/>
-            <classpath>
-                <fileset dir="core/build/lib/compile"/>
-                <fileset dir="hcatalog-pig-adapter/build/lib/compile" includes="pig*.jar"/>
-                <fileset dir="server-extensions/build/lib/compile" includes="jms*.jar"/>
-                <fileset dir="storage-handlers/hbase/build/lib/compile" includes="hbase*.jar,hive-hbase*.jar"/>
-                <fileset dir="webhcat/svr/build/lib/provided" includes="hcatalog-core*.jar"/>
-                <fileset dir="webhcat/svr/build/lib/compile" includes="jetty*.jar,jersey*.jar,commons-exec*.jar,jul-to-slf4j*.jar"/>
-            </classpath>
-            <group title="hcatalog" packages="org.apache.hive.hcatalog.*"/>
-        </javadoc>
-        <record name="${build.dir}/javadoc.log" action="stop"/>
-        <condition property="javadoc.warnings">
-            <isfileselected file="${build.dir}/javadoc.log">
-                <contains text="warnings"/>
-            </isfileselected>
-        </condition>
-        <fail if="javadoc.warnings">Javadoc comments contain warnings.</fail>
-    </target>
-
-    <!--
-    ===============================================================================
-    Deploy Section
-    ===============================================================================
-    -->
-
-    <target name="mvn-deploy" depends="mvn-init"
-            description="Deploy artifacts to a Maven repository.">
-        <artifact:deploy file="pom.xml">
-            <artifact:pom file="pom.xml"/>
-            <remoteRepository id="${mvn.deploy.repo.id}" url="${mvn.deploy.repo.url}"/>
-        </artifact:deploy>
-        <ant target="mvn-deploy" dir="core" inheritAll="false" useNativeBasedir="true"/>
-        <ant target="mvn-deploy" dir="hcatalog-pig-adapter" inheritAll="false" useNativeBasedir="true"/>
-        <ant target="mvn-deploy" dir="server-extensions" inheritAll="false" useNativeBasedir="true"/>
-        <ant target="mvn-deploy" dir="webhcat/java-client" inheritAll="false" useNativeBasedir="true"/>
-        <ant target="mvn-deploy" dir="webhcat/svr" inheritAll="false" useNativeBasedir="true"/>
-    </target>
-
-    <target name="mvn-deploy-signed" depends="mvn-init"
-            description="Sign and deploy artifacts to a Maven repository.">
-
-        <input message="Enter your gpg password (or just press return if using an agent): "
-               addproperty="gpg.passphrase">
-            <handler classname="org.apache.tools.ant.input.SecureInputHandler"/>
-        </input>
-
-        <_sign inputFile="pom.xml"/>
-        <artifact:deploy file="pom.xml">
-            <artifact:pom file="pom.xml"/>
-            <attach file="pom.xml.asc" type="pom.asc"/>
-            <remoteRepository id="${mvn.deploy.repo.id}" url="${mvn.deploy.repo.url}"/>
-        </artifact:deploy>
-
-        <ant target="mvn-deploy-signed" dir="core" inheritAll="false" useNativeBasedir="true">
-            <property name="gpg.passphrase" value="${gpg.passphrase}"/>
-        </ant>
-        <ant target="mvn-deploy-signed" dir="hcatalog-pig-adapter" inheritAll="false" useNativeBasedir="true">
-            <property name="gpg.passphrase" value="${gpg.passphrase}"/>
-        </ant>
-        <ant target="mvn-deploy-signed" dir="server-extensions" inheritAll="false" useNativeBasedir="true">
-            <property name="gpg.passphrase" value="${gpg.passphrase}"/>
-        </ant>
-        <ant target="mvn-deploy-signed" dir="webhcat/java-client" inheritAll="false" useNativeBasedir="true">
-            <property name="gpg.passphrase" value="${gpg.passphrase}"/>
-        </ant>
-        <ant target="mvn-deploy-signed" dir="webhcat/svr" inheritAll="false" useNativeBasedir="true">
-            <property name="gpg.passphrase" value="${gpg.passphrase}"/>
-        </ant>
-    </target>
-
-    <!--
-    ===============================================================================
-    Distribution Section
-    ===============================================================================
-    -->
-    <target name="package" depends="jar, docs" description="Create an HCatalog release">
-        <mkdir dir="${dist.dir}"/>
-        <mkdir dir="${dist.dir}/share/${ant.project.name}/lib"/>
-        <mkdir dir="${dist.dir}/etc/hcatalog"/>
-        <mkdir dir="${dist.dir}/bin"/>
-        <mkdir dir="${dist.dir}/sbin"/>
-        <mkdir dir="${dist.dir}/share/${ant.project.name}/scripts"/>
-        <mkdir dir="${dist.dir}/share/${ant.project.name}/templates/conf"/>
-        <mkdir dir="${dist.dir}/share/doc/${ant.project.name}"/>
-        <mkdir dir="${dist.dir}/share/doc/${ant.project.name}/api"/>
-        <mkdir dir="${dist.dir}/share/doc/${ant.project.name}/jdiff"/>
-        <mkdir dir="${dist.dir}/share/doc/${ant.project.name}/license"/>
-
-        <copy todir="${dist.dir}/share/${ant.project.name}" includeEmptyDirs="false">
-            <fileset dir="core/build">
-                <include name="hcatalog-*.jar"/>
-            </fileset>
-            <fileset dir="hcatalog-pig-adapter/build">
-                <include name="hcatalog-*.jar"/>
-            </fileset>
-            <fileset dir="server-extensions/build">
-                <include name="hcatalog-*.jar"/>
-            </fileset>
-        </copy>
-        <copy todir="${dist.dir}/share/webhcat/svr/" includeEmptyDirs="false">
-            <fileset dir="webhcat/svr/build">
-                <include name="webhcat-*.jar"/>
-            </fileset>
-        </copy>
-        <copy todir="${dist.dir}/share/webhcat/svr/lib/" includeEmptyDirs="false">
-            <fileset dir="webhcat/svr/build/lib/compile/">
-                <include name="*.jar"/>
-            </fileset>
-        </copy>
-        <copy todir="${dist.dir}/share/webhcat/java-client/" includeEmptyDirs="false">
-            <fileset dir="webhcat/java-client/build">
-                <include name="webhcat-java-client*.jar"/>
-            </fileset>
-        </copy>
-
-        <copy todir="${dist.dir}/bin">
-            <fileset dir="bin/">
-                <include name="hcat"/>
-                <include name="hcat.py"/>
-                <include name="hcatcfg.py"/>
-                <include name="templeton.cmd"/>
-            </fileset>
-
-        </copy>
-        <copy todir="${dist.dir}/libexec">
-            <fileset dir="bin">
-                <include name="hcat-config.sh"/>
-            </fileset>
-        </copy>
-
-        <copy todir="${dist.dir}/sbin">
-            <fileset dir="${package.dir}">
-                <include name="*.sh"/>
-            </fileset>
-        </copy>
-
-        <copy todir="${dist.dir}/etc/${ant.project.name}">
-            <fileset dir="conf"/>
-        </copy>
-
-        <copy todir="${dist.dir}/etc/webhcat">
-            <fileset dir="webhcat/svr/src/main/config/" />
-        </copy>
-
-        <copy todir="${dist.dir}/share/${ant.project.name}/scripts">
-            <fileset dir="scripts">
-                <include name="*.sh"/>
-            </fileset>
-        </copy>
-
-        <copy todir="${dist.dir}/share/${ant.project.name}/templates/conf">
-            <fileset dir="src/packages/templates/conf">
-                <include name="*"/>
-            </fileset>
-        </copy>
-
-        <copy todir="${dist.dir}/sbin">
-            <fileset dir="${package.dir}">
-                <include name="*.sh"/>
-            </fileset>
-            <fileset dir="webhcat/svr/src/main/bin">
-                <include name="*.sh"/>
-            </fileset>
-            <fileset dir="bin">
-                <include name="hcat_server.sh"/>
-                <include name="hcat_server.py"/>
-                <include name="hcatcfg.py"/>
-            </fileset>
-        </copy>
-
-        <!-- Copy the licenses and such -->
-        <copy todir="${dist.dir}/share/doc/${ant.project.name}">
-            <fileset dir=".">
-                <include name="*.txt"/>
-            </fileset>
-        </copy>
-
-        <chmod perm="ugo+x" type="file">
-            <fileset dir="${dist.dir}/bin"/>
-            <fileset dir="${dist.dir}/sbin"/>
-        </chmod>
-
-        <!--package storage-handlers -->
-        <property name="handlers.dir" value="${dist.dir}/share/hcatalog/storage-handlers"/>
-        <mkdir dir="${handlers.dir}"/>
-        <ant target="package" dir="storage-handlers/hbase" inheritAll="false">
-            <property name="dist.handlers.dir" value="${handlers.dir}"/>
-        </ant>
-
-        <tar destfile="${build.dir}/${final.name}.tar.gz" longfile="gnu" compression="gzip">
-            <tarfileset dir="${build.dir}" filemode="755">
-                <include name="${final.name}/bin/**"/>
-                <include name="${final.name}/sbin/**"/>
-            </tarfileset>
-            <tarfileset dir="${build.dir}">
-                <include name="${final.name}/**"/>
-                <exclude name="${final.name}/bin/**"/>
-                <exclude name="${final.name}/sbin/**"/>
-            </tarfileset>
-        </tar>
-        <checksum file="${build.dir}/${final.name}.tar.gz" forceOverwrite="yes"/>
-
-    </target>
-
-    <target name="releaseaudit" depends="init" description="generate a release audit report">
-        <get src="${mvnrepo}/org/apache/rat/apache-rat/${apache-rat.version}/apache-rat-${apache-rat.version}.jar"
-             dest="${basedir}/build/apache-rat-${apache-rat.version}.jar"
-             usetimestamp="true"
-             skipexisting="true"/>
-        <java jar="${basedir}/build/apache-rat-${apache-rat.version}.jar"
-              fork="true"
-              output="${basedir}/build/releaseaudit_report.txt">
-            <arg value="--dir"/>
-            <arg value="${basedir}"/>
-            <arg value="--exclude-file"/>
-            <arg value="build-support/conf/rat-excludes.txt"/>
-        </java>
-        <echo message="releaseaudit report generated at ${basedir}/build/releaseaudit_report.txt"/>
-    </target>
-
-    <!-- ================================================================== -->
-    <!-- Make release tarball                                               -->
-    <!-- ================================================================== -->
-    <target name="src-release" depends="clean" description="Source distribution">
-        <mkdir dir="${build.dir}"/>
-        <property name="src-release-tarball"
-                  value="${build.dir}/${ant.project.name}-src-${hcatalog.version}.tar.gz"/>
-        <tar compression="gzip" longfile="gnu" destfile="${src-release-tarball}">
-            <tarfileset dir="${basedir}" mode="644" prefix="${ant.project.name}-src-${hcatalog.version}">
-                <include name="build-support/**"/>
-                <exclude name="build-support/scripts/**"/>
-                <include name="conf/**"/>
-                <include name="core/**"/>
-                <include name="hcatalog-pig-adapter/**"/>
-                <include name="server-extensions/**"/>
-                <include name="webhcat/**"/>
-                <include name="license/**"/>
-                <include name="src/**"/>
-                <include name="storage-handlers/**"/>
-                <include name="*.properties"/>
-                <include name="*.txt"/>
-                <include name="*.xml"/>
-                <include name="KEYS"/>
-            </tarfileset>
-            <tarfileset dir="${basedir}" mode="755" prefix="${ant.project.name}-src-${hcatalog.version}">
-                <include name="bin/**"/>
-                <include name="build-support/scripts/**"/>
-                <include name="scripts/**"/>
-            </tarfileset>
-        </tar>
-        <checksum file="${src-release-tarball}" forceOverwrite="yes"/>
-    </target>
-
-    <!-- ================================================================== -->
-    <!-- End to end tests                                                   -->
-    <!-- ================================================================== -->
-
-    <target name="test-e2e" description="run end-to-end tests">
-        <ant dir="${test.e2e.dir}"/>
-    </target>
-
-    <target name="test-e2e-install" description="deploy end-to-end tests to existing cluster">
-        <ant dir="${test.e2e.dir}" target="install"/>
-    </target>
-
-    <target name="test-e2e-deploy" description="deploy end-to-end tests to existing cluster">
-        <ant dir="${test.e2e.dir}" target="deploy"/>
-    </target>
-
-    <import file="build-support/ant/checkstyle.xml"/>
-    <import file="build-support/ant/deploy.xml"/>
-    <import file="build-support/ant/findbugs.xml"/>
-    <import file="build-support/ant/test.xml"/>
-    
-    <target name="make-pom" description="no-op in hcatalog, here to make hive's build work"/>
-</project>
diff --git a/src/hcatalog/core/build.xml b/src/hcatalog/core/build.xml
deleted file mode 100644
index a3d08b9..0000000
--- a/src/hcatalog/core/build.xml
+++ /dev/null
@@ -1,42 +0,0 @@
-<?xml version="1.0" encoding="ISO-8859-1"?>
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="hcatalog-core">
-  <property name="path.to.basedir" value="${basedir}/.."/>
-  <property name="pom.file" location="pom.xml"/>
-
-  <import file="${path.to.basedir}/build-support/ant/build-common.xml"/>
-
-  <path id="compile.class.path">
-    <fileset dir="${build.dir}/lib/compile"/>
-  </path>
-
-  <path id="test.class.path">
-    <dirset dir="${basedir}/build/classes"/>
-    <dirset dir="${basedir}/build/test/classes"/>
-    <!-- TODO: break circular dependency -->
-    <fileset dir="${path.to.basedir}/hcatalog-pig-adapter/build/lib/test"/>
-    <dirset dir="${path.to.basedir}/hcatalog-pig-adapter/build/classes"/>
-  </path>
-
-  <path id="findbugs.class.path">
-    <fileset dir="${build.dir}/lib/compile"/>
-  </path>
-</project>
diff --git a/src/hcatalog/core/pom-old.xml b/src/hcatalog/core/pom-old.xml
deleted file mode 100644
index ed131f1..0000000
--- a/src/hcatalog/core/pom-old.xml
+++ /dev/null
@@ -1,85 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
-
-    <parent>
-        <groupId>org.apache.hive.hcatalog</groupId>
-        <artifactId>hcatalog</artifactId>
-        <version>0.12.0-cdh5.0.0-SNAPSHOT</version>
-        <relativePath>../pom.xml</relativePath>
-    </parent>
-
-    <modelVersion>4.0.0</modelVersion>
-    <artifactId>hcatalog-core</artifactId>
-    <packaging>jar</packaging>
-    <name>hcatalog-core</name>
-    <url>http://maven.apache.org</url>
-
-    <build>
-        <plugins>
-            <plugin>
-                <groupId>org.apache.maven.plugins</groupId>
-                <artifactId>maven-jar-plugin</artifactId>
-                <executions>
-                    <execution>
-                        <goals>
-                            <goal>test-jar</goal>
-                        </goals>
-                    </execution>
-                </executions>
-            </plugin>
-        </plugins>
-    </build>
-
-    <dependencies>
-        <dependency>
-            <groupId>com.google.guava</groupId>
-            <artifactId>guava</artifactId>
-            <version>${guava.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.hive</groupId>
-            <artifactId>hive-cli</artifactId>
-            <version>${hive.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.hive</groupId>
-            <artifactId>hive-metastore</artifactId>
-            <version>${hive.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.hive</groupId>
-            <artifactId>hive-common</artifactId>
-            <version>${hive.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.hive</groupId>
-            <artifactId>hive-exec</artifactId>
-            <version>${hive.version}</version>
-            <scope>compile</scope>
-        </dependency>
-    </dependencies>
-</project>
diff --git a/src/hcatalog/hcatalog-pig-adapter/build.xml b/src/hcatalog/hcatalog-pig-adapter/build.xml
deleted file mode 100644
index 229d88a..0000000
--- a/src/hcatalog/hcatalog-pig-adapter/build.xml
+++ /dev/null
@@ -1,42 +0,0 @@
-<?xml version="1.0" encoding="ISO-8859-1"?>
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="hcatalog-pig-adapter">
-  <property name="path.to.basedir" value="${basedir}/.."/>
-  <property name="pom.file" location="pom.xml"/>
-
-  <import file="${path.to.basedir}/build-support/ant/build-common.xml"/>
-
-  <path id="compile.class.path">
-    <fileset dir="${build.dir}/lib/compile"/>
-  </path>
-
-  <path id="test.class.path">
-    <fileset dir="${build.dir}/lib/test"/>
-    <dirset dir="${path.to.basedir}/core/build/test/classes"/>
-    <dirset dir="${basedir}/build/classes"/>
-    <dirset dir="${basedir}/build/test/classes"/>
-  </path>
-
-  <path id="findbugs.class.path">
-    <fileset dir="${build.dir}/lib/compile"/>
-  </path>
-
-</project>
diff --git a/src/hcatalog/hcatalog-pig-adapter/pom-old.xml b/src/hcatalog/hcatalog-pig-adapter/pom-old.xml
deleted file mode 100644
index c5c59ac..0000000
--- a/src/hcatalog/hcatalog-pig-adapter/pom-old.xml
+++ /dev/null
@@ -1,45 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
-
-    <parent>
-        <groupId>org.apache.hive.hcatalog</groupId>
-        <artifactId>hcatalog</artifactId>
-        <version>0.12.0-cdh5.0.0-SNAPSHOT</version>
-        <relativePath>../pom.xml</relativePath>
-    </parent>
-
-    <modelVersion>4.0.0</modelVersion>
-    <artifactId>hcatalog-pig-adapter</artifactId>
-    <packaging>jar</packaging>
-    <name>hcatalog-pig-adapter</name>
-    <url>http://maven.apache.org</url>
-
-    <dependencies>
-        <dependency>
-            <groupId>org.apache.hive.hcatalog</groupId>
-            <artifactId>hcatalog-core</artifactId>
-            <version>${hcatalog.version}</version>
-            <scope>compile</scope>
-        </dependency>
-    </dependencies>
-</project>
diff --git a/src/hcatalog/ivy.xml b/src/hcatalog/ivy.xml
deleted file mode 100644
index b5e8ec5..0000000
--- a/src/hcatalog/ivy.xml
+++ /dev/null
@@ -1,34 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-hcatalog" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-  </dependencies>
-</ivy-module>
diff --git a/src/hcatalog/pom-old.xml b/src/hcatalog/pom-old.xml
deleted file mode 100644
index e2bedfc..0000000
--- a/src/hcatalog/pom-old.xml
+++ /dev/null
@@ -1,251 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
-
-  <properties>
-      <activemq.version>5.5.0</activemq.version>
-      <commons-exec.version>1.1</commons-exec.version>
-      <commons-io.version>2.4</commons-io.version>
-      <guava.version>11.0.2</guava.version>
-      <hadoop20.version>1.0.3</hadoop20.version>
-      <hadoop23.version>2.1.0-beta</hadoop23.version>
-      <hbase.version>0.94.5</hbase.version>
-      <hcatalog.version>${project.version}</hcatalog.version>
-      <hive.version>${project.version}</hive.version>
-      <jackson.version>1.9.2</jackson.version>
-      <jersey.version>1.14</jersey.version>
-      <jetty.webhcat.version>7.6.0.v20120127</jetty.webhcat.version>
-      <jms.version>1.1</jms.version>
-      <pig.version>0.10.1</pig.version>
-      <slf4j.version>1.7.5</slf4j.version>
-      <wadl-resourcedoc-doclet.version>1.4</wadl-resourcedoc-doclet.version>
-      <zookeeper.version>3.4.3</zookeeper.version>
-      <metrics-core.version>2.1.2</metrics-core.version>
-  </properties>
-
-  <modelVersion>4.0.0</modelVersion>
-  <groupId>org.apache.hive.hcatalog</groupId>
-  <artifactId>hcatalog</artifactId>
-  <version>0.12.0-cdh5.0.0-SNAPSHOT</version>
-  <packaging>pom</packaging>
-
-  <build>
-    <plugins>
-      <plugin>
-        <groupId>org.apache.maven.plugins</groupId>
-        <artifactId>maven-compiler-plugin</artifactId>
-        <version>2.5.1</version>
-        <configuration>
-          <source>1.6</source>
-          <target>1.6</target>
-        </configuration>
-      </plugin>
-    </plugins>
-  </build>
-
-  <profiles>
-    <profile>
-      <id>hadoop20</id>
-      <dependencies>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-tools</artifactId>
-          <version>${hadoop20.version}</version>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-test</artifactId>
-          <version>${hadoop20.version}</version>
-          <scope>test</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.pig</groupId>
-          <artifactId>pig</artifactId>
-          <version>${pig.version}</version>
-          <scope>compile</scope>
-        </dependency>
-      </dependencies>
-    </profile>
-    <profile>
-      <id>hadoop23</id>
-      <dependencies>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-archives</artifactId>
-          <version>${hadoop23.version}</version>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-common</artifactId>
-          <version>${hadoop23.version}</version>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-hdfs</artifactId>
-          <version>${hadoop23.version}</version>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-hdfs</artifactId>
-          <version>${hadoop23.version}</version>
-          <classifier>tests</classifier>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-mapreduce-client-core</artifactId>
-          <version>${hadoop23.version}</version>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-mapreduce-client-jobclient</artifactId>
-          <version>${hadoop23.version}</version>
-          <classifier>tests</classifier>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-yarn-server-tests</artifactId>
-          <version>${hadoop23.version}</version>
-          <classifier>tests</classifier>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-mapreduce-client-app</artifactId>
-          <version>${hadoop23.version}</version>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-common</artifactId>
-          <version>${hadoop23.version}</version>
-          <classifier>tests</classifier>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-mapreduce-client-hs</artifactId>
-          <version>${hadoop23.version}</version>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.hadoop</groupId>
-          <artifactId>hadoop-minicluster</artifactId>
-          <version>${hadoop23.version}</version>
-          <scope>compile</scope>
-        </dependency>
-        <dependency>
-          <groupId>org.apache.pig</groupId>
-          <artifactId>pig</artifactId>
-          <version>${pig.version}</version>
-          <classifier>h2</classifier>
-          <scope>compile</scope>
-        </dependency>
-      </dependencies>
-    </profile>
-  </profiles>
-
-  <modules>
-    <module>core</module>
-    <module>hcatalog-pig-adapter</module>
-    <module>server-extensions</module>
-    <module>webhcat/java-client</module>
-    <module>webhcat/svr</module>
-    <module>storage-handlers/hbase</module>
-  </modules>
-
-  <repositories>
-    <!-- This is necessary for hive-metastore dependencies. -->
-    <repository>
-      <id>datanucleus</id>
-      <name>datanucleus maven repository</name>
-      <url>http://www.datanucleus.org/downloads/maven2</url>
-      <layout>default</layout>
-      <releases>
-        <enabled>true</enabled>
-        <checksumPolicy>warn</checksumPolicy>
-      </releases>
-    </repository>
-
-    <!-- A transitive dependency defines this repo in its pom, however, the repo
-       has moved and causes dependency resolutions for 'asm:asm:pom:3.1'. Here we
-       disable the repo as we prefer to use central anyway. -->
-    <repository>
-      <id>glassfish-repository</id>
-      <url>http://maven.glassfish.org/content/groups/glassfish</url>
-      <releases>
-        <enabled>false</enabled>
-      </releases>
-      <snapshots>
-        <enabled>false</enabled>
-      </snapshots>
-    </repository>
-    <repository>
-      <id>glassfish-repo-archive</id>
-      <url>http://maven.glassfish.org/content/groups/glassfish</url>
-      <releases>
-        <enabled>false</enabled>
-      </releases>
-      <snapshots>
-        <enabled>false</enabled>
-      </snapshots>
-    </repository>
-  </repositories>
-
-    <dependencies>
-        <dependency>
-            <groupId>junit</groupId>
-            <artifactId>junit</artifactId>
-            <version>4.10</version>
-            <scope>test</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.codehaus.jackson</groupId>
-            <artifactId>jackson-mapper-asl</artifactId>
-            <version>1.8.8</version>
-        </dependency>
-        <dependency>
-            <groupId>org.slf4j</groupId>
-            <artifactId>slf4j-api</artifactId>
-            <version>1.6.1</version>
-        </dependency>
-        <dependency>
-          <groupId>com.puppycrawl.tools</groupId>
-          <artifactId>checkstyle</artifactId>
-          <version>5.5</version>
-          <scope>test</scope>
-          <exclusions>
-            <exclusion>
-              <groupId>com.google.collections</groupId>
-              <artifactId>google-collections</artifactId>
-            </exclusion>
-          </exclusions>
-      </dependency>
-    </dependencies>
-
-</project>
diff --git a/src/hcatalog/server-extensions/build.xml b/src/hcatalog/server-extensions/build.xml
deleted file mode 100644
index 40962df..0000000
--- a/src/hcatalog/server-extensions/build.xml
+++ /dev/null
@@ -1,41 +0,0 @@
-<?xml version="1.0" encoding="ISO-8859-1"?>
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="hcatalog-server-extensions">
-    <property name="path.to.basedir" value="${basedir}/.."/>
-    <property name="pom.file" location="pom.xml"/>
-
-    <import file="${path.to.basedir}/build-support/ant/build-common.xml"/>
-
-    <path id="compile.class.path">
-        <fileset dir="${build.dir}/lib/compile"/>
-    </path>
-
-    <path id="test.class.path">
-        <fileset dir="${build.dir}/lib/test"/>
-        <dirset dir="${path.to.basedir}/core/build/test/classes"/>
-        <dirset dir="${build.dir}/classes"/>
-        <dirset dir="${build.dir}/test/classes"/>
-    </path>
-
-    <path id="findbugs.class.path">
-        <fileset dir="${build.dir}/lib/compile"/>
-    </path>
-</project>
diff --git a/src/hcatalog/server-extensions/pom-old.xml b/src/hcatalog/server-extensions/pom-old.xml
deleted file mode 100644
index 013f452..0000000
--- a/src/hcatalog/server-extensions/pom-old.xml
+++ /dev/null
@@ -1,77 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
-
-    <parent>
-        <groupId>org.apache.hive.hcatalog</groupId>
-        <artifactId>hcatalog</artifactId>
-        <version>0.12.0-cdh5.0.0-SNAPSHOT</version>
-        <relativePath>../pom.xml</relativePath>
-    </parent>
-
-    <modelVersion>4.0.0</modelVersion>
-    <artifactId>hcatalog-server-extensions</artifactId>
-    <packaging>jar</packaging>
-    <name>server-extensions</name>
-    <url>http://maven.apache.org</url>
-
-    <dependencies>
-        <dependency>
-            <groupId>javax.jms</groupId>
-            <artifactId>jms</artifactId>
-            <version>${jms.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.activemq</groupId>
-            <artifactId>activemq-core</artifactId>
-            <version>${activemq.version}</version>
-            <scope>compile</scope>
-            <exclusions>
-                <exclusion>
-                    <groupId>org.springframework</groupId>
-                    <artifactId>spring-context</artifactId>
-                </exclusion>
-            </exclusions>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.activemq</groupId>
-            <artifactId>kahadb</artifactId>
-            <version>${activemq.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.hive.hcatalog</groupId>
-            <artifactId>hcatalog-core</artifactId>
-            <version>${hcatalog.version}</version>
-            <scope>compile</scope>
-        </dependency>
-
-        <!-- test scope -->
-        <dependency>
-            <groupId>org.apache.pig</groupId>
-            <artifactId>pig</artifactId>
-            <version>${pig.version}</version>
-            <scope>test</scope>
-        </dependency>
-    </dependencies>
-</project>
diff --git a/src/hcatalog/src/test/e2e/hcatalog/build.xml b/src/hcatalog/src/test/e2e/hcatalog/build.xml
deleted file mode 100644
index 16cfbae..0000000
--- a/src/hcatalog/src/test/e2e/hcatalog/build.xml
+++ /dev/null
@@ -1,350 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="TestHarnessHCatTests" default="test">
-
-    <property name="hcat.jar"
-              value="${hcat.dir}/share/hcatalog/hcatalog-${hcatalog.version}.jar"/>
-
-    <!-- Separate property name for udfs' build.xml -->
-    <property name="hcat.jarfile" value="${hcat.jar}"/>
-    <property name="udf.dir" value="${basedir}/udfs"/>
-    <property name="udf.java.dir" value="${udf.dir}/java"/>
-    <property name="udf.jar" value="${udf.java.dir}/testudf.jar"/>
-    <property name="params.dir" value="${basedir}/paramfiles"/>
-    <property name="lib.dir" value="${basedir}/lib"/>
-    <property name="rctool.java.dir" value="${basedir}/tools/generate/java"/>
-
-    <property name="tar.name" value="${basedir}/hcattests.tar"/>
-    <property name="tar.dir" value="${basedir}/tar"/>
-    <property name="test.src" value="${basedir}/tests"/>
-    <property name="driver.src" value="${basedir}/drivers"/>
-    <property name="deployer.src" value="${basedir}/deployers"/>
-    <property name="conf.src" value="${basedir}/conf"/>
-    <property name="resource.src" value="${basedir}/resource"/>
-    <property name="tool.src" value="${basedir}/tools"/>
-    <property name="data.dir" value="${basedir}/data"/>
-
-    <property name="harness.dir" value="${basedir}/../harness"/>
-    <property name="harness.tar" value="${harness.dir}/harness.tar"/>
-    <property name="test.location" value="${basedir}/testdist"/>
-    <property name="benchmark.location" value="${test.location}/benchmarks"/>
-    <!--<property name="hadoop.core.path" value="${harness.hadoop.home}"/>-->
-    <property name="hadoop.core.path" value="${hadoop.home}"/>
-    <!-- Override on command line to use rpm.conf -->
-    <property name="harness.conf" value="${test.location}/conf/default.conf"/>
-    <!-- Default value for output directory -->
-    <property name="harness.PH_LOCAL" value="out"/>
-
-    <property name="hadoopversion" value="20"/>
-
-    <condition property="isHadoop23">
-        <equals arg1="${hadoopversion}" arg2="23"/>
-    </condition>
-
-    <!-- Build the UDFs -->
-    <target name="udfs">
-        <ant dir="${udf.java.dir}"/>
-    </target>
-
-    <path id="hadoop.core.jar.location">
-        <fileset dir="${hadoop.core.path}">
-            <include name="hadoop-core-*.jar" unless="isHadoop23"/>
-            <include name="**/hadoop-common-*.jar" if="isHadoop23"/>
-            <include name="**/hadoop-auth-*.jar" if="isHadoop23"/>
-            <include name="**/hadoop-hdfs-*.jar" if="isHadoop23"/>
-            <include name="**/hadoop-mapreduce-client-core-*.jar" if="isHadoop23"/>
-            <include name="**/hadoop-yarn-api-*.jar" if="isHadoop23"/>
-            <include name="**/hadoop-yarn-common-*.jar" if="isHadoop23"/>
-            <include name="**/hadoop-annotations-*.jar" if="isHadoop23"/>
-        </fileset>
-    </path>
-
-    <path id="hive.serde.jar.location">
-        <!-- <fileset dir="${hive.dir}/build/serde"> -->
-        <fileset dir="${hive.home}/lib">
-            <include name="hive-serde-*.jar"/>
-        </fileset>
-    </path>
-
-    <path id="hive.ql.jar.location">
-        <!--<fileset dir="${hive.dir}/build/ql"> -->
-        <fileset dir="${hive.home}/lib">
-            <include name="hive-exec-*.jar"/>
-        </fileset>
-    </path>
-
-    <!-- Build the RCfile data generator -->
-    <target name="rctool" depends="property-check">
-        <ant dir="${rctool.java.dir}">
-            <property name="hive.serde.jarfile" refid="hive.serde.jar.location"/>
-            <property name="hive.ql.jarfile" refid="hive.ql.jar.location"/>
-            <property name="hadoop.core.jarfile" refid="hadoop.core.jar.location"/>
-        </ant>
-    </target>
-
-    <!-- Build an archive to use in the tests -->
-    <target name="tar" description="Create tar file with hcat modules">
-        <mkdir dir="${tar.dir}"/>
-        <mkdir dir="${tar.dir}/tests"/>
-        <mkdir dir="${tar.dir}/drivers"/>
-        <mkdir dir="${tar.dir}/deployers"/>
-        <mkdir dir="${tar.dir}/conf"/>
-        <mkdir dir="${tar.dir}/resource"/>
-        <mkdir dir="${tar.dir}/libexec"/>
-        <mkdir dir="${tar.dir}/libexec/PigTest"/>
-        <mkdir dir="${tar.dir}/libexec/PigTest/test"/>
-        <mkdir dir="${tar.dir}/libexec/PigTest/generate"/>
-        <mkdir dir="${tar.dir}/lib"/>
-        <mkdir dir="${tar.dir}/lib/java"/>
-        <mkdir dir="${tar.dir}/paramfiles"/>
-
-        <copy todir="${tar.dir}/tests">
-            <fileset dir="${test.src}">
-            </fileset>
-        </copy>
-
-        <copy todir="${tar.dir}/data">
-            <fileset dir="${data.dir}">
-            </fileset>
-        </copy>
-
-
-        <copy todir="${tar.dir}">
-            <fileset dir="${driver.src}">
-                <exclude name="TestDriverScript.pm"/>
-            </fileset>
-            <fileset dir="${deployer.src}"/>
-        </copy>
-
-
-        <copy todir="${tar.dir}/conf">
-            <fileset dir="${conf.src}"/>
-        </copy>
-
-        <copy todir="${tar.dir}/resource">
-            <fileset dir="${resource.src}"/>
-        </copy>
-
-        <copy todir="${tar.dir}/libexec/HCatTest">
-            <fileset dir="${tool.src}/test"/>
-            <fileset dir="${tool.src}/generate"/>
-            <fileset dir="${tool.src}/install"/>
-        </copy>
-
-        <copy todir="${tar.dir}/lib/java">
-            <fileset file="${udf.jar}"/>
-        </copy>
-
-        <copy todir="${tar.dir}/paramfiles">
-            <fileset file="${params.dir}/params_3"/>
-        </copy>
-
-        <tar destfile="${tar.name}" basedir="${tar.dir}"/>
-    </target>
-
-    <!-- Get the tarball for the harness -->
-    <target name="build-harness">
-        <ant dir="${harness.dir}" inheritAll="false"/>
-    </target>
-
-    <!-- Check that the necessary properties are setup -->
-    <target name="property-check">
-        <!--
-      <fail message="Please set the property hadoop.home to the location Hadoop is installed "
-        unless="hadoop.home"/>
-        -->
-        <fail message="Please set the property hadoop.home to the location Hadoop is installed ">
-            <condition>
-                <and>
-                    <not>
-                        <isset property="hadoop.home"/>
-                    </not>
-                    <not>
-                        <contains string="${harness.conf}" substring="rpm.conf"/>
-                    </not>
-                </and>
-            </condition>
-        </fail>
-        <fail message="Please set the property harness.cluster.conf to the location Hadoop conf is installed ">
-            <condition>
-                <and>
-                    <not>
-                        <isset property="harness.cluster.conf"/>
-                    </not>
-                    <not>
-                        <contains string="${harness.conf}" substring="rpm.conf"/>
-                    </not>
-                </and>
-            </condition>
-        </fail>
-        <fail message="Please set the property hive.home to the location Hive is installed ">
-            <condition>
-                <and>
-                    <not>
-                        <isset property="hive.home"/>
-                    </not>
-                    <not>
-                        <contains string="${harness.conf}" substring="rpm.conf"/>
-                    </not>
-                </and>
-            </condition>
-        </fail>
-        <fail message="Please set the property hcat.home to the location HCatalog is installed ">
-            <condition>
-                <and>
-                    <not>
-                        <isset property="hcat.home"/>
-                    </not>
-                    <not>
-                        <contains string="${harness.conf}" substring="rpm.conf"/>
-                    </not>
-                </and>
-            </condition>
-        </fail>
-        <fail message="Please set the property pig.home to the location Pig is installed ">
-            <condition>
-                <and>
-                    <not>
-                        <isset property="pig.home"/>
-                    </not>
-                    <not>
-                        <contains string="${harness.conf}" substring="rpm.conf"/>
-                    </not>
-                </and>
-            </condition>
-        </fail>
-
-        <fail message="Please set the property hbase.home to the location HBase is installed ">
-            <condition>
-                <and>
-                    <not>
-                        <isset property="hbase.home"/>
-                    </not>
-                    <not>
-                        <contains string="${harness.conf}" substring="rpm.conf"/>
-                    </not>
-                </and>
-            </condition>
-        </fail>
-    </target>
-
-    <!-- Prep the test area -->
-    <target name="init-test" depends="build-harness, tar">
-        <mkdir dir="${test.location}"/>
-        <mkdir dir="${benchmark.location}"/>
-
-        <untar src="${tar.name}" dest="${test.location}"/>
-        <untar src="${harness.tar}" dest="${test.location}"/>
-
-        <chmod perm="ugo+x" type="file">
-            <fileset dir="${test.location}/libexec"/>
-            <fileset file="${test.location}/test_harness.pl"/>
-        </chmod>
-
-    </target>
-
-    <target name="test" depends="property-check, udfs, tar, init-test">
-
-        <!-- fork (parallelization) factors for e2e tests execution.
-             Defaults are 1, which means *no* parellelization: -->
-        <property name="fork.factor.group" value="1"/>
-        <property name="fork.factor.conf.file" value="1"/>
-        <property name="e2e.debug" value="false"/>
-
-        <!-- If they have not specified tests to run then null it out -->
-        <property name="tests.to.run" value=""/>
-        <echo/>
-        <exec executable="./test_harness.pl" dir="${test.location}" failonerror="true">
-            <env key="HARNESS_ROOT" value="."/>
-            <env key="PH_LOCAL" value="${harness.PH_LOCAL}"/>
-            <env key="FORK_FACTOR_GROUP" value="${fork.factor.group}"/>
-            <env key="FORK_FACTOR_FILE" value="${fork.factor.conf.file}"/>
-            <env key="E2E_DEBUG" value="${e2e.debug}"/>
-            <env key="HADOOP_HOME" value="${hadoop.home}"/>
-            <env key="HADOOP_CONF_DIR" value="${harness.cluster.conf}"/>
-            <env key="HIVE_HOME" value="${hive.home}"/>
-            <env key="HCAT_HOME" value="${hcat.home}"/>
-            <env key="PIG_HOME" value="${pig.home}"/>
-            <env key="HBASE_HOME" value="${hbase.home}"/>
-            <arg line="-conf ${harness.conf}"/>
-            <arg line="${tests.to.run}"/>
-            <arg value="${test.location}/tests/pig.conf"/>
-            <arg value="${test.location}/tests/hive.conf"/>
-            <arg value="${test.location}/tests/hcat.conf"/>
-            <arg value="${test.location}/tests/hadoop.conf"/>
-            <arg value="${test.location}/tests/hive_nightly.conf"/>
-            <arg value="${test.location}/tests/hive_cmdline.conf"/>
-        </exec>
-    </target>
-
-    <target name="init-deploy" depends="rctool">
-        <!-- For now default to the existing cluster deployer, since
-    it's all there is.  Once the local deployer is available that
-    should be the default. -->
-        <property name="deploy.conf"
-                  value="${test.location}/conf/existing_deployer.conf"/>
-    </target>
-
-    <target name="deploy-base" depends="property-check, tar, init-test, init-deploy">
-        <exec executable="./test_harness.pl" dir="${test.location}"
-              failonerror="true">
-            <env key="HARNESS_ROOT" value="."/>
-            <env key="PH_LOCAL" value="${harness.PH_LOCAL}"/>
-            <env key="HADOOP_HOME" value="${hadoop.home}"/>
-            <env key="HIVE_HOME" value="${hive.home}"/>
-            <env key="HCAT_HOME" value="${hcat.home}"/>
-            <env key="PIG_HOME" value="${pig.home}"/>
-            <env key="HBASE_HOME" value="${hbase.home}"/>
-            <arg line="-conf ${harness.conf}"/>
-            <arg value="-deploycfg"/>
-            <arg value="${deploy.conf}"/>
-            <arg value="${deploy.opt}"/>
-            <!-- Give a bogus test so it just does the deployment -->
-            <arg value="-t"/>
-            <arg value="NoSuchTest"/>
-        </exec>
-    </target>
-
-    <target name="deploy">
-        <antcall target="deploy-base">
-            <param name="deploy.opt" value="-deploy"/>
-        </antcall>
-    </target>
-
-    <target name="undeploy">
-        <antcall target="deploy-base">
-            <param name="deploy.opt" value="-undeploy"/>
-        </antcall>
-    </target>
-
-    <target name="deploy-test" depends="deploy, test"/>
-
-    <target name="deploy-test-undeploy" depends="deploy, test, undeploy"/>
-
-    <target name="clean">
-        <delete dir="${test.location}"/>
-        <delete file="${tar.name}"/>
-        <delete dir="${tar.dir}"/>
-        <ant dir="${udf.java.dir}" target="clean"/>
-    </target>
-
-</project>
-
-
diff --git a/src/hcatalog/src/test/e2e/hcatalog/tools/generate/java/build.xml b/src/hcatalog/src/test/e2e/hcatalog/tools/generate/java/build.xml
deleted file mode 100644
index faa610e..0000000
--- a/src/hcatalog/src/test/e2e/hcatalog/tools/generate/java/build.xml
+++ /dev/null
@@ -1,76 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="Hive-Data-Generator" default="generator-jar">
-
-    <property name="generator.jarfile" value="hive-gen.jar"/>
-    <property name="generator.build.dir" value="${basedir}/build"/>
-    <property name="generator.src.dir" value="${basedir}/org"/>
-
-
-    <path id="generator-classpath">
-        <fileset file="${hive.serde.jarfile}"/>
-        <fileset file="${hive.ql.jarfile}"/>
-        <pathelement path="${hadoop.core.jarfile}" />
-    </path>
-
-    <target name="init">
-        <mkdir dir="${generator.build.dir}"/>
-    </target>
-
-    <target name="clean">
-        <delete dir="${generator.build.dir}"/>
-        <delete file="${generator.jarfile}"/>
-    </target>
-
-    <target name="generator-compile"
-            depends="init, serde.jar.check, ql.jar.check, hadoop.jar.check">
-        <echo>*** Compiling UDFs ***</echo>
-        <javac srcdir="${generator.src.dir}" destdir="${generator.build.dir}" debug="on" includeantruntime="false"
-		source="${sourceJavaVersion}"
-		target="${targetJavaVersion}"
-               includes="**/*.java">
-            <classpath refid="generator-classpath"/>
-        </javac>
-    </target>
-
-    <target name="generator-jar" depends="generator-compile">
-        <echo>*** Creating UDF jar ***</echo>
-        <jar duplicate="preserve" jarfile="${generator.jarfile}">
-            <fileset dir="build"/>
-        </jar>
-    </target>
-
-    <target name="serde.jar.check" unless="hive.serde.jarfile">
-        <fail message="'hive.serde.jarfile' is not defined.
-		Please pass -Dhive.serde.jarfile=&lt;Hive serde jar to use&gt; to Ant on the command-line."/>
-    </target>
-
-    <target name="ql.jar.check" unless="hive.ql.jarfile">
-        <fail message="'hive.ql.jarfile' is not defined.
-		Please pass -Dhive.ql.jarfile=&lt;Hive ql jar to use&gt; to Ant on the command-line."/>
-    </target>
-
-    <target name="hadoop.jar.check" unless="hadoop.core.jarfile">
-        <fail message="'hadoop.core.jarfile' is not defined.
-		Please pass -Dhadoop.core.jarfile=&lt;Hadoop core jar to use&gt; to Ant on the command-line."/>
-    </target>
-
-
-</project>
diff --git a/src/hcatalog/src/test/e2e/hcatalog/udfs/java/build.xml b/src/hcatalog/src/test/e2e/hcatalog/udfs/java/build.xml
deleted file mode 100644
index b94a053..0000000
--- a/src/hcatalog/src/test/e2e/hcatalog/udfs/java/build.xml
+++ /dev/null
@@ -1,60 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="HCatalog-test-utils" default="udf-jar">
-
-    <property name="udf.jarfile" value="testudf.jar"/>
-    <property name="udfs.build.dir" value="${basedir}/build"/>
-    <property name="udfs.src.dir" value="${basedir}/org/"/>
-    <property name="hcatalog.base" value="../../../../../.."/>
-    <property name="hcatalog.core.build" value="${hcatalog.base}/core/build"/>
-    <property name="hcatalog.pig.build" value="${hcatalog.base}/hcatalog-pig-adapter/build"/>
-
-    <path id="udf-classpath">
-        <fileset file="${hcatalog.core.build}/hcatalog-core-*.jar"/>
-        <fileset file="${hcatalog.core.build}/lib/compile/*.jar"/>
-        <fileset file="${hcatalog.pig.build}/hcatalog-pig-adapter-*.jar"/>
-        <fileset file="${hcatalog.pig.build}/lib/compile/*.jar"/>
-    </path>
-
-    <target name="init">
-        <mkdir dir="${udfs.build.dir}"/>
-    </target>
-
-    <target name="clean">
-        <delete dir="${udfs.build.dir}"/>
-        <delete file="${udf.jarfile}"/>
-    </target>
-
-    <target name="udf-compile" depends="init">
-        <echo>*** Compiling UDFs ***</echo>
-        <javac srcdir="${udfs.src.dir}" destdir="${udfs.build.dir}" debug="on">
-		source="${sourceJavaVersion}"
-		target="${targetJavaVersion}"
-            <classpath refid="udf-classpath"/>
-        </javac>
-    </target>
-
-    <target name="udf-jar" depends="udf-compile">
-        <echo>*** Creating UDF jar ***</echo>
-        <jar duplicate="preserve" jarfile="${udf.jarfile}">
-            <fileset dir="build"/>
-        </jar>
-    </target>
-</project>
diff --git a/src/hcatalog/src/test/e2e/templeton/build.xml b/src/hcatalog/src/test/e2e/templeton/build.xml
deleted file mode 100644
index 1acb417..0000000
--- a/src/hcatalog/src/test/e2e/templeton/build.xml
+++ /dev/null
@@ -1,197 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="TestHarnessTempletonTests" default="test">
-
-    <!-- Separate property name for udfs' build.xml -->
-
-    <property name="test.src" value="${basedir}/tests"/>
-    <property name="driver.src" value="${basedir}/drivers"/>
-    <property name="conf.src" value="${basedir}/conf"/>
-    <property name="resource.src" value="${basedir}/resource"/>
-    <property name="harness.dir" value="${basedir}/../harness"/>
-    <property name="harness.tar" value="${harness.dir}/harness.tar"/>
-    <property name="inpdir.local" value="${basedir}/inpdir/"/>
-    <property name="tar.name" value="${basedir}/hcattests.tar"/>
-    <property name="tar.dir" value="${basedir}/tar"/>
-    <property name="test.location" value="${basedir}/testdist"/>
-
-    <!-- Check that the necessary properties are setup -->
-    <target name="property-check">
-        <fail message="Please set the property harness.webhdfs.url to the namenode base url of the cluster"
-              unless="harness.webhdfs.url"/>
-        <fail message="Please set the property harness.templeton.url to the templeton server base url of the cluster"
-              unless="harness.templeton.url"/>
-        <fail message="Please set the property inpdir.hdfs to the test input directory on hdfs"
-              unless="inpdir.hdfs"/>
-    </target>
-
-    <!-- Get the tarball for the harness -->
-    <target name="build-harness">
-        <ant dir="${harness.dir}" inheritAll="false"/>
-    </target>
-
-    <!-- Build an archive to use in the tests -->
-    <target name="tar" description="Create tar file with hcat modules">
-        <mkdir dir="${tar.dir}"/>
-        <mkdir dir="${tar.dir}/tests"/>
-        <mkdir dir="${tar.dir}/conf"/>
-        <mkdir dir="${tar.dir}/resource"/>
-        <copy todir="${tar.dir}/tests">
-            <fileset dir="${test.src}">
-            </fileset>
-        </copy>
-        <copy todir="${tar.dir}">
-            <fileset dir="${driver.src}"/>
-        </copy>
-        <copy todir="${tar.dir}/conf">
-            <fileset dir="${conf.src}"/>
-        </copy>
-        <copy todir="${tar.dir}/resource">
-            <fileset dir="${resource.src}"/>
-        </copy>
-        <tar destfile="${tar.name}" basedir="${tar.dir}"/>
-    </target>
-
-    <!-- Prep the test area -->
-    <target name="init-test" depends="build-harness, tar">
-        <mkdir dir="${test.location}"/>
-
-        <untar src="${tar.name}" dest="${test.location}"/>
-        <untar src="${harness.tar}" dest="${test.location}"/>
-
-        <chmod perm="ugo+x" type="file">
-            <fileset file="${test.location}/test_harness.pl"/>
-        </chmod>
-    </target>
-
-    <target name="test" depends="property-check, init-test">
-        <!-- fork (parallelization) factors for e2e tests execution.
-             Defaults are 1, which means *no* parellelization: 
-             if group=3, then 3 .conf files will be processed in parallel
-             if conf.file=2 there will be 2 thread per .conf file, each thread 
-             executing a single group (identified by 'name' element) -->
-        <property name="fork.factor.group" value="5"/>
-        <property name="fork.factor.conf.file" value="5"/>
-        <property name="e2e.debug" value="false"/>
-        <property name="tests.to.run" value=""/>
-
-        <exec executable="./test_harness.pl" dir="${test.location}" failonerror="true">
-            <env key="HARNESS_ROOT" value="."/>
-            <env key="DRIVER_ROOT" value="${basedir}/drivers"/>
-            <env key="TH_WORKING_DIR" value="${test.location}"/>
-            <env key="TH_INPDIR_LOCAL" value="${inpdir.local}"/>
-            <env key="TH_INPDIR_HDFS" value="${inpdir.hdfs}"/>
-            <env key="TH_OUT" value="."/>
-            <env key="TH_ROOT" value="."/>
-            <env key="FORK_FACTOR_GROUP" value="${fork.factor.group}"/>
-            <env key="FORK_FACTOR_FILE" value="${fork.factor.conf.file}"/>
-            <env key="E2E_DEBUG" value="${e2e.debug}"/>
-            <env key="WEBHDFS_URL" value="${harness.webhdfs.url}"/>
-            <env key="TEMPLETON_URL" value="${harness.templeton.url}"/>
-            <env key="USER_NAME" value="${test.user.name}"/>
-            <env key="OTHER_USER_NAME" value="${test.other.user.name}"/>
-            <env key="HARNESS_CONF" value="${basedir}/conf/default.conf"/>
-            <env key="SECURE_MODE" value="${secure.mode}"/>
-            <env key="HADOOP_VERSION" value="${hadoopversion}"/>
-            <arg line="${tests.to.run}"/>
-            <arg value="${basedir}/tests/serverstatus.conf"/>
-            <arg value="${basedir}/tests/jobsubmission_streaming.conf"/>
-            <arg value="${basedir}/tests/ddl.conf"/>
-            <arg value="${basedir}/tests/jobstatus.conf"/>
-            <arg value="${basedir}/tests/jobsubmission.conf"/>
-            <arg value="${basedir}/tests/jobsubmission2.conf"/>
-        </exec>
-    </target>
-
-    <target name="test-hcat-authorization" depends="property-check, init-test">
-        <!-- fork (parallelization) factors for e2e tests execution.
-             Defaults are 1, which means *no* parellelization: -->
-        <property name="fork.factor.group" value="1"/>
-        <property name="fork.factor.conf.file" value="1"/>
-        <property name="e2e.debug" value="false"/>
-        <property name="tests.to.run" value=""/>
-        <exec executable="./test_harness.pl" dir="${test.location}" failonerror="true">
-            <env key="HARNESS_ROOT" value="."/>
-            <env key="DRIVER_ROOT" value="${basedir}/drivers"/>
-            <env key="TH_WORKING_DIR" value="${test.location}"/>
-            <env key="TH_INPDIR_LOCAL" value="${inpdir.local}"/>
-            <env key="TH_INPDIR_HDFS" value="${inpdir.hdfs}"/>
-            <env key="TH_OUT" value="."/>
-            <env key="TH_ROOT" value="."/>
-            <env key="FORK_FACTOR_GROUP" value="${fork.factor.group}"/>
-            <env key="FORK_FACTOR_FILE" value="${fork.factor.conf.file}"/>
-            <env key="E2E_DEBUG" value="${e2e.debug}"/>
-            <env key="WEBHDFS_URL" value="${harness.webhdfs.url}"/>
-            <env key="TEMPLETON_URL" value="${harness.templeton.url}"/>
-            <env key="USER_NAME" value="${test.user.name}"/>
-            <env key="GROUP_NAME" value="${test.group.name}"/>
-            <env key="GROUP_USER_NAME" value="${test.group.user.name}"/>
-            <env key="OTHER_USER_NAME" value="${test.other.user.name}"/>
-            <env key="HARNESS_CONF" value="${basedir}/conf/default.conf"/>
-            <env key="SECURE_MODE" value="${secure.mode}"/>
-            <env key="KEYTAB_DIR" value="${keytab.dir}"/>
-            <arg line="${tests.to.run}"/>
-            <arg value="${basedir}/tests/hcatperms.conf"/>
-        </exec>
-    </target>
-    <target name="test-doas" depends="property-check, init-test" description="See README.txt for instructions">
-        <!-- fork (parallelization) factors for e2e tests execution.
-             Defaults are 1, which means *no* parellelization: 
-             if group=3, then 3 .conf files will be processed in parallel
-             if conf.file=2 there will be 2 thread per .conf file, each thread 
-             executing a single group (identified by 'name' element) -->
-        <property name="fork.factor.group" value="1"/>
-        <property name="fork.factor.conf.file" value="1"/>
-        <property name="e2e.debug" value="false"/>
-        <property name="tests.to.run" value=""/>
-        <property name="doas.user.tmp" value="${doas.user}" />
-        <condition property="doas.user" value="${test.user.name}">
-            <!--default doas.user (if not set) to test.user.name-->
-            <isset property="doas.user.tmp"/>
-        </condition>
-
-        <exec executable="./test_harness.pl" dir="${test.location}" failonerror="true">
-            <env key="HARNESS_ROOT" value="."/>
-            <env key="TH_WORKING_DIR" value="${test.location}"/>
-            <env key="TH_INPDIR_LOCAL" value="${inpdir.local}"/>
-            <env key="TH_INPDIR_HDFS" value="${inpdir.hdfs}"/>
-            <env key="TH_OUT" value="."/>
-            <env key="TH_ROOT" value="."/>
-            <env key="FORK_FACTOR_GROUP" value="${fork.factor.group}"/>
-            <env key="FORK_FACTOR_FILE" value="${fork.factor.conf.file}"/>
-            <env key="E2E_DEBUG" value="${e2e.debug}"/>
-            <env key="WEBHDFS_URL" value="${harness.webhdfs.url}"/>
-            <env key="TEMPLETON_URL" value="${harness.templeton.url}"/>
-            <env key="USER_NAME" value="${test.user.name}"/>
-            <env key="DOAS_USER" value="${doas.user}"/>
-            <env key="HARNESS_CONF" value="${basedir}/conf/default.conf"/>
-            <env key="SECURE_MODE" value="${secure.mode}"/>
-            <arg line="${tests.to.run}"/>
-            <arg value="${basedir}/tests/doas.conf"/>
-        </exec>
-    </target>
-
-    <target name="clean">
-        <delete dir="${test.location}"/>
-        <delete file="${tar.name}"/>
-        <delete dir="${tar.dir}"/>
-    </target>
-
-</project>
diff --git a/src/hcatalog/storage-handlers/hbase/build.xml b/src/hcatalog/storage-handlers/hbase/build.xml
deleted file mode 100644
index f902ce7..0000000
--- a/src/hcatalog/storage-handlers/hbase/build.xml
+++ /dev/null
@@ -1,224 +0,0 @@
-<?xml version="1.0"?>
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="hbase-storage-handler" default="jar"
-         xmlns:artifact="artifact:org.apache.maven.artifact.ant">
-
-    <property name="path.to.basedir" location="${basedir}/../.."/>
-    <loadproperties srcfile="${path.to.basedir}/build.properties"/>
-
-    <!--
-    ================================================================================
-    Properties and Classpaths Section
-    ================================================================================
-    -->
-    <!-- name and version -->
-    <property name="handler.version" value="0.1.0"/>
-    <property name="handler.jar" value="${ant.project.name}-${handler.version}.jar"/>
-    <property name="final.name" value="${ant.project.name}-${handler.version}" />
-    <property name="hcatalog.dir" value="${basedir}/../.." />
-
-    <!-- hive properties -->
-    <property name="hive.root" value="${hcatalog.dir}/hive/external"/>
-
-    <!-- build properties -->
-    <property name="lib.dir" value="${basedir}/lib/" />
-    <property name="src.dir"  location="${basedir}/src/java"/>
-    <property name="resources.dir"  location="${basedir}/src/resources"/>
-    <property name="build.dir" value="${basedir}/build"/>
-    <property name="build.classes" value="${build.dir}/classes" />
-    <property name="dist.dir" value="${build.dir}/${final.name}" />
-
-    <!-- javac properties -->
-    <property name="build.encoding" value="UTF8" />
-    <property name="excludes" value=""/>
-    <property name="javac.debug" value="on" />
-    <property name="javac.optimize" value="on" />
-    <property name="javac.deprecation" value="off" />
-    <property name="javac.args" value="" />
-
-    <!-- test properties -->
-    <property name="test.src.dir" value="${basedir}/src/test" />
-    <property name="test.build.dir" value="${build.dir}/test" />
-    <property name="test.build.classes" value="${test.build.dir}/classes" />
-    <property name="test.log.dir" value="${test.build.dir}/logs" />
-    <property name="test.tmp.dir" value="${test.build.dir}/temp" />
-    <property name="test.data.dir" value="${test.build.dir}/data" />
-    <property name="test.timeout" value="2700000" />
-    <property name="test.output" value="no"/>
-    <property name="hive.conf.dir" value="${hive.root}/conf"/>
-
-    <path id="compile.class.path">
-      <fileset dir="${build.dir}/lib/compile"/>
-    </path>
-
-    <path id="test.class.path">
-        <fileset dir="${build.dir}/lib/test"/>
-        <pathelement location="${test.build.classes}" />
-        <pathelement location="${build.classes}" />
-        <pathelement location="conf"/>
-    </path>
-
-    <target name="init" depends="mvn-dependencies">
-        <mkdir dir="${dist.dir}" />
-        <mkdir dir="${build.classes}" />
-        <mkdir dir="${test.build.classes}" />
-    </target>
-    <!--
-    ================================================================================
-    Main Build and Jar Section
-    ================================================================================
-    -->
-    <!-- Compile src files -->
-    <target name="compile-src" depends="init">
-        <javac encoding="${build.encoding}" srcdir="${src.dir}:${basedir}/src/gen-java:${basedir}/src/resources" excludes="${excludes}"
-               includes="**/*.java" destdir="${build.classes}" debug="${javac.debug}"
-               optimize="${javac.optimize}"
-               source="${sourceJavaVersion}"
-               target="${targetJavaVersion}"
-               deprecation="${javac.deprecation}"
-               includeantruntime="false">
-            <compilerarg line="${javac.args}"/>
-            <classpath refid="compile.class.path"/>
-        </javac>
-    </target>
-
-    <!-- Build the jar -->
-    <target name="jar" depends="compile-src">
-        <copy todir="${build.classes}" includeEmptyDirs="false">
-            <fileset dir="${resources.dir}">
-                <include name="*"/>
-            </fileset>
-        </copy>
-        <jar jarfile="${build.dir}/${handler.jar}" basedir="${build.classes}"/>
-    </target>
-
-    <!--
-    ================================================================================
-    Test Section
-    ================================================================================
-    -->
-    <!-- Build test files -->
-    <target name="compile-test" depends="jar">
-        <javac encoding="${build.encoding}" srcdir="${test.src.dir}" excludes="${excludes}"
-               includes="**/*.java" destdir="${test.build.classes}" debug="${javac.debug}"
-               optimize="${javac.optimize}"
-               source="${sourceJavaVersion}"
-               target="${targetJavaVersion}"
-               deprecation="${javac.deprecation}"
-               includeantruntime="false">
-            <compilerarg line="${javac.args}"/>
-            <classpath refid="test.class.path" />
-        </javac>
-    </target>
-
-    <!-- Run the unit tests -->
-    <target name="test" depends="compile-test">
-      <antcall target="testonly" />
-    </target>
-     
-    <target name="testonly">
-        <sequential>
-            <delete dir="${test.log.dir}"/>
-            <delete dir="${test.tmp.dir}" />
-            <delete dir="${test.data.dir}" />
-            <mkdir dir="${test.log.dir}"/> 
-            <mkdir dir="${test.tmp.dir}" />
-            <mkdir dir="${test.data.dir}" />
-            <junit showoutput="${test.output}" printsummary="yes" haltonfailure="no"
-                   fork="yes" maxmemory="512m" dir="${basedir}" timeout="${test.timeout}"
-                   errorProperty="tests.failed" failureProperty="tests.failed">
-                <classpath>
-                    <pathelement location="${test.build.classes}" />
-                    <pathelement location="." />
-                    <path refid="test.class.path"/>
-                    <pathelement path="${clover.jar}"/>
-                </classpath>
-                <jvmarg line="${junit.jvm.args}"/>
-                <formatter type="${test.junit.output.format}" />
-                <!-- If the user has not defined a particular test to run, run them all -->
-                <batchtest fork="yes" todir="${test.log.dir}" unless="testcase">
-                    <fileset dir="src/test" includes="**/Test*.java"/>
-                    <fileset dir="src/test" includes="**/lock/*Test.java"/>
-                </batchtest>
-                <!-- Run one test case.  To use this define -Dtestcase=X on the command line -->
-                <batchtest fork="yes" todir="${test.log.dir}" if="testcase">
-                    <fileset dir="src/test" includes="**/${testcase}.java"/>
-                </batchtest>
-                <assertions>
-                    <enable />
-                </assertions>
-            </junit>
-            <fail if="tests.failed">Tests failed!</fail>
-        </sequential>
-    </target>
-
-    <!--
-    ================================================================================
-    Clean Section
-    ================================================================================
-    -->
-
-    <!-- Clean up  -->
-    <target name="clean" description="Cleanup build artifacts">
-        <delete dir="${build.dir}" />
-    </target>
-
-    <target name="clean-test" description="Cleanup build artifacts">
-        <delete dir="${test.build.dir}" />
-    </target>
-
-
-    <!--
-    ===============================================================================
-    Distribution Section
-    ===============================================================================
-    -->
-    <target name="package" depends="jar" description="Create an HCatalog release">
-        <mkdir dir="${dist.dir}" />
-        <mkdir dir="${dist.dir}/conf" />
-        <mkdir dir="${dist.dir}/lib" />
-
-        <copy todir="${dist.dir}/lib" includeEmptyDirs="false">
-            <fileset dir="${build.dir}">
-                <include name="hbase-storage-handler-*.jar"/>
-            </fileset>
-        </copy>
-
-        <copy todir="${dist.dir}/conf">
-            <fileset dir="${basedir}/conf" />
-        </copy>
-
-        <antcall target="package-to-handlers"/>
-    </target>
-
-    <target name="package-to-handlers" if="dist.handlers.dir">
-        <mkdir dir="${dist.handlers.dir}/hbase"/>
-        <copy todir="${dist.handlers.dir}/hbase" includeEmptyDirs="true">
-            <fileset dir="${dist.dir}">
-              <include name="**/lib/hbase-storage-handler-*.jar"/>
-              <include name="**/conf/**/*"/>
-            </fileset>
-        </copy>
-    </target>
-
-    <import file="${path.to.basedir}/build-support/ant/deploy.xml"/>
-
-</project>
diff --git a/src/hcatalog/storage-handlers/hbase/pom-old.xml b/src/hcatalog/storage-handlers/hbase/pom-old.xml
deleted file mode 100644
index 0e93f42..0000000
--- a/src/hcatalog/storage-handlers/hbase/pom-old.xml
+++ /dev/null
@@ -1,115 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
-
-  <parent>
-    <groupId>org.apache.hive.hcatalog</groupId>
-    <artifactId>hcatalog</artifactId>
-    <version>0.12.0-cdh5.0.0-SNAPSHOT</version>
-    <relativePath>../../pom.xml</relativePath>
-  </parent>
-
-  <modelVersion>4.0.0</modelVersion>
-  <artifactId>hbase-storage-handler</artifactId>
-  <packaging>jar</packaging>
-  <name>hbase-storage-handler</name>
-  <url>http://maven.apache.org</url>
-
-  <dependencies>
-    <dependency>
-      <groupId>org.apache.hive</groupId>
-      <artifactId>hive-hbase-handler</artifactId>
-      <version>${hive.version}</version>
-      <scope>compile</scope>
-      <exclusions>
-        <exclusion>
-          <groupId>com.google.guava</groupId>
-          <artifactId>guava</artifactId>
-        </exclusion>
-      </exclusions>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hive.hcatalog</groupId>
-      <artifactId>hcatalog-core</artifactId>
-      <version>${hcatalog.version}</version>
-      <scope>compile</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hive.hcatalog</groupId>
-      <artifactId>hcatalog-pig-adapter</artifactId>
-      <version>${hcatalog.version}</version>
-      <scope>compile</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.zookeeper</groupId>
-      <artifactId>zookeeper</artifactId>
-      <version>${zookeeper.version}</version>
-      <scope>compile</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hbase</groupId>
-      <artifactId>hbase</artifactId>
-      <version>${hbase.version}</version>
-      <scope>compile</scope>
-    </dependency>
-
-    <!-- test scope -->
-    <dependency>
-      <groupId>org.apache.hive.hcatalog</groupId>
-      <artifactId>hcatalog-pig-adapter</artifactId>
-      <version>${hcatalog.version}</version>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>commons-io</groupId>
-      <artifactId>commons-io</artifactId>
-      <version>${commons-io.version}</version>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hbase</groupId>
-      <artifactId>hbase</artifactId>
-      <version>${hbase.version}</version>
-      <classifier>tests</classifier>
-      <scope>test</scope>
-      <exclusions>
-        <exclusion>
-          <groupId>com.google.guava</groupId>
-          <artifactId>guava</artifactId>
-        </exclusion>
-      </exclusions>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.zookeeper</groupId>
-      <artifactId>zookeeper</artifactId>
-      <version>${zookeeper.version}</version>
-      <classifier>tests</classifier>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>com.yammer.metrics</groupId>
-      <artifactId>metrics-core</artifactId>
-      <version>${metrics-core.version}</version>
-      <scope>test</scope>
-    </dependency>
-  </dependencies>
-</project>
diff --git a/src/hcatalog/webhcat/java-client/build.xml b/src/hcatalog/webhcat/java-client/build.xml
deleted file mode 100644
index 57beb85..0000000
--- a/src/hcatalog/webhcat/java-client/build.xml
+++ /dev/null
@@ -1,42 +0,0 @@
-<?xml version="1.0" encoding="ISO-8859-1"?>
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="webhcat-java-client">
-  <property name="path.to.basedir" location="${basedir}/../.."/>
-  <property name="pom.file" location="pom.xml"/>
-
-  <import file="${path.to.basedir}/build-support/ant/build-common.xml"/>
-
-  <path id="compile.class.path">
-    <fileset dir="${build.dir}/lib/compile"/>
-  </path>
-
-  <path id="test.class.path">
-    <fileset dir="${build.dir}/lib/test"/>
-    <dirset dir="${path.to.basedir}/core/build/test/classes"/>
-    <dirset dir="${basedir}/build/classes"/>
-    <dirset dir="${basedir}/build/test/classes"/>
-  </path>
-
-  <path id="findbugs.class.path">
-    <fileset dir="${build.dir}/lib/compile"/>
-  </path>
-
-</project>
diff --git a/src/hcatalog/webhcat/java-client/pom-old.xml b/src/hcatalog/webhcat/java-client/pom-old.xml
deleted file mode 100644
index 63e4bb6..0000000
--- a/src/hcatalog/webhcat/java-client/pom-old.xml
+++ /dev/null
@@ -1,45 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
-
-    <parent>
-        <groupId>org.apache.hive.hcatalog</groupId>
-        <artifactId>hcatalog</artifactId>
-        <version>0.12.0-cdh5.0.0-SNAPSHOT</version>
-        <relativePath>../../pom.xml</relativePath>
-    </parent>
-
-    <modelVersion>4.0.0</modelVersion>
-    <artifactId>webhcat-java-client</artifactId>
-    <packaging>jar</packaging>
-    <name>webhcat-java-client</name>
-    <url>http://maven.apache.org</url>
-
-    <dependencies>
-        <dependency>
-            <groupId>org.apache.hive.hcatalog</groupId>
-            <artifactId>hcatalog-core</artifactId>
-            <version>${hcatalog.version}</version>
-            <scope>compile</scope>
-        </dependency>
-    </dependencies>
-</project>
diff --git a/src/hcatalog/webhcat/svr/build.xml b/src/hcatalog/webhcat/svr/build.xml
deleted file mode 100644
index 8cf8303..0000000
--- a/src/hcatalog/webhcat/svr/build.xml
+++ /dev/null
@@ -1,63 +0,0 @@
-<?xml version="1.0" encoding="ISO-8859-1"?>
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project name="webhcat">
-  <property name="path.to.basedir" location="${basedir}/../.."/>
-  <property name="pom.file" location="pom.xml"/>
-
-  <import file="${path.to.basedir}/build-support/ant/build-common.xml"/>
-
-  <path id="compile.class.path">
-    <fileset dir="${build.dir}/lib/compile"/>
-    <fileset dir="${build.dir}/lib/provided"/>
-  </path>
-
-  <path id="test.class.path">
-    <fileset dir="${build.dir}/lib/test"/>
-    <fileset dir="${build.dir}/lib/provided"/>
-    <dirset dir="${path.to.basedir}/core/build/test/classes"/>
-    <dirset dir="${basedir}/build/classes"/>
-    <dirset dir="${basedir}/build/test/classes"/>
-  </path>
-
-  <path id="findbugs.class.path">
-    <fileset dir="${build.dir}/lib/compile"/>
-  </path>
-
-  <target name="compile-resource" depends="javadoc">
-    <echo message="${ant.project.name}"/>
-    <property name="resources.dir"  location="${path.to.basedir}/conf"/>
-    <copy todir="${build.classes}/">
-      <fileset dir="${basedir}/src/main/config/"/>
-    </copy>
-  </target>
-  
-  <target name="javadoc" unless="skip.javadoc">
-    <echo message="Generating wadl xml file"/>
-    <javadoc access="public" classpathref="compile.class.path" useexternalfile="yes">
-      <fileset dir="${basedir}/src/main/java" defaultexcludes="yes"/>
-      <doclet name="com.sun.jersey.wadl.resourcedoc.ResourceDoclet"
-              pathref="compile.class.path">
-        <param name="-output" value="${build.classes}/resourcedoc.xml" />
-      </doclet>
-    </javadoc>
-  </target>
-
-</project>
diff --git a/src/hcatalog/webhcat/svr/pom-old.xml b/src/hcatalog/webhcat/svr/pom-old.xml
deleted file mode 100644
index 47f69e0..0000000
--- a/src/hcatalog/webhcat/svr/pom-old.xml
+++ /dev/null
@@ -1,110 +0,0 @@
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one
-    or more contributor license agreements.  See the NOTICE file
-    distributed with this work for additional information
-    regarding copyright ownership.  The ASF licenses this file
-    to you under the Apache License, Version 2.0 (the
-    "License"); you may not use this file except in compliance
-    with the License.  You may obtain a copy of the License at
-
-        http://www.apache.org/licenses/LICENSE-2.0
-
-    Unless required by applicable law or agreed to in writing,
-    software distributed under the License is distributed on an
-    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-    KIND, either express or implied.  See the License for the
-    specific language governing permissions and limitations
-    under the License.
--->
-
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
-
-    <parent>
-        <groupId>org.apache.hive.hcatalog</groupId>
-        <artifactId>hcatalog</artifactId>
-        <version>0.12.0-cdh5.0.0-SNAPSHOT</version>
-        <relativePath>../../pom.xml</relativePath>
-    </parent>
-
-    <modelVersion>4.0.0</modelVersion>
-    <artifactId>webhcat</artifactId>
-    <packaging>jar</packaging>
-    <name>webhcat</name>
-    <url>http://maven.apache.org</url>
-
-    <dependencies>
-        <dependency>
-            <groupId>xerces</groupId>
-            <artifactId>xercesImpl</artifactId>
-            <version>2.9.1</version>
-        </dependency>
-        <!-- provided scope - made available as separate package
-          not packaged or added as dependency
-        -->
-
-        <dependency>
-            <groupId>org.apache.hive.hcatalog</groupId>
-            <artifactId>hcatalog-core</artifactId>
-            <version>${hcatalog.version}</version>
-            <scope>provided</scope>
-        </dependency>
-
-        <!-- compile scope - this is packaged -->
-        <dependency>
-            <groupId>com.sun.jersey</groupId>
-            <artifactId>jersey-json</artifactId>
-            <version>${jersey.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>com.sun.jersey</groupId>
-            <artifactId>jersey-servlet</artifactId>
-            <version>${jersey.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.commons</groupId>
-            <artifactId>commons-exec</artifactId>
-            <version>${commons-exec.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.zookeeper</groupId>
-            <artifactId>zookeeper</artifactId>
-            <version>${zookeeper.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.codehaus.jackson</groupId>
-            <artifactId>jackson-core-asl</artifactId>
-            <version>${jackson.version}</version>
-            <scope>compile</scope>
-        </dependency>
-         <dependency>
-            <groupId>org.codehaus.jackson</groupId>
-            <artifactId>jackson-mapper-asl</artifactId>
-            <version>${jackson.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.eclipse.jetty.aggregate</groupId>
-            <artifactId>jetty-all-server</artifactId>
-            <version>${jetty.webhcat.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>com.sun.jersey.contribs</groupId>
-            <artifactId>wadl-resourcedoc-doclet</artifactId>
-            <version>${wadl-resourcedoc-doclet.version}</version>
-            <scope>compile</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.slf4j</groupId>
-            <artifactId>jul-to-slf4j</artifactId>
-            <version>${slf4j.version}</version>
-            <scope>compile</scope>
-        </dependency>
-    </dependencies>
-</project>
diff --git a/src/hwi/build.xml b/src/hwi/build.xml
deleted file mode 100644
index 5e32554..0000000
--- a/src/hwi/build.xml
+++ /dev/null
@@ -1,75 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-<project name="hwi" default="jar">
-  
-  <property name="src.dir"  location="${basedir}/src/java"/>
-  <import file="../build-common.xml"/>
-
-  <!-- We include servlet jar in addition to the normal
-       Hive classpath. Some HWI components are linked
-       to the servlet libraries.  -->
-  <path id="classpath-hwi">
-    <fileset dir="${hadoop.root}">
-      <include name="lib/**/*.jar" />
-      <exclude name="lib/**/excluded/" />
-      <!-- below is for 0.23 onwards -->
-      <include name="share/hadoop/common/lib/*.jar" />
-      <exclude name="share/hadoop/common/lib/hadoop-mapreduce-*.jar" />
-      <exclude name="share/hadoop/common/lib/hadoop-yarn-*.jar" />
-    </fileset>
-    <path refid="classpath"/>
-  </path>
-
-  <!--hive_hwi.war file contains only the JSP sources -->
-  <target name="war">
-    <echo message="Project: ${ant.project.name}"/>
-    <jar jarfile="${build.dir.hive}/hwi/hive-hwi-${version}.war" basedir="${basedir}/web">
-      <manifest>
-        <!-- Not putting these in their own manifest section, since that inserts
-             a new-line, which breaks the reading of the attributes. -->
-        <attribute name="Implementation-Title" value="Hive"/>
-        <attribute name="Implementation-Version" value="${version}"/>
-        <attribute name="Implementation-Vendor" value="Apache"/>
-      </manifest>
-      <metainf dir="${hive.root}" includes="LICENSE,NOTICE"/>
-    </jar>
-  </target>
-
-  <!-- Compile is a clone of the build-common.xml compile, with one exception:
-       We include the war target as a dependency. In this way the war target
-       is called without changes to the upstream build infrastructure.
-  -->
-  <target name="compile" depends="init, setup, ivy-retrieve, war">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${src.dir}"
-     includes="**/*.java"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     destdir="${build.classes}"
-     debug="${javac.debug}"
-     deprecation="${javac.deprecation}">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="classpath"/>
-    </javac>
-  </target>
-
-</project>
diff --git a/src/hwi/ivy.xml b/src/hwi/ivy.xml
deleted file mode 100644
index ef9495c..0000000
--- a/src/hwi/ivy.xml
+++ /dev/null
@@ -1,40 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-hwi" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>  
-  <dependencies>
-    <dependency org="org.apache.hive" name="hive-cli" rev="${version}"
-                conf="compile->default" />
-    <dependency org="org.mortbay.jetty" name="jetty" rev="${jetty.version}" />
-    <dependency org="org.apache.ant" name="ant" rev="${apacheant.version}" />
-    <dependency org="org.apache.ant" name="ant-launcher" rev="${apacheant.version}" />
-
-    <!-- Test Dependencies -->
-    <dependency org="commons-httpclient" name="commons-httpclient" rev="${commons-httpclient.version}"
-                conf="test->default"
-                transitive="false"/>
-  </dependencies>
-</ivy-module>
diff --git a/src/ivy.xml b/src/ivy.xml
deleted file mode 100644
index e83437e..0000000
--- a/src/ivy.xml
+++ /dev/null
@@ -1,54 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-<ivy-module version="2.0">
-  <info organisation="org.apache.hive" module="${ant.project.name}" revision="${version}">
-    <license name="Apache 2.0"/>
-    <ivyauthor name="Apache Hive Team" url="http://hive.apache.org"/>
-    <description>Apache Hive</description>
-  </info>
-
-  <configurations defaultconfmapping="default">
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-    <!-- Private configurations -->
-    <conf name="docs" visibility="private"/>
-    <conf name="checkstyle" visibility="private"/>
-    <conf name="findbugs" visibility="private"/>
-    <conf name="rat" visibility="private"/>
-    <conf name="maven" visibility="private"/>
-  </configurations>
-
-
-  <dependencies>
-   <dependency org="org.apache.rat" name="apache-rat-tasks"
-               rev="${rat.version}" conf="rat->default"/>
-   <dependency org="org.apache.rat" name="apache-rat-core"
-               rev="${rat.version}" conf="rat->default"/>
-   <dependency org="checkstyle" name="checkstyle" rev="${checkstyle.version}"
-     conf="checkstyle->default"/>
-   <dependency org="com.google.code.findbugs" name="findbugs-ant" rev="${findbugs.version}"
-     conf="findbugs->default"/>
-   <dependency org="org.jdom" name="jdom" rev="${jdom.version}"
-     conf="docs->default"/>
-   <dependency org="org.apache.velocity" name="velocity" rev="${velocity.version}"
-     conf="docs->default"/>
-   <dependency org="org.apache.maven" name="maven-ant-tasks" rev="${maven-ant-tasks.version}"
-     conf="maven->default"/>
-   <conflict manager="all" />
-  </dependencies>
-  
-</ivy-module>
diff --git a/src/ivy/common-configurations.xml b/src/ivy/common-configurations.xml
deleted file mode 100644
index 154b7cb..0000000
--- a/src/ivy/common-configurations.xml
+++ /dev/null
@@ -1,33 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<configurations defaultconfmapping="default">
-  <!--these match the Maven configurations-->
-  <conf name="default" extends="master,compile"/>
-  <conf name="master" description="contains the artifact but no dependencies"/>
-  <conf name="compile" extends="hadoop${hadoop.mr.rev}.compile" description="contains the artifact but no dependencies" visibility="private"/>
-  <conf name="runtime" description="runtime but not the artifact"/>
-  <conf name="test" extends="hadoop${hadoop.mr.rev}.test,compile" visibility="private" />
-  <conf name="hadoop20.compile" visibility="private"/>
-  <conf name="hadoop20S.compile" visibility="private"/>
-  <conf name="hadoop23.compile" visibility="private"/>
-  <conf name="hadoop20.test" visibility="private"/>
-  <conf name="hadoop20S.test" visibility="private"/>
-  <conf name="hadoop23.test" visibility="private"/>
-  <conf name="hadoop0.20.shim" visibility="private"/>
-  <conf name="hadoop0.20S.shim" visibility="private"/>
-  <conf name="hadoop0.23.shim" visibility="private"/>
-</configurations>
diff --git a/src/ivy/ivysettings.xml b/src/ivy/ivysettings.xml
deleted file mode 100644
index d230f2c..0000000
--- a/src/ivy/ivysettings.xml
+++ /dev/null
@@ -1,106 +0,0 @@
-<ivysettings>
-
- <!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
- <!--
-  see http://www.jayasoft.org/ivy/doc/configuration
-  -->
-  <!-- you can override this property to use mirrors
-          http://repo1.maven.org/maven2/
-          http://mirrors.dotsrc.org/maven2
-          http://ftp.ggi-project.org/pub/packages/maven2
-          http://mirrors.sunsite.dk/maven2
-          http://public.planetmirror.com/pub/maven2
-          http://ibiblio.lsu.edu/main/pub/packages/maven2
-          http://www.ibiblio.net/pub/packages/maven2
-  -->
-
-  <property name="repo.maven.org" value="http://repo1.maven.org/maven2/" override="false"/>
-  <property name="snapshot.apache.org" value="https://repository.apache.org/content/repositories/snapshots/" override="false"/>
-  <property name="maven2.pattern" value="[organisation]/[module]/[revision]/[module]-[revision](-[classifier])"/>
-  <property name="repo.dir" value="${user.home}/.m2/repository" override="false"/>
-  <property name="maven2.pattern.ext"  value="${maven2.pattern}.[ext]"/>
-  <property name="sourceforge-repo" value="http://www.sourceforge.net/projects"/>
-  <property name="resolvers" value="default" override="false"/>
-  <!-- pull in the local repository -->
-  <include url="${ivy.default.conf.dir}/ivyconf-local.xml"/>
-  <settings defaultResolver="${resolvers}"/>
-
-  <resolvers>
-    <ibiblio name="maven2" root="${repo.maven.org}" pattern="${maven2.pattern.ext}" m2compatible="true"/>
-    <ibiblio name="apache-snapshot" root="${snapshot.apache.org}" m2compatible="true"
-             checkmodified="${ivy.checkmodified}" 
-             changingPattern="${ivy.changingPattern}"/>
-
-    <url name="datanucleus-repo" m2compatible="true">
-      <artifact pattern="${datanucleus.repo}/[organisation]/[module]/[revision]/[module]-[revision](-[classifier]).[ext]"/>
-    </url>
-
-    <url name="sourceforge" m2compatible="false" checksums="">
-      <artifact pattern="${sourceforge-repo}/[module]/files/[module]/[branch]/[module]-[revision](-[classifier]).[ext]"/>
-    </url>
-
-    <filesystem name="fs" m2compatible="true" alwaysCheckExactRevision="true">
-       <artifact pattern="${repo.dir}/[organisation]/[module]/[revision]/[module]-[revision](-[classifier]).[ext]"/>
-       <ivy pattern="${repo.dir}/[organisation]/[module]/[revision]/[module]-[revision](-[classifier]).pom"/>
-    </filesystem>
-
-    <chain name="default" dual="true" returnFirst="true" 
-           checkmodified="${ivy.checkmodified}" 
-           changingPattern="${ivy.changingPattern}">
-      <resolver ref="local" />
-      <resolver ref="apache-snapshot"/>
-      <resolver ref="maven2"/>
-      <resolver ref="datanucleus-repo"/>
-      <resolver ref="sourceforge"/>
-    </chain>
-
-    <chain name="internal" dual="true">
-      <resolver ref="local" />
-      <resolver ref="fs"/>
-      <resolver ref="apache-snapshot"/>
-      <resolver ref="maven2"/>
-      <resolver ref="datanucleus-repo"/>
-      <resolver ref="sourceforge"/>
-    </chain>
-
-    <chain name="external">
-      <resolver ref="maven2"/>
-      <resolver ref="datanucleus-repo"/>
-    </chain>
-
-  </resolvers>
-
-  <modules>
-    <module organisation="org.apache.hadoop" name="hadoop-*" resolver="${resolvers}"/>
-    <module organisation="org.apache.hive" name=".*" resolver="${resolvers}"/>
-  </modules>
-
-  <caches default="${ivy.cache.name}" 
-          resolutionCacheDir="${build.ivy.dir}/resolution-cache">
-    <cache name="online"/>
-    <!--
-         Set the defaultTTL to 1000 days. Ivy 2.1.0 allows you to
-         set this to "eternal", but we want to maintain backwards
-         compatibility with older versions of Ivy which are likely
-         to get picked up automatically from a user's $ANT_HOME
-         directory.
-      -->
-    <cache name="offline" defaultTTL="1000d"/>
-  </caches>
-</ivysettings>
diff --git a/src/ivy/libraries.properties b/src/ivy/libraries.properties
deleted file mode 100644
index 9654f04..0000000
--- a/src/ivy/libraries.properties
+++ /dev/null
@@ -1,73 +0,0 @@
-#   Licensed under the Apache License, Version 2.0 (the "License");
-#   you may not use this file except in compliance with the License.
-#   You may obtain a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#   Unless required by applicable law or agreed to in writing, software
-#   distributed under the License is distributed on an "AS IS" BASIS,
-#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#   See the License for the specific language governing permissions and
-#   limitations under the License.
-
-# This properties file lists the versions of the various artifacts used by Hive
-# and components.
-#
-# It drives Ivy, the generation of a maven POM, and the generation of Eclipse
-# project configuration files.
-
-# These are the versions of our dependencies (in alphabetical order)
-apacheant.version=1.7.1
-ant-contrib.version=1.0b3
-ant-task.version=2.0.10
-antlr.version=3.4
-antlr-runtime.version=3.4
-avro.version=1.7.1
-datanucleus-api-jdo.version=3.2.1
-datanucleus-core.version=3.2.2
-datanucleus-rdbms.version=3.2.1
-checkstyle.version=5.0
-findbugs.version=1.3.9
-BoneCP.version=0.7.1.RELEASE
-commons-cli.version=1.2
-commons-codec.version=1.4
-commons-collections.version=3.2.1
-commons-compress.version=1.4.1
-commons-configuration.version=1.6
-commons-httpclient.version=3.0.1
-commons-io.version=2.4
-commons-lang.version=2.4
-commons-logging.version=1.1.1
-commons-logging-api.version=1.0.4
-commons-pool.version=1.5.4
-derby.version=10.4.2.0
-guava.version=11.0.2
-hbase.version=0.94.6.1
-httpclient.version=4.2.5
-httpcore.version=4.2.4
-jackson.version=1.8.8
-javaewah.version=0.3.2
-jdo-api.version=3.0.1
-jdom.version=1.1
-jetty.version=6.1.26
-jline.version=0.9.94
-json.version=20090211
-junit.version=4.10
-kryo.version=2.22
-libfb303.version=0.9.0
-libthrift.version=0.9.0.cloudera.2
-log4j.version=1.2.16
-maven-ant-tasks.version=2.1.0
-mockito-all.version=1.8.2
-protobuf.version=2.5.0
-rat.version=0.8
-slf4j-api.version=1.7.5
-slf4j-log4j12.version=1.7.5
-ST4.version=4.0.4
-tempus-fugit.version=1.1
-snappy.version=0.2
-velocity.version=1.5
-metrics-core.version=2.1.2
-zookeeper.version=3.4.3
-javolution.version=5.5.1
-mina.version=2.0.0-M5
diff --git a/src/jdbc/build.xml b/src/jdbc/build.xml
deleted file mode 100644
index ed99f28..0000000
--- a/src/jdbc/build.xml
+++ /dev/null
@@ -1,63 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-<project name="jdbc" default="jar">
-  <property name="src.dir" value="${basedir}/src"/>
-
-  <import file="../build-common.xml"/>
-
-  <target name="set-test-classpath">
-    <typedef name="distinctelementsclasspath" classname="org.apache.hadoop.hive.ant.DistinctElementsClassPath"
-      classpath="${build.dir.hive}/anttasks/hive-anttasks-${version}.jar:${build.ivy.lib.dir}/default/commons-collections-${commons-collections.version}.jar:${build.ivy.lib.dir}/default/commons-lang-${commons-lang.version}.jar"/>
-    <distinctelementsclasspath  id="test.classpath">
-      <pathelement location="${test.build.classes}" />
-      <pathelement location="" />
-      <pathelement location="${test.src.data.dir}/conf"/>
-      <pathelement location="${hive.conf.dir}"/>
-      <fileset dir="${test.src.data.dir}" includes="files/*.jar"/>
-      <fileset dir="${hive.root}" includes="testlibs/*.jar"/>
-      <pathelement location="${build.dir.hive}/ql/test/classes"/>
-      <fileset dir="${build.ivy.lib.dir}" includes="default/*.jar"/>
-      <fileset dir="${hive.root}/build/ivy/lib/hadoop0.${hadoop.mr.rev}.shim" includes="*.jar" />     
-      <path refid="classpath" />
-    </distinctelementsclasspath>
-  </target>
-
-  <target name="compile" depends="init,ivy-retrieve">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-        encoding="${build.encoding}"
-        srcdir="${src.dir}/java"
-        includes="**/*.java"
-        destdir="${build.classes}"
-        source="${sourceJavaVersion}"
-        target="${targetJavaVersion}"
-        debug="${javac.debug}"
-        deprecation="${javac.deprecation}"
-        includeantruntime="false"
-        >
-      <classpath refid="classpath"/>
-    </javac>
-  </target>
-
-  <target name="clean">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete dir="${build.classes}/../"/>
-  </target>
-</project>
diff --git a/src/jdbc/ivy.xml b/src/jdbc/ivy.xml
deleted file mode 100644
index b9d0cea..0000000
--- a/src/jdbc/ivy.xml
+++ /dev/null
@@ -1,38 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-jdbc" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <dependency org="org.apache.hive" name="hive-cli" rev="${version}"
-                conf="compile->default" />
-    <dependency org="org.apache.httpcomponents" name="httpcore"
-                rev="${httpcore.version}"/>
-    <dependency org="org.apache.httpcomponents" name="httpclient"
-                rev="${httpclient.version}"/>
-
-  </dependencies>
-</ivy-module>
diff --git a/src/maven-delete-ant.sh b/src/maven-delete-ant.sh
deleted file mode 100644
index 426d318..0000000
--- a/src/maven-delete-ant.sh
+++ /dev/null
@@ -1,66 +0,0 @@
-#!/bin/bash
-function delete() {
-  rm -rf "$@"
-}
-delete build.properties
-delete build.xml
-delete build-common.xml
-delete build-offline.xml
-delete ant/build.xml
-delete beeline/build.xml
-delete cli/build.xml
-delete common/build.xml
-delete contrib/build.xml
-delete hbase-handler/build.xml
-delete hcatalog/build.xml
-delete hcatalog/core/build.xml
-delete hcatalog/hcatalog-pig-adapter/build.xml
-delete hcatalog/server-extensions/build.xml
-delete hcatalog/src/test/e2e/hcatalog/build.xml
-delete hcatalog/src/test/e2e/hcatalog/tools/generate/java/build.xml
-delete hcatalog/src/test/e2e/hcatalog/udfs/java/build.xml
-delete hcatalog/src/test/e2e/templeton/build.xml
-delete hcatalog/storage-handlers/hbase/build.xml
-delete hcatalog/webhcat/java-client/build.xml
-delete hcatalog/webhcat/svr/build.xml
-delete hwi/build.xml
-delete jdbc/build.xml
-delete metastore/build.xml
-delete odbc/build.xml
-delete ql/build.xml
-delete serde/build.xml
-delete service/build.xml
-delete shims/build.xml
-delete testutils/build.xml
-delete hcatalog/core/pom-old.xml
-delete hcatalog/hcatalog-pig-adapter/pom-old.xml
-delete hcatalog/pom-old.xml
-delete hcatalog/server-extensions/pom-old.xml
-delete hcatalog/storage-handlers/hbase/pom-old.xml
-delete hcatalog/webhcat/java-client/pom-old.xml
-delete hcatalog/webhcat/svr/pom-old.xml
-delete hcatalog/build-support/ant/build-command.xml
-delete hcatalog/build-support/ant/deploy.xml
-delete hcatalog/build-support/ant/test.xml
-delete ivy
-delete hwi/ivy.xml
-delete ivy.xml
-delete jdbc/ivy.xml
-delete testutils/ivy.xml
-delete odbc/ivy.xml
-delete common/ivy.xml
-delete contrib/ivy.xml
-delete hbase-handler/ivy.xml
-delete ant/ivy.xml
-delete hcatalog/ivy.xml
-delete shims/ivy.xml
-delete beeline/ivy.xml
-delete serde/ivy.xml
-delete service/ivy.xml
-delete metastore/ivy.xml
-delete cli/ivy.xml
-delete ql/ivy.xml
-delete eclipse-templates
-delete maven-rollback.sh
-delete maven-rollforward.sh
-delete maven-delete-ant.sh
diff --git a/src/maven-rollback.sh b/src/maven-rollback.sh
deleted file mode 100644
index 3ac1405..0000000
--- a/src/maven-rollback.sh
+++ /dev/null
@@ -1,149 +0,0 @@
-# rollback file, generated with:
-set -e
-move_source() {
-  source=$1
-  target=$2
-  mkdir -p $(dirname $target)
-  mv $source $target
-}
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/serde2/TestSerdeWithFieldComments.java serde/src/test/org/apache/hadoop/hive/serde2/TestSerdeWithFieldComments.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/serde2/dynamic_type/TestDynamicSerDe.java serde/src/test/org/apache/hadoop/hive/serde2/dynamic_type/TestDynamicSerDe.java
-move_source itests/hive-unit/src/test/java/org/apache/hive/service/cli/thrift/TestThriftHttpCLIService.java service/src/test/org/apache/hive/service/cli/thrift/TestThriftHttpCLIService.java
-move_source itests/hive-unit/src/test/java/org/apache/hive/service/auth/TestCustomAuthentication.java service/src/test/org/apache/hive/service/auth/TestCustomAuthentication.java
-move_source itests/hive-unit/src/test/java/org/apache/hive/service/server/TestHS2ThreadAllocation.java service/src/test/org/apache/hive/service/server/TestHS2ThreadAllocation.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreEventListenerOnlyOnCommit.java metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreEventListenerOnlyOnCommit.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreEndFunctionListener.java metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreEndFunctionListener.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStoreWithEnvironmentContext.java metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStoreWithEnvironmentContext.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreConnectionUrlHook.java metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreConnectionUrlHook.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestPartitionNameWhitelistValidation.java metastore/src/test/org/apache/hadoop/hive/metastore/TestPartitionNameWhitelistValidation.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreInitListener.java metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreInitListener.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMarkPartition.java metastore/src/test/org/apache/hadoop/hive/metastore/TestMarkPartition.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMarkPartitionRemote.java metastore/src/test/org/apache/hadoop/hive/metastore/TestMarkPartitionRemote.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreEventListener.java metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreEventListener.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRemoteHiveMetaStore.java metastore/src/test/org/apache/hadoop/hive/metastore/TestRemoteHiveMetaStore.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestEmbeddedHiveMetaStore.java metastore/src/test/org/apache/hadoop/hive/metastore/TestEmbeddedHiveMetaStore.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestSetUGIOnBothClientServer.java metastore/src/test/org/apache/hadoop/hive/metastore/TestSetUGIOnBothClientServer.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestSetUGIOnOnlyServer.java metastore/src/test/org/apache/hadoop/hive/metastore/TestSetUGIOnOnlyServer.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestSetUGIOnOnlyClient.java metastore/src/test/org/apache/hadoop/hive/metastore/TestSetUGIOnOnlyClient.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java metastore/src/test/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaTool.java metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaTool.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRawStoreTxn.java metastore/src/test/org/apache/hadoop/hive/metastore/TestRawStoreTxn.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreListenersError.java metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreListenersError.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java metastore/src/test/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRemoteUGIHiveMetaStoreIpAddress.java metastore/src/test/org/apache/hadoop/hive/metastore/TestRemoteUGIHiveMetaStoreIpAddress.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreAuthorization.java metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreAuthorization.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRemoteHiveMetaStoreIpAddress.java metastore/src/test/org/apache/hadoop/hive/metastore/TestRemoteHiveMetaStoreIpAddress.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/TestStorageBasedClientSideAuthorizationProvider.java ql/src/test/org/apache/hadoop/hive/ql/security/TestStorageBasedClientSideAuthorizationProvider.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/TestClientSideAuthorizationProvider.java ql/src/test/org/apache/hadoop/hive/ql/security/TestClientSideAuthorizationProvider.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/TestStorageBasedMetastoreAuthorizationProvider.java ql/src/test/org/apache/hadoop/hive/ql/security/TestStorageBasedMetastoreAuthorizationProvider.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/TestMetastoreAuthorizationProvider.java ql/src/test/org/apache/hadoop/hive/ql/security/TestMetastoreAuthorizationProvider.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/TestAuthorizationPreEventListener.java ql/src/test/org/apache/hadoop/hive/ql/security/TestAuthorizationPreEventListener.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/history/TestHiveHistory.java ql/src/test/org/apache/hadoop/hive/ql/history/TestHiveHistory.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
-move_source itests/hive-unit/src/test/java/org/apache/hive/service/server/TestHiveServer2Concurrency.java service/src/test/org/apache/hive/service/server/TestHiveServer2Concurrency.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/BaseTestQueries.java ql/src/test/org/apache/hadoop/hive/ql/BaseTestQueries.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/TestLocationQueries.java ql/src/test/org/apache/hadoop/hive/ql/TestLocationQueries.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/TestMTQueries.java ql/src/test/org/apache/hadoop/hive/ql/TestMTQueries.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java hbase-handler/src/test/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseTestSetup.java hbase-handler/src/test/org/apache/hadoop/hive/hbase/HBaseTestSetup.java
-
-move_source shims/0.20/src/main/java shims/src/0.20/java
-move_source shims/0.20S/src/main/java shims/src/0.20S/java
-move_source shims/0.23/src/main/java shims/src/0.23/java
-move_source shims/common/src/main/java shims/src/common/java
-move_source shims/common-secure/src/main/java shims/src/common-secure/java
-
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/thrift/TestDBTokenStore.java shims/src/common-secure/test/org/apache/hadoop/hive/thrift/TestDBTokenStore.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java shims/src/common-secure/test/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/thrift/TestZooKeeperTokenStore.java shims/src/common-secure/test/org/apache/hadoop/hive/thrift/TestZooKeeperTokenStore.java
-
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java
-move_source itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java
-
-move_source itests/hive-unit/src/test/java/org/apache/hive/service/cli/TestEmbeddedThriftBinaryCLIService.java service/src/test/org/apache/hive/service/cli/TestEmbeddedThriftBinaryCLIService.java
-move_source itests/hive-unit/src/test/java/org/apache/hive/service/cli/thrift/TestThriftBinaryCLIService.java service/src/test/org/apache/hive/service/cli/thrift/TestThriftBinaryCLIService.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/service/TestHiveServer.java service/src/test/org/apache/hadoop/hive/service/TestHiveServer.java
-
-move_source itests/util/src/main/java/org/apache/hadoop/hive/scripts/extracturl.java ql/src/test/org/apache/hadoop/hive/scripts/extracturl.java
-
-move_source itests/hive-unit/src/test/java/org/apache/hive/beeline/TestSchemaTool.java beeline/src/test/org/apache/hive/beeline/src/test/TestSchemaTool.java
-
-move_source beeline/src/main/resources/sql-keywords.properties beeline/src/java/org/apache/hive/beeline/sql-keywords.properties
-move_source beeline/src/main/resources/BeeLine.properties beeline/src/java/org/apache/hive/beeline/BeeLine.properties
-
-move_source ql/src/main/resources/hive-exec-log4j.properties ql/src/java/conf/hive-exec-log4j.properties
-move_source common/src/main/resources/hive-log4j.properties common/src/java/conf/hive-log4j.properties
-
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java ql/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java
-move_source ql/src/java/org/apache/hadoop/hive/ql/hooks/PreExecutePrinter.java ql/src/test/org/apache/hadoop/hive/ql/hooks/PreExecutePrinter.java
-move_source ql/src/java/org/apache/hadoop/hive/ql/hooks/PostExecutePrinter.java ql/src/test/org/apache/hadoop/hive/ql/hooks/PostExecutePrinter.java
-move_source ql/src/java/org/apache/hadoop/hive/ql/hooks/EnforceReadOnlyTables.java ql/src/test/org/apache/hadoop/hive/ql/hooks/EnforceReadOnlyTables.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/security/DummyAuthenticator.java ql/src/test/org/apache/hadoop/hive/ql/security/DummyAuthenticator.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/security/DummyHiveMetastoreAuthorizationProvider.java ql/src/test/org/apache/hadoop/hive/ql/security/DummyHiveMetastoreAuthorizationProvider.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/security/InjectableDummyAuthenticator.java ql/src/test/org/apache/hadoop/hive/ql/security/InjectableDummyAuthenticator.java
-
-
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyHiveSortedInputFormatUsedHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyHiveSortedInputFormatUsedHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/CheckTableAccessHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/CheckTableAccessHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyContentSummaryCacheHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyContentSummaryCacheHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifySessionStateLocalErrorsHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifySessionStateLocalErrorsHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifySessionStateStackTracesHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifySessionStateStackTracesHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/MapJoinCounterHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/MapJoinCounterHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/CheckQueryPropertiesHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/CheckQueryPropertiesHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyHooksRunInOrder.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyHooksRunInOrder.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyOutputTableLocationSchemeIsFileHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyOutputTableLocationSchemeIsFileHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyIsLocalModeHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyIsLocalModeHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyCachingPrintStreamHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyCachingPrintStreamHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyNumReducersHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyNumReducersHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyPartitionIsNotSubdirectoryOfTableHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyPartitionIsNotSubdirectoryOfTableHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyOverriddenConfigsHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyOverriddenConfigsHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyPartitionIsSubdirectoryOfTableHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyPartitionIsSubdirectoryOfTableHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/OptrStatGroupByHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/OptrStatGroupByHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/CheckColumnAccessHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/CheckColumnAccessHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyTableDirectoryIsEmptyHook.java ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyTableDirectoryIsEmptyHook.java
-
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/UDFTestErrorOnFalse.java ql/src/test/org/apache/hadoop/hive/ql/udf/UDFTestErrorOnFalse.java
-
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsPublisher.java ql/src/test/org/apache/hadoop/hive/ql/stats/DummyStatsPublisher.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java ql/src/test/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java ql/src/test/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java
-
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/io/udf/Rot13InputFormat.java ql/src/test/org/apache/hadoop/hive/ql/io/udf/Rot13InputFormat.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/io/udf/Rot13OutputFormat.java ql/src/test/org/apache/hadoop/hive/ql/io/udf/Rot13OutputFormat.java
-
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/DummyContextUDF.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/DummyContextUDF.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFSumList.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFSumList.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFEvaluateNPE.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/GenericUDFEvaluateNPE.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestGetJavaBoolean.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestGetJavaBoolean.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestGetJavaString.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestGetJavaString.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestTranslate.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestTranslate.java
-
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/UDAFTestMax.java ql/src/test/org/apache/hadoop/hive/ql/udf/UDAFTestMax.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/UDFTestLength2.java ql/src/test/org/apache/hadoop/hive/ql/udf/UDFTestLength2.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/UDFTestLength.java ql/src/test/org/apache/hadoop/hive/ql/udf/UDFTestLength.java
-
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/metadata/DummySemanticAnalyzerHook.java ql/src/test/org/apache/hadoop/hive/ql/metadata/DummySemanticAnalyzerHook.java
-move_source itests/util/src/main/java/org/apache/hadoop/hive/ql/metadata/DummySemanticAnalyzerHook1.java ql/src/test/org/apache/hadoop/hive/ql/metadata/DummySemanticAnalyzerHook1.java
-move_source itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/metadata/TestSemanticAnalyzerHookLoading.java ql/src/test/org/apache/hadoop/hive/ql/metadata/TestSemanticAnalyzerHookLoading.java
-
-move_source itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/mapreduce/TestSequenceFileReadWrite.java hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestSequenceFileReadWrite.java
-move_source itests/hcatalog-unit/src/test/java/org/apache/hcatalog/mapreduce/TestSequenceFileReadWrite.java hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestSequenceFileReadWrite.java
-
-move_source itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatHiveCompatibility.java hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatHiveCompatibility.java
-move_source itests/hcatalog-unit/src/test/java/org/apache/hcatalog/mapreduce/TestHCatHiveCompatibility.java hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestHCatHiveCompatibility.java
-move_source itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatHiveThriftCompatibility.java  hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatHiveThriftCompatibility.java
-move_source itests/hcatalog-unit/src/test/java/org/apache/hcatalog/mapreduce/TestHCatHiveThriftCompatibility.java hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestHCatHiveThriftCompatibility.java
-
-move_source itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/hbase/TestPigHBaseStorageHandler.java hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/TestPigHBaseStorageHandler.java
-
-move_source itests/test-serde/src/main/java/org/apache/hadoop/hive/serde2/TestSerDe.java ql/src/test/org/apache/hadoop/hive/serde2/TestSerDe.java
-move_source itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomNonSettableListObjectInspector1.java ql/src/test/org/apache/hadoop/hive/serde2/CustomNonSettableListObjectInspector1.java
-move_source itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomNonSettableStructObjectInspector1.java ql/src/test/org/apache/hadoop/hive/serde2/CustomNonSettableStructObjectInspector1.java
-move_source itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomNonSettableUnionObjectInspector1.java ql/src/test/org/apache/hadoop/hive/serde2/CustomNonSettableUnionObjectInspector1.java
-move_source itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe1.java ql/src/test/org/apache/hadoop/hive/serde2/CustomSerDe1.java
-move_source itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe2.java ql/src/test/org/apache/hadoop/hive/serde2/CustomSerDe2.java
-move_source itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe3.java ql/src/test/org/apache/hadoop/hive/serde2/CustomSerDe3.java
-move_source itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe4.java ql/src/test/org/apache/hadoop/hive/serde2/CustomSerDe4.java
-move_source itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe5.java ql/src/test/org/apache/hadoop/hive/serde2/CustomSerDe5.java
-
diff --git a/src/maven-rollforward.sh b/src/maven-rollforward.sh
deleted file mode 100644
index 77e1457..0000000
--- a/src/maven-rollforward.sh
+++ /dev/null
@@ -1,153 +0,0 @@
-set -e
-move_source() {
-  source=$1
-  target=$2
-  if [[ ! -e $source ]]
-  then
-    echo $source
-  fi
-  mkdir -p $(dirname $target)
-  git mv $source $target
-}
-move_source serde/src/test/org/apache/hadoop/hive/serde2/TestSerdeWithFieldComments.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/serde2/TestSerdeWithFieldComments.java
-move_source serde/src/test/org/apache/hadoop/hive/serde2/dynamic_type/TestDynamicSerDe.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/serde2/dynamic_type/TestDynamicSerDe.java
-move_source service/src/test/org/apache/hive/service/cli/thrift/TestThriftHttpCLIService.java itests/hive-unit/src/test/java/org/apache/hive/service/cli/thrift/TestThriftHttpCLIService.java
-move_source service/src/test/org/apache/hive/service/server/TestHS2ThreadAllocation.java itests/hive-unit/src/test/java/org/apache/hive/service/server/TestHS2ThreadAllocation.java
-move_source service/src/test/org/apache/hive/service/auth/TestCustomAuthentication.java itests/hive-unit/src/test/java/org/apache/hive/service/auth/TestCustomAuthentication.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreEventListenerOnlyOnCommit.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreEventListenerOnlyOnCommit.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreEndFunctionListener.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreEndFunctionListener.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStoreWithEnvironmentContext.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStoreWithEnvironmentContext.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreConnectionUrlHook.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreConnectionUrlHook.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestPartitionNameWhitelistValidation.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestPartitionNameWhitelistValidation.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreInitListener.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreInitListener.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestMarkPartition.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMarkPartition.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestMarkPartitionRemote.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMarkPartitionRemote.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreEventListener.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreEventListener.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestRemoteHiveMetaStore.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRemoteHiveMetaStore.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestEmbeddedHiveMetaStore.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestEmbeddedHiveMetaStore.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestSetUGIOnBothClientServer.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestSetUGIOnBothClientServer.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestSetUGIOnOnlyServer.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestSetUGIOnOnlyServer.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestSetUGIOnOnlyClient.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestSetUGIOnOnlyClient.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaTool.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaTool.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestRawStoreTxn.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRawStoreTxn.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreListenersError.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreListenersError.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestRemoteUGIHiveMetaStoreIpAddress.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRemoteUGIHiveMetaStoreIpAddress.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestMetaStoreAuthorization.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreAuthorization.java
-move_source metastore/src/test/org/apache/hadoop/hive/metastore/TestRemoteHiveMetaStoreIpAddress.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRemoteHiveMetaStoreIpAddress.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/security/TestStorageBasedClientSideAuthorizationProvider.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/TestStorageBasedClientSideAuthorizationProvider.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/security/TestClientSideAuthorizationProvider.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/TestClientSideAuthorizationProvider.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/security/TestStorageBasedMetastoreAuthorizationProvider.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/TestStorageBasedMetastoreAuthorizationProvider.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/security/TestMetastoreAuthorizationProvider.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/TestMetastoreAuthorizationProvider.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/security/TestAuthorizationPreEventListener.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/TestAuthorizationPreEventListener.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/history/TestHiveHistory.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/history/TestHiveHistory.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
-move_source service/src/test/org/apache/hive/service/server/TestHiveServer2Concurrency.java itests/hive-unit/src/test/java/org/apache/hive/service/server/TestHiveServer2Concurrency.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/BaseTestQueries.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/BaseTestQueries.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/TestLocationQueries.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/TestLocationQueries.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/TestMTQueries.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/TestMTQueries.java
-move_source hbase-handler/src/test/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java
-move_source hbase-handler/src/test/org/apache/hadoop/hive/hbase/HBaseTestSetup.java itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseTestSetup.java
-
-# eclipse doesn't like .. references in it's path to src
-move_source shims/src/0.20/java shims/0.20/src/main/java
-move_source shims/src/0.20S/java shims/0.20S/src/main/java
-move_source shims/src/0.23/java shims/0.23/src/main/java
-move_source shims/src/common/java shims/common/src/main/java
-move_source shims/src/common-secure/java shims/common-secure/src/main/java
-# cyclic deps
-move_source shims/src/common-secure/test/org/apache/hadoop/hive/thrift/TestDBTokenStore.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/thrift/TestDBTokenStore.java
-move_source shims/src/common-secure/test/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java
-move_source shims/src/common-secure/test/org/apache/hadoop/hive/thrift/TestZooKeeperTokenStore.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/thrift/TestZooKeeperTokenStore.java
-
-move_source jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java
-move_source jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java
-
-move_source service/src/test/org/apache/hive/service/cli/TestEmbeddedThriftBinaryCLIService.java itests/hive-unit/src/test/java/org/apache/hive/service/cli/TestEmbeddedThriftBinaryCLIService.java
-move_source service/src/test/org/apache/hive/service/cli/thrift/TestThriftBinaryCLIService.java itests/hive-unit/src/test/java/org/apache/hive/service/cli/thrift/TestThriftBinaryCLIService.java
-move_source service/src/test/org/apache/hadoop/hive/service/TestHiveServer.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/service/TestHiveServer.java
-
-move_source ql/src/test/org/apache/hadoop/hive/scripts/extracturl.java itests/util/src/main/java/org/apache/hadoop/hive/scripts/extracturl.java
-
-move_source beeline/src/test/org/apache/hive/beeline/src/test/TestSchemaTool.java itests/hive-unit/src/test/java/org/apache/hive/beeline/TestSchemaTool.java
-
-move_source beeline/src/java/org/apache/hive/beeline/sql-keywords.properties beeline/src/main/resources/sql-keywords.properties
-move_source beeline/src/java/org/apache/hive/beeline/BeeLine.properties beeline/src/main/resources/BeeLine.properties
-
-move_source ql/src/java/conf/hive-exec-log4j.properties ql/src/main/resources/hive-exec-log4j.properties
-move_source common/src/java/conf/hive-log4j.properties common/src/main/resources/hive-log4j.properties
-
-move_source ql/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java metastore/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/PreExecutePrinter.java ql/src/java/org/apache/hadoop/hive/ql/hooks/PreExecutePrinter.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/PostExecutePrinter.java ql/src/java/org/apache/hadoop/hive/ql/hooks/PostExecutePrinter.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/EnforceReadOnlyTables.java ql/src/java/org/apache/hadoop/hive/ql/hooks/EnforceReadOnlyTables.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/security/DummyAuthenticator.java itests/util/src/main/java/org/apache/hadoop/hive/ql/security/DummyAuthenticator.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/security/DummyHiveMetastoreAuthorizationProvider.java itests/util/src/main/java/org/apache/hadoop/hive/ql/security/DummyHiveMetastoreAuthorizationProvider.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/security/InjectableDummyAuthenticator.java itests/util/src/main/java/org/apache/hadoop/hive/ql/security/InjectableDummyAuthenticator.java
-
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyHiveSortedInputFormatUsedHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyHiveSortedInputFormatUsedHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/CheckTableAccessHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/CheckTableAccessHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyContentSummaryCacheHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyContentSummaryCacheHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifySessionStateLocalErrorsHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifySessionStateLocalErrorsHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifySessionStateStackTracesHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifySessionStateStackTracesHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/MapJoinCounterHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/MapJoinCounterHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/CheckQueryPropertiesHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/CheckQueryPropertiesHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyHooksRunInOrder.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyHooksRunInOrder.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyOutputTableLocationSchemeIsFileHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyOutputTableLocationSchemeIsFileHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyIsLocalModeHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyIsLocalModeHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyCachingPrintStreamHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyCachingPrintStreamHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyNumReducersHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyNumReducersHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyPartitionIsNotSubdirectoryOfTableHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyPartitionIsNotSubdirectoryOfTableHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyOverriddenConfigsHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyOverriddenConfigsHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyPartitionIsSubdirectoryOfTableHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyPartitionIsSubdirectoryOfTableHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/OptrStatGroupByHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/OptrStatGroupByHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/CheckColumnAccessHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/CheckColumnAccessHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyTableDirectoryIsEmptyHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/VerifyTableDirectoryIsEmptyHook.java
-
-move_source ql/src/test/org/apache/hadoop/hive/ql/udf/UDFTestErrorOnFalse.java itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/UDFTestErrorOnFalse.java
-
-move_source ql/src/test/org/apache/hadoop/hive/ql/stats/DummyStatsPublisher.java itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsPublisher.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java
-
-move_source ql/src/test/org/apache/hadoop/hive/ql/io/udf/Rot13InputFormat.java itests/util/src/main/java/org/apache/hadoop/hive/ql/io/udf/Rot13InputFormat.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/io/udf/Rot13OutputFormat.java itests/util/src/main/java/org/apache/hadoop/hive/ql/io/udf/Rot13OutputFormat.java
-
-move_source ql/src/test/org/apache/hadoop/hive/ql/udf/generic/DummyContextUDF.java itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/DummyContextUDF.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFSumList.java itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFSumList.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/udf/generic/GenericUDFEvaluateNPE.java itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFEvaluateNPE.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestGetJavaBoolean.java itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestGetJavaBoolean.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestGetJavaString.java itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestGetJavaString.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestTranslate.java itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTestTranslate.java
-
-move_source ql/src/test/org/apache/hadoop/hive/ql/udf/UDAFTestMax.java itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/UDAFTestMax.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/udf/UDFTestLength2.java itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/UDFTestLength2.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/udf/UDFTestLength.java itests/util/src/main/java/org/apache/hadoop/hive/ql/udf/UDFTestLength.java
-
-
-move_source ql/src/test/org/apache/hadoop/hive/ql/metadata/DummySemanticAnalyzerHook.java itests/util/src/main/java/org/apache/hadoop/hive/ql/metadata/DummySemanticAnalyzerHook.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/metadata/DummySemanticAnalyzerHook1.java itests/util/src/main/java/org/apache/hadoop/hive/ql/metadata/DummySemanticAnalyzerHook1.java
-move_source ql/src/test/org/apache/hadoop/hive/ql/metadata/TestSemanticAnalyzerHookLoading.java itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/metadata/TestSemanticAnalyzerHookLoading.java
-
-move_source hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestSequenceFileReadWrite.java itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/mapreduce/TestSequenceFileReadWrite.java
-move_source hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestSequenceFileReadWrite.java itests/hcatalog-unit/src/test/java/org/apache/hcatalog/mapreduce/TestSequenceFileReadWrite.java
-
-move_source hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatHiveCompatibility.java itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatHiveCompatibility.java
-move_source hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestHCatHiveCompatibility.java itests/hcatalog-unit/src/test/java/org/apache/hcatalog/mapreduce/TestHCatHiveCompatibility.java
-move_source hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatHiveThriftCompatibility.java itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatHiveThriftCompatibility.java
-move_source hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestHCatHiveThriftCompatibility.java itests/hcatalog-unit/src/test/java/org/apache/hcatalog/mapreduce/TestHCatHiveThriftCompatibility.java
-
-move_source hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/TestPigHBaseStorageHandler.java itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/hbase/TestPigHBaseStorageHandler.java
-
-move_source ql/src/test/org/apache/hadoop/hive/serde2/TestSerDe.java itests/test-serde/src/main/java/org/apache/hadoop/hive/serde2/TestSerDe.java
-move_source ql/src/test/org/apache/hadoop/hive/serde2/CustomNonSettableListObjectInspector1.java itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomNonSettableListObjectInspector1.java
-move_source ql/src/test/org/apache/hadoop/hive/serde2/CustomNonSettableStructObjectInspector1.java itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomNonSettableStructObjectInspector1.java
-move_source ql/src/test/org/apache/hadoop/hive/serde2/CustomNonSettableUnionObjectInspector1.java itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomNonSettableUnionObjectInspector1.java
-move_source ql/src/test/org/apache/hadoop/hive/serde2/CustomSerDe1.java itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe1.java
-move_source ql/src/test/org/apache/hadoop/hive/serde2/CustomSerDe2.java itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe2.java
-move_source ql/src/test/org/apache/hadoop/hive/serde2/CustomSerDe3.java itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe3.java
-move_source ql/src/test/org/apache/hadoop/hive/serde2/CustomSerDe4.java itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe4.java
-move_source ql/src/test/org/apache/hadoop/hive/serde2/CustomSerDe5.java itests/custom-serde/src/main/java/org/apache/hadoop/hive/serde2/CustomSerDe5.java
-
diff --git a/src/metastore/build.xml b/src/metastore/build.xml
deleted file mode 100755
index 55e9bd7..0000000
--- a/src/metastore/build.xml
+++ /dev/null
@@ -1,134 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-<project name="metastore" default="jar">
-  <property name="src.dir" value="${basedir}/src"/>
-  <import file="../build-common.xml"/>
-  <property name="model.dir" value="${src.dir}/model"/>
-
-  <uptodate property="grammarBuild.notRequired">
-    <srcfiles dir= "${src.dir}/java/org/apache/hadoop/hive/metastore/parser" includes="**/*.g"/>
-    <mapper type="merge" to="${build.dir}/gen/antlr/gen-java/org/apache/hadoop/hive/metastore/parser/FilterParser.java"/>
-  </uptodate>
-
-  <target name="build-grammar" unless="grammarBuild.notRequired" depends="ivy-retrieve">
-    <echo message="Project: ${ant.project.name}"/>
-    <echo>Building Grammar ${src.dir}/java/org/apache/hadoop/hive/metastore/parser/Filter.g  ....</echo>
-    <java classname="org.antlr.Tool" classpathref="classpath" fork="false" failonerror="true">
-       <arg value="-fo" />
-       <arg value="${build.dir}/gen/antlr/gen-java/org/apache/hadoop/hive/metastore/parser" />
-       <arg value="${src.dir}/java/org/apache/hadoop/hive/metastore/parser/Filter.g" />
-    </java>
-  </target>
-
-  <target name="metastore-init">
-    <echo message="Project: ${ant.project.name}"/>
-    <mkdir dir="${build.dir}/gen/antlr/gen-java/org/apache/hadoop/hive/metastore/parser"/>
-  </target>
-
-  <target name="core-compile" depends="init,metastore-init,build-grammar,model-compile,ivy-retrieve">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${src.dir}/java:${src.dir}/gen/thrift/gen-javabean:${build.dir}/gen/antlr/gen-java"
-     includes="**/*.java"
-     destdir="${build.classes}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     debug="${javac.debug}"
-     deprecation="${javac.deprecation}"
-     includeantruntime="false">
-      <classpath refid="classpath"/>
-    </javac>
-  </target>
-
-  <target name="compile" depends="core-compile, model-compile, model-enhance">
-    <echo message="Project: ${ant.project.name}"/>
-  </target>
-
-  <target name="model-compile" depends="init">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-        srcdir="${model.dir}"
-        destdir="${build.classes}"
-        source="${sourceJavaVersion}"
-        target="${targetJavaVersion}"
-        debug="${javac.debug}"
-        includeantruntime="false">
-       <classpath refid="classpath"/>
-    </javac>
-    <!-- ORM data for model -->
-    <copy file="${model.dir}/package.jdo" todir="${build.classes}"/>
-  </target>
-
-  <uptodate property="enhanceModel.notRequired">
-    <srcfiles dir= "${model.dir}" includes="**/*.java,*.jdo"/>
-    <mapper type="merge" to="${build.dir}/hive-${ant.project.name}-${version}.jar"/>
-  </uptodate>
-
-  <target name="model-enhance" depends="model-compile" unless="enhanceModel.notRequired" >
-    <echo message="Project: ${ant.project.name}"/>
-    <taskdef name="datanucleusenhancer"
-                classname="org.datanucleus.enhancer.EnhancerTask">
-       <classpath refid="classpath"/>
-   </taskdef>
-
-    <datanucleusenhancer
-        dir="${base.dir}" failonerror="true" verbose="true" fork="true">
-        <fileset dir="${model.dir}">
-            <include name="**/*.jdo"/>
-        </fileset>
-	<classpath>
-          <path refid="classpath"/>
-          <pathelement path="${build.dir}/classes/"/>
-	</classpath>
-	<jvmarg line="${jvm.args} -Dlog4j.configuration=${basedir}/../conf/hive-log4j.properties"/>
-    </datanucleusenhancer>
-  </target>
-
-
-  <target name="model-jar" depends="model-enhance">
-    <echo message="Project: ${ant.project.name}"/>
-    <jar
-      jarfile="${build.dir}/${name}-model-${version}.jar"
-      basedir="${build.classes}"
-      includes="**/model/M*">
-      <manifest>
-        <!-- Not putting these in their own manifest section, since that inserts
-             a new-line, which breaks the reading of the attributes. -->
-        <attribute name="Implementation-Title" value="Hive"/>
-        <attribute name="Implementation-Version" value="${version}"/>
-        <attribute name="Implementation-Vendor" value="Apache"/>
-      </manifest>
-      <metainf dir="${hive.root}" includes="LICENSE,NOTICE"/>
-    </jar>
-  </target>
-
-  <target name="generate-schema">
-    <echo message="Project: ${ant.project.name}"/>
-    <java classname="org.jpox.SchemaTool"  failonerror="true" dir="${basedir}" fork="true">
-      <classpath>
-        <path refid="classpath"/>
-        <pathelement path="${build.dir}/classes/"/>
-      </classpath>
-      <sysproperty key="log4j.configuration" value="file:${basedir}/../../../../conf/log4j.properties"/>
-      <arg line="-props jdo/jpox.properties -create jdo/package.jdo" />
-    </java>
-  </target>
-</project>
diff --git a/src/metastore/ivy.xml b/src/metastore/ivy.xml
deleted file mode 100644
index 4bbdfe6..0000000
--- a/src/metastore/ivy.xml
+++ /dev/null
@@ -1,53 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-metastore" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <dependency org="org.antlr" name="antlr" rev="${antlr.version}" transitive="false"/>
-    <dependency org="org.antlr" name="antlr-runtime" rev="${antlr-runtime.version}" transitive="false"/>
-    <dependency org="org.antlr" name="ST4" rev="${ST4.version}" transitive="false"/><!-- manually added (antlr dep), bad POM -->
-    <dependency org="org.apache.hive" name="hive-serde" rev="${version}"
-                conf="compile->default" />
-    <dependency org="com.jolbox" name="bonecp" rev="${BoneCP.version}">
-        <exclude org="com.google.guava" module="guava"/>
-    </dependency>
-
-    <dependency org="commons-pool" name="commons-pool" rev="${commons-pool.version}"/>
-    <dependency org="org.datanucleus" name="datanucleus-api-jdo" rev="${datanucleus-api-jdo.version}">
-        <exclude org="javax.jdo" module="jdo2-api"/>
-        <exclude org="junit" module="junit"/>
-        <exclude org="log4j" module="log4j"/>
-    </dependency>
-    <dependency org="org.datanucleus" name="datanucleus-core" rev="${datanucleus-core.version}"
-                transitive="false"/>
-    <dependency org="org.datanucleus" name="datanucleus-rdbms" rev="${datanucleus-rdbms.version}"
-                transitive="false"/>
-    <dependency org="javax.jdo" name="jdo-api" rev="${jdo-api.version}"
-                transitive="false"/>
-    <dependency org="org.apache.derby" name="derby" rev="${derby.version}"/>
-
-  </dependencies>
-</ivy-module>
diff --git a/src/odbc/build.xml b/src/odbc/build.xml
deleted file mode 100644
index 2228f02..0000000
--- a/src/odbc/build.xml
+++ /dev/null
@@ -1,122 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-<project name="odbc" default="compile-cpp">
-  <property name="src.dir" value="${basedir}/src"/>
-
-  <!--
-    Override properties defined in ../build-common.xml.
-  -->
-  <property name="test.junit.output.format" value="plain"/>
-  <property name="test.output" value="false"/>
-  <property name="test.junit.output.usefile" value="false"/>
-  <property name="make.cmd" value="make"/>
-  <import file="../build-common.xml"/>
-
-  <!--Skip the Make file execution on windows-->
-  <condition property="execute.makefile">
-    <not>
-      <equals arg1="windows" arg2="${os.family}"/>
-    </not>
-  </condition>
-
-  <!-- Only run tests if thrift.home is defined and not on windows-->
-  <condition property="execute.tests">
-    <and>
-      <istrue value="${execute.makefile}"/>
-      <istrue value="${thrift.home.defined}"/>
-    </and>
-  </condition>
-
-  <target name="set-test-classpath">
-    <path id="test.classpath">
-      <pathelement location="${test.build.classes}" />
-      <pathelement location="" />
-      <pathelement location="${test.src.data.dir}/conf"/>
-      <pathelement location="${hive.conf.dir}"/>
-      <fileset dir="${test.src.data.dir}" includes="files/*.jar"/>
-      <fileset dir="${hive.root}" includes="testlibs/*.jar"/>
-      <pathelement location="${build.dir.hive}/ql/test/classes"/>
-      <path refid="classpath"/>
-    </path>
-  </target>
-
-  <target name="check-word-size">
-    <echo message="Project: ${ant.project.name}"/>
-    <condition property="word.size" value="64" else="32">
-      <contains string="${os.arch}" substring="64"/>
-    </condition>
-  </target>
-
-  <target name="compile-cpp" depends="init,check-word-size" if="execute.makefile">
-    <echo message="Project: ${ant.project.name}"/>
-    <exec dir="." executable="${make.cmd}" failonerror="true">
-      <env key="WORD_SIZE" value="${word.size}"/>
-      <env key="THRIFT_HOME" value="${thrift.home}"/>
-      <env key="BOOST_HOME" value="${boost.home}"/>
-      <env key="HIVE_ROOT" value="${hive.root}"/>
-      <env key="BASE_DIR" value="${basedir}"/>
-    </exec>
-    <mkdir dir="${build.dir.hive}/odbc/include"/>
-    <copy file="${basedir}/src/cpp/hiveclient.h" todir="${build.dir.hive}/odbc/include"/>
-    <copy file="${basedir}/src/cpp/hiveconstants.h" todir="${build.dir.hive}/odbc/include"/>
-  </target>
-
-  <target name="clean" if="execute.makefile">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete dir="${build.dir.hive}/odbc/include"/>
-    <exec dir="." executable="${make.cmd}" failonerror="true">
-      <arg line="clean"/>
-      <env key="HIVE_ROOT" value="${hive.root}"/>
-      <env key="BASE_DIR" value="${basedir}"/>
-    </exec>
-  </target>
-
-  <target name="install" depends="check-word-size" if="execute.makefile">
-    <echo message="Project: ${ant.project.name}"/>
-    <exec dir="." executable="${make.cmd}" failonerror="true">
-      <arg line="install"/>
-      <env key="WORD_SIZE" value="${word.size}"/>
-      <env key="THRIFT_HOME" value="${thrift.home}"/>
-      <env key="HIVE_ROOT" value="${hive.root}"/>
-      <env key="BASE_DIR" value="${basedir}"/>
-    </exec>
-  </target>
-
-  <target name="uninstall" if="execute.makefile">
-    <echo message="Project: ${ant.project.name}"/>
-    <exec dir="." executable="${make.cmd}" failonerror="true">
-      <arg line="uninstall"/>
-      <env key="HIVE_ROOT" value="${hive.root}"/>
-      <env key="BASE_DIR" value="${basedir}"/>
-    </exec>
-  </target>
-
-  <!-- Only run tests if thrift.home is defined so that we don't break other tests -->
-  <target name="test" depends="check-word-size,check-thrift-home,set-test-classpath" if="execute.tests">
-    <echo message="Project: ${ant.project.name}"/>
-    <exec dir="." executable="${make.cmd}" failonerror="true">
-      <arg line="test"/>
-      <env key="WORD_SIZE" value="${word.size}"/>
-      <env key="THRIFT_HOME" value="${thrift.home}"/>
-      <env key="HIVE_ROOT" value="${hive.root}"/>
-      <env key="BASE_DIR" value="${basedir}"/>
-    </exec>
-  </target>
-</project>
diff --git a/src/odbc/ivy.xml b/src/odbc/ivy.xml
deleted file mode 100644
index be556ab..0000000
--- a/src/odbc/ivy.xml
+++ /dev/null
@@ -1,34 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-odbc" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <!-- THIS POM IS NOT PUBLISHED! IT EXISTS ONLY TO KEEP IVY/ANT HAPPY DURING THE BUILD.
-         PLEASE IGNORE.
-         -->
-  </dependencies>
-</ivy-module>
diff --git a/src/ql/build.xml b/src/ql/build.xml
deleted file mode 100644
index 277909c..0000000
--- a/src/ql/build.xml
+++ /dev/null
@@ -1,349 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-
-<project xmlns:ivy="antlib:org.apache.ivy.ant" name="ql" default="jar">
-
-  <property name="ql.lib.dir" value="${basedir}/lib"/>
-  <property name="src.dir"  location="${basedir}/src/java"/>
-  <property name="protobuf.src.dir"  location="${basedir}/src/protobuf"/>
-  <property name="protobuf.build.dir"  
-            location="${basedir}/src/gen/protobuf/gen-java"/>
-  <property name="ql.test.query.dir" location="${basedir}/src/test/queries"/>
-  <property name="ql.test.template.dir" location="${basedir}/src/test/templates"/>
-  <property name="ql.test.results.dir" location="${basedir}/src/test/results"/>
-
-  <property name="ql.test.query.clientpositive.dir" location="${ql.test.query.dir}/clientpositive"/>
-  <property name="ql.test.query.beelinepositive.dir" location="${ql.test.query.dir}/beelinepositive"/>
-  <property name="ql.test.results.clientpositive.dir" location="${ql.test.results.dir}/clientpositive"/>
-  <property name="ql.test.results.beelinepositive.dir" location="${ql.test.results.dir}/beelinepositive"/>
-
-  <import file="../build-common.xml"/>
-  <property name="ql.test.clientpositive.exclude" value="${minimr.query.files}"/>
-
-  <property name="ql.test.beelinepositive.exclude" value="${test.beelinepositive.exclude}"/>
-  
-  <target name="gen-test" depends="test-conditions, test-init" >
-    <echo message="${ant.project.name}"/>
-    <taskdef name="qtestgen" classname="org.apache.hadoop.hive.ant.QTestGenTask"
-             classpath="${build.dir.hive}/anttasks/hive-anttasks-${version}.jar:${build.ivy.lib.dir}/default/velocity-${velocity.version}.jar:${build.ivy.lib.dir}/default/commons-collections-${commons-collections.version}.jar:${build.ivy.lib.dir}/default/commons-lang-${commons-lang.version}.jar:${build.ivy.lib.dir}/default/derby-${derby.version}.jar"/>
-    
-    <qtestgen hiveRootDirectory="${hive.root}"
-              outputDirectory="${test.build.src}/org/apache/hadoop/hive/ql/parse" 
-              templatePath="${ql.test.template.dir}" template="TestParse.vm" 
-              queryDirectory="${ql.test.query.dir}/positive"
-              queryFile="${qfile}"
-              queryFileRegex="${qfile_regex}"
-              runDisabled="${run_disabled}"
-              resultsDirectory="${ql.test.results.dir}/compiler" className="TestParse"
-              logFile="${test.log.dir}/testparsegen.log"
-              hadoopVersion="${hadoopVersion}"
-              logDirectory="${test.log.dir}/positive"/>
-    
-    <qtestgen hiveRootDirectory="${hive.root}"
-              outputDirectory="${test.build.src}/org/apache/hadoop/hive/ql/parse" 
-              templatePath="${ql.test.template.dir}" template="TestParseNegative.vm" 
-              queryDirectory="${ql.test.query.dir}/negative" 
-              queryFile="${qfile}"
-              queryFileRegex="${qfile_regex}"
-              runDisabled="${run_disabled}"
-              resultsDirectory="${ql.test.results.dir}/compiler/errors" className="TestParseNegative"
-              logFile="${test.log.dir}/testparseneggen.log"
-              hadoopVersion="${hadoopVersion}"
-              logDirectory="${test.log.dir}/negative"/>
-
-    <qtestgen hiveRootDirectory="${hive.root}"
-              outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli" 
-              templatePath="${ql.test.template.dir}" template="TestCliDriver.vm" 
-              queryDirectory="${ql.test.query.clientpositive.dir}" 
-              queryFile="${qfile}"
-              excludeQueryFile="${ql.test.clientpositive.exclude}"
-              queryFileRegex="${qfile_regex}"
-              clusterMode="${clustermode}"
-              runDisabled="${run_disabled}"
-              resultsDirectory="${ql.test.results.clientpositive.dir}" className="TestCliDriver"
-              logFile="${test.log.dir}/testclidrivergen.log"
-              logDirectory="${test.log.dir}/clientpositive"
-              hadoopVersion="${hadoopVersion}"/>
-
-    <if>
-      <matches string="${iterate.hive.all}" pattern="beeline"/>
-      <then>
-        <qtestgen hiveRootDirectory="${hive.root}"
-                  outputDirectory="${test.build.src}/org/apache/hive/beeline/util" 
-                  templatePath="${ql.test.template.dir}" template="TestBeeLineDriver.vm" 
-                  queryDirectory="${ql.test.query.clientpositive.dir}" 
-                  queryFile="${qfile}"
-                  excludeQueryFile="${ql.test.beelinepositive.exclude}"
-                  queryFileRegex="${qfile_regex}"
-                  clusterMode="${clustermode}"
-                  runDisabled="${run_disabled}"
-                  resultsDirectory="${ql.test.results.beelinepositive.dir}" className="TestBeeLineDriver"
-                  logFile="${test.log.dir}/testbeelinedrivergen.log"
-                  logDirectory="${test.log.dir}/beelinepositive"
-                  hadoopVersion="${hadoopVersion}" />
-      </then>
-    </if>
-
-    <if>
-      <not>
-        <matches string="${hadoop.version.ant-internal}" pattern="^0\.17\..*" />
-      </not>
-      <then>
-        <qtestgen hiveRootDirectory="${hive.root}"
-                  outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli" 
-                  templatePath="${ql.test.template.dir}" template="TestCliDriver.vm" 
-                  queryDirectory="${ql.test.query.clientpositive.dir}" 
-                  queryFile="${qfile}"
-                  includeQueryFile="${minimr.query.files}"
-                  queryFileRegex="${qfile_regex}"
-                  clusterMode="miniMR"
-                  runDisabled="${run_disabled}"
-                  resultsDirectory="${ql.test.results.clientpositive.dir}" className="TestMinimrCliDriver"
-                  logFile="${test.log.dir}/testminimrclidrivergen.log"
-                  logDirectory="${test.log.dir}/clientpositive"
-                  hadoopVersion="${hadoopVersion}"
-                  />
-
-        <qtestgen hiveRootDirectory="${hive.root}"
-                  outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli" 
-                  templatePath="${ql.test.template.dir}" template="TestNegativeCliDriver.vm" 
-                  queryDirectory="${ql.test.query.dir}/clientnegative"
-                  queryFile="${qfile}"
-                  includeQueryFile="${minimr.query.negative.files}"
-                  queryFileRegex="${qfile_negative_regex}"
-                  clusterMode="miniMR"
-                  runDisabled="${run_disabled}"
-                  resultsDirectory="${ql.test.results.dir}/clientnegative" className="TestNegativeMinimrCliDriver"
-                  logFile="${test.log.dir}/testnegativeminimrclidrivergen.log"
-                  logDirectory="${test.log.dir}/clientnegative"
-                  hadoopVersion="${hadoopVersion}"
-                  />
-      </then>
-    </if>
-
-    <qtestgen hiveRootDirectory="${hive.root}"
-              outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli" 
-              templatePath="${ql.test.template.dir}" template="TestNegativeCliDriver.vm" 
-              queryDirectory="${ql.test.query.dir}/clientnegative" 
-              queryFile="${qfile}"
-              queryFileRegex="${qfile_regex}"
-              excludeQueryFile="${minimr.query.negative.files}"
-              runDisabled="${run_disabled}"
-              resultsDirectory="${ql.test.results.dir}/clientnegative" className="TestNegativeCliDriver"
-              logFile="${test.log.dir}/testnegclidrivergen.log"
-              logDirectory="${test.log.dir}/clientnegative"
-              hadoopVersion="${hadoopVersion}"/>
-
-  </target>
-
-  <uptodate property="grammarBuild.notRequired">
-    <srcfiles dir= "${src.dir}/org/apache/hadoop/hive/ql/parse" includes="**/*.g"/>
-    <mapper type="merge" to="${build.dir.hive}/ql/gen/antlr/gen-java/org/apache/hadoop/hive/ql/parse/HiveParser.java"/>
-  </uptodate>
-
-  <target name="build-grammar" unless="grammarBuild.notRequired">
-    <echo message="Project: ${ant.project.name}"/>
-    <echo>Building Grammar ${src.dir}/org/apache/hadoop/hive/ql/parse/Hive.g  ....</echo>
-    <java classname="org.antlr.Tool" classpathref="classpath" fork="true">
-       <arg value="-fo" />
-       <arg value="${build.dir}/gen/antlr/gen-java/org/apache/hadoop/hive/ql/parse" />
-       <arg value="${src.dir}/org/apache/hadoop/hive/ql/parse/HiveLexer.g" />
-       <arg value="${src.dir}/org/apache/hadoop/hive/ql/parse/HiveParser.g" />
-    </java>
-  </target>
-
-  <target name="protobuf">
-    <echo message="Project: ${ant.project.name}"/>
-    <echo>Building ORC Protobuf</echo>
-    <mkdir dir="${protobuf.build.dir}"/>
-    <exec executable="protoc" failonerror="true">
-      <arg value="--java_out=${protobuf.build.dir}"/>
-      <arg value="-I=${protobuf.src.dir}/org/apache/hadoop/hive/ql/io/orc"/>
-      <arg value="${protobuf.src.dir}/org/apache/hadoop/hive/ql/io/orc/orc_proto.proto"/>
-    </exec>
-  </target>
-
-  <target name="ql-init">
-    <echo message="Project: ${ant.project.name}"/>
-    <mkdir dir="${build.dir}/gen/antlr/gen-java/org/apache/hadoop/hive/ql/parse"/>
-  </target>
-
-  <target name="compile" 
-          depends="init, ql-init, ivy-retrieve, build-grammar">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${src.dir}:${basedir}/src/gen/thrift/gen-javabean:${build.dir}/gen/antlr/gen-java:${protobuf.build.dir}"
-     includes="**/*.java"
-     destdir="${build.classes}"
-     debug="${javac.debug}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     deprecation="${javac.deprecation}"
-     includeantruntime="false">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="classpath"/>
-    </javac>
-    <copy todir="${build.classes}" failonerror="false">
-      <fileset dir="${src.dir}/conf"/>
-    </copy>
-  </target>
-	
-  <!-- Override jar target to specify main class and compiler stuff -->
-
-  <target name="jar" depends="make-pom,compile">
-    <echo message="Project: ${ant.project.name}"/>
-    <unzip src="${build.ivy.lib.dir}/default/libthrift-${libthrift.version}.jar" dest="${build.dir.hive}/thrift/classes">
-      <patternset>
-          <exclude name="META-INF"/>
-          <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-    <unzip src="${build.ivy.lib.dir}/default/commons-lang-${commons-lang.version}.jar" dest="${build.dir.hive}/commons-lang/classes">
-      <patternset>
-          <exclude name="META-INF"/>
-          <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-    <unzip src="${build.ivy.lib.dir}/default/json-${json.version}.jar" dest="${build.dir.hive}/json/classes">
-      <patternset>
-          <exclude name="META-INF"/>
-          <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-    <unzip src="${build.ivy.lib.dir}/default/JavaEWAH-${javaewah.version}.jar" dest="${build.dir.hive}/javaewah/classes">
-      <patternset>
-        <exclude name="meta-inf"/>
-        <exclude name="meta-inf/manifest.mf"/>
-      </patternset>
-    </unzip>
-    <unzip src="${build.ivy.lib.dir}/default/avro-${avro.version}.jar" dest="${build.dir.hive}/avro/classes">
-      <patternset>
-        <exclude name="META-INF"/>
-        <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-    <unzip src="${build.ivy.lib.dir}/default/avro-mapred-${avro.version}.jar" dest="${build.dir.hive}/avro-mapred/classes">
-      <patternset>
-        <exclude name="META-INF"/>
-        <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-    <unzip src="${build.ivy.lib.dir}/default/javolution-${javolution.version}.jar" dest="${build.dir.hive}/javolution/classes">
-      <patternset>
-        <exclude name="META-INF"/>
-        <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-     <unzip 
-      src="${build.ivy.lib.dir}/default/kryo-${kryo.version}.jar" 
-      dest="${build.dir.hive}/kryo/classes">
-      <patternset>
-        <exclude name="META-INF"/>
-        <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-
-    <unzip
-      src="${build.ivy.lib.dir}/default/protobuf-java-${protobuf.version}.jar"
-      dest="${build.dir.hive}/protobuf-java/classes">
-      <patternset>
-        <exclude name="META-INF"/>
-        <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-    <unzip
-      src="${build.ivy.lib.dir}/default/guava-${guava.version}.jar"
-      dest="${build.dir.hive}/guava/classes">
-      <patternset>
-        <exclude name="META-INF"/>
-        <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-
-    <unzip
-      src="${build.ivy.lib.dir}/default/snappy-${snappy.version}.jar" 
-      dest="${build.dir.hive}/snappy/classes">
-      <patternset>
-        <exclude name="META-INF"/>
-        <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-    <unzip 
-      src="${build.ivy.lib.dir}/default/jackson-core-asl-${jackson.version}.jar" 
-      dest="${build.dir.hive}/jackson-core-asl/classes">
-      <patternset>
-        <exclude name="META-INF"/>
-        <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-    <unzip 
-      src="${build.ivy.lib.dir}/default/jackson-mapper-asl-${jackson.version}.jar" 
-      dest="${build.dir.hive}/jackson-mapper-asl/classes">
-      <patternset>
-        <exclude name="META-INF"/>
-        <exclude name="META-INF/MANIFEST.MF"/>
-      </patternset>
-    </unzip>
-
-    <!-- jar jarfile="${build.dir}/hive_${name}.jar" basedir="${build.classes}" / -->
-    <jar jarfile="${build.dir}/hive-exec-${version}.jar">
-      <fileset dir="${build.dir.hive}/common/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/ql/classes" includes="**/*.class,**/*.properties"/>
-      <fileset dir="${build.dir.hive}/serde/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/thrift/classes" includes="**/*.class"/>
-     
-      <fileset dir="${build.dir.hive}/kryo/classes" includes="**/*.class"/>
- <fileset dir="${build.dir.hive}/commons-lang/classes" includes="**/StringUtils.class,**/WordUtils.class"/>
-      <fileset dir="${build.dir.hive}/json/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/avro/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/avro-mapred/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/shims/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/javaewah/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/javolution/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/protobuf-java/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/snappy/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/jackson-core-asl/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/jackson-mapper-asl/classes" includes="**/*.class"/>
-      <fileset dir="${build.dir.hive}/guava/classes" includes="**/*.class"/>
-      <manifest>
-        <!-- Not putting these in their own manifest section, since that inserts
-             a new-line, which breaks the reading of the attributes. -->
-        <attribute name="Implementation-Title" value="Hive"/>
-        <attribute name="Implementation-Version" value="${version}"/>
-        <attribute name="Implementation-Vendor" value="Apache"/>
-      </manifest>
-      <metainf dir="${hive.root}" includes="LICENSE,NOTICE"/>
-    </jar>
-    <ivy:publish settingsRef="${ant.project.name}.ivy.settings"
-                 resolver="local" pubrevision="${version}" overwrite="true"
-                 artifactspattern="${build.dir}/${ivy.publish.pattern}"/>
-  </target>
-
-  <!-- Override deploy since we are deploying hive_exec and not hive_ql -->
-  <target name="deploy" depends="jar">
-    <echo message="${ant.project.name}"/>
-    <mkdir dir="${deploy.dir}"/>
-    <copy file="${build.dir}/hive-exec-${version}.jar"
-          todir="${deploy.dir}"/>
-  </target>
-
-
-</project>
diff --git a/src/ql/ivy.xml b/src/ql/ivy.xml
deleted file mode 100644
index df07f4e..0000000
--- a/src/ql/ivy.xml
+++ /dev/null
@@ -1,90 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0" xmlns:m="http://ant.apache.org/ivy/maven">
-  <info organisation="${hive.ivy.org}" module="hive-exec" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <dependency org="org.apache.hive" name="hive-metastore" rev="${version}"
-                conf="compile->default" />
-    <dependency org="org.apache.mina" name="mina-core" rev="${mina.version}"
-                conf="test->default" />
-    <dependency org="org.apache.hive" name="hive-hbase-handler" rev="${version}"
-                conf="test->default" transitive="false"/>
-    <dependency org="org.apache.hive" name="hive-contrib" rev="${version}"
-                conf="test->default" transitive="false"/>
-    <dependency org="org.apache.hive" name="hive-testutils" rev="${version}"
-                conf="test->default" transitive="false"/>
-    <dependency org="org.apache.hbase" name="hbase" rev="${hbase.version}"
-                conf="test->default" transitive="false">
-      <artifact name="hbase" type="jar"/>
-      <artifact name="hbase" type="test-jar" ext="jar"
-                m:classifier="tests"/>
-    </dependency>
-    <dependency org="com.google.protobuf" name="protobuf-java" 
-                rev="${protobuf.version}" transitive="false"/>
-    <dependency org="org.iq80.snappy" name="snappy" 
-                rev="${snappy.version}" transitive="false"/>
-    <dependency org="com.esotericsoftware.kryo" name="kryo" 
-                rev="${kryo.version}" />
-
-    <dependency org="org.json" name="json" rev="${json.version}"/>
-    <dependency org="commons-collections" name="commons-collections" rev="${commons-collections.version}"/>
-    <dependency org="commons-configuration" name="commons-configuration" rev="${commons-configuration.version}"
-                transitive="false"/>
-    <dependency org="com.googlecode.javaewah" name="JavaEWAH" rev="${javaewah.version}"/>
-    <dependency org="javolution" name="javolution" rev="${javolution.version}"/>
-
-    <dependency org="jline" name="jline" rev="${jline.version}" transitive="false"/>
-
-    <!-- Hack to get jobclient tests dependency in. -->
-    <dependency org="org.apache.hadoop" name="hadoop-yarn-server-tests"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop23.test->default">
-      <artifact name="hadoop-yarn-server-tests" type="tests" ext="jar" m:classifier="tests"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-mapreduce-client-app"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop23.test->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-mapreduce-client-hs"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop23.test->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-
-    <dependency org="com.google.guava" name="guava" rev="${guava.version}" transitive="false"/>
-
-    <!-- Test Dependencies -->
-    <dependency org="junit" name="junit" rev="${junit.version}" conf="test->default" />
-    
-  </dependencies>
-</ivy-module>
diff --git a/src/serde/build.xml b/src/serde/build.xml
deleted file mode 100644
index 0122786..0000000
--- a/src/serde/build.xml
+++ /dev/null
@@ -1,69 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-<project name="serde" default="jar">
-    
-  <property name="src.dir"  location="${basedir}/src"/> 
-  <import file="../build-common.xml"/>
-
-
-  <target name="dynamic-serde" depends="init" if="javacc.home">
-    <echo message="Project: ${ant.project.name}"/>
-    <jjtree buildnodefiles="true"
-      target="${src.dir}/java/org/apache/hadoop/hive/serde2/dynamic_type/thrift_grammar.jjt"
-      outputdirectory="${src.dir}/java/org/apache/hadoop/hive/serde2/dynamic_type"
-      javacchome="${javacc.home}"
-    />
-    <javacc
-      target="${src.dir}/java/org/apache/hadoop/hive/serde2/dynamic_type/thrift_grammar.jj"
-      outputdirectory="${src.dir}/java/org/apache/hadoop/hive/serde2/dynamic_type"
-      javacchome="${javacc.home}"
-    />
-  </target>
-
-  <target name="compile" depends="init,ivy-retrieve,dynamic-serde">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${src.dir}/java/:${src.dir}/gen/thrift/gen-javabean/:${src.dir}/gen/protobuf/gen-java/"
-     destdir="${build.classes}"
-     debug="${javac.debug}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     deprecation="${javac.deprecation}"
-     includeantruntime="false">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="classpath"/>
-    </javac>
-  </target>
-
-  <target name="gen-testdata" depends="compile-test,test-jar">
-    <echo message="Project: ${ant.project.name}"/>
-    <echo>Generating data/files/complex.seq... </echo>
-    <java
-     dir="${hive.root}"
-     classname="org.apache.hadoop.hive.serde2.thrift_test.CreateSequenceFile"
-     fork="true"
-     failonerror="true">
-      <arg value="data/files/complex.seq"/>
-      <classpath refid="${test.classpath.id}"/>
-    </java>
-  </target>
-
-</project>
diff --git a/src/serde/ivy.xml b/src/serde/ivy.xml
deleted file mode 100644
index 94fa97e..0000000
--- a/src/serde/ivy.xml
+++ /dev/null
@@ -1,47 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0" xmlns:m="http://ant.apache.org/ivy/maven">
-  <info organisation="${hive.ivy.org}" module="hive-serde" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <dependency org="org.apache.hive" name="hive-common" rev="${version}"
-                conf="compile->default" />
-    <dependency org="org.slf4j" name="slf4j-api" rev="${slf4j-api.version}"/>
-    <dependency org="org.slf4j" name="slf4j-log4j12" rev="${slf4j-log4j12.version}"
-                transitive="false"/>
-    <dependency org="org.mockito" name="mockito-all" rev="${mockito-all.version}"/>
-    <dependency org="org.apache.thrift" name="libfb303" rev="${libfb303.version}"
-                transitive="false"/>
-    <dependency org="commons-codec" name="commons-codec" rev="${commons-codec.version}"
-                transitive="false"/>
-    <dependency org="org.apache.avro" name="avro" rev="${avro.version}"
-                transitive="false"/>
-    <dependency org="org.apache.avro" name="avro-mapred" rev="${avro.version}"
-                transitive="false"/>
-
-    <!-- Test Dependencies -->
-    <dependency org="junit" name="junit" rev="${junit.version}" conf="test->default" />
-  </dependencies>
-</ivy-module>
diff --git a/src/service/build.xml b/src/service/build.xml
deleted file mode 100644
index f49456d..0000000
--- a/src/service/build.xml
+++ /dev/null
@@ -1,45 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-<project name="service" default="jar">
-  <property name="src.dir" value="${basedir}/src"/>
-
-  <import file="../build-common.xml"/>
-
-  <target name="compile" depends="init,ivy-retrieve">
-    <echo message="Project: ${ant.project.name}"/>
-    <javac
-     encoding="${build.encoding}"
-     srcdir="${src.dir}/java:${src.dir}/gen/thrift/gen-javabean"
-     includes="**/*.java"
-     destdir="${build.classes}"
-     debug="${javac.debug}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     deprecation="${javac.deprecation}"
-     includeantruntime="false">
-      <classpath refid="classpath"/>
-    </javac>
-  </target>
- 
-  <target name="clean">
-    <echo message="Project: ${ant.project.name}"/>
-    <delete dir="${build.classes}/../"/>
-  </target>
-</project>
diff --git a/src/service/ivy.xml b/src/service/ivy.xml
deleted file mode 100644
index 0ff53cc..0000000
--- a/src/service/ivy.xml
+++ /dev/null
@@ -1,35 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-service" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <dependency org="org.apache.hive" name="hive-exec" rev="${version}"
-                conf="compile->default" />
-
-    <!-- Test Dependencies -->
-  </dependencies>
-</ivy-module>
diff --git a/src/shims/build.xml b/src/shims/build.xml
deleted file mode 100644
index 0f0648a..0000000
--- a/src/shims/build.xml
+++ /dev/null
@@ -1,184 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-
-
-<!--
-Before you can run these subtargets directly, you need
-to call at top-level: ant deploy-contrib compile-core-test
--->
-<project xmlns:ivy="antlib:org.apache.ivy.ant" name="shims" default="jar">
-  <import file="../build-common.xml"/>
-
-  <!-- default list of shims to build -->
-  <property name="shims.include" value="0.20,0.20S,0.23"/>
-  <property name="shims.common.sources" value="${basedir}/src/common/java"/>	
-  <property name="shims.common.secure.sources" value="${basedir}/src/common/java;${basedir}/src/common-secure/java"/>
-  <!-- sources and hadoop version for each shim -->
-  <property name="shims.0.20.sources" value="${shims.common.sources};${basedir}/src/0.20/java" />	
-  <property name="shims.0.20.version" value="${hadoop-0.20.version}" />	
-  <property name="shims.0.20S.sources" value="${shims.common.secure.sources};${basedir}/src/0.20S/java" />	
-  <property name="shims.0.20S.version" value="${hadoop-0.20S.version}" />	
-  <property name="shims.0.23.sources" value="${shims.common.secure.sources};${basedir}/src/0.23/java" />	
-  <property name="shims.0.23.version" value="${hadoop-0.23.version}" />	
-  <property name="shims.0.20.hadoop.ivy.dir" value="${hive.root}/build/ivy/lib/hadoop0.20.shim" />
-  <property name="shims.0.20S.hadoop.ivy.dir" value="${hive.root}/build/ivy/lib/hadoop0.20S.shim" />
-  <property name="shims.0.23.hadoop.ivy.dir" value="${hive.root}/build/ivy/lib/hadoop0.23.shim" />
-  <property name="sourceJavaVersion" value="${javac.version}" />
-  <property name="targetJavaVersion" value="${javac.version}" />
-
-  <target name="build-shims"
-          description="Build shims against a particular hadoop version">
-    <echo message="Project: ${ant.project.name}"/>
-    <echo message="Compiling ${sources} against hadoop ${hadoop.version.ant-internal} (${hadoop.root})"/>
-
-    <antcall target="ivy-retrieve-hadoop-shim" inheritRefs="false" inheritAll="false">
-      <param name="ivy.hadoop.shim.conf" value="hadoop${shim.name}.shim" />
-    </antcall>
-    
-    <path id="shims.classpath">
-      <fileset dir="${hadoop.ivy.dir}" includes="*.jar" />
-      <fileset dir="../lib" includes="*.jar" />
-      <fileset dir="${hive.root}/build/ivy/lib/default" includes="*.jar" />
-    </path>
-
-    <javac
-     encoding="${build.encoding}"
-     includes="**/*.java"
-     destdir="${build.classes}"
-     debug="${javac.debug}"
-     source="${sourceJavaVersion}"
-     target="${targetJavaVersion}"
-     deprecation="${javac.deprecation}"
-     srcdir="${sources}"
-     includeantruntime="false">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="shims.classpath"/>
-    </javac>
-  </target>
-	
-  <target name="compile" depends="init,ivy-retrieve">
-    <echo message="Project: ${ant.project.name}"/>
-    <for param="shimName" list="${shims.include}">
-      <sequential>
-        <echo>Building shims @{shimName}</echo>
-        <antcall target="build-shims" inheritRefs="false" inheritAll="false">
-          <param name="hadoop.version.ant-internal" value="${shims.@{shimName}.version}" />
-          <param name="sources" value="${shims.@{shimName}.sources}" />
-          <param name="hadoop.ivy.dir" value="${shims.@{shimName}.hadoop.ivy.dir}" />
-          <param name="shim.name" value="@{shimName}" />
-        </antcall>
-      </sequential>
-    </for>  	
-  </target>
-
-  <target name="compile-test-worker"
-          description="worker to compile tests, takes worker.test.src.dir parameter"
-          depends="set-test-classpath">  
-    <echo message="Project: ${ant.project.name}"/>
-    <echo message="Compiling shim tests against hadoop ${hadoop.mr.rev}"/>
-    <if>
-      <available file="${worker.test.src.dir}" type="dir"/>
-      <then>
-        <echo message="        Test srcdir : ${worker.test.src.dir} "/>
-        <javac
-         encoding="${build.encoding}"
-         srcdir="${worker.test.src.dir}"
-         includes="org/apache/hadoop/**/*.java"
-         excludes="**/TestSerDe.java"
-         destdir="${test.build.classes}"
-         source="${sourceJavaVersion}"
-         target="${targetJavaVersion}"
-         debug="${javac.debug}"
-         optimize="${javac.optimize}"
-         deprecation="${javac.deprecation}"
-         includeantruntime="false">
-          <compilerarg line="${javac.args} ${javac.args.warnings}" />
-          <classpath refid="test.classpath"/>
-        </javac>
-      </then>
-      <else>
-        <echo message="        Skipping nonexistent test srcdir : ${worker.test.src.dir} "/>
-      </else>
-    </if>
-  </target>
-
-  <target name="determine-versions-for-tests">
-    <condition property="is.20">
-      <equals arg1="${hadoop.mr.rev}" arg2="20" />
-    </condition>
-    <condition property="is.20S">
-      <equals arg1="${hadoop.mr.rev}" arg2="20S" />
-    </condition>
-    <condition property="is.23">
-      <equals arg1="${hadoop.mr.rev}" arg2="23" />
-    </condition>
-    <condition property="is.secure">
-      <or>
-        <istrue value="${is.20S}" />
-        <istrue value="${is.23}" />
-      </or>
-    </condition>
-  </target>
-
-  <target name="compile-23-test" if="is.23">
-    <antcall target="compile-test-worker" inheritRefs="false" inheritAll="false">
-      <param name="worker.test.src.dir" value="${basedir}/src/0.23/test" />
-    </antcall>
-  </target>
-
-  <target name="compile-20S-test" if="is.20S">
-    <antcall target="compile-test-worker" inheritRefs="false" inheritAll="false">
-      <param name="worker.test.src.dir" value="${basedir}/src/0.20S/test" />
-    </antcall>
-  </target>
-
-  <target name="compile-20-test" if="is.20">
-    <antcall target="compile-test-worker" inheritRefs="false" inheritAll="false">
-      <param name="worker.test.src.dir" value="${basedir}/src/0.20/test" />
-    </antcall>
-   </target>
-
-  <target name="compile-common-secure-test" if="is.secure">
-     <antcall target="compile-test-worker" inheritRefs="false" inheritAll="false">
-       <param name="worker.test.src.dir" value="${basedir}/src/common-secure/test" />
-     </antcall>
-   </target>
-
-  <target name="compile-common-test">
-    <antcall target="compile-test-worker" inheritRefs="false" inheritAll="false">
-      <param name="worker.test.src.dir" value="${basedir}/src/test" />
-    </antcall>
-    <antcall target="compile-test-worker" inheritRefs="false" inheritAll="false">
-      <param name="worker.test.src.dir" value="${basedir}/src/common/test" />
-    </antcall>
-    <antcall target="compile-test-worker" inheritRefs="false" inheritAll="false">
-      <param name="worker.test.src.dir" value="${test.build.src}" />
-    </antcall>
-  </target>
-
-  <target name="compile-test" depends="compile,ivy-retrieve-test,determine-versions-for-tests">
-    <echo message="Project: ${ant.project.name}"/>
-    <antcall target="compile-common-test" />
-    <antcall target="compile-common-secure-test" />
-    <antcall target="compile-20-test" />
-    <antcall target="compile-20S-test" />
-    <antcall target="compile-23-test" />
-  </target>
-
-</project>
diff --git a/src/shims/ivy.xml b/src/shims/ivy.xml
deleted file mode 100644
index 165632d..0000000
--- a/src/shims/ivy.xml
+++ /dev/null
@@ -1,195 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0" xmlns:m="http://ant.apache.org/ivy/maven">
-  <info organisation="${hive.ivy.org}" module="hive-shims" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <!-- General dependencies. -->
-    <dependency org="org.apache.zookeeper" name="zookeeper"
-                rev="${zookeeper.version}" transitive="false">
-      <include type="jar"/>
-    </dependency>
-    <dependency org="org.apache.thrift" name="libthrift" rev="${libthrift.version}"
-                transitive="false"/>
-    <dependency org="commons-logging" name="commons-logging" rev="${commons-logging.version}"
-                transitive="false"/>
-    <dependency org="commons-logging" name="commons-logging-api" rev="${commons-logging-api.version}"
-                transitive="false"/>
-    <dependency org="org.codehaus.jackson" name="jackson-core-asl" rev="${jackson.version}"/>
-    <dependency org="org.codehaus.jackson" name="jackson-mapper-asl" rev="${jackson.version}"/>
-    <dependency org="log4j" name="log4j" rev="${log4j.version}" />
-    <dependency org="com.google.guava" name="guava" rev="${guava.version}" transitive="false"/>
-
-    <!-- Hadoop 0.23 dependencies. Used both for shims and for building against Hadoop 0.23. -->
-    <dependency org="org.apache.hadoop" name="hadoop-common"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop0.23.shim->default">
-      <artifact name="hadoop-common" ext="jar" />
-      <artifact name="hadoop-common" type="tests" ext="jar" m:classifier="tests"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-mapreduce-client-core"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop0.23.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-archives"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop0.23.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-hdfs"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop0.23.shim->default">
-      <artifact name="hadoop-hdfs" ext="jar" />
-      <artifact name="hadoop-hdfs" type="tests" ext="jar" m:classifier="tests"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-mapreduce-client-jobclient"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop0.23.shim->default">
-      <artifact name="hadoop-mapreduce-client-jobclient" ext="jar" />
-      <artifact name="hadoop-mapreduce-client-jobclient" type="tests" ext="jar" m:classifier="tests"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-mapreduce-client-common"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop0.23.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-
-    <!-- jobclient tests dependency -->
-    <dependency org="org.apache.hadoop" name="hadoop-mapreduce-client-jobclient" rev="${hadoop-0.23.version}"
-                conf="hadoop0.23.shim->default" transitive="false">
-      <artifact name="hadoop-mapreduce-client-jobclient" ext="jar" />
-      <artifact name="hadoop-mapreduce-client-jobclient" type="tests" ext="jar" m:classifier="tests"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-yarn-server-tests"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop0.23.shim->default">
-      <artifact name="hadoop-yarn-server-tests" type="tests" ext="jar" m:classifier="tests"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-mapreduce-client-app"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop0.23.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-mapreduce-client-hs"
-                rev="${hadoop-0.23.version}"
-                conf="hadoop0.23.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-
-    <!-- Hadoop 0.20 shim dependencies. Used for building 0.20 shims. -->
-    <dependency org="commons-io" name="commons-io" rev="${commons-io.version}">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-      <exclude org="commons-codec" module="commons-codec" /><!--ignore commons-codec 1.3 to use 1.4-->
-      <exclude org="org.apache.commons" module="commons-codec" /><!--ignore commons-codec 1.3 to use 1.4-->
-    </dependency>
-
-    <dependency org="commons-codec" name="commons-codec" 
-                rev="${commons-codec.version}" conf="hadoop0.20.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-
-    <dependency org="org.apache.hadoop" name="hadoop-core"
-                rev="${hadoop-0.20.version}"
-                conf="hadoop0.20.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-      <exclude org="commons-codec" module="commons-codec" /><!--ignore commons-codec 1.3 to use 1.4-->
-      <exclude org="org.apache.commons" module="commons-codec" /><!--ignore commons-codec 1.3 to use 1.4-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-tools"
-                rev="${hadoop-0.20.version}"
-                conf="hadoop0.20.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-      <exclude org="commons-codec" module="commons-codec" /><!--ignore commons-codec 1.3 to use 1.4-->
-      <exclude org="org.apache.commons" module="commons-codec" /><!--ignore commons-codec 1.3 to use 1.4-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-test"
-                rev="${hadoop-0.20.version}"
-                conf="hadoop0.20.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-      <exclude org="commons-codec" module="commons-codec" /><!--ignore commons-codec 1.3 to use 1.4-->
-      <exclude org="org.apache.commons" module="commons-codec" /><!--ignore commons-codec 1.3 to use 1.4-->
-    </dependency>
-
-    <!-- Hadoop 0.20S (or 1.0.0) shim dependencies. Used for building 0.20S shims. -->
-    <dependency org="org.apache.hadoop" name="hadoop-core"
-                rev="${hadoop-0.20S.version}"
-                conf="hadoop0.20S.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-tools"
-                rev="${hadoop-0.20S.version}"
-                conf="hadoop0.20S.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-    <dependency org="org.apache.hadoop" name="hadoop-test"
-                rev="${hadoop-0.20S.version}"
-                conf="hadoop0.20S.shim->default">
-      <include type="jar"/>
-      <exclude org="commons-daemon" module="commons-daemon"/><!--bad POM-->
-      <exclude org="org.apache.commons" module="commons-daemon"/><!--bad POM-->
-    </dependency>
-
-    <!-- Test Dependencies -->
-    <dependency org="junit" name="junit" rev="${junit.version}" conf="test->default" />
-
-    <conflict manager="all" />
-  </dependencies>
-</ivy-module>
diff --git a/src/testutils/build.xml b/src/testutils/build.xml
deleted file mode 100644
index 558bc50..0000000
--- a/src/testutils/build.xml
+++ /dev/null
@@ -1,24 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<project name="testutils" default="jar">
-
-  <property name="src.dir"  location="${basedir}/src/java"/>
-  <import file="../build-common.xml"/>
-  
-</project>
diff --git a/src/testutils/ivy.xml b/src/testutils/ivy.xml
deleted file mode 100644
index 10690c1..0000000
--- a/src/testutils/ivy.xml
+++ /dev/null
@@ -1,34 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<ivy-module version="2.0">
-  <info organisation="${hive.ivy.org}" module="hive-testutils" revision="${version}">
-    <license name="The Apache Software License, Version 2.0" url="http://www.apache.org/licenses/LICENSE-2.0.txt" />
-    <description homepage="http://hive.apache.org">
-      The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage.
-      https://cwiki.apache.org/confluence/display/Hive/Home
-    </description>
-  </info>
-  <configurations>
-    <include file="${ivy.conf.dir}/common-configurations.xml"/>
-  </configurations>
-  <dependencies>
-    <dependency org="junit" name="junit" rev="${junit.version}" />
-    <dependency org="com.google.code.tempus-fugit" name="tempus-fugit"
-                rev="${tempus-fugit.version}"/>
-  </dependencies>
-</ivy-module>
-- 
1.7.0.4

