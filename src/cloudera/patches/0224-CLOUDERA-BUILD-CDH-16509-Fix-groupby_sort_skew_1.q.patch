From 37ca640b2fed571e68563ec1a79eb462f51dd81b Mon Sep 17 00:00:00 2001
From: Szehon Ho <szehon@cloudera.com>
Date: Wed, 8 Jan 2014 16:43:54 -0800
Subject: [PATCH 224/375] CLOUDERA-BUILD: CDH-16509 Fix groupby_sort_skew_1.q

Use explain instead of explain extended to skip comparing of numFiles of the table, amongst other things.  Local mode MR2 allows multiple reducers, leading to more files.
---
 .../queries/clientpositive/groupby_sort_skew_1.q   |   34 +-
 .../clientpositive/groupby_sort_skew_1.q.out       | 3289 +-------------------
 2 files changed, 51 insertions(+), 3272 deletions(-)

diff --git a/src/ql/src/test/queries/clientpositive/groupby_sort_skew_1.q b/src/ql/src/test/queries/clientpositive/groupby_sort_skew_1.q
index db0faa0..b94fdff 100644
--- a/src/ql/src/test/queries/clientpositive/groupby_sort_skew_1.q
+++ b/src/ql/src/test/queries/clientpositive/groupby_sort_skew_1.q
@@ -17,7 +17,7 @@ CREATE TABLE outputTbl1(key int, cnt int);
 -- The plan should be converted to a map-side group by if the group by key
 -- matches the sorted key
 -- addind a order by at the end to make the test results deterministic
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key, count(1) FROM T1 GROUP BY key;
 
@@ -29,7 +29,7 @@ SELECT * FROM outputTbl1 ORDER BY key;
 CREATE TABLE outputTbl2(key1 int, key2 string, cnt int);
 
 -- no map-side group by even if the group by key is a superset of sorted key
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl2
 SELECT key, val, count(1) FROM T1 GROUP BY key, val;
 
@@ -39,7 +39,7 @@ SELECT key, val, count(1) FROM T1 GROUP BY key, val;
 SELECT * FROM outputTbl2 ORDER BY key1, key2;
 
 -- It should work for sub-queries
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key, count(1) FROM (SELECT key, val FROM T1) subq1 GROUP BY key;
 
@@ -49,7 +49,7 @@ SELECT key, count(1) FROM (SELECT key, val FROM T1) subq1 GROUP BY key;
 SELECT * FROM outputTbl1 ORDER BY key;
 
 -- It should work for sub-queries with column aliases
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT k, count(1) FROM (SELECT key as k, val as v FROM T1) subq1 GROUP BY k;
 
@@ -62,7 +62,7 @@ CREATE TABLE outputTbl3(key1 int, key2 int, cnt int);
 
 -- The plan should be converted to a map-side group by if the group by key contains a constant followed
 -- by a match to the sorted key
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl3
 SELECT 1, key, count(1) FROM T1 GROUP BY 1, key;
 
@@ -74,7 +74,7 @@ SELECT * FROM outputTbl3 ORDER BY key1, key2;
 CREATE TABLE outputTbl4(key1 int, key2 int, key3 string, cnt int);
 
 -- no map-side group by if the group by key contains a constant followed by another column
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 SELECT key, 1, val, count(1) FROM T1 GROUP BY key, 1, val;
 
@@ -84,7 +84,7 @@ SELECT key, 1, val, count(1) FROM T1 GROUP BY key, 1, val;
 SELECT * FROM outputTbl4 ORDER BY key1, key2, key3;
 
 -- no map-side group by if the group by key contains a function
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl3
 SELECT key, key + 1, count(1) FROM T1 GROUP BY key, key + 1;
 
@@ -97,7 +97,7 @@ SELECT * FROM outputTbl3 ORDER BY key1, key2;
 -- test various cases
 
 -- group by followed by another group by
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key + key, sum(cnt) from
 (SELECT key, count(1) as cnt FROM T1 GROUP BY key) subq1
@@ -111,7 +111,7 @@ group by key + key;
 SELECT * FROM outputTbl1 ORDER BY key;
 
 -- group by followed by a union
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT * FROM (
 SELECT key, count(1) FROM T1 GROUP BY key
@@ -129,7 +129,7 @@ SELECT key, count(1) FROM T1 GROUP BY key
 SELECT * FROM outputTbl1 ORDER BY key;
 
 -- group by followed by a union where one of the sub-queries is map-side group by
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT * FROM (
 SELECT key, count(1) FROM T1 GROUP BY key
@@ -147,7 +147,7 @@ SELECT key + key as key, count(1) as cnt FROM T1 GROUP BY key + key
 SELECT * FROM outputTbl1 ORDER BY key;
 
 -- group by followed by a join
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT subq1.key, subq1.cnt+subq2.cnt FROM 
 (SELECT key, count(1) as cnt FROM T1 GROUP BY key) subq1
@@ -165,7 +165,7 @@ ON subq1.key = subq2.key;
 SELECT * FROM outputTbl1 ORDER BY key;
 
 -- group by followed by a join where one of the sub-queries can be performed in the mapper
-EXPLAIN EXTENDED 
+EXPLAIN
 SELECT * FROM 
 (SELECT key, count(1) FROM T1 GROUP BY key) subq1
 JOIN
@@ -179,7 +179,7 @@ CLUSTERED BY (key, val) SORTED BY (key, val) INTO 2 BUCKETS STORED AS TEXTFILE;
 INSERT OVERWRITE TABLE T2 select key, val from T1;
 
 -- no mapside sort group by if the group by is a prefix of the sorted key
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key, count(1) FROM T2 GROUP BY key;
 
@@ -190,7 +190,7 @@ SELECT * FROM outputTbl1 ORDER BY key;
 
 -- The plan should be converted to a map-side group by if the group by key contains a constant in between the
 -- sorted keys
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 SELECT key, 1, val, count(1) FROM T2 GROUP BY key, 1, val;
 
@@ -203,7 +203,7 @@ CREATE TABLE outputTbl5(key1 int, key2 int, key3 string, key4 int, cnt int);
 
 -- The plan should be converted to a map-side group by if the group by key contains a constant in between the
 -- sorted keys followed by anything
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl5
 SELECT key, 1, val, 2, count(1) FROM T2 GROUP BY key, 1, val, 2;
 
@@ -214,7 +214,7 @@ SELECT * FROM outputTbl5
 ORDER BY key1, key2, key3, key4;
 
 -- contants from sub-queries should work fine
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 SELECT key, constant, val, count(1) from 
 (SELECT key, 1 as constant, val from T2)subq
@@ -228,7 +228,7 @@ group by key, constant, val;
 SELECT * FROM outputTbl4 ORDER BY key1, key2, key3;
 
 -- multiple levels of contants from sub-queries should work fine
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 select key, constant3, val, count(1) from
 (
diff --git a/src/ql/src/test/results/clientpositive/groupby_sort_skew_1.q.out b/src/ql/src/test/results/clientpositive/groupby_sort_skew_1.q.out
index 59b51c6..4b703d1 100644
--- a/src/ql/src/test/results/clientpositive/groupby_sort_skew_1.q.out
+++ b/src/ql/src/test/results/clientpositive/groupby_sort_skew_1.q.out
@@ -33,14 +33,14 @@ POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 PREHOOK: query: -- The plan should be converted to a map-side group by if the group by key
 -- matches the sorted key
 -- addind a order by at the end to make the test results deterministic
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key, count(1) FROM T1 GROUP BY key
 PREHOOK: type: QUERY
 POSTHOOK: query: -- The plan should be converted to a map-side group by if the group by key
 -- matches the sorted key
 -- addind a order by at the end to make the test results deterministic
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key, count(1) FROM T1 GROUP BY key
 POSTHOOK: type: QUERY
@@ -66,7 +66,6 @@ STAGE PLANS:
         t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -91,78 +90,11 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-#### A masked pattern was here ####
-                    NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        properties:
-                          bucket_count -1
-                          columns key,cnt
-                          columns.types int:int
-#### A masked pattern was here ####
-                          name default.outputtbl1
-                          serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                          serialization.format 1
-                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: default.outputtbl1
-                    TotalFiles: 1
-                    GatherStats: true
-                    MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [t1]
 
   Stage: Stage-7
     Conditional Operator
@@ -177,161 +109,42 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl1
-#### A masked pattern was here ####
 
   Stage: Stage-2
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key,cnt
-              columns.types int:int
-#### A masked pattern was here ####
-              name default.outputtbl1
-              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl1
-            name: default.outputtbl1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key,cnt
-              columns.types int:int
-#### A masked pattern was here ####
-              name default.outputtbl1
-              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl1
-            name: default.outputtbl1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-6
     Move Operator
@@ -381,12 +194,12 @@ POSTHOOK: Lineage: outputtbl1.key EXPRESSION [(t1)t1.FieldSchema(name:key, type:
 POSTHOOK: Lineage: t1.key SIMPLE [(t1)t1.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comment:null), ]
 PREHOOK: query: -- no map-side group by even if the group by key is a superset of sorted key
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl2
 SELECT key, val, count(1) FROM T1 GROUP BY key, val
 PREHOOK: type: QUERY
 POSTHOOK: query: -- no map-side group by even if the group by key is a superset of sorted key
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl2
 SELECT key, val, count(1) FROM T1 GROUP BY key, val
 POSTHOOK: type: QUERY
@@ -410,7 +223,6 @@ STAGE PLANS:
         t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -443,58 +255,6 @@ STAGE PLANS:
                   value expressions:
                         expr: _col2
                         type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [t1]
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -510,27 +270,16 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-#### A masked pattern was here ####
-            NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                properties:
-                  columns _col0,_col1,_col2
-                  columns.types string,string,bigint
-                  escape.delim \
-                  serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                 serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            TotalFiles: 1
-            GatherStats: false
-            MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -547,32 +296,6 @@ STAGE PLANS:
               value expressions:
                     expr: _col2
                     type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -mr-10002
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1,_col2
-              columns.types string,string,bigint
-              escape.delim \
-              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1,_col2
-                columns.types string,string,bigint
-                escape.delim \
-                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -597,53 +320,24 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 1
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
-#### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,cnt
-                    columns.types int:string:int
-#### A masked pattern was here ####
-                    name default.outputtbl2
-                    serialization.ddl struct outputtbl2 { i32 key1, string key2, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl2
-              TotalFiles: 1
-              GatherStats: true
-              MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,cnt
-                columns.types int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl2
-                serialization.ddl struct outputtbl2 { i32 key1, string key2, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl2
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
 
 PREHOOK: query: INSERT OVERWRITE TABLE outputTbl2
@@ -685,12 +379,12 @@ POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 8	18	1
 8	28	1
 PREHOOK: query: -- It should work for sub-queries
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key, count(1) FROM (SELECT key, val FROM T1) subq1 GROUP BY key
 PREHOOK: type: QUERY
 POSTHOOK: query: -- It should work for sub-queries
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key, count(1) FROM (SELECT key, val FROM T1) subq1 GROUP BY key
 POSTHOOK: type: QUERY
@@ -721,7 +415,6 @@ STAGE PLANS:
         subq1:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -746,83 +439,11 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-#### A masked pattern was here ####
-                    NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        properties:
-                          bucket_count -1
-                          columns key,cnt
-                          columns.types int:int
-#### A masked pattern was here ####
-                          name default.outputtbl1
-                          numFiles 1
-                          numPartitions 0
-                          numRows 5
-                          rawDataSize 15
-                          serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                          serialization.format 1
-                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          totalSize 20
-#### A masked pattern was here ####
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: default.outputtbl1
-                    TotalFiles: 1
-                    GatherStats: true
-                    MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [subq1:t1]
 
   Stage: Stage-7
     Conditional Operator
@@ -837,196 +458,42 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 15
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 20
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl1
-#### A masked pattern was here ####
 
   Stage: Stage-2
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 5
-                    rawDataSize 15
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 20
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key,cnt
-              columns.types int:int
-#### A masked pattern was here ####
-              name default.outputtbl1
-              numFiles 1
-              numPartitions 0
-              numRows 5
-              rawDataSize 15
-              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 20
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 15
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 20
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl1
-            name: default.outputtbl1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 5
-                    rawDataSize 15
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 20
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key,cnt
-              columns.types int:int
-#### A masked pattern was here ####
-              name default.outputtbl1
-              numFiles 1
-              numPartitions 0
-              numRows 5
-              rawDataSize 15
-              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 20
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 15
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 20
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl1
-            name: default.outputtbl1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-6
     Move Operator
@@ -1077,12 +544,12 @@ POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 7	1
 8	2
 PREHOOK: query: -- It should work for sub-queries with column aliases
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT k, count(1) FROM (SELECT key as k, val as v FROM T1) subq1 GROUP BY k
 PREHOOK: type: QUERY
 POSTHOOK: query: -- It should work for sub-queries with column aliases
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT k, count(1) FROM (SELECT key as k, val as v FROM T1) subq1 GROUP BY k
 POSTHOOK: type: QUERY
@@ -1115,7 +582,6 @@ STAGE PLANS:
         subq1:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -1140,83 +606,11 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-#### A masked pattern was here ####
-                    NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        properties:
-                          bucket_count -1
-                          columns key,cnt
-                          columns.types int:int
-#### A masked pattern was here ####
-                          name default.outputtbl1
-                          numFiles 1
-                          numPartitions 0
-                          numRows 5
-                          rawDataSize 15
-                          serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                          serialization.format 1
-                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          totalSize 20
-#### A masked pattern was here ####
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: default.outputtbl1
-                    TotalFiles: 1
-                    GatherStats: true
-                    MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [subq1:t1]
 
   Stage: Stage-7
     Conditional Operator
@@ -1231,196 +625,42 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 15
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 20
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl1
-#### A masked pattern was here ####
 
   Stage: Stage-2
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 5
-                    rawDataSize 15
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 20
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key,cnt
-              columns.types int:int
-#### A masked pattern was here ####
-              name default.outputtbl1
-              numFiles 1
-              numPartitions 0
-              numRows 5
-              rawDataSize 15
-              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 20
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 15
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 20
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl1
-            name: default.outputtbl1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 5
-                    rawDataSize 15
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 20
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key,cnt
-              columns.types int:int
-#### A masked pattern was here ####
-              name default.outputtbl1
-              numFiles 1
-              numPartitions 0
-              numRows 5
-              rawDataSize 15
-              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 20
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 15
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 20
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl1
-            name: default.outputtbl1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-6
     Move Operator
@@ -1492,13 +732,13 @@ POSTHOOK: Lineage: t1.key SIMPLE [(t1)t1.FieldSchema(name:key, type:string, comm
 POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comment:null), ]
 PREHOOK: query: -- The plan should be converted to a map-side group by if the group by key contains a constant followed
 -- by a match to the sorted key
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl3
 SELECT 1, key, count(1) FROM T1 GROUP BY 1, key
 PREHOOK: type: QUERY
 POSTHOOK: query: -- The plan should be converted to a map-side group by if the group by key contains a constant followed
 -- by a match to the sorted key
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl3
 SELECT 1, key, count(1) FROM T1 GROUP BY 1, key
 POSTHOOK: type: QUERY
@@ -1533,7 +773,6 @@ STAGE PLANS:
         t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -1562,78 +801,11 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-#### A masked pattern was here ####
-                    NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        properties:
-                          bucket_count -1
-                          columns key1,key2,cnt
-                          columns.types int:int:int
-#### A masked pattern was here ####
-                          name default.outputtbl3
-                          serialization.ddl struct outputtbl3 { i32 key1, i32 key2, i32 cnt}
-                          serialization.format 1
-                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: default.outputtbl3
-                    TotalFiles: 1
-                    GatherStats: true
-                    MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [t1]
 
   Stage: Stage-7
     Conditional Operator
@@ -1648,161 +820,42 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,cnt
-                columns.types int:int:int
-#### A masked pattern was here ####
-                name default.outputtbl3
-                serialization.ddl struct outputtbl3 { i32 key1, i32 key2, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl3
-#### A masked pattern was here ####
 
   Stage: Stage-2
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,cnt
-                    columns.types int:int:int
-#### A masked pattern was here ####
-                    name default.outputtbl3
-                    serialization.ddl struct outputtbl3 { i32 key1, i32 key2, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl3
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key1,key2,cnt
-              columns.types int:int:int
-#### A masked pattern was here ####
-              name default.outputtbl3
-              serialization.ddl struct outputtbl3 { i32 key1, i32 key2, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,cnt
-                columns.types int:int:int
-#### A masked pattern was here ####
-                name default.outputtbl3
-                serialization.ddl struct outputtbl3 { i32 key1, i32 key2, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl3
-            name: default.outputtbl3
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,cnt
-                    columns.types int:int:int
-#### A masked pattern was here ####
-                    name default.outputtbl3
-                    serialization.ddl struct outputtbl3 { i32 key1, i32 key2, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl3
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key1,key2,cnt
-              columns.types int:int:int
-#### A masked pattern was here ####
-              name default.outputtbl3
-              serialization.ddl struct outputtbl3 { i32 key1, i32 key2, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,cnt
-                columns.types int:int:int
-#### A masked pattern was here ####
-                name default.outputtbl3
-                serialization.ddl struct outputtbl3 { i32 key1, i32 key2, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl3
-            name: default.outputtbl3
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-6
     Move Operator
@@ -1882,12 +935,12 @@ POSTHOOK: Lineage: outputtbl3.key2 EXPRESSION [(t1)t1.FieldSchema(name:key, type
 POSTHOOK: Lineage: t1.key SIMPLE [(t1)t1.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comment:null), ]
 PREHOOK: query: -- no map-side group by if the group by key contains a constant followed by another column
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 SELECT key, 1, val, count(1) FROM T1 GROUP BY key, 1, val
 PREHOOK: type: QUERY
 POSTHOOK: query: -- no map-side group by if the group by key contains a constant followed by another column
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 SELECT key, 1, val, count(1) FROM T1 GROUP BY key, 1, val
 POSTHOOK: type: QUERY
@@ -1921,7 +974,6 @@ STAGE PLANS:
         t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -1958,58 +1010,6 @@ STAGE PLANS:
                   value expressions:
                         expr: _col3
                         type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [t1]
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -2027,27 +1027,16 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-#### A masked pattern was here ####
-            NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                properties:
-                  columns _col0,_col1,_col2,_col3
-                  columns.types string,int,string,bigint
-                  escape.delim \
-                  serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                 serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            TotalFiles: 1
-            GatherStats: false
-            MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2068,32 +1057,6 @@ STAGE PLANS:
               value expressions:
                     expr: _col3
                     type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -mr-10002
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1,_col2,_col3
-              columns.types string,int,string,bigint
-              escape.delim \
-              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1,_col2,_col3
-                columns.types string,int,string,bigint
-                escape.delim \
-                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -2122,53 +1085,24 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 1
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
-#### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,key3,cnt
-                    columns.types int:int:string:int
-#### A masked pattern was here ####
-                    name default.outputtbl4
-                    serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl4
-              TotalFiles: 1
-              GatherStats: true
-              MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,cnt
-                columns.types int:int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl4
-                serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl4
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
 
 PREHOOK: query: INSERT OVERWRITE TABLE outputTbl4
@@ -2232,12 +1166,12 @@ POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 8	1	18	1
 8	1	28	1
 PREHOOK: query: -- no map-side group by if the group by key contains a function
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl3
 SELECT key, key + 1, count(1) FROM T1 GROUP BY key, key + 1
 PREHOOK: type: QUERY
 POSTHOOK: query: -- no map-side group by if the group by key contains a function
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl3
 SELECT key, key + 1, count(1) FROM T1 GROUP BY key, key + 1
 POSTHOOK: type: QUERY
@@ -2275,7 +1209,6 @@ STAGE PLANS:
         t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -2306,58 +1239,6 @@ STAGE PLANS:
                   value expressions:
                         expr: _col2
                         type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [t1]
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -2373,27 +1254,16 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-#### A masked pattern was here ####
-            NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                properties:
-                  columns _col0,_col1,_col2
-                  columns.types string,double,bigint
-                  escape.delim \
-                  serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                 serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            TotalFiles: 1
-            GatherStats: false
-            MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2410,32 +1280,6 @@ STAGE PLANS:
               value expressions:
                     expr: _col2
                     type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -mr-10002
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1,_col2
-              columns.types string,double,bigint
-              escape.delim \
-              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1,_col2
-                columns.types string,double,bigint
-                escape.delim \
-                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -2460,63 +1304,24 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 1
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
-#### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,cnt
-                    columns.types int:int:int
-#### A masked pattern was here ####
-                    name default.outputtbl3
-                    numFiles 1
-                    numPartitions 0
-                    numRows 5
-                    rawDataSize 25
-                    serialization.ddl struct outputtbl3 { i32 key1, i32 key2, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 30
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl3
-              TotalFiles: 1
-              GatherStats: true
-              MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,cnt
-                columns.types int:int:int
-#### A masked pattern was here ####
-                name default.outputtbl3
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 25
-                serialization.ddl struct outputtbl3 { i32 key1, i32 key2, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl3
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
 
 PREHOOK: query: INSERT OVERWRITE TABLE outputTbl3
@@ -2588,7 +1393,7 @@ PREHOOK: query: -- it should not matter what follows the group by
 -- test various cases
 
 -- group by followed by another group by
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key + key, sum(cnt) from
 (SELECT key, count(1) as cnt FROM T1 GROUP BY key) subq1
@@ -2598,7 +1403,7 @@ POSTHOOK: query: -- it should not matter what follows the group by
 -- test various cases
 
 -- group by followed by another group by
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key + key, sum(cnt) from
 (SELECT key, count(1) as cnt FROM T1 GROUP BY key) subq1
@@ -2641,7 +1446,6 @@ STAGE PLANS:
         subq1:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -2684,58 +1488,6 @@ STAGE PLANS:
                       value expressions:
                             expr: _col1
                             type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [subq1:t1]
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -2749,27 +1501,16 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-#### A masked pattern was here ####
-            NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                properties:
-                  columns _col0,_col1
-                  columns.types double,bigint
-                  escape.delim \
-                  serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                 serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            TotalFiles: 1
-            GatherStats: false
-            MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2782,32 +1523,6 @@ STAGE PLANS:
               value expressions:
                     expr: _col1
                     type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -mr-10002
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1
-              columns.types double,bigint
-              escape.delim \
-              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1
-                columns.types double,bigint
-                escape.delim \
-                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -2828,63 +1543,24 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 1
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
-#### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 5
-                    rawDataSize 15
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 20
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: true
-              MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 15
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 20
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl1
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
 
 PREHOOK: query: INSERT OVERWRITE TABLE outputTbl1
@@ -2961,7 +1637,7 @@ POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 14	1
 16	2
 PREHOOK: query: -- group by followed by a union
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT * FROM (
 SELECT key, count(1) FROM T1 GROUP BY key
@@ -2970,7 +1646,7 @@ SELECT key, count(1) FROM T1 GROUP BY key
 ) subq1
 PREHOOK: type: QUERY
 POSTHOOK: query: -- group by followed by a union
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT * FROM (
 SELECT key, count(1) FROM T1 GROUP BY key
@@ -3021,7 +1697,6 @@ STAGE PLANS:
         null-subquery1:subq1-subquery1:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -3054,36 +1729,14 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-#### A masked pattern was here ####
-                        NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            properties:
-                              bucket_count -1
-                              columns key,cnt
-                              columns.types int:int
-#### A masked pattern was here ####
-                              name default.outputtbl1
-                              numFiles 1
-                              numPartitions 0
-                              numRows 5
-                              rawDataSize 17
-                              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                              serialization.format 1
-                              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              totalSize 22
-#### A masked pattern was here ####
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: default.outputtbl1
-                        TotalFiles: 1
-                        GatherStats: true
-                        MultiFileSpray: false
         null-subquery2:subq1-subquery2:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -3116,83 +1769,11 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-#### A masked pattern was here ####
-                        NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            properties:
-                              bucket_count -1
-                              columns key,cnt
-                              columns.types int:int
-#### A masked pattern was here ####
-                              name default.outputtbl1
-                              numFiles 1
-                              numPartitions 0
-                              numRows 5
-                              rawDataSize 17
-                              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                              serialization.format 1
-                              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              totalSize 22
-#### A masked pattern was here ####
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: default.outputtbl1
-                        TotalFiles: 1
-                        GatherStats: true
-                        MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [null-subquery1:subq1-subquery1:t1, null-subquery2:subq1-subquery2:t1]
 
   Stage: Stage-7
     Conditional Operator
@@ -3207,196 +1788,42 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 17
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 22
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl1
-#### A masked pattern was here ####
 
   Stage: Stage-2
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 5
-                    rawDataSize 17
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 22
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key,cnt
-              columns.types int:int
-#### A masked pattern was here ####
-              name default.outputtbl1
-              numFiles 1
-              numPartitions 0
-              numRows 5
-              rawDataSize 17
-              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 22
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 17
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 22
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl1
-            name: default.outputtbl1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 5
-                    rawDataSize 17
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 22
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key,cnt
-              columns.types int:int
-#### A masked pattern was here ####
-              name default.outputtbl1
-              numFiles 1
-              numPartitions 0
-              numRows 5
-              rawDataSize 17
-              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 22
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 17
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 22
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl1
-            name: default.outputtbl1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-6
     Move Operator
@@ -3492,7 +1919,7 @@ POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 8	2
 8	2
 PREHOOK: query: -- group by followed by a union where one of the sub-queries is map-side group by
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT * FROM (
 SELECT key, count(1) FROM T1 GROUP BY key
@@ -3501,7 +1928,7 @@ SELECT key + key as key, count(1) FROM T1 GROUP BY key + key
 ) subq1
 PREHOOK: type: QUERY
 POSTHOOK: query: -- group by followed by a union where one of the sub-queries is map-side group by
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT * FROM (
 SELECT key, count(1) FROM T1 GROUP BY key
@@ -3556,7 +1983,6 @@ STAGE PLANS:
         null-subquery2:subq1-subquery2:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -3583,58 +2009,6 @@ STAGE PLANS:
                   value expressions:
                         expr: _col1
                         type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [null-subquery2:subq1-subquery2:t1]
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -3648,27 +2022,16 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-#### A masked pattern was here ####
-            NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                properties:
-                  columns _col0,_col1
-                  columns.types double,bigint
-                  escape.delim \
-                  serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                 serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            TotalFiles: 1
-            GatherStats: false
-            MultiFileSpray: false
 
   Stage: Stage-10
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -3681,32 +2044,6 @@ STAGE PLANS:
               value expressions:
                     expr: _col1
                     type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -mr-10003
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1
-              columns.types double,bigint
-              escape.delim \
-              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1
-                columns.types double,bigint
-                escape.delim \
-                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -3727,27 +2064,16 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                  properties:
-                    columns _col0,_col1
-                    columns.types double,bigint
-                    escape.delim \
-                    serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                   serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             Union
               Select Operator
                 expressions:
@@ -3759,36 +2085,14 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-#### A masked pattern was here ####
-                  NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      properties:
-                        bucket_count -1
-                        columns key,cnt
-                        columns.types int:int
-#### A masked pattern was here ####
-                        name default.outputtbl1
-                        numFiles 1
-                        numPartitions 0
-                        numRows 10
-                        rawDataSize 30
-                        serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                        serialization.format 1
-                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        totalSize 40
-#### A masked pattern was here ####
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: default.outputtbl1
-                  TotalFiles: 1
-                  GatherStats: true
-                  MultiFileSpray: false
         null-subquery1:subq1-subquery1:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -3821,104 +2125,11 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-#### A masked pattern was here ####
-                        NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            properties:
-                              bucket_count -1
-                              columns key,cnt
-                              columns.types int:int
-#### A masked pattern was here ####
-                              name default.outputtbl1
-                              numFiles 1
-                              numPartitions 0
-                              numRows 10
-                              rawDataSize 30
-                              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                              serialization.format 1
-                              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              totalSize 40
-#### A masked pattern was here ####
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: default.outputtbl1
-                        TotalFiles: 1
-                        GatherStats: true
-                        MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -mr-10004
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1
-              columns.types double,bigint
-              escape.delim \
-              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1
-                columns.types double,bigint
-                escape.delim \
-                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [null-subquery1:subq1-subquery1:t1]
-#### A masked pattern was here ####
 
   Stage: Stage-8
     Conditional Operator
@@ -3933,196 +2144,42 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 10
-                rawDataSize 30
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 40
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl1
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
   Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 10
-                    rawDataSize 30
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 40
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key,cnt
-              columns.types int:int
-#### A masked pattern was here ####
-              name default.outputtbl1
-              numFiles 1
-              numPartitions 0
-              numRows 10
-              rawDataSize 30
-              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 40
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 10
-                rawDataSize 30
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 40
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl1
-            name: default.outputtbl1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 10
-                    rawDataSize 30
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 40
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key,cnt
-              columns.types int:int
-#### A masked pattern was here ####
-              name default.outputtbl1
-              numFiles 1
-              numPartitions 0
-              numRows 10
-              rawDataSize 30
-              serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 40
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 10
-                rawDataSize 30
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 40
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl1
-            name: default.outputtbl1
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-7
     Move Operator
@@ -4222,7 +2279,7 @@ POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 14	1
 16	2
 PREHOOK: query: -- group by followed by a join
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT subq1.key, subq1.cnt+subq2.cnt FROM 
 (SELECT key, count(1) as cnt FROM T1 GROUP BY key) subq1
@@ -4231,7 +2288,7 @@ JOIN
 ON subq1.key = subq2.key
 PREHOOK: type: QUERY
 POSTHOOK: query: -- group by followed by a join
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT subq1.key, subq1.cnt+subq2.cnt FROM 
 (SELECT key, count(1) as cnt FROM T1 GROUP BY key) subq1
@@ -4281,7 +2338,6 @@ STAGE PLANS:
         subq1:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -4320,7 +2376,6 @@ STAGE PLANS:
         subq2:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -4354,58 +2409,6 @@ STAGE PLANS:
                     value expressions:
                           expr: _col1
                           type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [subq1:t1, subq2:t1]
-      Needs Tagging: true
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -4425,63 +2428,24 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 1
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
-#### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 10
-                    rawDataSize 32
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 42
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: true
-              MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 10
-                rawDataSize 32
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 42
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl1
-#### A masked pattern was here ####
 
   Stage: Stage-2
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
 
 PREHOOK: query: INSERT OVERWRITE TABLE outputTbl1
@@ -4574,7 +2538,7 @@ POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 7	2
 8	4
 PREHOOK: query: -- group by followed by a join where one of the sub-queries can be performed in the mapper
-EXPLAIN EXTENDED 
+EXPLAIN
 SELECT * FROM 
 (SELECT key, count(1) FROM T1 GROUP BY key) subq1
 JOIN
@@ -4582,7 +2546,7 @@ JOIN
 ON subq1.key = subq2.key
 PREHOOK: type: QUERY
 POSTHOOK: query: -- group by followed by a join where one of the sub-queries can be performed in the mapper
-EXPLAIN EXTENDED 
+EXPLAIN
 SELECT * FROM 
 (SELECT key, count(1) FROM T1 GROUP BY key) subq1
 JOIN
@@ -4634,7 +2598,6 @@ STAGE PLANS:
         subq2:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -4667,58 +2630,6 @@ STAGE PLANS:
                   value expressions:
                         expr: _col2
                         type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [subq2:t1]
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -4734,27 +2645,16 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-#### A masked pattern was here ####
-            NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                properties:
-                  columns _col0,_col1,_col2
-                  columns.types string,string,bigint
-                  escape.delim \
-                  serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                 serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            TotalFiles: 1
-            GatherStats: false
-            MultiFileSpray: false
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -4771,32 +2671,6 @@ STAGE PLANS:
               value expressions:
                     expr: _col2
                     type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -mr-10002
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1,_col2
-              columns.types string,string,bigint
-              escape.delim \
-              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1,_col2
-                columns.types string,string,bigint
-                escape.delim \
-                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -4821,27 +2695,16 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                  properties:
-                    columns _col0,_col1,_col2
-                    columns.types string,string,bigint
-                    escape.delim \
-                    serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                   serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
 
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
         $INTNAME 
           TableScan
-            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -4861,7 +2724,6 @@ STAGE PLANS:
         subq1:t1 
           TableScan
             alias: t1
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -4897,79 +2759,6 @@ STAGE PLANS:
                           type: string
                           expr: _col1
                           type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -mr-10003
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1,_col2
-              columns.types string,string,bigint
-              escape.delim \
-              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1,_col2
-                columns.types string,string,bigint
-                escape.delim \
-                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-#### A masked pattern was here ####
-          Partition
-            base file name: t1
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t1
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t1 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t1
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t1 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t1
-            name: default.t1
-      Truncated Path -> Alias:
-        /t1 [subq1:t1]
-#### A masked pattern was here ####
-      Needs Tagging: true
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -4995,23 +2784,10 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
-#### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    columns _col0,_col1,_col2,_col3,_col4
-                    columns.types string:bigint:string:string:bigint
-                    escape.delim \
-                    hive.serialization.extend.nesting.levels true
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
 
   Stage: Stage-0
     Fetch Operator
@@ -5096,12 +2872,12 @@ POSTHOOK: Lineage: t1.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 POSTHOOK: Lineage: t2.key SIMPLE [(t1)t1.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: t2.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comment:null), ]
 PREHOOK: query: -- no mapside sort group by if the group by is a prefix of the sorted key
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key, count(1) FROM T2 GROUP BY key
 PREHOOK: type: QUERY
 POSTHOOK: query: -- no mapside sort group by if the group by is a prefix of the sorted key
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl1
 SELECT key, count(1) FROM T2 GROUP BY key
 POSTHOOK: type: QUERY
@@ -5152,7 +2928,6 @@ STAGE PLANS:
         t2 
           TableScan
             alias: t2
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -5179,58 +2954,6 @@ STAGE PLANS:
                   value expressions:
                         expr: _col1
                         type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t2
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t2
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t2 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t2
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t2 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t2
-            name: default.t2
-      Truncated Path -> Alias:
-        /t2 [t2]
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -5244,27 +2967,16 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-#### A masked pattern was here ####
-            NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                properties:
-                  columns _col0,_col1
-                  columns.types string,bigint
-                  escape.delim \
-                  serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                 serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            TotalFiles: 1
-            GatherStats: false
-            MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -5277,32 +2989,6 @@ STAGE PLANS:
               value expressions:
                     expr: _col1
                     type: bigint
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -mr-10002
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1
-              columns.types string,bigint
-              escape.delim \
-              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1
-                columns.types string,bigint
-                escape.delim \
-                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
-      Needs Tagging: false
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -5323,63 +3009,24 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 1
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
-#### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key,cnt
-                    columns.types int:int
-#### A masked pattern was here ####
-                    name default.outputtbl1
-                    numFiles 1
-                    numPartitions 0
-                    numRows 5
-                    rawDataSize 15
-                    serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 20
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl1
-              TotalFiles: 1
-              GatherStats: true
-              MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key,cnt
-                columns.types int:int
-#### A masked pattern was here ####
-                name default.outputtbl1
-                numFiles 1
-                numPartitions 0
-                numRows 5
-                rawDataSize 15
-                serialization.ddl struct outputtbl1 { i32 key, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 20
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl1
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
 
 PREHOOK: query: INSERT OVERWRITE TABLE outputTbl1
@@ -5473,13 +3120,13 @@ POSTHOOK: Lineage: t2.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 8	2
 PREHOOK: query: -- The plan should be converted to a map-side group by if the group by key contains a constant in between the
 -- sorted keys
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 SELECT key, 1, val, count(1) FROM T2 GROUP BY key, 1, val
 PREHOOK: type: QUERY
 POSTHOOK: query: -- The plan should be converted to a map-side group by if the group by key contains a constant in between the
 -- sorted keys
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 SELECT key, 1, val, count(1) FROM T2 GROUP BY key, 1, val
 POSTHOOK: type: QUERY
@@ -5536,7 +3183,6 @@ STAGE PLANS:
         t2 
           TableScan
             alias: t2
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -5571,83 +3217,11 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-#### A masked pattern was here ####
-                    NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        properties:
-                          bucket_count -1
-                          columns key1,key2,key3,cnt
-                          columns.types int:int:string:int
-#### A masked pattern was here ####
-                          name default.outputtbl4
-                          numFiles 1
-                          numPartitions 0
-                          numRows 6
-                          rawDataSize 48
-                          serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                          serialization.format 1
-                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          totalSize 54
-#### A masked pattern was here ####
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: default.outputtbl4
-                    TotalFiles: 1
-                    GatherStats: true
-                    MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t2
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t2
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t2 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t2
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t2 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t2
-            name: default.t2
-      Truncated Path -> Alias:
-        /t2 [t2]
 
   Stage: Stage-7
     Conditional Operator
@@ -5662,196 +3236,42 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,cnt
-                columns.types int:int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl4
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 48
-                serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 54
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl4
-#### A masked pattern was here ####
 
   Stage: Stage-2
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,key3,cnt
-                    columns.types int:int:string:int
-#### A masked pattern was here ####
-                    name default.outputtbl4
-                    numFiles 1
-                    numPartitions 0
-                    numRows 6
-                    rawDataSize 48
-                    serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 54
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl4
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key1,key2,key3,cnt
-              columns.types int:int:string:int
-#### A masked pattern was here ####
-              name default.outputtbl4
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 48
-              serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 54
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,cnt
-                columns.types int:int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl4
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 48
-                serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 54
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl4
-            name: default.outputtbl4
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,key3,cnt
-                    columns.types int:int:string:int
-#### A masked pattern was here ####
-                    name default.outputtbl4
-                    numFiles 1
-                    numPartitions 0
-                    numRows 6
-                    rawDataSize 48
-                    serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 54
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl4
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key1,key2,key3,cnt
-              columns.types int:int:string:int
-#### A masked pattern was here ####
-              name default.outputtbl4
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 48
-              serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 54
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,cnt
-                columns.types int:int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl4
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 48
-                serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 54
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl4
-            name: default.outputtbl4
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-6
     Move Operator
@@ -6002,13 +3422,13 @@ POSTHOOK: Lineage: t2.key SIMPLE [(t1)t1.FieldSchema(name:key, type:string, comm
 POSTHOOK: Lineage: t2.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comment:null), ]
 PREHOOK: query: -- The plan should be converted to a map-side group by if the group by key contains a constant in between the
 -- sorted keys followed by anything
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl5
 SELECT key, 1, val, 2, count(1) FROM T2 GROUP BY key, 1, val, 2
 PREHOOK: type: QUERY
 POSTHOOK: query: -- The plan should be converted to a map-side group by if the group by key contains a constant in between the
 -- sorted keys followed by anything
-EXPLAIN EXTENDED 
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl5
 SELECT key, 1, val, 2, count(1) FROM T2 GROUP BY key, 1, val, 2
 POSTHOOK: type: QUERY
@@ -6069,7 +3489,6 @@ STAGE PLANS:
         t2 
           TableScan
             alias: t2
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -6108,78 +3527,11 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-#### A masked pattern was here ####
-                    NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        properties:
-                          bucket_count -1
-                          columns key1,key2,key3,key4,cnt
-                          columns.types int:int:string:int:int
-#### A masked pattern was here ####
-                          name default.outputtbl5
-                          serialization.ddl struct outputtbl5 { i32 key1, i32 key2, string key3, i32 key4, i32 cnt}
-                          serialization.format 1
-                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: default.outputtbl5
-                    TotalFiles: 1
-                    GatherStats: true
-                    MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t2
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t2
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t2 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t2
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t2 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t2
-            name: default.t2
-      Truncated Path -> Alias:
-        /t2 [t2]
 
   Stage: Stage-7
     Conditional Operator
@@ -6194,161 +3546,42 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,key4,cnt
-                columns.types int:int:string:int:int
-#### A masked pattern was here ####
-                name default.outputtbl5
-                serialization.ddl struct outputtbl5 { i32 key1, i32 key2, string key3, i32 key4, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl5
-#### A masked pattern was here ####
 
   Stage: Stage-2
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,key3,key4,cnt
-                    columns.types int:int:string:int:int
-#### A masked pattern was here ####
-                    name default.outputtbl5
-                    serialization.ddl struct outputtbl5 { i32 key1, i32 key2, string key3, i32 key4, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl5
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key1,key2,key3,key4,cnt
-              columns.types int:int:string:int:int
-#### A masked pattern was here ####
-              name default.outputtbl5
-              serialization.ddl struct outputtbl5 { i32 key1, i32 key2, string key3, i32 key4, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,key4,cnt
-                columns.types int:int:string:int:int
-#### A masked pattern was here ####
-                name default.outputtbl5
-                serialization.ddl struct outputtbl5 { i32 key1, i32 key2, string key3, i32 key4, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl5
-            name: default.outputtbl5
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,key3,key4,cnt
-                    columns.types int:int:string:int:int
-#### A masked pattern was here ####
-                    name default.outputtbl5
-                    serialization.ddl struct outputtbl5 { i32 key1, i32 key2, string key3, i32 key4, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl5
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key1,key2,key3,key4,cnt
-              columns.types int:int:string:int:int
-#### A masked pattern was here ####
-              name default.outputtbl5
-              serialization.ddl struct outputtbl5 { i32 key1, i32 key2, string key3, i32 key4, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,key4,cnt
-                columns.types int:int:string:int:int
-#### A masked pattern was here ####
-                name default.outputtbl5
-                serialization.ddl struct outputtbl5 { i32 key1, i32 key2, string key3, i32 key4, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl5
-            name: default.outputtbl5
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-6
     Move Operator
@@ -6468,14 +3701,14 @@ POSTHOOK: Lineage: t2.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 8	1	18	2	1
 8	1	28	2	1
 PREHOOK: query: -- contants from sub-queries should work fine
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 SELECT key, constant, val, count(1) from 
 (SELECT key, 1 as constant, val from T2)subq
 group by key, constant, val
 PREHOOK: type: QUERY
 POSTHOOK: query: -- contants from sub-queries should work fine
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 SELECT key, constant, val, count(1) from 
 (SELECT key, 1 as constant, val from T2)subq
@@ -6543,7 +3776,6 @@ STAGE PLANS:
         subq:t2 
           TableScan
             alias: t2
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -6580,83 +3812,11 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-#### A masked pattern was here ####
-                    NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        properties:
-                          bucket_count -1
-                          columns key1,key2,key3,cnt
-                          columns.types int:int:string:int
-#### A masked pattern was here ####
-                          name default.outputtbl4
-                          numFiles 1
-                          numPartitions 0
-                          numRows 6
-                          rawDataSize 48
-                          serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                          serialization.format 1
-                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          totalSize 54
-#### A masked pattern was here ####
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: default.outputtbl4
-                    TotalFiles: 1
-                    GatherStats: true
-                    MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t2
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t2
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t2 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t2
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t2 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t2
-            name: default.t2
-      Truncated Path -> Alias:
-        /t2 [subq:t2]
 
   Stage: Stage-7
     Conditional Operator
@@ -6671,196 +3831,42 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,cnt
-                columns.types int:int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl4
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 48
-                serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 54
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl4
-#### A masked pattern was here ####
 
   Stage: Stage-2
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,key3,cnt
-                    columns.types int:int:string:int
-#### A masked pattern was here ####
-                    name default.outputtbl4
-                    numFiles 1
-                    numPartitions 0
-                    numRows 6
-                    rawDataSize 48
-                    serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 54
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl4
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key1,key2,key3,cnt
-              columns.types int:int:string:int
-#### A masked pattern was here ####
-              name default.outputtbl4
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 48
-              serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 54
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,cnt
-                columns.types int:int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl4
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 48
-                serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 54
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl4
-            name: default.outputtbl4
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,key3,cnt
-                    columns.types int:int:string:int
-#### A masked pattern was here ####
-                    name default.outputtbl4
-                    numFiles 1
-                    numPartitions 0
-                    numRows 6
-                    rawDataSize 48
-                    serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 54
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl4
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key1,key2,key3,cnt
-              columns.types int:int:string:int
-#### A masked pattern was here ####
-              name default.outputtbl4
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 48
-              serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 54
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,cnt
-                columns.types int:int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl4
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 48
-                serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 54
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl4
-            name: default.outputtbl4
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-6
     Move Operator
@@ -6990,7 +3996,7 @@ POSTHOOK: Lineage: t2.val SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comm
 8	1	18	1
 8	1	28	1
 PREHOOK: query: -- multiple levels of contants from sub-queries should work fine
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 select key, constant3, val, count(1) from
 (
@@ -7000,7 +4006,7 @@ SELECT key, constant as constant2, val, 2 as constant3 from
 group by key, constant3, val
 PREHOOK: type: QUERY
 POSTHOOK: query: -- multiple levels of contants from sub-queries should work fine
-EXPLAIN EXTENDED
+EXPLAIN
 INSERT OVERWRITE TABLE outputTbl4
 select key, constant3, val, count(1) from
 (
@@ -7075,7 +4081,6 @@ STAGE PLANS:
         subq2:subq:t2 
           TableScan
             alias: t2
-            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -7112,83 +4117,11 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-#### A masked pattern was here ####
-                    NumFilesPerFileSink: 1
-#### A masked pattern was here ####
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        properties:
-                          bucket_count -1
-                          columns key1,key2,key3,cnt
-                          columns.types int:int:string:int
-#### A masked pattern was here ####
-                          name default.outputtbl4
-                          numFiles 1
-                          numPartitions 0
-                          numRows 6
-                          rawDataSize 48
-                          serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                          serialization.format 1
-                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          totalSize 54
-#### A masked pattern was here ####
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: default.outputtbl4
-                    TotalFiles: 1
-                    GatherStats: true
-                    MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: t2
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              SORTBUCKETCOLSPREFIX TRUE
-              bucket_count 2
-              bucket_field_name key
-              columns key,val
-              columns.types string:string
-#### A masked pattern was here ####
-              name default.t2
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 24
-              serialization.ddl struct t2 { string key, string val}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 30
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                SORTBUCKETCOLSPREFIX TRUE
-                bucket_count 2
-                bucket_field_name key
-                columns key,val
-                columns.types string:string
-#### A masked pattern was here ####
-                name default.t2
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 24
-                serialization.ddl struct t2 { string key, string val}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 30
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.t2
-            name: default.t2
-      Truncated Path -> Alias:
-        /t2 [subq2:subq:t2]
 
   Stage: Stage-7
     Conditional Operator
@@ -7203,196 +4136,42 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-#### A masked pattern was here ####
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,cnt
-                columns.types int:int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl4
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 48
-                serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 54
-#### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.outputtbl4
-#### A masked pattern was here ####
 
   Stage: Stage-2
     Stats-Aggr Operator
-#### A masked pattern was here ####
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,key3,cnt
-                    columns.types int:int:string:int
-#### A masked pattern was here ####
-                    name default.outputtbl4
-                    numFiles 1
-                    numPartitions 0
-                    numRows 6
-                    rawDataSize 48
-                    serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 54
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl4
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key1,key2,key3,cnt
-              columns.types int:int:string:int
-#### A masked pattern was here ####
-              name default.outputtbl4
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 48
-              serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 54
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,cnt
-                columns.types int:int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl4
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 48
-                serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 54
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl4
-            name: default.outputtbl4
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
 #### A masked pattern was here ####
           TableScan
-            GatherStats: false
             File Output Operator
               compressed: false
               GlobalTableId: 0
-#### A masked pattern was here ####
-              NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  properties:
-                    bucket_count -1
-                    columns key1,key2,key3,cnt
-                    columns.types int:int:string:int
-#### A masked pattern was here ####
-                    name default.outputtbl4
-                    numFiles 1
-                    numPartitions 0
-                    numRows 6
-                    rawDataSize 48
-                    serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                    serialization.format 1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    totalSize 54
-#### A masked pattern was here ####
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: default.outputtbl4
-              TotalFiles: 1
-              GatherStats: false
-              MultiFileSpray: false
-      Path -> Alias:
-#### A masked pattern was here ####
-      Path -> Partition:
-#### A masked pattern was here ####
-          Partition
-            base file name: -ext-10002
-            input format: org.apache.hadoop.mapred.TextInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            properties:
-              bucket_count -1
-              columns key1,key2,key3,cnt
-              columns.types int:int:string:int
-#### A masked pattern was here ####
-              name default.outputtbl4
-              numFiles 1
-              numPartitions 0
-              numRows 6
-              rawDataSize 48
-              serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-              serialization.format 1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              totalSize 54
-#### A masked pattern was here ####
-            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-          
-              input format: org.apache.hadoop.mapred.TextInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              properties:
-                bucket_count -1
-                columns key1,key2,key3,cnt
-                columns.types int:int:string:int
-#### A masked pattern was here ####
-                name default.outputtbl4
-                numFiles 1
-                numPartitions 0
-                numRows 6
-                rawDataSize 48
-                serialization.ddl struct outputtbl4 { i32 key1, i32 key2, string key3, i32 cnt}
-                serialization.format 1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                totalSize 54
-#### A masked pattern was here ####
-              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: default.outputtbl4
-            name: default.outputtbl4
-      Truncated Path -> Alias:
-#### A masked pattern was here ####
 
   Stage: Stage-6
     Move Operator
-- 
1.7.0.4

