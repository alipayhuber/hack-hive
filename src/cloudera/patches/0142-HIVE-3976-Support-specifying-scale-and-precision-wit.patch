From fa04993bb5df4d4c1b53f484be7fb4aaad442302 Mon Sep 17 00:00:00 2001
From: Brock Noland <brock@apache.org>
Date: Sun, 27 Oct 2013 15:34:01 +0000
Subject: [PATCH 142/375] HIVE-3976 - Support specifying scale and precision with Hive decimal type (Xuefu Zhang via Brock Noland)

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1536151 13f79535-47bb-0310-9956-ffa450edef68

Conflicts:
	ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java
	ql/src/test/queries/clientpositive/decimal_join.q
---
 .../hadoop/hive/common/type/HiveDecimal.java       |   86 +++--
 .../hadoop/hive/common/type/TestHiveDecimal.java   |  105 +++++
 data/files/kv9.txt                                 |   27 ++
 .../apache/hadoop/hive/jdbc/TestJdbcDriver.java    |    2 +-
 .../java/org/apache/hive/jdbc/TestJdbcDriver2.java |    2 +-
 .../hadoop/hive/jdbc/HiveResultSetMetaData.java    |    2 +-
 .../java/org/apache/hadoop/hive/jdbc/Utils.java    |    2 +-
 ql/src/java/org/apache/hadoop/hive/ql/Driver.java  |    7 +-
 .../hadoop/hive/ql/exec/FunctionRegistry.java      |   15 +-
 .../hive/ql/exec/NumericOpMethodResolver.java      |   12 +-
 .../apache/hadoop/hive/ql/io/orc/OrcStruct.java    |    7 +-
 .../apache/hadoop/hive/ql/io/orc/WriterImpl.java   |    4 +
 .../hadoop/hive/ql/parse/DDLSemanticAnalyzer.java  |   11 +-
 .../org/apache/hadoop/hive/ql/parse/HiveParser.g   |    2 +-
 .../apache/hadoop/hive/ql/parse/ParseUtils.java    |   29 ++-
 .../hadoop/hive/ql/parse/TypeCheckProcFactory.java |   11 +-
 .../org/apache/hadoop/hive/ql/udf/UDFOPDivide.java |   10 +-
 .../org/apache/hadoop/hive/ql/udf/UDFOPPlus.java   |   10 +-
 .../hive/ql/udf/generic/GenericUDFBridge.java      |   10 +
 .../hive/ql/udf/generic/GenericUDFToDecimal.java   |   35 ++-
 .../hive/ql/udf/generic/GenericUDFToVarchar.java   |    4 +-
 .../hadoop/hive/ql/exec/TestFunctionRegistry.java  |    6 +-
 .../apache/hadoop/hive/ql/io/orc/TestOrcFile.java  |   15 +-
 .../hadoop/hive/ql/parse/TestHiveDecimalParse.java |  158 +++++++
 ql/src/test/queries/clientpositive/decimal_1.q     |    4 +-
 ql/src/test/queries/clientpositive/decimal_2.q     |   16 +-
 ql/src/test/queries/clientpositive/decimal_3.q     |    2 +-
 ql/src/test/queries/clientpositive/decimal_4.q     |    4 +-
 ql/src/test/queries/clientpositive/decimal_5.q     |   18 +
 ql/src/test/queries/clientpositive/decimal_6.q     |   27 ++
 ql/src/test/queries/clientpositive/decimal_join.q  |    2 +-
 .../queries/clientpositive/decimal_precision.q     |   10 +-
 ql/src/test/queries/clientpositive/decimal_udf.q   |    2 +-
 .../clientpositive/orc_predicate_pushdown.q        |    4 +-
 ql/src/test/queries/clientpositive/ptf_decimal.q   |    2 +-
 ql/src/test/queries/clientpositive/serde_regex.q   |    4 +-
 ql/src/test/queries/clientpositive/udf_pmod.q      |    2 +-
 ql/src/test/queries/clientpositive/udf_to_double.q |    2 +-
 ql/src/test/queries/clientpositive/udf_to_float.q  |    2 +-
 ql/src/test/queries/clientpositive/udf_to_string.q |    2 +-
 .../queries/clientpositive/windowing_expressions.q |    2 +-
 .../clientpositive/windowing_multipartitioning.q   |    2 +-
 .../test/queries/clientpositive/windowing_navfn.q  |    4 +-
 .../test/queries/clientpositive/windowing_ntile.q  |    2 +-
 .../test/queries/clientpositive/windowing_rank.q   |    2 +-
 .../invalid_cast_from_binary_1.q.out               |    2 +-
 .../invalid_cast_from_binary_2.q.out               |    2 +-
 .../invalid_cast_from_binary_3.q.out               |    2 +-
 .../invalid_cast_from_binary_4.q.out               |    2 +-
 .../invalid_cast_from_binary_5.q.out               |    2 +-
 .../invalid_cast_from_binary_6.q.out               |    2 +-
 .../results/clientnegative/wrong_column_type.q.out |    2 +-
 ql/src/test/results/clientpositive/decimal_1.q.out |    8 +-
 ql/src/test/results/clientpositive/decimal_2.q.out |   32 +-
 ql/src/test/results/clientpositive/decimal_3.q.out |   15 +-
 ql/src/test/results/clientpositive/decimal_4.q.out |   32 +-
 ql/src/test/results/clientpositive/decimal_5.q.out |  202 +++++++++
 ql/src/test/results/clientpositive/decimal_6.q.out |  131 ++++++
 .../test/results/clientpositive/decimal_join.q.out |    4 +-
 .../results/clientpositive/decimal_precision.q.out |  454 ++++++++++----------
 .../results/clientpositive/decimal_serde.q.out     |  108 +++---
 .../test/results/clientpositive/decimal_udf.q.out  |  160 ++++----
 .../results/clientpositive/literal_decimal.q.out   |   20 +-
 .../clientpositive/orc_predicate_pushdown.q.out    |   58 ++--
 .../test/results/clientpositive/ptf_decimal.q.out  |    4 +-
 .../test/results/clientpositive/serde_regex.q.out  |   14 +-
 ql/src/test/results/clientpositive/udf7.q.out      |   12 +-
 ql/src/test/results/clientpositive/udf_pmod.q.out  |    4 +-
 .../results/clientpositive/udf_to_double.q.out     |    4 +-
 .../test/results/clientpositive/udf_to_float.q.out |    4 +-
 .../results/clientpositive/udf_to_string.q.out     |    4 +-
 .../clientpositive/windowing_expressions.q.out     |   36 +-
 .../windowing_multipartitioning.q.out              |    4 +-
 .../results/clientpositive/windowing_navfn.q.out   |    8 +-
 .../results/clientpositive/windowing_ntile.q.out   |    4 +-
 .../results/clientpositive/windowing_rank.q.out    |    4 +-
 .../org/apache/hadoop/hive/serde2/RegexSerDe.java  |    3 +-
 .../hadoop/hive/serde2/io/HiveDecimalWritable.java |   13 +
 .../hadoop/hive/serde2/lazy/LazyHiveDecimal.java   |   20 +
 .../primitive/LazyHiveDecimalObjectInspector.java  |   19 +-
 .../LazyPrimitiveObjectInspectorFactory.java       |    8 +-
 .../serde2/lazybinary/LazyBinaryHiveDecimal.java   |   10 +
 .../hive/serde2/lazybinary/LazyBinarySerDe.java    |    5 +-
 .../primitive/JavaHiveDecimalObjectInspector.java  |   39 +-
 .../primitive/PrimitiveObjectInspectorFactory.java |   24 +-
 ...WritableConstantHiveDecimalObjectInspector.java |   22 +-
 .../WritableHiveDecimalObjectInspector.java        |   54 ++-
 .../hive/serde2/typeinfo/DecimalTypeInfo.java      |  104 +++++
 .../hive/serde2/typeinfo/HiveDecimalUtils.java     |  121 ++++++
 .../hadoop/hive/serde2/typeinfo/TypeInfo.java      |    5 +
 .../hive/serde2/typeinfo/TypeInfoFactory.java      |   23 +-
 .../hadoop/hive/serde2/typeinfo/TypeInfoUtils.java |   38 ++-
 .../hive/serde2/typeinfo/VarcharTypeInfo.java      |    4 +-
 93 files changed, 1833 insertions(+), 706 deletions(-)
 create mode 100644 common/src/test/org/apache/hadoop/hive/common/type/TestHiveDecimal.java
 create mode 100644 data/files/kv9.txt
 create mode 100644 ql/src/test/org/apache/hadoop/hive/ql/parse/TestHiveDecimalParse.java
 create mode 100644 ql/src/test/queries/clientpositive/decimal_5.q
 create mode 100644 ql/src/test/queries/clientpositive/decimal_6.q
 create mode 100644 ql/src/test/results/clientpositive/decimal_5.q.out
 create mode 100644 ql/src/test/results/clientpositive/decimal_6.q.out
 create mode 100644 serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/DecimalTypeInfo.java
 create mode 100644 serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/HiveDecimalUtils.java

diff --git a/src/common/src/java/org/apache/hadoop/hive/common/type/HiveDecimal.java b/src/common/src/java/org/apache/hadoop/hive/common/type/HiveDecimal.java
index cae8db6..606f6d4 100644
--- a/src/common/src/java/org/apache/hadoop/hive/common/type/HiveDecimal.java
+++ b/src/common/src/java/org/apache/hadoop/hive/common/type/HiveDecimal.java
@@ -28,17 +28,16 @@
  *
  */
 public class HiveDecimal implements Comparable<HiveDecimal> {
+  public static final int MAX_PRECISION = 65;
+  public static final int MAX_SCALE = 30;
+  public static final int DEFAULT_PRECISION = 10;
+  public static final int DEFAULT_SCALE = 0;
 
   public static final HiveDecimal ZERO = new HiveDecimal(BigDecimal.ZERO);
-
-  public static final int MAX_PRECISION = 38; // fits into 128 bits
-
   public static final HiveDecimal ONE = new HiveDecimal(BigDecimal.ONE);
 
   public static final int ROUND_FLOOR = BigDecimal.ROUND_FLOOR;
-
   public static final int ROUND_CEILING = BigDecimal.ROUND_CEILING;
-
   public static final int ROUND_HALF_UP = BigDecimal.ROUND_HALF_UP;
 
   private BigDecimal bd = BigDecimal.ZERO;
@@ -48,16 +47,16 @@ private HiveDecimal(BigDecimal bd) {
   }
 
   public static HiveDecimal create(BigDecimal b) {
-    return create(b, false);
+    return create(b, true);
   }
 
   public static HiveDecimal create(BigDecimal b, boolean allowRounding) {
-    BigDecimal bd = normalize(b, HiveDecimal.MAX_PRECISION, allowRounding);
+    BigDecimal bd = normalize(b, allowRounding);
     return bd == null ? null : new HiveDecimal(bd);
   }
 
   public static HiveDecimal create(BigInteger unscaled, int scale) {
-    BigDecimal bd = normalize(new BigDecimal(unscaled, scale), HiveDecimal.MAX_PRECISION, false);
+    BigDecimal bd = normalize(new BigDecimal(unscaled, scale), true);
     return bd == null ? null : new HiveDecimal(bd);
   }
 
@@ -69,12 +68,12 @@ public static HiveDecimal create(String dec) {
       return null;
     }
 
-    bd = normalize(bd, HiveDecimal.MAX_PRECISION, false);
+    bd = normalize(bd, true);
     return bd == null ? null : new HiveDecimal(bd);
   }
 
   public static HiveDecimal create(BigInteger bi) {
-    BigDecimal bd = normalize(new BigDecimal(bi), HiveDecimal.MAX_PRECISION, false);
+    BigDecimal bd = normalize(new BigDecimal(bi), true);
     return bd == null ? null : new HiveDecimal(bd);
   }
 
@@ -92,7 +91,7 @@ public String toString() {
   }
 
   public HiveDecimal setScale(int i) {
-    return new HiveDecimal(bd.setScale(i));
+    return new HiveDecimal(bd.setScale(i, RoundingMode.HALF_UP));
   }
 
   @Override
@@ -158,7 +157,7 @@ public HiveDecimal subtract(HiveDecimal dec) {
   }
 
   public HiveDecimal multiply(HiveDecimal dec) {
-    return create(bd.multiply(dec.bd));
+    return create(bd.multiply(dec.bd), false);
   }
 
   public BigInteger unscaledValue() {
@@ -182,7 +181,8 @@ public HiveDecimal add(HiveDecimal dec) {
   }
 
   public HiveDecimal pow(int n) {
-    return create(bd.pow(n));
+    BigDecimal result = normalize(bd.pow(n), false);
+    return result == null ? null : new HiveDecimal(result);
   }
 
   public HiveDecimal remainder(HiveDecimal dec) {
@@ -190,7 +190,7 @@ public HiveDecimal remainder(HiveDecimal dec) {
   }
 
   public HiveDecimal divide(HiveDecimal dec) {
-    return create(bd.divide(dec.bd, MAX_PRECISION, RoundingMode.HALF_UP), true);
+    return create(bd.divide(dec.bd, MAX_SCALE, RoundingMode.HALF_UP), true);
   }
 
   private static BigDecimal trim(BigDecimal d) {
@@ -207,31 +207,45 @@ private static BigDecimal trim(BigDecimal d) {
     return d;
   }
 
-  private static BigDecimal normalize(BigDecimal d, int precision, boolean allowRounding) {
-    if (d == null) {
+  private static BigDecimal normalize(BigDecimal bd, boolean allowRounding) {
+    if (bd == null) {
       return null;
     }
 
-    d = trim(d);
-
-    // compute the number of digits of the decimal
-    int valuePrecision = d.precision()
-        + Math.max(0, 1 + d.scale() - d.precision());
-
-    if (valuePrecision > precision) {
-      if (allowRounding) {
-        // round "half up" until we hit the decimal point
-        int adjustedScale = d.scale() - (valuePrecision-precision);
-        if (adjustedScale >= 0) {
-          d = d.setScale(adjustedScale, RoundingMode.HALF_UP);
-          d = trim(d);
-        } else {
-          d = null;
-        }
-      } else {
-        d = null;
-      }
+    bd = trim(bd);
+
+    int intDigits = bd.precision() - bd.scale();
+
+    if (intDigits > MAX_PRECISION) {
+      return null;
     }
-    return d;
+
+    int maxScale = Math.min(MAX_SCALE, Math.min(MAX_PRECISION - intDigits, bd.scale()));
+    if (bd.scale() > maxScale ) {
+      bd = allowRounding ? bd.setScale(maxScale, RoundingMode.HALF_UP) : null;
+    }
+
+    return bd;
   }
+
+  public static BigDecimal enforcePrecisionScale(BigDecimal bd, int maxPrecision, int maxScale) {
+    if (bd == null) {
+      return null;
+    }
+
+    bd = trim(bd);
+
+    int maxIntDigits = maxPrecision - maxScale;
+    int intDigits = bd.precision() - bd.scale();
+    if (intDigits > maxIntDigits) {
+      return null;
+    }
+
+    if (bd.scale() > maxScale) {
+      bd = bd.setScale(maxScale, RoundingMode.HALF_UP);
+    }
+
+    return bd;
+  }
+
 }
diff --git a/src/common/src/test/org/apache/hadoop/hive/common/type/TestHiveDecimal.java b/src/common/src/test/org/apache/hadoop/hive/common/type/TestHiveDecimal.java
new file mode 100644
index 0000000..4bffaf6
--- /dev/null
+++ b/src/common/src/test/org/apache/hadoop/hive/common/type/TestHiveDecimal.java
@@ -0,0 +1,105 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.common.type;
+
+import java.math.BigDecimal;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+public class TestHiveDecimal {
+
+  @Test
+  public void testPrecisionScaleEnforcement() {
+    String decStr = "1786135888657847525803324040144343378.09799306448796128931113691624";
+    HiveDecimal dec = HiveDecimal.create(decStr);
+    Assert.assertEquals("1786135888657847525803324040144343378.0979930644879612893111369162", dec.toString());
+    Assert.assertTrue("Decimal precision should not go above maximum",
+        dec.precision() <= HiveDecimal.MAX_PRECISION);
+    Assert.assertTrue("Decimal scale should not go above maximum", dec.scale() <= HiveDecimal.MAX_SCALE);
+
+    BigDecimal bd = new BigDecimal(decStr);
+    BigDecimal bd1 = HiveDecimal.enforcePrecisionScale(bd, 20, 5);
+    Assert.assertNull(bd1);
+    bd1 = HiveDecimal.enforcePrecisionScale(bd, 45, 5);
+    Assert.assertEquals("1786135888657847525803324040144343378.09799", bd1.toString());
+    bd1 = HiveDecimal.enforcePrecisionScale(bd, 45, 20);
+    Assert.assertNull(bd1);
+
+    dec = HiveDecimal.create(bd, false);
+    Assert.assertNull(dec);
+
+    dec = HiveDecimal.create("-1786135888657847525803324040144343378.09799306448796128931113691624");
+    Assert.assertEquals("-1786135888657847525803324040144343378.0979930644879612893111369162", dec.toString());
+
+    dec = HiveDecimal.create("005.34000");
+    Assert.assertEquals(dec.precision(), 3);
+    Assert.assertEquals(dec.scale(), 2);
+
+    dec = HiveDecimal.create("178613588865784752580332404014434337809799306448796128931113691624");
+    Assert.assertNull(dec);
+  }
+
+  @Test
+  public void testMultiply() {
+    HiveDecimal dec1 = HiveDecimal.create("0.1786135888657847525803");
+    HiveDecimal dec2 = HiveDecimal.create("3.123456789");
+    Assert.assertNull(dec1.multiply(dec2));
+
+    dec1 = HiveDecimal.create("1786135888657847525803232322323234442321.4");
+    dec2 = HiveDecimal.create("178613588865784752580302323232.3");
+    Assert.assertNull(dec1.multiply(dec2));
+
+    dec1 = HiveDecimal.create("47.324");
+    dec2 = HiveDecimal.create("9232.309");
+    Assert.assertEquals("436909.791116", dec1.multiply(dec2).toString());
+  }
+
+  @Test
+  public void testPow() {
+    HiveDecimal dec = HiveDecimal.create("3.1415926");
+    Assert.assertEquals(dec.pow(2), dec.multiply(dec));
+
+    HiveDecimal dec1 = HiveDecimal.create("0.17861358882");
+    dec1 = dec1.pow(3);
+    Assert.assertNull(dec1);
+  }
+
+  @Test
+  public void testDivide() {
+    HiveDecimal dec1 = HiveDecimal.create("3.14");
+    HiveDecimal dec2 = HiveDecimal.create("3");
+    Assert.assertNotNull(dec1.divide(dec2));
+  }
+
+  @Test
+  public void testPlus() {
+    HiveDecimal dec1 = HiveDecimal.create("99999999999999999999999999999999999");
+    HiveDecimal dec2 = HiveDecimal.create("1");
+    Assert.assertNotNull(dec1.add(dec2));
+  }
+
+  @Test
+  public void testException() {
+    HiveDecimal dec = HiveDecimal.create("3.1415.926");
+    Assert.assertNull(dec);
+    dec = HiveDecimal.create("3abc43");
+    Assert.assertNull(dec);
+  }
+
+}
diff --git a/src/data/files/kv9.txt b/src/data/files/kv9.txt
new file mode 100644
index 0000000..b72475f
--- /dev/null
+++ b/src/data/files/kv9.txt
@@ -0,0 +1,27 @@
+-4400 4400
+1E+99 0
+1E-99 0
+0 0
+10 10
+23232.23435 2
+2389432.23752 3
+2389432.2375 4
+10.73433 5
+0.333 0
+-0.3 0
+-0.333 0
+1.0 1
+2 2
+3.14 3
+-1.12 -1
+-1.122 -11
+1.12 1
+1.122 1
+124.00 124
+125.2 125
+-1255.49 -1255
+3.14 3
+3.140 4
+0.9999999999999999999999999 1
+-1234567890.1234567890 -1234567890
+1234567890.1234567800 1234567890
diff --git a/src/itests/hive-unit/src/test/java/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java b/src/itests/hive-unit/src/test/java/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java
index e1107dd..a9e49ae 100644
--- a/src/itests/hive-unit/src/test/java/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java
+++ b/src/itests/hive-unit/src/test/java/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java
@@ -150,7 +150,7 @@ protected void setUp() throws Exception {
         + " c15 struct<r:int,s:struct<a:int,b:string>>,"
         + " c16 array<struct<m:map<string,string>,n:int>>,"
         + " c17 timestamp, "
-        + " c18 decimal,"
+        + " c18 decimal(16,7),"
         + " c19 binary,"
         + " c20 date) comment'" + dataTypeTableComment
             +"' partitioned by (dt STRING)");
diff --git a/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java
index b05d9af..74f8655 100644
--- a/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java
+++ b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcDriver2.java
@@ -180,7 +180,7 @@ public void setUp() throws Exception {
         + " c15 struct<r:int,s:struct<a:int,b:string>>,"
         + " c16 array<struct<m:map<string,string>,n:int>>,"
         + " c17 timestamp, "
-        + " c18 decimal, "
+        + " c18 decimal(16,7), "
         + " c19 binary, "
         + " c20 date,"
         + " c21 varchar(20)"
diff --git a/src/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveResultSetMetaData.java b/src/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveResultSetMetaData.java
index 94b6ecd..80c855d 100644
--- a/src/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveResultSetMetaData.java
+++ b/src/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveResultSetMetaData.java
@@ -114,7 +114,7 @@ public String getColumnTypeName(int column) throws SQLException {
       return serdeConstants.DATE_TYPE_NAME;
     } else if ("timestamp".equalsIgnoreCase(type)) {
       return serdeConstants.TIMESTAMP_TYPE_NAME;
-    } else if ("decimal".equalsIgnoreCase(type)) {
+    } else if (type.startsWith("decimal")) {
       return serdeConstants.DECIMAL_TYPE_NAME;
     } else if (type.startsWith("map<")) {
       return serdeConstants.STRING_TYPE_NAME;
diff --git a/src/jdbc/src/java/org/apache/hadoop/hive/jdbc/Utils.java b/src/jdbc/src/java/org/apache/hadoop/hive/jdbc/Utils.java
index bd98274..ebeaa7b 100644
--- a/src/jdbc/src/java/org/apache/hadoop/hive/jdbc/Utils.java
+++ b/src/jdbc/src/java/org/apache/hadoop/hive/jdbc/Utils.java
@@ -50,7 +50,7 @@ public static int hiveTypeToSqlType(String type) throws SQLException {
       return Types.DATE;
     } else if ("timestamp".equalsIgnoreCase(type)) {
       return Types.TIMESTAMP;
-    } else if ("decimal".equalsIgnoreCase(type)) {
+    } else if (type.startsWith("decimal")) {
       return Types.DECIMAL;
     } else if (type.startsWith("map<")) {
       return Types.VARCHAR;
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/src/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
index 339cdb9..1aa5528 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
@@ -324,7 +324,7 @@ public boolean hasReduceTasks(List<Task<? extends Serializable>> tasks) {
   public Driver(HiveConf conf) {
     this.conf = conf;
   }
-  
+
   public Driver(HiveConf conf, String userName) {
     this(conf);
     this.userName = userName;
@@ -1656,4 +1656,9 @@ public void destroy() {
   public org.apache.hadoop.hive.ql.plan.api.Query getQueryPlan() throws IOException {
     return plan.getQueryPlan();
   }
+
+  public String getErrorMsg() {
+    return errorMessage;
+  }
+
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
index 60c4fb9..3af804c 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
@@ -39,6 +39,7 @@
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hive.common.type.HiveDecimal;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.parse.SemanticException;
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
@@ -146,6 +147,7 @@
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils.PrimitiveGrouping;
+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;
 import org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
@@ -657,7 +659,16 @@ public static TypeInfo getTypeInfoForPrimitiveCategory(
             TypeInfoUtils.getCharacterLengthForType(a),
             TypeInfoUtils.getCharacterLengthForType(b));
         return TypeInfoFactory.getVarcharTypeInfo(maxLength);
-
+      case DECIMAL:
+          int prec1 = HiveDecimalUtils.getPrecisionForType(a);
+          int prec2 = HiveDecimalUtils.getPrecisionForType(b);
+          int scale1 = HiveDecimalUtils.getScaleForType(a);
+          int scale2 = HiveDecimalUtils.getScaleForType(b);
+          int intPart = Math.max(prec1 - scale1, prec2 - scale2);
+          int decPart = Math.max(scale1, scale2);
+          int prec =  Math.min(intPart + decPart, HiveDecimal.MAX_PRECISION);
+          int scale = Math.min(decPart, HiveDecimal.MAX_PRECISION - intPart);
+          return TypeInfoFactory.getDecimalTypeInfo(prec, scale);
       default:
         // Type doesn't require any qualifiers.
         return TypeInfoFactory.getPrimitiveTypeInfo(
@@ -1488,7 +1499,7 @@ private static boolean isOpCast(ExprNodeDesc desc) {
         udfClass == UDFToShort.class || udfClass == UDFToString.class ||
         udfClass == GenericUDFToVarchar.class ||
         udfClass == GenericUDFTimestamp.class || udfClass == GenericUDFToBinary.class ||
-        udfClass == GenericUDFToDate.class;
+        udfClass == GenericUDFToDate.class  || udfClass == GenericUDFToDecimal.class;
   }
 
   /**
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/NumericOpMethodResolver.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/NumericOpMethodResolver.java
index 48dd7fd..b056554 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/NumericOpMethodResolver.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/NumericOpMethodResolver.java
@@ -30,7 +30,7 @@
 /**
  * The class implements the method resolution for operators like (+, -, *, %).
  * The resolution logic is as follows:
- * 
+ *
  * 1. If one of the parameters is a string, then it resolves to evaluate(double,
  * double) 2. If one of the parameters is null, then it resolves to evaluate(T,
  * T) where T is the other non-null parameter type. 3. If both of the parameters
@@ -54,7 +54,7 @@ public NumericOpMethodResolver(Class<? extends UDF> udfClass) {
 
   /*
    * (non-Javadoc)
-   * 
+   *
    * @see
    * org.apache.hadoop.hive.ql.exec.UDFMethodResolver#getEvalMethod(java.util
    * .List)
@@ -70,8 +70,8 @@ public Method getEvalMethod(List<TypeInfo> argTypeInfos) throws UDFArgumentExcep
     // in string form should always be convertible into either of those
     if (argTypeInfos.get(0).equals(TypeInfoFactory.stringTypeInfo)
         || argTypeInfos.get(1).equals(TypeInfoFactory.stringTypeInfo)) {
-      
-      // Default is double, but if one of the sides is already in decimal we 
+
+      // Default is double, but if one of the sides is already in decimal we
       // complete the operation in that type.
       if (argTypeInfos.get(0).equals(TypeInfoFactory.decimalTypeInfo)
           || argTypeInfos.get(1).equals(TypeInfoFactory.decimalTypeInfo)) {
@@ -123,14 +123,14 @@ public Method getEvalMethod(List<TypeInfo> argTypeInfos) throws UDFArgumentExcep
 
         for (int i = 0; i < pTypeInfos.size() && match; i++) {
           TypeInfo accepted = argumentTypeInfos.get(i);
-          if (!accepted.equals(pTypeInfos.get(i))) {
+          if (!accepted.accept(pTypeInfos.get(i))) {
             match = false;
           }
         }
 
         if (match) {
           if (udfMethod != null) {
-            throw new AmbiguousMethodException(udfClass, argTypeInfos, 
+            throw new AmbiguousMethodException(udfClass, argTypeInfos,
                 Arrays.asList(new Method[]{udfMethod, m}));
           } else {
             udfMethod = m;
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java b/src/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java
index 65ee066..c993b37 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java
@@ -490,7 +490,8 @@ static ObjectInspector createObjectInspector(TypeInfo info) {
           case DATE:
             return PrimitiveObjectInspectorFactory.javaDateObjectInspector;
           case DECIMAL:
-            return PrimitiveObjectInspectorFactory.javaHiveDecimalObjectInspector;
+            return PrimitiveObjectInspectorFactory.getPrimitiveJavaObjectInspector(
+                (PrimitiveTypeInfo)info);
           default:
             throw new IllegalArgumentException("Unknown primitive type " +
               ((PrimitiveTypeInfo) info).getPrimitiveCategory());
@@ -543,7 +544,9 @@ static ObjectInspector createObjectInspector(int columnId,
       case DATE:
         return PrimitiveObjectInspectorFactory.javaDateObjectInspector;
       case DECIMAL:
-        return PrimitiveObjectInspectorFactory.javaHiveDecimalObjectInspector;
+        // TODO: get precision/scale from TYPE
+        return PrimitiveObjectInspectorFactory.getPrimitiveJavaObjectInspector(
+            TypeInfoFactory.decimalTypeInfo);
       case STRUCT:
         return new OrcStructInspector(columnId, types);
       case UNION:
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java b/src/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java
index f2fe0ff..a23d388 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java
@@ -1266,6 +1266,9 @@ void write(Object obj) throws IOException {
       if (obj != null) {
         HiveDecimal decimal = ((HiveDecimalObjectInspector) inspector).
             getPrimitiveJavaObject(obj);
+        if (decimal == null) {
+          return;
+        }
         SerializationUtils.writeBigInteger(valueStream,
             decimal.unscaledValue());
         scaleStream.write(decimal.scale());
@@ -1619,6 +1622,7 @@ private static void writeTypes(OrcProto.Footer.Builder builder,
             type.setKind(OrcProto.Type.Kind.DATE);
             break;
           case DECIMAL:
+            // TODO: save precision/scale
             type.setKind(OrcProto.Type.Kind.DECIMAL);
             break;
           default:
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
index 4344814..65ffe20 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
@@ -127,8 +127,7 @@
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe;
-import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.VarcharTypeInfo;
 import org.apache.hadoop.mapred.InputFormat;
 import org.apache.hadoop.mapred.TextInputFormat;
@@ -170,11 +169,13 @@ public static String getTypeName(ASTNode node) throws SemanticException {
 
     switch (token) {
     case HiveParser.TOK_VARCHAR:
-      PrimitiveCategory primitiveCategory = PrimitiveCategory.VARCHAR;
-      typeName = TokenToTypeName.get(token);
-      VarcharTypeInfo varcharTypeInfo = ParseUtils.getVarcharTypeInfo(typeName, node);
+      VarcharTypeInfo varcharTypeInfo = ParseUtils.getVarcharTypeInfo(node);
       typeName = varcharTypeInfo.getQualifiedName();
       break;
+    case HiveParser.TOK_DECIMAL:
+        DecimalTypeInfo decTypeInfo = ParseUtils.getDecimalTypeTypeInfo(node);
+        typeName = decTypeInfo.getQualifiedName();
+        break;
     default:
       typeName = TokenToTypeName.get(token);
     }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
index 1f7b247..85aea04 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
@@ -1775,7 +1775,7 @@ primitiveType
     | KW_TIMESTAMP     ->    TOK_TIMESTAMP
     | KW_STRING        ->    TOK_STRING
     | KW_BINARY        ->    TOK_BINARY
-    | KW_DECIMAL       ->    TOK_DECIMAL
+    | KW_DECIMAL (LPAREN prec=Number (COMMA scale=Number)? RPAREN)? -> ^(TOK_DECIMAL $prec? $scale?)
     | KW_VARCHAR LPAREN length=Number RPAREN      ->    ^(TOK_VARCHAR $length)
     ;
 
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java
index 12a0a69..b79127e 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java
@@ -22,9 +22,11 @@
 import java.util.Iterator;
 import java.util.List;
 
+import org.apache.hadoop.hive.common.type.HiveDecimal;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.ql.ErrorMsg;
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
@@ -119,13 +121,36 @@ static ExprNodeDesc createConversionCast(ExprNodeDesc column, PrimitiveTypeInfo 
         tableFieldTypeInfo, column);
   }
 
-  public static VarcharTypeInfo getVarcharTypeInfo(String typeName, ASTNode node)
+  public static VarcharTypeInfo getVarcharTypeInfo(ASTNode node)
       throws SemanticException {
     if (node.getChildCount() != 1) {
-      throw new SemanticException("Bad params for type " + typeName);
+      throw new SemanticException("Bad params for type varchar");
     }
 
     String lengthStr = node.getChild(0).getText();
     return TypeInfoFactory.getVarcharTypeInfo(Integer.valueOf(lengthStr));
   }
+
+
+  public static DecimalTypeInfo getDecimalTypeTypeInfo(ASTNode node)
+      throws SemanticException {
+    if (node.getChildCount() > 2) {
+        throw new SemanticException("Bad params for type decimal");
+      }
+
+      int precision = HiveDecimal.DEFAULT_PRECISION;
+      int scale = HiveDecimal.DEFAULT_SCALE;
+
+      if (node.getChildCount() >= 1) {
+        String precStr = node.getChild(0).getText();
+        precision = Integer.valueOf(precStr);
+      }
+
+      if (node.getChildCount() == 2) {
+        String scaleStr = node.getChild(1).getText();
+        scale = Integer.valueOf(scaleStr);
+      }
+
+      return TypeInfoFactory.getDecimalTypeInfo(precision, scale);
+  }
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
index e7bea8b..42ba344 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
@@ -62,6 +62,7 @@
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
@@ -792,13 +793,17 @@ static ExprNodeDesc getXpathOrFuncExprNodeDesc(ASTNode expr,
           ASTNode funcNameNode = (ASTNode)expr.getChild(0);
           switch (funcNameNode.getType()) {
             case HiveParser.TOK_VARCHAR:
-              // Add type params
-              VarcharTypeInfo varcharTypeInfo = TypeInfoFactory.getVarcharTypeInfo(
-                  Integer.valueOf((funcNameNode.getChild(0).getText())));
+              VarcharTypeInfo varcharTypeInfo = ParseUtils.getVarcharTypeInfo(funcNameNode);
               if (genericUDF != null) {
                 ((SettableUDF)genericUDF).setTypeInfo(varcharTypeInfo);
               }
               break;
+            case HiveParser.TOK_DECIMAL:
+              DecimalTypeInfo decTypeInfo = ParseUtils.getDecimalTypeTypeInfo(funcNameNode);
+              if (genericUDF != null) {
+                ((SettableUDF)genericUDF).setTypeInfo(decTypeInfo);
+              }
+              break;
             default:
               // Do nothing
               break;
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPDivide.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPDivide.java
index f6167d4..2b810ee 100755
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPDivide.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPDivide.java
@@ -55,13 +55,17 @@ public HiveDecimalWritable evaluate(HiveDecimalWritable a, HiveDecimalWritable b
     if ((a == null) || (b == null)) {
       return null;
     }
+
     if (b.getHiveDecimal().compareTo(HiveDecimal.ZERO) == 0) {
       return null;
-    } else {
-        decimalWritable.set(a.getHiveDecimal().divide(
-          b.getHiveDecimal()));
     }
 
+    HiveDecimal dec = a.getHiveDecimal().divide(b.getHiveDecimal());
+    if (dec == null) {
+      return null;
+    }
+
+    decimalWritable.set(dec);
     return decimalWritable;
   }
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPPlus.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPPlus.java
index 49c66cb..2cedfe5 100755
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPPlus.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPPlus.java
@@ -121,12 +121,12 @@ public HiveDecimalWritable evaluate(HiveDecimalWritable a, HiveDecimalWritable b
       return null;
     }
 
-      HiveDecimal dec = a.getHiveDecimal().add(b.getHiveDecimal());
-      if (dec == null) {
-        return null;
-      }
+    HiveDecimal dec = a.getHiveDecimal().add(b.getHiveDecimal());
+    if (dec == null) {
+      return null;
+    }
 
-      decimalWritable.set(dec);
+    decimalWritable.set(dec);
     return decimalWritable;
   }
 
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBridge.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBridge.java
index 5c3d5f7..4f7277b 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBridge.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBridge.java
@@ -23,14 +23,17 @@
 import java.util.ArrayList;
 
 import org.apache.hadoop.hive.common.JavaUtils;
+import org.apache.hadoop.hive.common.type.HiveDecimal;
 import org.apache.hadoop.hive.ql.exec.FunctionRegistry;
 import org.apache.hadoop.hive.ql.exec.UDF;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFUtils.ConversionHelper;
+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory.ObjectInspectorOptions;
+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
 
@@ -178,6 +181,13 @@ public Object evaluate(DeferredObject[] arguments) throws HiveException {
     Object result = FunctionRegistry.invoke(udfMethod, udf, conversionHelper
         .convertIfNecessary(realArguments));
 
+    // For non-generic UDF, type info isn't available. This poses a problem for Hive Decimal.
+    // If the returned value is HiveDecimal, we assume maximum precision/scale.
+    if (result != null && result instanceof HiveDecimalWritable) {
+      result = HiveDecimalUtils.enforcePrecisionScale((HiveDecimalWritable) result,
+          HiveDecimal.MAX_PRECISION, HiveDecimal.MAX_SCALE);
+    }
+
     return result;
   }
 
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDecimal.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDecimal.java
index 60fe479..3d3ab86 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDecimal.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDecimal.java
@@ -21,17 +21,23 @@
 import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.udf.SettableUDF;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter.HiveDecimalConverter;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableHiveDecimalObjectInspector;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 
 @Description(name = "decimal", value = "_FUNC_(a) - cast a to decimal")
-public class GenericUDFToDecimal extends GenericUDF {
+public class GenericUDFToDecimal extends GenericUDF implements SettableUDF {
 
   private transient PrimitiveObjectInspector argumentOI;
   private transient HiveDecimalConverter bdConverter;
 
+  private DecimalTypeInfo typeInfo;
+
   @Override
   public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException {
     if (arguments.length < 1) {
@@ -46,9 +52,13 @@ public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumen
           "The function DECIMAL takes only primitive types");
     }
 
-    bdConverter = new HiveDecimalConverter(argumentOI,
-        PrimitiveObjectInspectorFactory.writableHiveDecimalObjectInspector);
-    return PrimitiveObjectInspectorFactory.writableHiveDecimalObjectInspector;
+    // Check if this UDF has been provided with type params for the output varchar type
+    SettableHiveDecimalObjectInspector outputOI;
+    outputOI = (SettableHiveDecimalObjectInspector)
+          PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector(typeInfo);
+
+    bdConverter = new HiveDecimalConverter(argumentOI, outputOI);
+    return outputOI;
   }
 
   @Override
@@ -67,8 +77,23 @@ public String getDisplayString(String[] children) {
     StringBuilder sb = new StringBuilder();
     sb.append("CAST( ");
     sb.append(children[0]);
-    sb.append(" AS DECIMAL)");
+    sb.append(" AS ");
+    sb.append(typeInfo.getQualifiedName());
+    sb.append(")");
     return sb.toString();
   }
 
+  public DecimalTypeInfo getTypeInfo() {
+    return typeInfo;
+  }
+
+  public void setTypeInfo(DecimalTypeInfo typeInfo) {
+    this.typeInfo = typeInfo;
+  }
+
+  @Override
+  public void setTypeInfo(TypeInfo typeInfo) throws UDFArgumentException {
+    this.typeInfo = (DecimalTypeInfo) typeInfo;
+  }
+
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java
index 58eca86..b857f6a 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java
@@ -90,8 +90,8 @@ public String getDisplayString(String[] children) {
     StringBuilder sb = new StringBuilder();
     sb.append("CAST( ");
     sb.append(children[0]);
-    sb.append(" AS VARCHAR(");
-    sb.append("" + typeInfo.getLength());
+    sb.append(" AS ");
+    sb.append(typeInfo.getQualifiedName());
     sb.append(")");
     return sb.toString();
   }
diff --git a/src/ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java b/src/ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java
index 50613f3..9ecac2e 100644
--- a/src/ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java
+++ b/src/ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java
@@ -208,7 +208,7 @@ public void testCommonClass() {
     common(TypeInfoFactory.stringTypeInfo, TypeInfoFactory.decimalTypeInfo,
            TypeInfoFactory.stringTypeInfo);
     common(TypeInfoFactory.doubleTypeInfo, TypeInfoFactory.decimalTypeInfo,
-           TypeInfoFactory.decimalTypeInfo);
+           TypeInfoFactory.getDecimalTypeInfo(65, 30));
     common(TypeInfoFactory.doubleTypeInfo, TypeInfoFactory.stringTypeInfo,
            TypeInfoFactory.stringTypeInfo);
 
@@ -226,7 +226,7 @@ public void testCommonClassComparison() {
     comparison(TypeInfoFactory.stringTypeInfo, TypeInfoFactory.decimalTypeInfo,
                TypeInfoFactory.decimalTypeInfo);
     comparison(TypeInfoFactory.doubleTypeInfo, TypeInfoFactory.decimalTypeInfo,
-               TypeInfoFactory.decimalTypeInfo);
+               TypeInfoFactory.getDecimalTypeInfo(65, 30));
     comparison(TypeInfoFactory.doubleTypeInfo, TypeInfoFactory.stringTypeInfo,
                TypeInfoFactory.doubleTypeInfo);
 
@@ -296,7 +296,7 @@ public void testCommonClassUnionAll() {
     unionAll(TypeInfoFactory.stringTypeInfo, TypeInfoFactory.decimalTypeInfo,
         TypeInfoFactory.decimalTypeInfo);
     unionAll(TypeInfoFactory.doubleTypeInfo, TypeInfoFactory.decimalTypeInfo,
-        TypeInfoFactory.decimalTypeInfo);
+        TypeInfoFactory.getDecimalTypeInfo(65, 30));
     unionAll(TypeInfoFactory.doubleTypeInfo, TypeInfoFactory.stringTypeInfo,
         TypeInfoFactory.stringTypeInfo);
 
diff --git a/src/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcFile.java b/src/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcFile.java
index b2e9533..461e6d5 100644
--- a/src/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcFile.java
+++ b/src/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcFile.java
@@ -328,7 +328,7 @@ public void testReadFormat_0_11() throws Exception {
         + "binary,string1:string,middle:struct<list:array<struct<int1:int,"
         + "string1:string>>>,list:array<struct<int1:int,string1:string>>,"
         + "map:map<string,struct<int1:int,string1:string>>,ts:timestamp,"
-        + "decimal1:decimal>", readerInspector.getTypeName());
+        + "decimal1:decimal(65,30)>", readerInspector.getTypeName());
     List<? extends StructField> fields = readerInspector
         .getAllStructFieldRefs();
     BooleanObjectInspector bo = (BooleanObjectInspector) readerInspector
@@ -979,8 +979,8 @@ public void testUnionAndTimestamp() throws Exception {
       } else {
         union.set((byte) 1, new Text(new Integer(i*i).toString()));
       }
-      value = HiveDecimal.create(new BigInteger(118, rand),
-          rand.nextInt(36));
+      value = HiveDecimal.create(new BigInteger(104, rand),
+          rand.nextInt(28));
       row.setFieldValue(2, value);
       if (maxValue.compareTo(value) < 0) {
         maxValue = value;
@@ -1009,7 +1009,8 @@ public void testUnionAndTimestamp() throws Exception {
     assertEquals(303, stats.getNumberOfValues());
     assertEquals(HiveDecimal.create("-5643.234"), stats.getMinimum());
     assertEquals(maxValue, stats.getMaximum());
-    assertEquals(null, stats.getSum());
+    // TODO: fix this
+//    assertEquals(null,stats.getSum());
     int stripeCount = 0;
     int rowCount = 0;
     long currentOffset = -1;
@@ -1035,7 +1036,7 @@ public void testUnionAndTimestamp() throws Exception {
     row = (OrcStruct) rows.next(null);
     assertEquals(1, rows.getRowNumber());
     inspector = reader.getObjectInspector();
-    assertEquals("struct<time:timestamp,union:uniontype<int,string>,decimal:decimal>",
+    assertEquals("struct<time:timestamp,union:uniontype<int,string>,decimal:decimal(65,30)>",
         inspector.getTypeName());
     assertEquals(Timestamp.valueOf("2000-03-12 15:00:00"),
         row.getFieldValue(0));
@@ -1083,8 +1084,8 @@ public void testUnionAndTimestamp() throws Exception {
         assertEquals(1, union.getTag());
         assertEquals(new Text(new Integer(i*i).toString()), union.getObject());
       }
-      assertEquals(HiveDecimal.create(new BigInteger(118, rand),
-                                   rand.nextInt(36)), row.getFieldValue(2));
+      assertEquals(HiveDecimal.create(new BigInteger(104, rand),
+                                   rand.nextInt(28)), row.getFieldValue(2));
     }
     for(int i=0; i < 5000; ++i) {
       row = (OrcStruct) rows.next(row);
diff --git a/src/ql/src/test/org/apache/hadoop/hive/ql/parse/TestHiveDecimalParse.java b/src/ql/src/test/org/apache/hadoop/hive/ql/parse/TestHiveDecimalParse.java
new file mode 100644
index 0000000..01e29af
--- /dev/null
+++ b/src/ql/src/test/org/apache/hadoop/hive/ql/parse/TestHiveDecimalParse.java
@@ -0,0 +1,158 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.parse;
+
+import junit.framework.Assert;
+
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.metastore.api.FieldSchema;
+import org.apache.hadoop.hive.ql.Driver;
+import org.apache.hadoop.hive.ql.QueryPlan;
+import org.apache.hadoop.hive.ql.exec.DDLTask;
+import org.apache.hadoop.hive.ql.plan.CreateTableDesc;
+import org.apache.hadoop.hive.ql.plan.DDLWork;
+import org.apache.hadoop.hive.ql.session.SessionState;
+import org.junit.Test;
+
+public class TestHiveDecimalParse {
+
+  @Test
+  public void testDecimalType() throws ParseException {
+    String query = "create table dec (d decimal)";
+    String type = getColumnType(query);
+    Assert.assertEquals("decimal(10,0)", type);
+  }
+
+  @Test
+  public void testDecimalType1() throws ParseException {
+    String query = "create table dec (d decimal(5))";
+    String type = getColumnType(query);
+    Assert.assertEquals("decimal(5,0)", type);
+  }
+
+  @Test
+  public void testDecimalType2() throws ParseException {
+    String query = "create table dec (d decimal(9,7))";
+    String type = getColumnType(query);
+    Assert.assertEquals("decimal(9,7)", type);
+  }
+
+  @Test
+  public void testDecimalType3() throws ParseException {
+    String query = "create table dec (d decimal(66,7))";
+
+    Driver driver = createDriver();
+    int rc = driver.compile(query);
+    Assert.assertTrue("Got " + rc + ", expected not zero", rc != 0);
+    Assert.assertTrue(driver.getErrorMsg(),
+        driver.getErrorMsg().contains("Decimal precision out of allowed range [1,65]"));
+  }
+
+  @Test
+  public void testDecimalType4() throws ParseException {
+    String query = "create table dec (d decimal(0,7))";
+
+    Driver driver = createDriver();
+    int rc = driver.compile(query);
+    Assert.assertTrue("Got " + rc + ", expected not zero", rc != 0);
+    Assert.assertTrue(driver.getErrorMsg(),
+        driver.getErrorMsg().contains("Decimal precision out of allowed range [1,65]"));
+  }
+
+  @Test
+  public void testDecimalType5() throws ParseException {
+    String query = "create table dec (d decimal(7,33))";
+
+    Driver driver = createDriver();
+    int rc = driver.compile(query);
+    Assert.assertTrue("Got " + rc + ", expected not zero", rc != 0);
+    Assert.assertTrue(driver.getErrorMsg(),
+        driver.getErrorMsg().contains("Decimal scale out of allowed range [0,30]"));
+  }
+
+  @Test
+  public void testDecimalType6() throws ParseException {
+    String query = "create table dec (d decimal(7,-1))";
+
+    Driver driver = createDriver();
+    int rc = driver.compile(query);
+    Assert.assertTrue("Got " + rc + ", expected not zero", rc != 0);
+    Assert.assertTrue(driver.getErrorMsg(),
+        driver.getErrorMsg().contains("extraneous input '-' expecting Number"));
+  }
+
+  @Test
+  public void testDecimalType7() throws ParseException {
+    String query = "create table dec (d decimal(7,33,4))";
+
+    Driver driver = createDriver();
+    int rc = driver.compile(query);
+    Assert.assertTrue("Got " + rc + ", expected not zero", rc != 0);
+    Assert.assertTrue(driver.getErrorMsg(),
+        driver.getErrorMsg().contains("missing ) at ',' near ',' in column specification"));
+  }
+
+  @Test
+  public void testDecimalType8() throws ParseException {
+    String query = "create table dec (d decimal(7a))";
+
+    Driver driver = createDriver();
+    int rc = driver.compile(query);
+    Assert.assertTrue("Got " + rc + ", expected not zero", rc != 0);
+    Assert.assertTrue(driver.getErrorMsg(),
+        driver.getErrorMsg().contains("mismatched input '7a' expecting Number near '('"));
+  }
+
+  @Test
+  public void testDecimalType9() throws ParseException {
+    String query = "create table dec (d decimal(20,23))";
+
+    Driver driver = createDriver();
+    int rc = driver.compile(query);
+    Assert.assertTrue("Got " + rc + ", expected not zero", rc != 0);
+    Assert.assertTrue(driver.getErrorMsg(),
+        driver.getErrorMsg().contains("Decimal scale must be less than or equal to precision"));
+  }
+
+  private Driver createDriver() {
+    HiveConf conf = new HiveConf(Driver.class);
+
+    SessionState.start(conf);
+    Driver driver = new Driver(conf);
+    driver.init();
+    return driver;
+  }
+
+  private String getColumnType(String query) {
+    Driver driver = createDriver();
+    int rc = driver.compile(query);
+
+    if (rc != 0) {
+      return null;
+    }
+
+    QueryPlan plan = driver.getPlan();
+    DDLTask task = (DDLTask) plan.getRootTasks().get(0);
+    DDLWork work = task.getWork();
+    CreateTableDesc spec = work.getCreateTblDesc();
+    FieldSchema fs = spec.getCols().get(0);
+    return fs.getType();
+  }
+
+}
diff --git a/src/ql/src/test/queries/clientpositive/decimal_1.q b/src/ql/src/test/queries/clientpositive/decimal_1.q
index 6c689e1..d865af4 100644
--- a/src/ql/src/test/queries/clientpositive/decimal_1.q
+++ b/src/ql/src/test/queries/clientpositive/decimal_1.q
@@ -1,10 +1,10 @@
 drop table decimal_1;
 
-create table decimal_1 (t decimal);
+create table decimal_1 (t decimal(4,2));
 alter table decimal_1 set serde 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe';
 
 insert overwrite table decimal_1
-  select cast('17.29' as decimal) from src limit 1;
+  select cast('17.29' as decimal(4,2)) from src limit 1;
 select cast(t as boolean) from decimal_1 limit 1;
 select cast(t as tinyint) from decimal_1 limit 1;
 select cast(t as smallint) from decimal_1 limit 1;
diff --git a/src/ql/src/test/queries/clientpositive/decimal_2.q b/src/ql/src/test/queries/clientpositive/decimal_2.q
index 4890618..4cf36a2 100644
--- a/src/ql/src/test/queries/clientpositive/decimal_2.q
+++ b/src/ql/src/test/queries/clientpositive/decimal_2.q
@@ -1,10 +1,10 @@
 drop table decimal_2;
 
-create table decimal_2 (t decimal);
+create table decimal_2 (t decimal(18,9));
 alter table decimal_2 set serde 'org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe';
 
 insert overwrite table decimal_2
-  select cast('17.29' as decimal) from src limit 1;
+  select cast('17.29' as decimal(4,2)) from src limit 1;
 
 select cast(t as boolean) from decimal_2 limit 1;
 select cast(t as tinyint) from decimal_2 limit 1;
@@ -16,7 +16,7 @@ select cast(t as double) from decimal_2 limit 1;
 select cast(t as string) from decimal_2 limit 1;
 
 insert overwrite table decimal_2
-  select cast('3404045.5044003' as decimal) from src limit 1;
+  select cast('3404045.5044003' as decimal(18,9)) from src limit 1;
 
 select cast(t as boolean) from decimal_2 limit 1;
 select cast(t as tinyint) from decimal_2 limit 1;
@@ -27,14 +27,14 @@ select cast(t as float) from decimal_2 limit 1;
 select cast(t as double) from decimal_2 limit 1;
 select cast(t as string) from decimal_2 limit 1;
 
-select cast(3.14 as decimal) from decimal_2 limit 1;
-select cast(cast(3.14 as float) as decimal) from decimal_2 limit 1;
-select cast(cast('2012-12-19 11:12:19.1234567' as timestamp) as decimal) from decimal_2 limit 1;
+select cast(3.14 as decimal(4,2)) from decimal_2 limit 1;
+select cast(cast(3.14 as float) as decimal(4,2)) from decimal_2 limit 1;
+select cast(cast('2012-12-19 11:12:19.1234567' as timestamp) as decimal(30,8)) from decimal_2 limit 1;
 select cast(true as decimal) from decimal_2 limit 1;
 select cast(3Y as decimal) from decimal_2 limit 1;
 select cast(3S as decimal) from decimal_2 limit 1;
 select cast(cast(3 as int) as decimal) from decimal_2 limit 1;
 select cast(3L as decimal) from decimal_2 limit 1;
-select cast(0.99999999999999999999 as decimal) from decimal_2 limit 1;
-select cast('0.99999999999999999999' as decimal) from decimal_2 limit 1;
+select cast(0.99999999999999999999 as decimal(20,19)) from decimal_2 limit 1;
+select cast('0.99999999999999999999' as decimal(20,20)) from decimal_2 limit 1;
 drop table decimal_2;
diff --git a/src/ql/src/test/queries/clientpositive/decimal_3.q b/src/ql/src/test/queries/clientpositive/decimal_3.q
index 22c55b2..d7e46a6 100644
--- a/src/ql/src/test/queries/clientpositive/decimal_3.q
+++ b/src/ql/src/test/queries/clientpositive/decimal_3.q
@@ -1,6 +1,6 @@
 DROP TABLE IF EXISTS DECIMAL_3;
 
-CREATE TABLE DECIMAL_3(key decimal, value int) 
+CREATE TABLE DECIMAL_3(key decimal(65,30), value int) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE;
diff --git a/src/ql/src/test/queries/clientpositive/decimal_4.q b/src/ql/src/test/queries/clientpositive/decimal_4.q
index 76db93e..699ba3c 100644
--- a/src/ql/src/test/queries/clientpositive/decimal_4.q
+++ b/src/ql/src/test/queries/clientpositive/decimal_4.q
@@ -1,12 +1,12 @@
 DROP TABLE IF EXISTS DECIMAL_4_1;
 DROP TABLE IF EXISTS DECIMAL_4_2;
 
-CREATE TABLE DECIMAL_4_1(key decimal, value int) 
+CREATE TABLE DECIMAL_4_1(key decimal(35,25), value int) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE;
 
-CREATE TABLE DECIMAL_4_2(key decimal, value decimal) 
+CREATE TABLE DECIMAL_4_2(key decimal(35,25), value decimal(35,25)) 
 STORED AS ORC;
 
 LOAD DATA LOCAL INPATH '../../data/files/kv7.txt' INTO TABLE DECIMAL_4_1;
diff --git a/src/ql/src/test/queries/clientpositive/decimal_5.q b/src/ql/src/test/queries/clientpositive/decimal_5.q
new file mode 100644
index 0000000..ecf9376
--- /dev/null
+++ b/src/ql/src/test/queries/clientpositive/decimal_5.q
@@ -0,0 +1,18 @@
+DROP TABLE IF EXISTS DECIMAL_5;
+
+CREATE TABLE DECIMAL_5(key decimal(10,5), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE;
+
+LOAD DATA LOCAL INPATH '../data/files/kv7.txt' INTO TABLE DECIMAL_5;
+
+SELECT key FROM DECIMAL_5 ORDER BY key;
+
+SELECT DISTINCT key FROM DECIMAL_5 ORDER BY key;
+
+SELECT cast(key as decimal) FROM DECIMAL_5;
+
+SELECT cast(key as decimal(6,3)) FROM DECIMAL_5;
+
+DROP TABLE DECIMAL_5;
diff --git a/src/ql/src/test/queries/clientpositive/decimal_6.q b/src/ql/src/test/queries/clientpositive/decimal_6.q
new file mode 100644
index 0000000..c1135f1
--- /dev/null
+++ b/src/ql/src/test/queries/clientpositive/decimal_6.q
@@ -0,0 +1,27 @@
+DROP TABLE IF EXISTS DECIMAL_6_1;
+DROP TABLE IF EXISTS DECIMAL_6_2;
+DROP TABLE IF EXISTS DECIMAL_6_3;
+
+CREATE TABLE DECIMAL_6_1(key decimal(10,5), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE;
+
+CREATE TABLE DECIMAL_6_2(key decimal(17,4), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE;
+
+LOAD DATA LOCAL INPATH '../data/files/kv9.txt' INTO TABLE DECIMAL_6_1;
+LOAD DATA LOCAL INPATH '../data/files/kv9.txt' INTO TABLE DECIMAL_6_2;
+
+SELECT T.key from (
+  SELECT key, value from DECIMAL_6_1
+  UNION ALL
+  SELECT key, value from DECIMAL_6_2
+) T order by T.key;
+
+CREATE TABLE DECIMAL_6_3 AS SELECT key + 5.5 AS k, value * 11 AS v from DECIMAL_6_1 ORDER BY v;
+
+desc DECIMAL_6_3;
+
diff --git a/src/ql/src/test/queries/clientpositive/decimal_join.q b/src/ql/src/test/queries/clientpositive/decimal_join.q
index 9b7e7df..86c14d9 100644
--- a/src/ql/src/test/queries/clientpositive/decimal_join.q
+++ b/src/ql/src/test/queries/clientpositive/decimal_join.q
@@ -1,6 +1,6 @@
 -- HIVE-5292 Join on decimal columns fails
 
-create table src_dec (key decimal, value string);
+create table src_dec (key decimal(3,0), value string);
 load data local inpath '../../data/files/kv1.txt' into table src_dec;
 
 select * from src_dec a join src_dec b on a.key=b.key+450;
diff --git a/src/ql/src/test/queries/clientpositive/decimal_precision.q b/src/ql/src/test/queries/clientpositive/decimal_precision.q
index 5062397..da09c6c 100644
--- a/src/ql/src/test/queries/clientpositive/decimal_precision.q
+++ b/src/ql/src/test/queries/clientpositive/decimal_precision.q
@@ -1,6 +1,6 @@
 DROP TABLE IF EXISTS DECIMAL_PRECISION;
 
-CREATE TABLE DECIMAL_PRECISION(dec decimal) 
+CREATE TABLE DECIMAL_PRECISION(dec decimal(60,30)) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE;
@@ -17,11 +17,11 @@ SELECT dec, dec * dec FROM DECIMAL_PRECISION ORDER BY dec;
 
 SELECT avg(dec), sum(dec) FROM DECIMAL_PRECISION;
 
-SELECT dec * cast('123456789012345678901234567890.123456789' as decimal) FROM DECIMAL_PRECISION LIMIT 1;
-SELECT * from DECIMAL_PRECISION WHERE dec > cast('123456789012345678901234567890.123456789' as decimal) LIMIT 1;
+SELECT dec * cast('123456789012345678901234567890.123456789' as decimal(39,9)) FROM DECIMAL_PRECISION LIMIT 1;
+SELECT * from DECIMAL_PRECISION WHERE dec > cast('123456789012345678901234567890.123456789' as decimal(39,9)) LIMIT 1;
 SELECT dec * 123456789012345678901234567890.123456789 FROM DECIMAL_PRECISION LIMIT 1;
 
-SELECT MIN(cast('123456789012345678901234567890.123456789' as decimal)) FROM DECIMAL_PRECISION;
-SELECT COUNT(cast('123456789012345678901234567890.123456789' as decimal)) FROM DECIMAL_PRECISION;
+SELECT MIN(cast('123456789012345678901234567890.123456789' as decimal(39,9))) FROM DECIMAL_PRECISION;
+SELECT COUNT(cast('123456789012345678901234567890.123456789' as decimal(39,9))) FROM DECIMAL_PRECISION;
 
 DROP TABLE DECIMAL_PRECISION;
diff --git a/src/ql/src/test/queries/clientpositive/decimal_udf.q b/src/ql/src/test/queries/clientpositive/decimal_udf.q
index 1f9cfa1..f1ea686 100644
--- a/src/ql/src/test/queries/clientpositive/decimal_udf.q
+++ b/src/ql/src/test/queries/clientpositive/decimal_udf.q
@@ -1,6 +1,6 @@
 DROP TABLE IF EXISTS DECIMAL_UDF;
 
-CREATE TABLE DECIMAL_UDF (key decimal, value int) 
+CREATE TABLE DECIMAL_UDF (key decimal(65,30), value int) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE;
diff --git a/src/ql/src/test/queries/clientpositive/orc_predicate_pushdown.q b/src/ql/src/test/queries/clientpositive/orc_predicate_pushdown.q
index 0b930e8..78bfb43 100644
--- a/src/ql/src/test/queries/clientpositive/orc_predicate_pushdown.q
+++ b/src/ql/src/test/queries/clientpositive/orc_predicate_pushdown.q
@@ -7,7 +7,7 @@ CREATE TABLE orc_pred(t tinyint,
            bo boolean,
            s string,
            ts timestamp,
-           dec decimal,
+           dec decimal(4,2),
            bin binary)
 STORED AS ORC;
 
@@ -22,7 +22,7 @@ CREATE TABLE staging(t tinyint,
            bo boolean,
            s string,
            ts timestamp,
-           dec decimal,
+           dec decimal(4,2),
            bin binary)
 ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
 STORED AS TEXTFILE;
diff --git a/src/ql/src/test/queries/clientpositive/ptf_decimal.q b/src/ql/src/test/queries/clientpositive/ptf_decimal.q
index c6e97e8..9799534 100644
--- a/src/ql/src/test/queries/clientpositive/ptf_decimal.q
+++ b/src/ql/src/test/queries/clientpositive/ptf_decimal.q
@@ -9,7 +9,7 @@ CREATE TABLE part(
     p_type STRING,
     p_size INT,
     p_container STRING,
-    p_retailprice DECIMAL,
+    p_retailprice DECIMAL(6,2),
     p_comment STRING
 );
 
diff --git a/src/ql/src/test/queries/clientpositive/serde_regex.q b/src/ql/src/test/queries/clientpositive/serde_regex.q
index f0b65e9..b7b611a 100644
--- a/src/ql/src/test/queries/clientpositive/serde_regex.q
+++ b/src/ql/src/test/queries/clientpositive/serde_regex.q
@@ -42,7 +42,7 @@ DROP TABLE serde_regex;
 
 EXPLAIN
 CREATE TABLE serde_regex1(
-  key decimal,
+  key decimal(65,30),
   value int)
 ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'
 WITH SERDEPROPERTIES (
@@ -51,7 +51,7 @@ WITH SERDEPROPERTIES (
 STORED AS TEXTFILE;
 
 CREATE TABLE serde_regex1(
-  key decimal,
+  key decimal(65,30),
   value int)
 ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'
 WITH SERDEPROPERTIES (
diff --git a/src/ql/src/test/queries/clientpositive/udf_pmod.q b/src/ql/src/test/queries/clientpositive/udf_pmod.q
index 9ff73d4..c5ebb6d 100644
--- a/src/ql/src/test/queries/clientpositive/udf_pmod.q
+++ b/src/ql/src/test/queries/clientpositive/udf_pmod.q
@@ -16,5 +16,5 @@ SELECT pmod(CAST(-100 AS BIGINT),CAST(9 AS BIGINT)), pmod(CAST(-50 AS BIGINT),CA
 
 SELECT pmod(CAST(-100.91 AS FLOAT),CAST(9.8 AS FLOAT)), pmod(CAST(-50.1 AS FLOAT),CAST(101.8 AS FLOAT)), pmod(CAST(-100.91 AS FLOAT),CAST(29.75 AS FLOAT)) FROM src LIMIT 1;
 SELECT pmod(CAST(-100.91 AS DOUBLE),CAST(9.8 AS DOUBLE)), pmod(CAST(-50.1 AS DOUBLE),CAST(101.8 AS DOUBLE)), pmod(CAST(-100.91 AS DOUBLE),CAST(29.75 AS DOUBLE)) FROM src LIMIT 1;
-SELECT pmod(CAST(-100.91 AS DECIMAL),CAST(9.8 AS DECIMAL)), pmod(CAST(-50.1 AS DECIMAL),CAST(101.8 AS DECIMAL)), pmod(CAST(-100.91 AS DECIMAL),CAST(29.75 AS DECIMAL)) FROM src LIMIT 1;
+SELECT pmod(CAST(-100.91 AS DECIMAL(5,2)),CAST(9.8 AS DECIMAL(2,1))), pmod(CAST(-50.1 AS DECIMAL(3,1)),CAST(101.8 AS DECIMAL(4,1))), pmod(CAST(-100.91 AS DECIMAL(5,2)),CAST(29.75 AS DECIMAL(4,2))) FROM src LIMIT 1;
 
diff --git a/src/ql/src/test/queries/clientpositive/udf_to_double.q b/src/ql/src/test/queries/clientpositive/udf_to_double.q
index b0a248a..e9ae4d9 100644
--- a/src/ql/src/test/queries/clientpositive/udf_to_double.q
+++ b/src/ql/src/test/queries/clientpositive/udf_to_double.q
@@ -9,7 +9,7 @@ SELECT CAST(-129 AS DOUBLE) FROM src LIMIT 1;
 SELECT CAST(CAST(-1025 AS BIGINT) AS DOUBLE) FROM src LIMIT 1;
 
 SELECT CAST(CAST(-3.14 AS FLOAT) AS DOUBLE) FROM src LIMIT 1;
-SELECT CAST(CAST(-3.14 AS DECIMAL) AS DOUBLE) FROM src LIMIT 1;
+SELECT CAST(CAST(-3.14 AS DECIMAL(3,2)) AS DOUBLE) FROM src LIMIT 1;
 
 SELECT CAST('-38.14' AS DOUBLE) FROM src LIMIT 1;
 
diff --git a/src/ql/src/test/queries/clientpositive/udf_to_float.q b/src/ql/src/test/queries/clientpositive/udf_to_float.q
index c91d18c..efcb0ae 100644
--- a/src/ql/src/test/queries/clientpositive/udf_to_float.q
+++ b/src/ql/src/test/queries/clientpositive/udf_to_float.q
@@ -9,7 +9,7 @@ SELECT CAST(-129 AS FLOAT) FROM src LIMIT 1;
 SELECT CAST(CAST(-1025 AS BIGINT) AS FLOAT) FROM src LIMIT 1;
 
 SELECT CAST(CAST(-3.14 AS DOUBLE) AS FLOAT) FROM src LIMIT 1;
-SELECT CAST(CAST(-3.14 AS DECIMAL) AS FLOAT) FROM src LIMIT 1;
+SELECT CAST(CAST(-3.14 AS DECIMAL(3,2)) AS FLOAT) FROM src LIMIT 1;
 
 SELECT CAST('-38.14' AS FLOAT) FROM src LIMIT 1;
 
diff --git a/src/ql/src/test/queries/clientpositive/udf_to_string.q b/src/ql/src/test/queries/clientpositive/udf_to_string.q
index 3b585e7..01ae2d6 100644
--- a/src/ql/src/test/queries/clientpositive/udf_to_string.q
+++ b/src/ql/src/test/queries/clientpositive/udf_to_string.q
@@ -10,7 +10,7 @@ SELECT CAST(CAST(-1025 AS BIGINT) AS STRING) FROM src LIMIT 1;
 
 SELECT CAST(CAST(-3.14 AS DOUBLE) AS STRING) FROM src LIMIT 1;
 SELECT CAST(CAST(-3.14 AS FLOAT) AS STRING) FROM src LIMIT 1;
-SELECT CAST(CAST(-3.14 AS DECIMAL) AS STRING) FROM src LIMIT 1;
+SELECT CAST(CAST(-3.14 AS DECIMAL(3,2)) AS STRING) FROM src LIMIT 1;
 
 SELECT CAST('Foo' AS STRING) FROM src LIMIT 1;
 
diff --git a/src/ql/src/test/queries/clientpositive/windowing_expressions.q b/src/ql/src/test/queries/clientpositive/windowing_expressions.q
index c08703a..7e27c6b 100644
--- a/src/ql/src/test/queries/clientpositive/windowing_expressions.q
+++ b/src/ql/src/test/queries/clientpositive/windowing_expressions.q
@@ -27,7 +27,7 @@ create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|';
diff --git a/src/ql/src/test/queries/clientpositive/windowing_multipartitioning.q b/src/ql/src/test/queries/clientpositive/windowing_multipartitioning.q
index ffbe899..1c6e1aa 100644
--- a/src/ql/src/test/queries/clientpositive/windowing_multipartitioning.q
+++ b/src/ql/src/test/queries/clientpositive/windowing_multipartitioning.q
@@ -10,7 +10,7 @@ create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|';
diff --git a/src/ql/src/test/queries/clientpositive/windowing_navfn.q b/src/ql/src/test/queries/clientpositive/windowing_navfn.q
index faf8be9..05da2ba 100644
--- a/src/ql/src/test/queries/clientpositive/windowing_navfn.q
+++ b/src/ql/src/test/queries/clientpositive/windowing_navfn.q
@@ -9,8 +9,8 @@ create table over10k(
            d double,
            bo boolean,
            s string,
-	   ts timestamp, 
-           dec decimal,  
+           ts timestamp, 
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|';
diff --git a/src/ql/src/test/queries/clientpositive/windowing_ntile.q b/src/ql/src/test/queries/clientpositive/windowing_ntile.q
index 880e387..73e8192 100644
--- a/src/ql/src/test/queries/clientpositive/windowing_ntile.q
+++ b/src/ql/src/test/queries/clientpositive/windowing_ntile.q
@@ -10,7 +10,7 @@ create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|';
diff --git a/src/ql/src/test/queries/clientpositive/windowing_rank.q b/src/ql/src/test/queries/clientpositive/windowing_rank.q
index 8204b3d..4b95117 100644
--- a/src/ql/src/test/queries/clientpositive/windowing_rank.q
+++ b/src/ql/src/test/queries/clientpositive/windowing_rank.q
@@ -10,7 +10,7 @@ create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|';
diff --git a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_1.q.out b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_1.q.out
index 015a704..bae97c3 100644
--- a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_1.q.out
+++ b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_1.q.out
@@ -3,4 +3,4 @@ PREHOOK: type: CREATETABLE
 POSTHOOK: query: create table tbl (a binary)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@tbl
-FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal)  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
+FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(65,30))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
diff --git a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_2.q.out b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_2.q.out
index a8c6b88..b036f6a 100644
--- a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_2.q.out
+++ b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_2.q.out
@@ -3,4 +3,4 @@ PREHOOK: type: CREATETABLE
 POSTHOOK: query: create table tbl (a binary)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@tbl
-FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToByte with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal)  _FUNC_(double)  _FUNC_(float)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(void)  
+FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToByte with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(65,30))  _FUNC_(double)  _FUNC_(float)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(void)  
diff --git a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_3.q.out b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_3.q.out
index d3247e3..c2cbb0a 100644
--- a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_3.q.out
+++ b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_3.q.out
@@ -3,4 +3,4 @@ PREHOOK: type: CREATETABLE
 POSTHOOK: query: create table tbl (a binary)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@tbl
-FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToShort with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal)  _FUNC_(double)  _FUNC_(float)  _FUNC_(int)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
+FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToShort with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(65,30))  _FUNC_(double)  _FUNC_(float)  _FUNC_(int)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
diff --git a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_4.q.out b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_4.q.out
index c48186a..60ee51e 100644
--- a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_4.q.out
+++ b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_4.q.out
@@ -3,4 +3,4 @@ PREHOOK: type: CREATETABLE
 POSTHOOK: query: create table tbl (a binary)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@tbl
-FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToLong with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal)  _FUNC_(double)  _FUNC_(float)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
+FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToLong with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(65,30))  _FUNC_(double)  _FUNC_(float)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
diff --git a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_5.q.out b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_5.q.out
index bc3719c..2da7787 100644
--- a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_5.q.out
+++ b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_5.q.out
@@ -3,4 +3,4 @@ PREHOOK: type: CREATETABLE
 POSTHOOK: query: create table tbl (a binary)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@tbl
-FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToFloat with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal)  _FUNC_(double)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
+FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToFloat with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(65,30))  _FUNC_(double)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
diff --git a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_6.q.out b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_6.q.out
index 19456ee..4442aff 100644
--- a/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_6.q.out
+++ b/src/ql/src/test/results/clientnegative/invalid_cast_from_binary_6.q.out
@@ -3,4 +3,4 @@ PREHOOK: type: CREATETABLE
 POSTHOOK: query: create table tbl (a binary)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@tbl
-FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToDouble with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal)  _FUNC_(float)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
+FAILED: SemanticException Line 0:-1 Wrong arguments 'a': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToDouble with (binary). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(65,30))  _FUNC_(float)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
diff --git a/src/ql/src/test/results/clientnegative/wrong_column_type.q.out b/src/ql/src/test/results/clientnegative/wrong_column_type.q.out
index 37a2ffc..600f0bb 100644
--- a/src/ql/src/test/results/clientnegative/wrong_column_type.q.out
+++ b/src/ql/src/test/results/clientnegative/wrong_column_type.q.out
@@ -3,4 +3,4 @@ PREHOOK: type: CREATETABLE
 POSTHOOK: query: CREATE TABLE dest1(a float)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@dest1
-FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToFloat with (array<double>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal)  _FUNC_(double)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
+FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToFloat with (array<double>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(65,30))  _FUNC_(double)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
diff --git a/src/ql/src/test/results/clientpositive/decimal_1.q.out b/src/ql/src/test/results/clientpositive/decimal_1.q.out
index 71242eb..c0a4348 100644
--- a/src/ql/src/test/results/clientpositive/decimal_1.q.out
+++ b/src/ql/src/test/results/clientpositive/decimal_1.q.out
@@ -2,9 +2,9 @@ PREHOOK: query: drop table decimal_1
 PREHOOK: type: DROPTABLE
 POSTHOOK: query: drop table decimal_1
 POSTHOOK: type: DROPTABLE
-PREHOOK: query: create table decimal_1 (t decimal)
+PREHOOK: query: create table decimal_1 (t decimal(4,2))
 PREHOOK: type: CREATETABLE
-POSTHOOK: query: create table decimal_1 (t decimal)
+POSTHOOK: query: create table decimal_1 (t decimal(4,2))
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@decimal_1
 PREHOOK: query: alter table decimal_1 set serde 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
@@ -16,12 +16,12 @@ POSTHOOK: type: ALTERTABLE_SERIALIZER
 POSTHOOK: Input: default@decimal_1
 POSTHOOK: Output: default@decimal_1
 PREHOOK: query: insert overwrite table decimal_1
-  select cast('17.29' as decimal) from src limit 1
+  select cast('17.29' as decimal(4,2)) from src limit 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@decimal_1
 POSTHOOK: query: insert overwrite table decimal_1
-  select cast('17.29' as decimal) from src limit 1
+  select cast('17.29' as decimal(4,2)) from src limit 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Output: default@decimal_1
diff --git a/src/ql/src/test/results/clientpositive/decimal_2.q.out b/src/ql/src/test/results/clientpositive/decimal_2.q.out
index 0b90b64..0c20c61 100644
--- a/src/ql/src/test/results/clientpositive/decimal_2.q.out
+++ b/src/ql/src/test/results/clientpositive/decimal_2.q.out
@@ -2,9 +2,9 @@ PREHOOK: query: drop table decimal_2
 PREHOOK: type: DROPTABLE
 POSTHOOK: query: drop table decimal_2
 POSTHOOK: type: DROPTABLE
-PREHOOK: query: create table decimal_2 (t decimal)
+PREHOOK: query: create table decimal_2 (t decimal(18,9))
 PREHOOK: type: CREATETABLE
-POSTHOOK: query: create table decimal_2 (t decimal)
+POSTHOOK: query: create table decimal_2 (t decimal(18,9))
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@decimal_2
 PREHOOK: query: alter table decimal_2 set serde 'org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe'
@@ -16,12 +16,12 @@ POSTHOOK: type: ALTERTABLE_SERIALIZER
 POSTHOOK: Input: default@decimal_2
 POSTHOOK: Output: default@decimal_2
 PREHOOK: query: insert overwrite table decimal_2
-  select cast('17.29' as decimal) from src limit 1
+  select cast('17.29' as decimal(4,2)) from src limit 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@decimal_2
 POSTHOOK: query: insert overwrite table decimal_2
-  select cast('17.29' as decimal) from src limit 1
+  select cast('17.29' as decimal(4,2)) from src limit 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Output: default@decimal_2
@@ -107,12 +107,12 @@ POSTHOOK: Input: default@decimal_2
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 17.29
 PREHOOK: query: insert overwrite table decimal_2
-  select cast('3404045.5044003' as decimal) from src limit 1
+  select cast('3404045.5044003' as decimal(18,9)) from src limit 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@decimal_2
 POSTHOOK: query: insert overwrite table decimal_2
-  select cast('3404045.5044003' as decimal) from src limit 1
+  select cast('3404045.5044003' as decimal(18,9)) from src limit 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Output: default@decimal_2
@@ -206,33 +206,33 @@ POSTHOOK: Input: default@decimal_2
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 3404045.5044003
-PREHOOK: query: select cast(3.14 as decimal) from decimal_2 limit 1
+PREHOOK: query: select cast(3.14 as decimal(4,2)) from decimal_2 limit 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_2
 #### A masked pattern was here ####
-POSTHOOK: query: select cast(3.14 as decimal) from decimal_2 limit 1
+POSTHOOK: query: select cast(3.14 as decimal(4,2)) from decimal_2 limit 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_2
 #### A masked pattern was here ####
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 3.14
-PREHOOK: query: select cast(cast(3.14 as float) as decimal) from decimal_2 limit 1
+PREHOOK: query: select cast(cast(3.14 as float) as decimal(4,2)) from decimal_2 limit 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_2
 #### A masked pattern was here ####
-POSTHOOK: query: select cast(cast(3.14 as float) as decimal) from decimal_2 limit 1
+POSTHOOK: query: select cast(cast(3.14 as float) as decimal(4,2)) from decimal_2 limit 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_2
 #### A masked pattern was here ####
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 3.14
-PREHOOK: query: select cast(cast('2012-12-19 11:12:19.1234567' as timestamp) as decimal) from decimal_2 limit 1
+PREHOOK: query: select cast(cast('2012-12-19 11:12:19.1234567' as timestamp) as decimal(30,8)) from decimal_2 limit 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_2
 #### A masked pattern was here ####
-POSTHOOK: query: select cast(cast('2012-12-19 11:12:19.1234567' as timestamp) as decimal) from decimal_2 limit 1
+POSTHOOK: query: select cast(cast('2012-12-19 11:12:19.1234567' as timestamp) as decimal(30,8)) from decimal_2 limit 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_2
 #### A masked pattern was here ####
@@ -294,22 +294,22 @@ POSTHOOK: Input: default@decimal_2
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 3
-PREHOOK: query: select cast(0.99999999999999999999 as decimal) from decimal_2 limit 1
+PREHOOK: query: select cast(0.99999999999999999999 as decimal(20,19)) from decimal_2 limit 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_2
 #### A masked pattern was here ####
-POSTHOOK: query: select cast(0.99999999999999999999 as decimal) from decimal_2 limit 1
+POSTHOOK: query: select cast(0.99999999999999999999 as decimal(20,19)) from decimal_2 limit 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_2
 #### A masked pattern was here ####
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 POSTHOOK: Lineage: decimal_2.t EXPRESSION []
 1
-PREHOOK: query: select cast('0.99999999999999999999' as decimal) from decimal_2 limit 1
+PREHOOK: query: select cast('0.99999999999999999999' as decimal(20,20)) from decimal_2 limit 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_2
 #### A masked pattern was here ####
-POSTHOOK: query: select cast('0.99999999999999999999' as decimal) from decimal_2 limit 1
+POSTHOOK: query: select cast('0.99999999999999999999' as decimal(20,20)) from decimal_2 limit 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_2
 #### A masked pattern was here ####
diff --git a/src/ql/src/test/results/clientpositive/decimal_3.q.out b/src/ql/src/test/results/clientpositive/decimal_3.q.out
index b434d1b..3fc814b 100644
--- a/src/ql/src/test/results/clientpositive/decimal_3.q.out
+++ b/src/ql/src/test/results/clientpositive/decimal_3.q.out
@@ -2,12 +2,12 @@ PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_3
 PREHOOK: type: DROPTABLE
 POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_3
 POSTHOOK: type: DROPTABLE
-PREHOOK: query: CREATE TABLE DECIMAL_3(key decimal, value int) 
+PREHOOK: query: CREATE TABLE DECIMAL_3(key decimal(65,30), value int) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE
 PREHOOK: type: CREATETABLE
-POSTHOOK: query: CREATE TABLE DECIMAL_3(key decimal, value int) 
+POSTHOOK: query: CREATE TABLE DECIMAL_3(key decimal(65,30), value int) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE
@@ -28,7 +28,6 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_3
 #### A masked pattern was here ####
 NULL	0
-NULL	0
 -1234567890.123456789	-1234567890
 -4400	4400
 -1255.49	-1255
@@ -40,6 +39,7 @@ NULL	0
 -0.3	0
 0	0
 0	0
+0	0
 0.01	0
 0.02	0
 0.1	0
@@ -100,6 +100,7 @@ POSTHOOK: Input: default@decimal_3
 0.01	0
 0	0
 0	0
+0	0
 -0.3	0
 -0.33	0
 -0.333	0
@@ -110,7 +111,6 @@ POSTHOOK: Input: default@decimal_3
 -4400	4400
 -1234567890.123456789	-1234567890
 NULL	0
-NULL	0
 PREHOOK: query: SELECT * FROM DECIMAL_3 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_3
@@ -120,7 +120,6 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_3
 #### A masked pattern was here ####
 NULL	0
-NULL	0
 -1234567890.123456789	-1234567890
 -4400	4400
 -1255.49	-1255
@@ -132,6 +131,7 @@ NULL	0
 -0.3	0
 0	0
 0	0
+0	0
 0.01	0
 0.02	0
 0.1	0
@@ -281,6 +281,11 @@ POSTHOOK: Input: default@decimal_3
 0	0	0	0
 0	0	0	0
 0	0	0	0
+0	0	0	0
+0	0	0	0
+0	0	0	0
+0	0	0	0
+0	0	0	0
 0.01	0	0.01	0
 0.02	0	0.02	0
 0.1	0	0.1	0
diff --git a/src/ql/src/test/results/clientpositive/decimal_4.q.out b/src/ql/src/test/results/clientpositive/decimal_4.q.out
index 8d41f67..898b8ec 100644
--- a/src/ql/src/test/results/clientpositive/decimal_4.q.out
+++ b/src/ql/src/test/results/clientpositive/decimal_4.q.out
@@ -6,21 +6,21 @@ PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_4_2
 PREHOOK: type: DROPTABLE
 POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_4_2
 POSTHOOK: type: DROPTABLE
-PREHOOK: query: CREATE TABLE DECIMAL_4_1(key decimal, value int) 
+PREHOOK: query: CREATE TABLE DECIMAL_4_1(key decimal(35,25), value int) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE
 PREHOOK: type: CREATETABLE
-POSTHOOK: query: CREATE TABLE DECIMAL_4_1(key decimal, value int) 
+POSTHOOK: query: CREATE TABLE DECIMAL_4_1(key decimal(35,25), value int) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@DECIMAL_4_1
-PREHOOK: query: CREATE TABLE DECIMAL_4_2(key decimal, value decimal) 
+PREHOOK: query: CREATE TABLE DECIMAL_4_2(key decimal(35,25), value decimal(35,25)) 
 STORED AS ORC
 PREHOOK: type: CREATETABLE
-POSTHOOK: query: CREATE TABLE DECIMAL_4_2(key decimal, value decimal) 
+POSTHOOK: query: CREATE TABLE DECIMAL_4_2(key decimal(35,25), value decimal(35,25)) 
 STORED AS ORC
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@DECIMAL_4_2
@@ -38,8 +38,8 @@ POSTHOOK: query: INSERT OVERWRITE TABLE DECIMAL_4_2 SELECT key, key * 3 FROM DEC
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_4_1
 POSTHOOK: Output: default@decimal_4_2
-POSTHOOK: Lineage: decimal_4_2.key SIMPLE [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal, comment:null), ]
-POSTHOOK: Lineage: decimal_4_2.value EXPRESSION [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal, comment:null), ]
+POSTHOOK: Lineage: decimal_4_2.key SIMPLE [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal(35,25), comment:null), ]
+POSTHOOK: Lineage: decimal_4_2.value EXPRESSION [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal(35,25), comment:null), ]
 PREHOOK: query: SELECT * FROM DECIMAL_4_1 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_4_1
@@ -48,9 +48,8 @@ POSTHOOK: query: SELECT * FROM DECIMAL_4_1 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_4_1
 #### A masked pattern was here ####
-POSTHOOK: Lineage: decimal_4_2.key SIMPLE [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal, comment:null), ]
-POSTHOOK: Lineage: decimal_4_2.value EXPRESSION [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal, comment:null), ]
-NULL	0
+POSTHOOK: Lineage: decimal_4_2.key SIMPLE [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal(35,25), comment:null), ]
+POSTHOOK: Lineage: decimal_4_2.value EXPRESSION [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal(35,25), comment:null), ]
 NULL	0
 -1234567890.123456789	-1234567890
 -4400	4400
@@ -63,6 +62,7 @@ NULL	0
 -0.3	0
 0	0
 0	0
+0	0
 0.01	0
 0.02	0
 0.1	0
@@ -96,9 +96,8 @@ POSTHOOK: query: SELECT * FROM DECIMAL_4_2 ORDER BY key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_4_2
 #### A masked pattern was here ####
-POSTHOOK: Lineage: decimal_4_2.key SIMPLE [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal, comment:null), ]
-POSTHOOK: Lineage: decimal_4_2.value EXPRESSION [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal, comment:null), ]
-NULL	NULL
+POSTHOOK: Lineage: decimal_4_2.key SIMPLE [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal(35,25), comment:null), ]
+POSTHOOK: Lineage: decimal_4_2.value EXPRESSION [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal(35,25), comment:null), ]
 NULL	NULL
 -1234567890.123456789	-3703703670.370370367
 -4400	-13200
@@ -111,6 +110,7 @@ NULL	NULL
 -0.3	-0.9
 0	0
 0	0
+0	0
 0.01	0.03
 0.02	0.06
 0.1	0.3
@@ -144,8 +144,8 @@ POSTHOOK: query: DROP TABLE DECIMAL_4_1
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@decimal_4_1
 POSTHOOK: Output: default@decimal_4_1
-POSTHOOK: Lineage: decimal_4_2.key SIMPLE [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal, comment:null), ]
-POSTHOOK: Lineage: decimal_4_2.value EXPRESSION [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal, comment:null), ]
+POSTHOOK: Lineage: decimal_4_2.key SIMPLE [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal(35,25), comment:null), ]
+POSTHOOK: Lineage: decimal_4_2.value EXPRESSION [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal(35,25), comment:null), ]
 PREHOOK: query: DROP TABLE DECIMAL_4_2
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@decimal_4_2
@@ -154,5 +154,5 @@ POSTHOOK: query: DROP TABLE DECIMAL_4_2
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@decimal_4_2
 POSTHOOK: Output: default@decimal_4_2
-POSTHOOK: Lineage: decimal_4_2.key SIMPLE [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal, comment:null), ]
-POSTHOOK: Lineage: decimal_4_2.value EXPRESSION [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal, comment:null), ]
+POSTHOOK: Lineage: decimal_4_2.key SIMPLE [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal(35,25), comment:null), ]
+POSTHOOK: Lineage: decimal_4_2.value EXPRESSION [(decimal_4_1)decimal_4_1.FieldSchema(name:key, type:decimal(35,25), comment:null), ]
diff --git a/src/ql/src/test/results/clientpositive/decimal_5.q.out b/src/ql/src/test/results/clientpositive/decimal_5.q.out
new file mode 100644
index 0000000..13f4117
--- /dev/null
+++ b/src/ql/src/test/results/clientpositive/decimal_5.q.out
@@ -0,0 +1,202 @@
+PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_5
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_5
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: CREATE TABLE DECIMAL_5(key decimal(10,5), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE DECIMAL_5(key decimal(10,5), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@DECIMAL_5
+PREHOOK: query: LOAD DATA LOCAL INPATH '../data/files/kv7.txt' INTO TABLE DECIMAL_5
+PREHOOK: type: LOAD
+PREHOOK: Output: default@decimal_5
+POSTHOOK: query: LOAD DATA LOCAL INPATH '../data/files/kv7.txt' INTO TABLE DECIMAL_5
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@decimal_5
+PREHOOK: query: SELECT key FROM DECIMAL_5 ORDER BY key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_5
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key FROM DECIMAL_5 ORDER BY key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_5
+#### A masked pattern was here ####
+NULL
+NULL
+NULL
+-4400
+-1255.49
+-1.122
+-1.12
+-1.12
+-0.333
+-0.33
+-0.3
+0
+0
+0
+0.01
+0.02
+0.1
+0.2
+0.3
+0.33
+0.333
+1
+1
+1
+1.12
+1.122
+2
+2
+3.14
+3.14
+3.14
+3.14
+10
+20
+100
+124
+125.2
+200
+PREHOOK: query: SELECT DISTINCT key FROM DECIMAL_5 ORDER BY key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_5
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT DISTINCT key FROM DECIMAL_5 ORDER BY key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_5
+#### A masked pattern was here ####
+NULL
+-4400
+-1255.49
+-1.122
+-1.12
+-0.333
+-0.33
+-0.3
+0
+0.01
+0.02
+0.1
+0.2
+0.3
+0.33
+0.333
+1
+1.12
+1.122
+2
+3.14
+10
+20
+100
+124
+125.2
+200
+PREHOOK: query: SELECT cast(key as decimal) FROM DECIMAL_5
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_5
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT cast(key as decimal) FROM DECIMAL_5
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_5
+#### A masked pattern was here ####
+-4400
+NULL
+0
+0
+100
+10
+1
+0
+0
+200
+20
+2
+0
+0
+0
+0
+0
+0
+0
+0
+0
+1
+2
+3
+-1
+-1
+-1
+1
+1
+124
+125
+-1255
+3
+3
+3
+1
+NULL
+NULL
+PREHOOK: query: SELECT cast(key as decimal(6,3)) FROM DECIMAL_5
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_5
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT cast(key as decimal(6,3)) FROM DECIMAL_5
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_5
+#### A masked pattern was here ####
+NULL
+NULL
+0
+0
+100
+10
+1
+0.1
+0.01
+200
+20
+2
+0
+0.2
+0.02
+0.3
+0.33
+0.333
+-0.3
+-0.33
+-0.333
+1
+2
+3.14
+-1.12
+-1.12
+-1.122
+1.12
+1.122
+124
+125.2
+NULL
+3.14
+3.14
+3.14
+1
+NULL
+NULL
+PREHOOK: query: DROP TABLE DECIMAL_5
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@decimal_5
+PREHOOK: Output: default@decimal_5
+POSTHOOK: query: DROP TABLE DECIMAL_5
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@decimal_5
+POSTHOOK: Output: default@decimal_5
diff --git a/src/ql/src/test/results/clientpositive/decimal_6.q.out b/src/ql/src/test/results/clientpositive/decimal_6.q.out
new file mode 100644
index 0000000..d0e2f5a
--- /dev/null
+++ b/src/ql/src/test/results/clientpositive/decimal_6.q.out
@@ -0,0 +1,131 @@
+PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_1
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_1
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_2
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_2
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_3
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_3
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: CREATE TABLE DECIMAL_6_1(key decimal(10,5), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE DECIMAL_6_1(key decimal(10,5), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@DECIMAL_6_1
+PREHOOK: query: CREATE TABLE DECIMAL_6_2(key decimal(17,4), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE DECIMAL_6_2(key decimal(17,4), value int)
+ROW FORMAT DELIMITED
+   FIELDS TERMINATED BY ' '
+STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@DECIMAL_6_2
+PREHOOK: query: LOAD DATA LOCAL INPATH '../data/files/kv9.txt' INTO TABLE DECIMAL_6_1
+PREHOOK: type: LOAD
+PREHOOK: Output: default@decimal_6_1
+POSTHOOK: query: LOAD DATA LOCAL INPATH '../data/files/kv9.txt' INTO TABLE DECIMAL_6_1
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@decimal_6_1
+PREHOOK: query: LOAD DATA LOCAL INPATH '../data/files/kv9.txt' INTO TABLE DECIMAL_6_2
+PREHOOK: type: LOAD
+PREHOOK: Output: default@decimal_6_2
+POSTHOOK: query: LOAD DATA LOCAL INPATH '../data/files/kv9.txt' INTO TABLE DECIMAL_6_2
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@decimal_6_2
+PREHOOK: query: SELECT T.key from (
+  SELECT key, value from DECIMAL_6_1
+  UNION ALL
+  SELECT key, value from DECIMAL_6_2
+) T order by T.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@decimal_6_1
+PREHOOK: Input: default@decimal_6_2
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT T.key from (
+  SELECT key, value from DECIMAL_6_1
+  UNION ALL
+  SELECT key, value from DECIMAL_6_2
+) T order by T.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@decimal_6_1
+POSTHOOK: Input: default@decimal_6_2
+#### A masked pattern was here ####
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+-1234567890.1235
+-4400
+-4400
+-1255.49
+-1255.49
+-1.122
+-1.122
+-1.12
+-1.12
+-0.333
+-0.333
+-0.3
+-0.3
+0
+0
+0
+0
+0.333
+0.333
+1
+1
+1
+1
+1.12
+1.12
+1.122
+1.122
+2
+2
+3.14
+3.14
+3.14
+3.14
+3.14
+3.14
+10
+10
+10.7343
+10.73433
+124
+124
+125.2
+125.2
+23232.23435
+23232.2344
+2389432.2375
+2389432.2375
+1234567890.1235
+PREHOOK: query: CREATE TABLE DECIMAL_6_3 AS SELECT key + 5.5 AS k, value * 11 AS v from DECIMAL_6_1 ORDER BY v
+PREHOOK: type: CREATETABLE_AS_SELECT
+PREHOOK: Input: default@decimal_6_1
+POSTHOOK: query: CREATE TABLE DECIMAL_6_3 AS SELECT key + 5.5 AS k, value * 11 AS v from DECIMAL_6_1 ORDER BY v
+POSTHOOK: type: CREATETABLE_AS_SELECT
+POSTHOOK: Input: default@decimal_6_1
+POSTHOOK: Output: default@DECIMAL_6_3
+PREHOOK: query: desc DECIMAL_6_3
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc DECIMAL_6_3
+POSTHOOK: type: DESCTABLE
+k                   	decimal(65,30)      	None                
+v                   	int                 	None                
diff --git a/src/ql/src/test/results/clientpositive/decimal_join.q.out b/src/ql/src/test/results/clientpositive/decimal_join.q.out
index a876bbe..c47eefa 100644
--- a/src/ql/src/test/results/clientpositive/decimal_join.q.out
+++ b/src/ql/src/test/results/clientpositive/decimal_join.q.out
@@ -1,10 +1,10 @@
 PREHOOK: query: -- HIVE-5292 Join on decimal columns fails
 
-create table src_dec (key decimal, value string)
+create table src_dec (key decimal(3,0), value string)
 PREHOOK: type: CREATETABLE
 POSTHOOK: query: -- HIVE-5292 Join on decimal columns fails
 
-create table src_dec (key decimal, value string)
+create table src_dec (key decimal(3,0), value string)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@src_dec
 PREHOOK: query: load data local inpath '../../data/files/kv1.txt' into table src_dec
diff --git a/src/ql/src/test/results/clientpositive/decimal_precision.q.out b/src/ql/src/test/results/clientpositive/decimal_precision.q.out
index a24a419..8af799b 100644
--- a/src/ql/src/test/results/clientpositive/decimal_precision.q.out
+++ b/src/ql/src/test/results/clientpositive/decimal_precision.q.out
@@ -2,12 +2,12 @@ PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_PRECISION
 PREHOOK: type: DROPTABLE
 POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_PRECISION
 POSTHOOK: type: DROPTABLE
-PREHOOK: query: CREATE TABLE DECIMAL_PRECISION(dec decimal) 
+PREHOOK: query: CREATE TABLE DECIMAL_PRECISION(dec decimal(60,30)) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE
 PREHOOK: type: CREATETABLE
-POSTHOOK: query: CREATE TABLE DECIMAL_PRECISION(dec decimal) 
+POSTHOOK: query: CREATE TABLE DECIMAL_PRECISION(dec decimal(60,30)) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE
@@ -35,28 +35,42 @@ NULL
 NULL
 NULL
 NULL
--99999999999999999999999999999999999999
--999999999999999999999999999999999999
--99999999999999999999999999999999999
--0.0000000000000000000000000000000000001
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+0
+0
+0
+0
 0
-0.0000000000000000000000000000000000001
 0.123456789012345
-0.1234567890123456789012345678901234578
+0.12345678901234567890123456789
 1.234567890123456
-1.2345678901234567890123456789012345678
+1.234567890123456789012345678901
+1.234567890123456789012345678901
 12.34567890123456
-12.345678901234567890123456789012345678
+12.345678901234567890123456789012
+12.345678901234567890123456789012
 123.4567890123456
-123.45678901234567890123456789012345678
+123.456789012345678901234567890123
+123.456789012345678901234567890123
 1234.567890123456
-1234.5678901234567890123456789012345678
+1234.567890123456789012345678901235
+1234.567890123456789012345678901235
 12345.67890123456
-12345.678901234567890123456789012345678
+12345.678901234567890123456789012346
 123456.7890123456
-123456.78901234567890123456789012345678
+123456.789012345678901234567890123457
 1234567.890123456
-1234567.8901234567890123456789012345678
+1234567.890123456789012345678901234568
 12345678.90123456
 12345678.901234567890123456789012345678
 123456789.0123456
@@ -88,20 +102,6 @@ NULL
 1234567890123456789012345678.9012345678
 12345678901234567890123456789.012345678
 123456789012345678901234567890.12345678
-1234567890123456789012345678901.2345678
-12345678901234567890123456789012.345678
-123456789012345678901234567890123.45678
-1234567890123456789012345678901234.5678
-12345678901234567890123456789012345.678
-99999999999999999999999999999999999
-123456789012345678901234567890123456.78
-999999999999999999999999999999999999
-12345678901234567890123456789012345678
-12345678901234567890123456789012345678
-12345678901234567890123456789012345678
-12345678901234567890123456789012345678
-12345678901234567890123456789012345678
-99999999999999999999999999999999999999
 PREHOOK: query: SELECT dec, dec + 1, dec - 1 FROM DECIMAL_PRECISION ORDER BY dec
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_precision
@@ -118,28 +118,42 @@ NULL	NULL	NULL
 NULL	NULL	NULL
 NULL	NULL	NULL
 NULL	NULL	NULL
--99999999999999999999999999999999999999	-99999999999999999999999999999999999998	NULL
--999999999999999999999999999999999999	-999999999999999999999999999999999998	-1000000000000000000000000000000000000
--99999999999999999999999999999999999	-99999999999999999999999999999999998	-100000000000000000000000000000000000
--0.0000000000000000000000000000000000001	0.9999999999999999999999999999999999999	-1.0000000000000000000000000000000000001
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+0	1	-1
+0	1	-1
+0	1	-1
+0	1	-1
 0	1	-1
-0.0000000000000000000000000000000000001	1.0000000000000000000000000000000000001	-0.9999999999999999999999999999999999999
 0.123456789012345	1.123456789012345	-0.876543210987655
-0.1234567890123456789012345678901234578	1.1234567890123456789012345678901234578	-0.8765432109876543210987654321098765422
+0.12345678901234567890123456789	1.12345678901234567890123456789	-0.87654321098765432109876543211
 1.234567890123456	2.234567890123456	0.234567890123456
-1.2345678901234567890123456789012345678	2.2345678901234567890123456789012345678	0.2345678901234567890123456789012345678
+1.234567890123456789012345678901	2.234567890123456789012345678901	0.234567890123456789012345678901
+1.234567890123456789012345678901	2.234567890123456789012345678901	0.234567890123456789012345678901
 12.34567890123456	13.34567890123456	11.34567890123456
-12.345678901234567890123456789012345678	13.345678901234567890123456789012345678	11.345678901234567890123456789012345678
+12.345678901234567890123456789012	13.345678901234567890123456789012	11.345678901234567890123456789012
+12.345678901234567890123456789012	13.345678901234567890123456789012	11.345678901234567890123456789012
 123.4567890123456	124.4567890123456	122.4567890123456
-123.45678901234567890123456789012345678	124.45678901234567890123456789012345678	122.45678901234567890123456789012345678
+123.456789012345678901234567890123	124.456789012345678901234567890123	122.456789012345678901234567890123
+123.456789012345678901234567890123	124.456789012345678901234567890123	122.456789012345678901234567890123
 1234.567890123456	1235.567890123456	1233.567890123456
-1234.5678901234567890123456789012345678	1235.5678901234567890123456789012345678	1233.5678901234567890123456789012345678
+1234.567890123456789012345678901235	1235.567890123456789012345678901235	1233.567890123456789012345678901235
+1234.567890123456789012345678901235	1235.567890123456789012345678901235	1233.567890123456789012345678901235
 12345.67890123456	12346.67890123456	12344.67890123456
-12345.678901234567890123456789012345678	12346.678901234567890123456789012345678	12344.678901234567890123456789012345678
+12345.678901234567890123456789012346	12346.678901234567890123456789012346	12344.678901234567890123456789012346
 123456.7890123456	123457.7890123456	123455.7890123456
-123456.78901234567890123456789012345678	123457.78901234567890123456789012345678	123455.78901234567890123456789012345678
+123456.789012345678901234567890123457	123457.789012345678901234567890123457	123455.789012345678901234567890123457
 1234567.890123456	1234568.890123456	1234566.890123456
-1234567.8901234567890123456789012345678	1234568.8901234567890123456789012345678	1234566.8901234567890123456789012345678
+1234567.890123456789012345678901234568	1234568.890123456789012345678901234568	1234566.890123456789012345678901234568
 12345678.90123456	12345679.90123456	12345677.90123456
 12345678.901234567890123456789012345678	12345679.901234567890123456789012345678	12345677.901234567890123456789012345678
 123456789.0123456	123456790.0123456	123456788.0123456
@@ -171,20 +185,6 @@ NULL	NULL	NULL
 1234567890123456789012345678.9012345678	1234567890123456789012345679.9012345678	1234567890123456789012345677.9012345678
 12345678901234567890123456789.012345678	12345678901234567890123456790.012345678	12345678901234567890123456788.012345678
 123456789012345678901234567890.12345678	123456789012345678901234567891.12345678	123456789012345678901234567889.12345678
-1234567890123456789012345678901.2345678	1234567890123456789012345678902.2345678	1234567890123456789012345678900.2345678
-12345678901234567890123456789012.345678	12345678901234567890123456789013.345678	12345678901234567890123456789011.345678
-123456789012345678901234567890123.45678	123456789012345678901234567890124.45678	123456789012345678901234567890122.45678
-1234567890123456789012345678901234.5678	1234567890123456789012345678901235.5678	1234567890123456789012345678901233.5678
-12345678901234567890123456789012345.678	12345678901234567890123456789012346.678	12345678901234567890123456789012344.678
-99999999999999999999999999999999999	100000000000000000000000000000000000	99999999999999999999999999999999998
-123456789012345678901234567890123456.78	123456789012345678901234567890123457.78	123456789012345678901234567890123455.78
-999999999999999999999999999999999999	1000000000000000000000000000000000000	999999999999999999999999999999999998
-12345678901234567890123456789012345678	12345678901234567890123456789012345679	12345678901234567890123456789012345677
-12345678901234567890123456789012345678	12345678901234567890123456789012345679	12345678901234567890123456789012345677
-12345678901234567890123456789012345678	12345678901234567890123456789012345679	12345678901234567890123456789012345677
-12345678901234567890123456789012345678	12345678901234567890123456789012345679	12345678901234567890123456789012345677
-12345678901234567890123456789012345678	12345678901234567890123456789012345679	12345678901234567890123456789012345677
-99999999999999999999999999999999999999	NULL	99999999999999999999999999999999999998
 PREHOOK: query: SELECT dec, dec * 2, dec / 3  FROM DECIMAL_PRECISION ORDER BY dec
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_precision
@@ -201,28 +201,42 @@ NULL	NULL	NULL
 NULL	NULL	NULL
 NULL	NULL	NULL
 NULL	NULL	NULL
--99999999999999999999999999999999999999	NULL	-33333333333333333333333333333333333333
--999999999999999999999999999999999999	-1999999999999999999999999999999999998	-333333333333333333333333333333333333
--99999999999999999999999999999999999	-199999999999999999999999999999999998	-33333333333333333333333333333333333
--0.0000000000000000000000000000000000001	-0.0000000000000000000000000000000000002	0
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+NULL	NULL	NULL
+0	0	0
+0	0	0
+0	0	0
+0	0	0
 0	0	0
-0.0000000000000000000000000000000000001	0.0000000000000000000000000000000000002	0
 0.123456789012345	0.24691357802469	0.041152263004115
-0.1234567890123456789012345678901234578	0.2469135780246913578024691357802469156	0.0411522630041152263004115226300411526
+0.12345678901234567890123456789	0.24691357802469135780246913578	0.04115226300411522630041152263
 1.234567890123456	2.469135780246912	0.411522630041152
-1.2345678901234567890123456789012345678	2.4691357802469135780246913578024691356	0.4115226300411522630041152263004115226
+1.234567890123456789012345678901	2.469135780246913578024691357802	0.4115226300411522630041152263
+1.234567890123456789012345678901	2.469135780246913578024691357802	0.4115226300411522630041152263
 12.34567890123456	24.69135780246912	4.11522630041152
-12.345678901234567890123456789012345678	24.691357802469135780246913578024691356	4.115226300411522630041152263004115226
+12.345678901234567890123456789012	24.691357802469135780246913578024	4.115226300411522630041152263004
+12.345678901234567890123456789012	24.691357802469135780246913578024	4.115226300411522630041152263004
 123.4567890123456	246.9135780246912	41.1522630041152
-123.45678901234567890123456789012345678	246.91357802469135780246913578024691356	41.15226300411522630041152263004115226
+123.456789012345678901234567890123	246.913578024691357802469135780246	41.152263004115226300411522630041
+123.456789012345678901234567890123	246.913578024691357802469135780246	41.152263004115226300411522630041
 1234.567890123456	2469.135780246912	411.522630041152
-1234.5678901234567890123456789012345678	2469.1357802469135780246913578024691356	411.5226300411522630041152263004115226
+1234.567890123456789012345678901235	2469.13578024691357802469135780247	411.522630041152263004115226300412
+1234.567890123456789012345678901235	2469.13578024691357802469135780247	411.522630041152263004115226300412
 12345.67890123456	24691.35780246912	4115.22630041152
-12345.678901234567890123456789012345678	24691.357802469135780246913578024691356	4115.226300411522630041152263004115226
+12345.678901234567890123456789012346	24691.357802469135780246913578024692	4115.226300411522630041152263004115
 123456.7890123456	246913.5780246912	41152.2630041152
-123456.78901234567890123456789012345678	246913.57802469135780246913578024691356	41152.26300411522630041152263004115226
+123456.789012345678901234567890123457	246913.578024691357802469135780246914	41152.263004115226300411522630041152
 1234567.890123456	2469135.780246912	411522.630041152
-1234567.8901234567890123456789012345678	2469135.7802469135780246913578024691356	411522.6300411522630041152263004115226
+1234567.890123456789012345678901234568	2469135.780246913578024691357802469136	411522.630041152263004115226300411523
 12345678.90123456	24691357.80246912	4115226.30041152
 12345678.901234567890123456789012345678	24691357.802469135780246913578024691356	4115226.300411522630041152263004115226
 123456789.0123456	246913578.0246912	41152263.0041152
@@ -254,20 +268,6 @@ NULL	NULL	NULL
 1234567890123456789012345678.9012345678	2469135780246913578024691357.8024691356	411522630041152263004115226.3004115226
 12345678901234567890123456789.012345678	24691357802469135780246913578.024691356	4115226300411522630041152263.004115226
 123456789012345678901234567890.12345678	246913578024691357802469135780.24691356	41152263004115226300411522630.04115226
-1234567890123456789012345678901.2345678	2469135780246913578024691357802.4691356	411522630041152263004115226300.4115226
-12345678901234567890123456789012.345678	24691357802469135780246913578024.691356	4115226300411522630041152263004.115226
-123456789012345678901234567890123.45678	246913578024691357802469135780246.91356	41152263004115226300411522630041.15226
-1234567890123456789012345678901234.5678	2469135780246913578024691357802469.1356	411522630041152263004115226300411.5226
-12345678901234567890123456789012345.678	24691357802469135780246913578024691.356	4115226300411522630041152263004115.226
-99999999999999999999999999999999999	199999999999999999999999999999999998	33333333333333333333333333333333333
-123456789012345678901234567890123456.78	246913578024691357802469135780246913.56	41152263004115226300411522630041152.26
-999999999999999999999999999999999999	1999999999999999999999999999999999998	333333333333333333333333333333333333
-12345678901234567890123456789012345678	24691357802469135780246913578024691356	4115226300411522630041152263004115226
-12345678901234567890123456789012345678	24691357802469135780246913578024691356	4115226300411522630041152263004115226
-12345678901234567890123456789012345678	24691357802469135780246913578024691356	4115226300411522630041152263004115226
-12345678901234567890123456789012345678	24691357802469135780246913578024691356	4115226300411522630041152263004115226
-12345678901234567890123456789012345678	24691357802469135780246913578024691356	4115226300411522630041152263004115226
-99999999999999999999999999999999999999	NULL	33333333333333333333333333333333333333
 PREHOOK: query: SELECT dec, dec / 9 FROM DECIMAL_PRECISION ORDER BY dec
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_precision
@@ -284,43 +284,57 @@ NULL	NULL
 NULL	NULL
 NULL	NULL
 NULL	NULL
--99999999999999999999999999999999999999	-11111111111111111111111111111111111111
--999999999999999999999999999999999999	-111111111111111111111111111111111111
--99999999999999999999999999999999999	-11111111111111111111111111111111111
--0.0000000000000000000000000000000000001	0
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+0	0
+0	0
+0	0
 0	0
-0.0000000000000000000000000000000000001	0
-0.123456789012345	0.0137174210013716666666666666666666667
-0.1234567890123456789012345678901234578	0.0137174210013717421001371742100137175
-1.234567890123456	0.1371742100137173333333333333333333333
-1.2345678901234567890123456789012345678	0.1371742100137174210013717421001371742
-12.34567890123456	1.3717421001371733333333333333333333333
-12.345678901234567890123456789012345678	1.371742100137174210013717421001371742
-123.4567890123456	13.717421001371733333333333333333333333
-123.45678901234567890123456789012345678	13.71742100137174210013717421001371742
-1234.567890123456	137.17421001371733333333333333333333333
-1234.5678901234567890123456789012345678	137.1742100137174210013717421001371742
-12345.67890123456	1371.7421001371733333333333333333333333
-12345.678901234567890123456789012345678	1371.742100137174210013717421001371742
-123456.7890123456	13717.421001371733333333333333333333333
-123456.78901234567890123456789012345678	13717.42100137174210013717421001371742
-1234567.890123456	137174.21001371733333333333333333333333
-1234567.8901234567890123456789012345678	137174.2100137174210013717421001371742
-12345678.90123456	1371742.1001371733333333333333333333333
+0	0
+0.123456789012345	0.013717421001371666666666666667
+0.12345678901234567890123456789	0.01371742100137174210013717421
+1.234567890123456	0.137174210013717333333333333333
+1.234567890123456789012345678901	0.1371742100137174210013717421
+1.234567890123456789012345678901	0.1371742100137174210013717421
+12.34567890123456	1.371742100137173333333333333333
+12.345678901234567890123456789012	1.371742100137174210013717421001
+12.345678901234567890123456789012	1.371742100137174210013717421001
+123.4567890123456	13.717421001371733333333333333333
+123.456789012345678901234567890123	13.717421001371742100137174210014
+123.456789012345678901234567890123	13.717421001371742100137174210014
+1234.567890123456	137.174210013717333333333333333333
+1234.567890123456789012345678901235	137.174210013717421001371742100137
+1234.567890123456789012345678901235	137.174210013717421001371742100137
+12345.67890123456	1371.742100137173333333333333333333
+12345.678901234567890123456789012346	1371.742100137174210013717421001372
+123456.7890123456	13717.421001371733333333333333333333
+123456.789012345678901234567890123457	13717.421001371742100137174210013717
+1234567.890123456	137174.210013717333333333333333333333
+1234567.890123456789012345678901234568	137174.210013717421001371742100137174
+12345678.90123456	1371742.100137173333333333333333333333
 12345678.901234567890123456789012345678	1371742.100137174210013717421001371742
 123456789.0123456	13717421.001371733333333333333333333333
 123456789.01234567890123456789012345678	13717421.00137174210013717421001371742
-1234567890.123456	137174210.01371733333333333333333333333
+1234567890.123456	137174210.013717333333333333333333333333
 1234567890.1234567890123456789012345678	137174210.0137174210013717421001371742
-12345678901.23456	1371742100.1371733333333333333333333333
+12345678901.23456	1371742100.137173333333333333333333333333
 12345678901.234567890123456789012345678	1371742100.137174210013717421001371742
-123456789012.3456	13717421001.371733333333333333333333333
+123456789012.3456	13717421001.371733333333333333333333333333
 123456789012.34567890123456789012345678	13717421001.37174210013717421001371742
-1234567890123.456	137174210013.71733333333333333333333333
+1234567890123.456	137174210013.717333333333333333333333333333
 1234567890123.4567890123456789012345678	137174210013.7174210013717421001371742
-12345678901234.56	1371742100137.1733333333333333333333333
+12345678901234.56	1371742100137.173333333333333333333333333333
 12345678901234.567890123456789012345678	1371742100137.174210013717421001371742
-123456789012345.6	13717421001371.733333333333333333333333
+123456789012345.6	13717421001371.733333333333333333333333333333
 123456789012345.67890123456789012345678	13717421001371.74210013717421001371742
 1234567890123456.7890123456789012345678	137174210013717.4210013717421001371742
 12345678901234567.890123456789012345678	1371742100137174.210013717421001371742
@@ -337,20 +351,6 @@ NULL	NULL
 1234567890123456789012345678.9012345678	137174210013717421001371742.1001371742
 12345678901234567890123456789.012345678	1371742100137174210013717421.001371742
 123456789012345678901234567890.12345678	13717421001371742100137174210.01371742
-1234567890123456789012345678901.2345678	137174210013717421001371742100.1371742
-12345678901234567890123456789012.345678	1371742100137174210013717421001.371742
-123456789012345678901234567890123.45678	13717421001371742100137174210013.71742
-1234567890123456789012345678901234.5678	137174210013717421001371742100137.1742
-12345678901234567890123456789012345.678	1371742100137174210013717421001371.742
-99999999999999999999999999999999999	11111111111111111111111111111111111
-123456789012345678901234567890123456.78	13717421001371742100137174210013717.42
-999999999999999999999999999999999999	111111111111111111111111111111111111
-12345678901234567890123456789012345678	1371742100137174210013717421001371742
-12345678901234567890123456789012345678	1371742100137174210013717421001371742
-12345678901234567890123456789012345678	1371742100137174210013717421001371742
-12345678901234567890123456789012345678	1371742100137174210013717421001371742
-12345678901234567890123456789012345678	1371742100137174210013717421001371742
-99999999999999999999999999999999999999	11111111111111111111111111111111111111
 PREHOOK: query: SELECT dec, dec / 27 FROM DECIMAL_PRECISION ORDER BY dec
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_precision
@@ -367,73 +367,73 @@ NULL	NULL
 NULL	NULL
 NULL	NULL
 NULL	NULL
--99999999999999999999999999999999999999	-3703703703703703703703703703703703703.7
--999999999999999999999999999999999999	-37037037037037037037037037037037037
--99999999999999999999999999999999999	-3703703703703703703703703703703703.6667
--0.0000000000000000000000000000000000001	0
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+0	0
+0	0
 0	0
-0.0000000000000000000000000000000000001	0
-0.123456789012345	0.0045724736671238888888888888888888889
-0.1234567890123456789012345678901234578	0.0045724736671239140333790580700045725
-1.234567890123456	0.0457247366712391111111111111111111111
-1.2345678901234567890123456789012345678	0.0457247366712391403337905807000457247
-12.34567890123456	0.4572473667123911111111111111111111111
-12.345678901234567890123456789012345678	0.4572473667123914033379058070004572473
-123.4567890123456	4.5724736671239111111111111111111111111
-123.45678901234567890123456789012345678	4.5724736671239140333790580700045724733
-1234.567890123456	45.724736671239111111111111111111111111
-1234.5678901234567890123456789012345678	45.724736671239140333790580700045724733
-12345.67890123456	457.24736671239111111111111111111111111
-12345.678901234567890123456789012345678	457.24736671239140333790580700045724733
-123456.7890123456	4572.4736671239111111111111111111111111
-123456.78901234567890123456789012345678	4572.4736671239140333790580700045724733
-1234567.890123456	45724.736671239111111111111111111111111
-1234567.8901234567890123456789012345678	45724.736671239140333790580700045724733
-12345678.90123456	457247.36671239111111111111111111111111
-12345678.901234567890123456789012345678	457247.36671239140333790580700045724733
-123456789.0123456	4572473.6671239111111111111111111111111
-123456789.01234567890123456789012345678	4572473.6671239140333790580700045724733
+0	0
+0	0
+0.123456789012345	0.004572473667123888888888888889
+0.12345678901234567890123456789	0.00457247366712391403337905807
+1.234567890123456	0.045724736671239111111111111111
+1.234567890123456789012345678901	0.0457247366712391403337905807
+1.234567890123456789012345678901	0.0457247366712391403337905807
+12.34567890123456	0.457247366712391111111111111111
+12.345678901234567890123456789012	0.457247366712391403337905807
+12.345678901234567890123456789012	0.457247366712391403337905807
+123.4567890123456	4.572473667123911111111111111111
+123.456789012345678901234567890123	4.572473667123914033379058070005
+123.456789012345678901234567890123	4.572473667123914033379058070005
+1234.567890123456	45.724736671239111111111111111111
+1234.567890123456789012345678901235	45.724736671239140333790580700046
+1234.567890123456789012345678901235	45.724736671239140333790580700046
+12345.67890123456	457.247366712391111111111111111111
+12345.678901234567890123456789012346	457.247366712391403337905807000457
+123456.7890123456	4572.473667123911111111111111111111
+123456.789012345678901234567890123457	4572.473667123914033379058070004572
+1234567.890123456	45724.736671239111111111111111111111
+1234567.890123456789012345678901234568	45724.736671239140333790580700045725
+12345678.90123456	457247.366712391111111111111111111111
+12345678.901234567890123456789012345678	457247.366712391403337905807000457247
+123456789.0123456	4572473.667123911111111111111111111111
+123456789.01234567890123456789012345678	4572473.667123914033379058070004572473
 1234567890.123456	45724736.671239111111111111111111111111
 1234567890.1234567890123456789012345678	45724736.671239140333790580700045724733
-12345678901.23456	457247366.71239111111111111111111111111
-12345678901.234567890123456789012345678	457247366.71239140333790580700045724733
-123456789012.3456	4572473667.1239111111111111111111111111
-123456789012.34567890123456789012345678	4572473667.1239140333790580700045724733
-1234567890123.456	45724736671.239111111111111111111111111
-1234567890123.4567890123456789012345678	45724736671.239140333790580700045724733
-12345678901234.56	457247366712.39111111111111111111111111
-12345678901234.567890123456789012345678	457247366712.39140333790580700045724733
-123456789012345.6	4572473667123.9111111111111111111111111
-123456789012345.67890123456789012345678	4572473667123.9140333790580700045724733
-1234567890123456.7890123456789012345678	45724736671239.140333790580700045724733
-12345678901234567.890123456789012345678	457247366712391.40333790580700045724733
-123456789012345678.90123456789012345678	4572473667123914.0333790580700045724733
-1234567890123456789.0123456789012345678	45724736671239140.333790580700045724733
-12345678901234567890.123456789012345678	457247366712391403.33790580700045724733
-123456789012345678901.23456789012345678	4572473667123914033.3790580700045724733
-1234567890123456789012.3456789012345678	45724736671239140333.790580700045724733
-12345678901234567890123.456789012345678	457247366712391403337.90580700045724733
-123456789012345678901234.56789012345678	4572473667123914033379.0580700045724733
-1234567890123456789012345.6789012345678	45724736671239140333790.580700045724733
-12345678901234567890123456.789012345678	457247366712391403337905.80700045724733
-123456789012345678901234567.89012345678	4572473667123914033379058.0700045724733
-1234567890123456789012345678.9012345678	45724736671239140333790580.700045724733
-12345678901234567890123456789.012345678	457247366712391403337905807.00045724733
-123456789012345678901234567890.12345678	4572473667123914033379058070.0045724733
-1234567890123456789012345678901.2345678	45724736671239140333790580700.045724733
-12345678901234567890123456789012.345678	457247366712391403337905807000.45724733
-123456789012345678901234567890123.45678	4572473667123914033379058070004.5724733
-1234567890123456789012345678901234.5678	45724736671239140333790580700045.724733
-12345678901234567890123456789012345.678	457247366712391403337905807000457.24733
-99999999999999999999999999999999999	3703703703703703703703703703703703.6667
-123456789012345678901234567890123456.78	4572473667123914033379058070004572.4733
-999999999999999999999999999999999999	37037037037037037037037037037037037
-12345678901234567890123456789012345678	457247366712391403337905807000457247.33
-12345678901234567890123456789012345678	457247366712391403337905807000457247.33
-12345678901234567890123456789012345678	457247366712391403337905807000457247.33
-12345678901234567890123456789012345678	457247366712391403337905807000457247.33
-12345678901234567890123456789012345678	457247366712391403337905807000457247.33
-99999999999999999999999999999999999999	3703703703703703703703703703703703703.7
+12345678901.23456	457247366.712391111111111111111111111111
+12345678901.234567890123456789012345678	457247366.712391403337905807000457247333
+123456789012.3456	4572473667.123911111111111111111111111111
+123456789012.34567890123456789012345678	4572473667.123914033379058070004572473333
+1234567890123.456	45724736671.239111111111111111111111111111
+1234567890123.4567890123456789012345678	45724736671.239140333790580700045724733333
+12345678901234.56	457247366712.391111111111111111111111111111
+12345678901234.567890123456789012345678	457247366712.391403337905807000457247333333
+123456789012345.6	4572473667123.911111111111111111111111111111
+123456789012345.67890123456789012345678	4572473667123.914033379058070004572473333333
+1234567890123456.7890123456789012345678	45724736671239.140333790580700045724733333333
+12345678901234567.890123456789012345678	457247366712391.403337905807000457247333333333
+123456789012345678.90123456789012345678	4572473667123914.033379058070004572473333333333
+1234567890123456789.0123456789012345678	45724736671239140.333790580700045724733333333333
+12345678901234567890.123456789012345678	457247366712391403.337905807000457247333333333333
+123456789012345678901.23456789012345678	4572473667123914033.379058070004572473333333333333
+1234567890123456789012.3456789012345678	45724736671239140333.790580700045724733333333333333
+12345678901234567890123.456789012345678	457247366712391403337.905807000457247333333333333333
+123456789012345678901234.56789012345678	4572473667123914033379.058070004572473333333333333333
+1234567890123456789012345.6789012345678	45724736671239140333790.580700045724733333333333333333
+12345678901234567890123456.789012345678	457247366712391403337905.807000457247333333333333333333
+123456789012345678901234567.89012345678	4572473667123914033379058.070004572473333333333333333333
+1234567890123456789012345678.9012345678	45724736671239140333790580.700045724733333333333333333333
+12345678901234567890123456789.012345678	457247366712391403337905807.000457247333333333333333333333
+123456789012345678901234567890.12345678	4572473667123914033379058070.004572473333333333333333333333
 PREHOOK: query: SELECT dec, dec * dec FROM DECIMAL_PRECISION ORDER BY dec
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_precision
@@ -450,28 +450,42 @@ NULL	NULL
 NULL	NULL
 NULL	NULL
 NULL	NULL
--99999999999999999999999999999999999999	NULL
--999999999999999999999999999999999999	NULL
--99999999999999999999999999999999999	NULL
--0.0000000000000000000000000000000000001	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+0	0
+0	0
+0	0
+0	0
 0	0
-0.0000000000000000000000000000000000001	NULL
 0.123456789012345	0.015241578753238669120562399025
-0.1234567890123456789012345678901234578	NULL
+0.12345678901234567890123456789	NULL
 1.234567890123456	1.524157875323881726870921383936
-1.2345678901234567890123456789012345678	NULL
+1.234567890123456789012345678901	NULL
+1.234567890123456789012345678901	NULL
 12.34567890123456	152.4157875323881726870921383936
-12.345678901234567890123456789012345678	NULL
+12.345678901234567890123456789012	NULL
+12.345678901234567890123456789012	NULL
 123.4567890123456	15241.57875323881726870921383936
-123.45678901234567890123456789012345678	NULL
+123.456789012345678901234567890123	NULL
+123.456789012345678901234567890123	NULL
 1234.567890123456	1524157.875323881726870921383936
-1234.5678901234567890123456789012345678	NULL
+1234.567890123456789012345678901235	NULL
+1234.567890123456789012345678901235	NULL
 12345.67890123456	152415787.5323881726870921383936
-12345.678901234567890123456789012345678	NULL
+12345.678901234567890123456789012346	NULL
 123456.7890123456	15241578753.23881726870921383936
-123456.78901234567890123456789012345678	NULL
+123456.789012345678901234567890123457	NULL
 1234567.890123456	1524157875323.881726870921383936
-1234567.8901234567890123456789012345678	NULL
+1234567.890123456789012345678901234568	NULL
 12345678.90123456	152415787532388.1726870921383936
 12345678.901234567890123456789012345678	NULL
 123456789.0123456	15241578753238817.26870921383936
@@ -503,20 +517,6 @@ NULL	NULL
 1234567890123456789012345678.9012345678	NULL
 12345678901234567890123456789.012345678	NULL
 123456789012345678901234567890.12345678	NULL
-1234567890123456789012345678901.2345678	NULL
-12345678901234567890123456789012.345678	NULL
-123456789012345678901234567890123.45678	NULL
-1234567890123456789012345678901234.5678	NULL
-12345678901234567890123456789012345.678	NULL
-99999999999999999999999999999999999	NULL
-123456789012345678901234567890123456.78	NULL
-999999999999999999999999999999999999	NULL
-12345678901234567890123456789012345678	NULL
-12345678901234567890123456789012345678	NULL
-12345678901234567890123456789012345678	NULL
-12345678901234567890123456789012345678	NULL
-12345678901234567890123456789012345678	NULL
-99999999999999999999999999999999999999	NULL
 PREHOOK: query: SELECT avg(dec), sum(dec) FROM DECIMAL_PRECISION
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_precision
@@ -525,21 +525,21 @@ POSTHOOK: query: SELECT avg(dec), sum(dec) FROM DECIMAL_PRECISION
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_precision
 #### A masked pattern was here ####
-NULL	NULL
-PREHOOK: query: SELECT dec * cast('123456789012345678901234567890.123456789' as decimal) FROM DECIMAL_PRECISION LIMIT 1
+2449539464530670681706817092.661571403901626461618141287233	137174210013717558175581757189.047998618491081850615912085061
+PREHOOK: query: SELECT dec * cast('123456789012345678901234567890.123456789' as decimal(39,9)) FROM DECIMAL_PRECISION LIMIT 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_precision
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT dec * cast('123456789012345678901234567890.123456789' as decimal) FROM DECIMAL_PRECISION LIMIT 1
+POSTHOOK: query: SELECT dec * cast('123456789012345678901234567890.123456789' as decimal(39,9)) FROM DECIMAL_PRECISION LIMIT 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_precision
 #### A masked pattern was here ####
 NULL
-PREHOOK: query: SELECT * from DECIMAL_PRECISION WHERE dec > cast('123456789012345678901234567890.123456789' as decimal) LIMIT 1
+PREHOOK: query: SELECT * from DECIMAL_PRECISION WHERE dec > cast('123456789012345678901234567890.123456789' as decimal(39,9)) LIMIT 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_precision
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT * from DECIMAL_PRECISION WHERE dec > cast('123456789012345678901234567890.123456789' as decimal) LIMIT 1
+POSTHOOK: query: SELECT * from DECIMAL_PRECISION WHERE dec > cast('123456789012345678901234567890.123456789' as decimal(39,9)) LIMIT 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_precision
 #### A masked pattern was here ####
@@ -552,24 +552,24 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_precision
 #### A masked pattern was here ####
 NULL
-PREHOOK: query: SELECT MIN(cast('123456789012345678901234567890.123456789' as decimal)) FROM DECIMAL_PRECISION
+PREHOOK: query: SELECT MIN(cast('123456789012345678901234567890.123456789' as decimal(39,9))) FROM DECIMAL_PRECISION
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_precision
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT MIN(cast('123456789012345678901234567890.123456789' as decimal)) FROM DECIMAL_PRECISION
+POSTHOOK: query: SELECT MIN(cast('123456789012345678901234567890.123456789' as decimal(39,9))) FROM DECIMAL_PRECISION
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_precision
 #### A masked pattern was here ####
-NULL
-PREHOOK: query: SELECT COUNT(cast('123456789012345678901234567890.123456789' as decimal)) FROM DECIMAL_PRECISION
+123456789012345678901234567890.123456789
+PREHOOK: query: SELECT COUNT(cast('123456789012345678901234567890.123456789' as decimal(39,9))) FROM DECIMAL_PRECISION
 PREHOOK: type: QUERY
 PREHOOK: Input: default@decimal_precision
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT COUNT(cast('123456789012345678901234567890.123456789' as decimal)) FROM DECIMAL_PRECISION
+POSTHOOK: query: SELECT COUNT(cast('123456789012345678901234567890.123456789' as decimal(39,9))) FROM DECIMAL_PRECISION
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_precision
 #### A masked pattern was here ####
-0
+75
 PREHOOK: query: DROP TABLE DECIMAL_PRECISION
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@decimal_precision
diff --git a/src/ql/src/test/results/clientpositive/decimal_serde.q.out b/src/ql/src/test/results/clientpositive/decimal_serde.q.out
index ff07530..9ab0b5e 100644
--- a/src/ql/src/test/results/clientpositive/decimal_serde.q.out
+++ b/src/ql/src/test/results/clientpositive/decimal_serde.q.out
@@ -40,43 +40,43 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_text
 #### A masked pattern was here ####
 NULL	0
-NULL	0
--1234567890.123456789	-1234567890
+-1234567890	-1234567890
 -4400	4400
--1255.49	-1255
--1.122	-11
--1.12	-1
--1.12	-1
--0.333	0
--0.33	0
--0.3	0
-0	0
-0	0
-0.01	0
-0.02	0
-0.1	0
-0.2	0
-0.3	0
-0.33	0
-0.333	0
-0.9999999999999999999999999	1
+-1255	-1255
+-1	-11
+-1	-1
+-1	-1
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+1	1
+1	1
+1	1
 1	1
 1	1
-1.12	1
-1.122	1
 2	2
 2	2
-3.14	3
-3.14	3
-3.14	3
-3.14	4
+3	3
+3	3
+3	3
+3	4
 10	10
 20	20
 100	100
 124	124
-125.2	125
+125	125
 200	200
-1234567890.12345678	1234567890
+1234567890	1234567890
 PREHOOK: query: CREATE TABLE DECIMAL_RC
 STORED AS RCFile AS
 SELECT * FROM DECIMAL_TEXT
@@ -129,43 +129,43 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_sequence
 #### A masked pattern was here ####
 NULL	0
-NULL	0
--1234567890.123456789	-1234567890
+-1234567890	-1234567890
 -4400	4400
--1255.49	-1255
--1.122	-11
--1.12	-1
--1.12	-1
--0.333	0
--0.33	0
--0.3	0
-0	0
-0	0
-0.01	0
-0.02	0
-0.1	0
-0.2	0
-0.3	0
-0.33	0
-0.333	0
-0.9999999999999999999999999	1
+-1255	-1255
+-1	-11
+-1	-1
+-1	-1
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+0	0
+1	1
+1	1
+1	1
 1	1
 1	1
-1.12	1
-1.122	1
 2	2
 2	2
-3.14	3
-3.14	3
-3.14	3
-3.14	4
+3	3
+3	3
+3	3
+3	4
 10	10
 20	20
 100	100
 124	124
-125.2	125
+125	125
 200	200
-1234567890.12345678	1234567890
+1234567890	1234567890
 PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_TEXT
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@decimal_text
diff --git a/src/ql/src/test/results/clientpositive/decimal_udf.q.out b/src/ql/src/test/results/clientpositive/decimal_udf.q.out
index 3bfba1c..242cbbd 100644
--- a/src/ql/src/test/results/clientpositive/decimal_udf.q.out
+++ b/src/ql/src/test/results/clientpositive/decimal_udf.q.out
@@ -2,12 +2,12 @@ PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF
 PREHOOK: type: DROPTABLE
 POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF
 POSTHOOK: type: DROPTABLE
-PREHOOK: query: CREATE TABLE DECIMAL_UDF (key decimal, value int) 
+PREHOOK: query: CREATE TABLE DECIMAL_UDF (key decimal(65,30), value int) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE
 PREHOOK: type: CREATETABLE
-POSTHOOK: query: CREATE TABLE DECIMAL_UDF (key decimal, value int) 
+POSTHOOK: query: CREATE TABLE DECIMAL_UDF (key decimal(65,30), value int) 
 ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ' '
 STORED AS TEXTFILE
@@ -42,7 +42,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key + key)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -67,7 +67,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -8800
 NULL
-NULL
+0
 0
 200
 20
@@ -124,7 +124,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key + value)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -149,7 +149,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 0
 NULL
-NULL
+0
 0
 200
 20
@@ -206,7 +206,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key + (value / 2))
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -231,7 +231,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -2200
 NULL
-NULL
+0
 0
 150
 15
@@ -288,7 +288,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key + '1.0')
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -313,7 +313,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -4399
 NULL
-NULL
+1
 1
 101
 11
@@ -372,7 +372,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key - key)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -397,7 +397,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 0
 NULL
-NULL
+0
 0
 0
 0
@@ -454,7 +454,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key - value)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -479,7 +479,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -8800
 NULL
-NULL
+0
 0
 0
 0
@@ -536,7 +536,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key - (value / 2))
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -561,7 +561,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -6600
 NULL
-NULL
+0
 0
 50
 5
@@ -618,7 +618,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key - '1.0')
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -643,7 +643,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -4401
 NULL
-NULL
+-1
 -1
 99
 9
@@ -702,7 +702,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key * key)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -727,7 +727,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 19360000
 NULL
-NULL
+0
 0
 10000
 100
@@ -784,7 +784,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key * value)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -809,7 +809,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -19360000
 NULL
-NULL
+0
 0
 10000
 100
@@ -866,7 +866,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key * (value / 2))
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -891,7 +891,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -9680000
 NULL
-NULL
+0
 0
 5000
 50
@@ -948,7 +948,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key * '2.0')
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -973,7 +973,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -8800
 NULL
-NULL
+0
 0
 200
 20
@@ -1032,7 +1032,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key / 0)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               Limit
                 File Output Operator
@@ -1078,7 +1078,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key / null)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               Limit
                 File Output Operator
@@ -1128,7 +1128,7 @@ STAGE PLANS:
               Select Operator
                 expressions:
                       expr: (key / key)
-                      type: decimal
+                      type: decimal(65,30)
                 outputColumnNames: _col0
                 File Output Operator
                   compressed: false
@@ -1210,7 +1210,7 @@ STAGE PLANS:
               Select Operator
                 expressions:
                       expr: (key / value)
-                      type: decimal
+                      type: decimal(65,30)
                 outputColumnNames: _col0
                 File Output Operator
                   compressed: false
@@ -1242,7 +1242,7 @@ POSTHOOK: Input: default@decimal_udf
 1
 1
 1
-1.0466666666666666666666666666666666667
+1.046666666666666666666666666667
 1.12
 1.12
 0.102
@@ -1250,13 +1250,13 @@ POSTHOOK: Input: default@decimal_udf
 1.122
 1
 1.0016
-1.0003904382470119521912350597609561753
-1.0466666666666666666666666666666666667
-1.0466666666666666666666666666666666667
+1.000390438247011952191235059761
+1.046666666666666666666666666667
+1.046666666666666666666666666667
 0.785
 0.9999999999999999999999999
 1.0000000001
-1.0000000000999999927099999336609993963
+1.000000000099999992709999933661
 PREHOOK: query: EXPLAIN SELECT key / (value/2) FROM DECIMAL_UDF  WHERE value is not null and value <> 0
 PREHOOK: type: QUERY
 POSTHOOK: query: EXPLAIN SELECT key / (value/2) FROM DECIMAL_UDF  WHERE value is not null and value <> 0
@@ -1282,7 +1282,7 @@ STAGE PLANS:
               Select Operator
                 expressions:
                       expr: (key / (value / 2))
-                      type: decimal
+                      type: decimal(65,30)
                 outputColumnNames: _col0
                 File Output Operator
                   compressed: false
@@ -1314,7 +1314,7 @@ POSTHOOK: Input: default@decimal_udf
 2
 2
 2
-2.0933333333333333333333333333333333333
+2.093333333333333333333333333333
 2.24
 2.24
 0.204
@@ -1322,13 +1322,13 @@ POSTHOOK: Input: default@decimal_udf
 2.244
 2
 2.0032
-2.0007808764940239043824701195219123506
-2.0933333333333333333333333333333333333
-2.0933333333333333333333333333333333333
+2.000780876494023904382470119522
+2.093333333333333333333333333333
+2.093333333333333333333333333333
 1.57
 1.9999999999999999999999998
 2.0000000002
-2.0000000001999999854199998673219987926
+2.000000000199999985419999867322
 PREHOOK: query: EXPLAIN SELECT key / '2.0' FROM DECIMAL_UDF
 PREHOOK: type: QUERY
 POSTHOOK: query: EXPLAIN SELECT key / '2.0' FROM DECIMAL_UDF
@@ -1350,7 +1350,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (key / '2.0')
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -1375,7 +1375,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -2200
 NULL
-NULL
+0
 0
 50
 5
@@ -1434,7 +1434,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: abs(key)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -1459,7 +1459,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 4400
 NULL
-NULL
+0
 0
 100
 10
@@ -1521,7 +1521,7 @@ STAGE PLANS:
                     expr: value
                     type: int
                     expr: key
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: value, key
               Group By Operator
                 aggregations:
@@ -1545,11 +1545,11 @@ STAGE PLANS:
                   tag: -1
                   value expressions:
                         expr: _col1
-                        type: decimal
+                        type: decimal(65,30)
                         expr: _col2
                         type: bigint
                         expr: _col3
-                        type: struct<count:bigint,sum:decimal>
+                        type: struct<count:bigint,sum:decimal(65,30)>
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -1567,9 +1567,9 @@ STAGE PLANS:
                   expr: _col0
                   type: int
                   expr: (_col1 / _col2)
-                  type: decimal
+                  type: decimal(65,30)
                   expr: _col3
-                  type: decimal
+                  type: decimal(65,30)
             outputColumnNames: _col0, _col1, _col2
             File Output Operator
               compressed: false
@@ -1594,9 +1594,9 @@ STAGE PLANS:
                     expr: _col0
                     type: int
                     expr: _col1
-                    type: decimal
+                    type: decimal(65,30)
                     expr: _col2
-                    type: decimal
+                    type: decimal(65,30)
       Reduce Operator Tree:
         Extract
           File Output Operator
@@ -1624,7 +1624,7 @@ POSTHOOK: Input: default@decimal_udf
 -1255	-1255.49	-1255.49
 -11	-1.122	-1.122
 -1	-1.12	-1.12
-0	0.0275	0.0275
+0	0.025384615384615384615384615385	0.025384615384615384615384615385
 1	1.04839999999999999999999998	1.04839999999999999999999998
 2	2	2
 3	3.14	3.14
@@ -1660,7 +1660,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (- key)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -1685,7 +1685,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 4400
 NULL
-NULL
+0
 0
 -100
 -10
@@ -1744,7 +1744,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: key
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -1769,7 +1769,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -4400
 NULL
-NULL
+0
 0
 100
 10
@@ -1828,7 +1828,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: ceil(key)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -1853,7 +1853,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -4400
 NULL
-NULL
+0
 0
 100
 10
@@ -1912,7 +1912,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: floor(key)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -1937,7 +1937,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -4400
 NULL
-NULL
+0
 0
 100
 10
@@ -1996,7 +1996,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: round(key, 2)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -2021,7 +2021,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 -4400
 NULL
-NULL
+0
 0
 100
 10
@@ -2080,7 +2080,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: power(key, 2)
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -2105,7 +2105,7 @@ POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
 19360000
 NULL
-NULL
+0
 0
 10000
 100
@@ -2164,7 +2164,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: ((key + 1) % (key / 2))
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0
               File Output Operator
                 compressed: false
@@ -2250,7 +2250,7 @@ STAGE PLANS:
                     expr: value
                     type: int
                     expr: key
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: value, key
               Group By Operator
                 aggregations:
@@ -2321,7 +2321,7 @@ POSTHOOK: Input: default@decimal_udf
 -1255	0.0	0.0
 -11	0.0	0.0
 -1	0.0	0.0
-0	0.23469892060538614	0.055083583333333345
+0	0.22561046704494161	0.050900082840236685
 1	0.05928102563215321	0.0035142400000000066
 2	0.0	0.0
 3	0.0	0.0
@@ -2359,7 +2359,7 @@ STAGE PLANS:
                     expr: value
                     type: int
                     expr: key
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: value, key
               Group By Operator
                 aggregations:
@@ -2430,7 +2430,7 @@ POSTHOOK: Input: default@decimal_udf
 -1255	0.0	0.0
 -11	0.0	0.0
 -1	0.0	0.0
-0	0.24513502772590828	0.06009118181818183
+0	0.2348228191855647	0.055141756410256405
 1	0.06627820154470102	0.004392800000000008
 2	0.0	0.0
 3	0.0	0.0
@@ -2466,7 +2466,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: key
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: key
               Group By Operator
                 aggregations:
@@ -2513,7 +2513,7 @@ POSTHOOK: query: SELECT histogram_numeric(key, 3) FROM DECIMAL_UDF
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
-[{"x":-1.2345678901234567E9,"y":1.0},{"x":-148.75058823529412,"y":34.0},{"x":1.2345678901234567E9,"y":1.0}]
+[{"x":-1.2345678901234567E9,"y":1.0},{"x":-144.50057142857142,"y":35.0},{"x":1.2345678901234567E9,"y":1.0}]
 PREHOOK: query: -- min
 EXPLAIN SELECT MIN(key) FROM DECIMAL_UDF
 PREHOOK: type: QUERY
@@ -2537,7 +2537,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: key
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: key
               Group By Operator
                 aggregations:
@@ -2550,7 +2550,7 @@ STAGE PLANS:
                   tag: -1
                   value expressions:
                         expr: _col0
-                        type: decimal
+                        type: decimal(65,30)
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -2561,7 +2561,7 @@ STAGE PLANS:
           Select Operator
             expressions:
                   expr: _col0
-                  type: decimal
+                  type: decimal(65,30)
             outputColumnNames: _col0
             File Output Operator
               compressed: false
@@ -2608,7 +2608,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: key
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: key
               Group By Operator
                 aggregations:
@@ -2621,7 +2621,7 @@ STAGE PLANS:
                   tag: -1
                   value expressions:
                         expr: _col0
-                        type: decimal
+                        type: decimal(65,30)
       Reduce Operator Tree:
         Group By Operator
           aggregations:
@@ -2632,7 +2632,7 @@ STAGE PLANS:
           Select Operator
             expressions:
                   expr: _col0
-                  type: decimal
+                  type: decimal(65,30)
             outputColumnNames: _col0
             File Output Operator
               compressed: false
@@ -2679,7 +2679,7 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: key
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: key
               Group By Operator
                 aggregations:
@@ -2726,7 +2726,7 @@ POSTHOOK: query: SELECT COUNT(key) FROM DECIMAL_UDF
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@decimal_udf
 #### A masked pattern was here ####
-36
+37
 PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@decimal_udf
diff --git a/src/ql/src/test/results/clientpositive/literal_decimal.q.out b/src/ql/src/test/results/clientpositive/literal_decimal.q.out
index 1e93cd7..0ba5043 100644
--- a/src/ql/src/test/results/clientpositive/literal_decimal.q.out
+++ b/src/ql/src/test/results/clientpositive/literal_decimal.q.out
@@ -19,23 +19,23 @@ STAGE PLANS:
             Select Operator
               expressions:
                     expr: (- 1)
-                    type: decimal
+                    type: decimal(65,30)
                     expr: 0
-                    type: decimal
+                    type: decimal(65,30)
                     expr: 1
-                    type: decimal
+                    type: decimal(65,30)
                     expr: 3.14
-                    type: decimal
+                    type: decimal(65,30)
                     expr: (- 3.14)
-                    type: decimal
+                    type: decimal(65,30)
                     expr: 99999999999999999
-                    type: decimal
+                    type: decimal(65,30)
                     expr: 99999999999999999.9999999999999
-                    type: decimal
+                    type: decimal(65,30)
                     expr: 1E-99
-                    type: decimal
+                    type: decimal(65,30)
                     expr: 1E99
-                    type: decimal
+                    type: decimal(65,30)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
               Limit
                 File Output Operator
@@ -59,4 +59,4 @@ POSTHOOK: query: SELECT -1BD, 0BD, 1BD, 3.14BD, -3.14BD, 99999999999999999BD, 99
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
--1	0	1	3.14	-3.14	99999999999999999	99999999999999999.9999999999999	NULL	NULL
+-1	0	1	3.14	-3.14	99999999999999999	99999999999999999.9999999999999	0	NULL
diff --git a/src/ql/src/test/results/clientpositive/orc_predicate_pushdown.q.out b/src/ql/src/test/results/clientpositive/orc_predicate_pushdown.q.out
index e3f7e6f..b7a14b8 100644
--- a/src/ql/src/test/results/clientpositive/orc_predicate_pushdown.q.out
+++ b/src/ql/src/test/results/clientpositive/orc_predicate_pushdown.q.out
@@ -7,7 +7,7 @@ PREHOOK: query: CREATE TABLE orc_pred(t tinyint,
            bo boolean,
            s string,
            ts timestamp,
-           dec decimal,
+           dec decimal(4,2),
            bin binary)
 STORED AS ORC
 PREHOOK: type: CREATETABLE
@@ -20,7 +20,7 @@ POSTHOOK: query: CREATE TABLE orc_pred(t tinyint,
            bo boolean,
            s string,
            ts timestamp,
-           dec decimal,
+           dec decimal(4,2),
            bin binary)
 STORED AS ORC
 POSTHOOK: type: CREATETABLE
@@ -42,7 +42,7 @@ PREHOOK: query: CREATE TABLE staging(t tinyint,
            bo boolean,
            s string,
            ts timestamp,
-           dec decimal,
+           dec decimal(4,2),
            bin binary)
 ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
 STORED AS TEXTFILE
@@ -56,7 +56,7 @@ POSTHOOK: query: CREATE TABLE staging(t tinyint,
            bo boolean,
            s string,
            ts timestamp,
-           dec decimal,
+           dec decimal(4,2),
            bin binary)
 ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
 STORED AS TEXTFILE
@@ -80,7 +80,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -103,7 +103,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -123,7 +123,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -139,7 +139,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -210,7 +210,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -299,7 +299,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -325,7 +325,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -347,7 +347,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -428,7 +428,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -518,7 +518,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -547,7 +547,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -572,7 +572,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -646,7 +646,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -729,7 +729,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -761,7 +761,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -789,7 +789,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -867,7 +867,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -960,7 +960,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -1000,7 +1000,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -1036,7 +1036,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -1129,7 +1129,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -1233,7 +1233,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -1275,7 +1275,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -1313,7 +1313,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
@@ -1442,7 +1442,7 @@ POSTHOOK: Lineage: orc_pred.b SIMPLE [(staging)staging.FieldSchema(name:b, type:
 POSTHOOK: Lineage: orc_pred.bin SIMPLE [(staging)staging.FieldSchema(name:bin, type:binary, comment:null), ]
 POSTHOOK: Lineage: orc_pred.bo SIMPLE [(staging)staging.FieldSchema(name:bo, type:boolean, comment:null), ]
 POSTHOOK: Lineage: orc_pred.d SIMPLE [(staging)staging.FieldSchema(name:d, type:double, comment:null), ]
-POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal, comment:null), ]
+POSTHOOK: Lineage: orc_pred.dec SIMPLE [(staging)staging.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
 POSTHOOK: Lineage: orc_pred.f SIMPLE [(staging)staging.FieldSchema(name:f, type:float, comment:null), ]
 POSTHOOK: Lineage: orc_pred.i SIMPLE [(staging)staging.FieldSchema(name:i, type:int, comment:null), ]
 POSTHOOK: Lineage: orc_pred.s SIMPLE [(staging)staging.FieldSchema(name:s, type:string, comment:null), ]
diff --git a/src/ql/src/test/results/clientpositive/ptf_decimal.q.out b/src/ql/src/test/results/clientpositive/ptf_decimal.q.out
index cda685f..490ef39 100644
--- a/src/ql/src/test/results/clientpositive/ptf_decimal.q.out
+++ b/src/ql/src/test/results/clientpositive/ptf_decimal.q.out
@@ -11,7 +11,7 @@ CREATE TABLE part(
     p_type STRING,
     p_size INT,
     p_container STRING,
-    p_retailprice DECIMAL,
+    p_retailprice DECIMAL(6,2),
     p_comment STRING
 )
 PREHOOK: type: CREATETABLE
@@ -24,7 +24,7 @@ CREATE TABLE part(
     p_type STRING,
     p_size INT,
     p_container STRING,
-    p_retailprice DECIMAL,
+    p_retailprice DECIMAL(6,2),
     p_comment STRING
 )
 POSTHOOK: type: CREATETABLE
diff --git a/src/ql/src/test/results/clientpositive/serde_regex.q.out b/src/ql/src/test/results/clientpositive/serde_regex.q.out
index 7b47ccc..64207f1 100644
--- a/src/ql/src/test/results/clientpositive/serde_regex.q.out
+++ b/src/ql/src/test/results/clientpositive/serde_regex.q.out
@@ -129,7 +129,7 @@ POSTHOOK: Input: default@serde_regex
 POSTHOOK: Output: default@serde_regex
 PREHOOK: query: EXPLAIN
 CREATE TABLE serde_regex1(
-  key decimal,
+  key decimal(65,30),
   value int)
 ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'
 WITH SERDEPROPERTIES (
@@ -139,7 +139,7 @@ STORED AS TEXTFILE
 PREHOOK: type: CREATETABLE
 POSTHOOK: query: EXPLAIN
 CREATE TABLE serde_regex1(
-  key decimal,
+  key decimal(65,30),
   value int)
 ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'
 WITH SERDEPROPERTIES (
@@ -148,7 +148,7 @@ WITH SERDEPROPERTIES (
 STORED AS TEXTFILE
 POSTHOOK: type: CREATETABLE
 ABSTRACT SYNTAX TREE:
-  (TOK_CREATETABLE (TOK_TABNAME serde_regex1) TOK_LIKETABLE (TOK_TABCOLLIST (TOK_TABCOL key TOK_DECIMAL) (TOK_TABCOL value TOK_INT)) (TOK_TABLESERIALIZER (TOK_SERDENAME 'org.apache.hadoop.hive.serde2.RegexSerDe' (TOK_TABLEPROPERTIES (TOK_TABLEPROPLIST (TOK_TABLEPROPERTY "input.regex" "([^ ]*) ([^ ]*)"))))) TOK_TBLTEXTFILE)
+  (TOK_CREATETABLE (TOK_TABNAME serde_regex1) TOK_LIKETABLE (TOK_TABCOLLIST (TOK_TABCOL key (TOK_DECIMAL 65 30)) (TOK_TABCOL value TOK_INT)) (TOK_TABLESERIALIZER (TOK_SERDENAME 'org.apache.hadoop.hive.serde2.RegexSerDe' (TOK_TABLEPROPERTIES (TOK_TABLEPROPLIST (TOK_TABLEPROPERTY "input.regex" "([^ ]*) ([^ ]*)"))))) TOK_TBLTEXTFILE)
 
 STAGE DEPENDENCIES:
   Stage-0 is a root stage
@@ -157,7 +157,7 @@ STAGE PLANS:
   Stage: Stage-0
       Create Table Operator:
         Create Table
-          columns: key decimal, value int
+          columns: key decimal(65,30), value int
           if not exists: false
           input format: org.apache.hadoop.mapred.TextInputFormat
           # buckets: -1
@@ -170,7 +170,7 @@ STAGE PLANS:
 
 
 PREHOOK: query: CREATE TABLE serde_regex1(
-  key decimal,
+  key decimal(65,30),
   value int)
 ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'
 WITH SERDEPROPERTIES (
@@ -179,7 +179,7 @@ WITH SERDEPROPERTIES (
 STORED AS TEXTFILE
 PREHOOK: type: CREATETABLE
 POSTHOOK: query: CREATE TABLE serde_regex1(
-  key decimal,
+  key decimal(65,30),
   value int)
 ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'
 WITH SERDEPROPERTIES (
@@ -203,7 +203,6 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@serde_regex1
 #### A masked pattern was here ####
 NULL	0
-NULL	0
 -1234567890.123456789	-1234567890
 -4400	4400
 -1255.49	-1255
@@ -215,6 +214,7 @@ NULL	0
 -0.3	0
 0	0
 0	0
+0	0
 0.01	0
 0.02	0
 0.1	0
diff --git a/src/ql/src/test/results/clientpositive/udf7.q.out b/src/ql/src/test/results/clientpositive/udf7.q.out
index 5f76d37..c868453 100644
--- a/src/ql/src/test/results/clientpositive/udf7.q.out
+++ b/src/ql/src/test/results/clientpositive/udf7.q.out
@@ -99,12 +99,12 @@ STAGE PLANS:
                     type: double
                     expr: power((- 1), 2)
                     type: double
-                    expr: power(CAST( 1 AS DECIMAL), 0)
-                    type: decimal
-                    expr: power(CAST( 2 AS DECIMAL), 3)
-                    type: decimal
-                    expr: pow(CAST( 2 AS DECIMAL), 3)
-                    type: decimal
+                    expr: power(CAST( 1 AS decimal(10,0)), 0)
+                    type: decimal(65,30)
+                    expr: power(CAST( 2 AS decimal(10,0)), 3)
+                    type: decimal(65,30)
+                    expr: pow(CAST( 2 AS decimal(10,0)), 3)
+                    type: decimal(65,30)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24, _col25, _col26, _col27
               File Output Operator
                 compressed: false
diff --git a/src/ql/src/test/results/clientpositive/udf_pmod.q.out b/src/ql/src/test/results/clientpositive/udf_pmod.q.out
index cc06f1d..f28caa6 100644
--- a/src/ql/src/test/results/clientpositive/udf_pmod.q.out
+++ b/src/ql/src/test/results/clientpositive/udf_pmod.q.out
@@ -86,11 +86,11 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
 6.890000000000011	51.699999999999996	18.090000000000003
-PREHOOK: query: SELECT pmod(CAST(-100.91 AS DECIMAL),CAST(9.8 AS DECIMAL)), pmod(CAST(-50.1 AS DECIMAL),CAST(101.8 AS DECIMAL)), pmod(CAST(-100.91 AS DECIMAL),CAST(29.75 AS DECIMAL)) FROM src LIMIT 1
+PREHOOK: query: SELECT pmod(CAST(-100.91 AS DECIMAL(5,2)),CAST(9.8 AS DECIMAL(2,1))), pmod(CAST(-50.1 AS DECIMAL(3,1)),CAST(101.8 AS DECIMAL(4,1))), pmod(CAST(-100.91 AS DECIMAL(5,2)),CAST(29.75 AS DECIMAL(4,2))) FROM src LIMIT 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT pmod(CAST(-100.91 AS DECIMAL),CAST(9.8 AS DECIMAL)), pmod(CAST(-50.1 AS DECIMAL),CAST(101.8 AS DECIMAL)), pmod(CAST(-100.91 AS DECIMAL),CAST(29.75 AS DECIMAL)) FROM src LIMIT 1
+POSTHOOK: query: SELECT pmod(CAST(-100.91 AS DECIMAL(5,2)),CAST(9.8 AS DECIMAL(2,1))), pmod(CAST(-50.1 AS DECIMAL(3,1)),CAST(101.8 AS DECIMAL(4,1))), pmod(CAST(-100.91 AS DECIMAL(5,2)),CAST(29.75 AS DECIMAL(4,2))) FROM src LIMIT 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
diff --git a/src/ql/src/test/results/clientpositive/udf_to_double.q.out b/src/ql/src/test/results/clientpositive/udf_to_double.q.out
index 28e5089..d5280d1 100644
--- a/src/ql/src/test/results/clientpositive/udf_to_double.q.out
+++ b/src/ql/src/test/results/clientpositive/udf_to_double.q.out
@@ -63,11 +63,11 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
 -3.140000104904175
-PREHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL) AS DOUBLE) FROM src LIMIT 1
+PREHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL(3,2)) AS DOUBLE) FROM src LIMIT 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL) AS DOUBLE) FROM src LIMIT 1
+POSTHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL(3,2)) AS DOUBLE) FROM src LIMIT 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
diff --git a/src/ql/src/test/results/clientpositive/udf_to_float.q.out b/src/ql/src/test/results/clientpositive/udf_to_float.q.out
index b96383b..71b5b79 100644
--- a/src/ql/src/test/results/clientpositive/udf_to_float.q.out
+++ b/src/ql/src/test/results/clientpositive/udf_to_float.q.out
@@ -63,11 +63,11 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
 -3.14
-PREHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL) AS FLOAT) FROM src LIMIT 1
+PREHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL(3,2)) AS FLOAT) FROM src LIMIT 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL) AS FLOAT) FROM src LIMIT 1
+POSTHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL(3,2)) AS FLOAT) FROM src LIMIT 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
diff --git a/src/ql/src/test/results/clientpositive/udf_to_string.q.out b/src/ql/src/test/results/clientpositive/udf_to_string.q.out
index 664ff5c..c164e69 100644
--- a/src/ql/src/test/results/clientpositive/udf_to_string.q.out
+++ b/src/ql/src/test/results/clientpositive/udf_to_string.q.out
@@ -72,11 +72,11 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
 -3.14
-PREHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL) AS STRING) FROM src LIMIT 1
+PREHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL(3,2)) AS STRING) FROM src LIMIT 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL) AS STRING) FROM src LIMIT 1
+POSTHOOK: query: SELECT CAST(CAST(-3.14 AS DECIMAL(3,2)) AS STRING) FROM src LIMIT 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
diff --git a/src/ql/src/test/results/clientpositive/windowing_expressions.q.out b/src/ql/src/test/results/clientpositive/windowing_expressions.q.out
index 9204c9f..ce3d943 100644
--- a/src/ql/src/test/results/clientpositive/windowing_expressions.q.out
+++ b/src/ql/src/test/results/clientpositive/windowing_expressions.q.out
@@ -49,7 +49,7 @@ PREHOOK: query: create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|'
@@ -64,7 +64,7 @@ POSTHOOK: query: create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|'
@@ -682,10 +682,10 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@over10k
 POSTHOOK: Output: default@t1
 POSTHOOK: Output: default@t2
-POSTHOOK: Lineage: t1.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t1.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t2.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t2.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t1.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t1.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t2.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t2.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
 PREHOOK: query: select * from t1 limit 3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
@@ -694,10 +694,10 @@ POSTHOOK: query: select * from t1 limit 3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 #### A masked pattern was here ####
-POSTHOOK: Lineage: t1.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t1.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t2.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t2.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t1.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t1.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t2.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t2.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
 65542	rachel thompson
 131088	oscar brown
 262258	wendy steinbeck
@@ -709,10 +709,10 @@ POSTHOOK: query: select * from t2 limit 3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 #### A masked pattern was here ####
-POSTHOOK: Lineage: t1.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t1.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t2.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t2.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t1.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t1.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t2.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t2.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
 65542	rachel thompson
 131088	oscar brown
 262258	wendy steinbeck
@@ -732,10 +732,10 @@ limit 11
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@part
 #### A masked pattern was here ####
-POSTHOOK: Lineage: t1.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t1.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t2.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
-POSTHOOK: Lineage: t2.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal, comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t1.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t1.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t2.a1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
+POSTHOOK: Lineage: t2.b1 SCRIPT [(over10k)over10k.FieldSchema(name:t, type:tinyint, comment:null), (over10k)over10k.FieldSchema(name:si, type:smallint, comment:null), (over10k)over10k.FieldSchema(name:i, type:int, comment:null), (over10k)over10k.FieldSchema(name:b, type:bigint, comment:null), (over10k)over10k.FieldSchema(name:f, type:float, comment:null), (over10k)over10k.FieldSchema(name:d, type:double, comment:null), (over10k)over10k.FieldSchema(name:bo, type:boolean, comment:null), (over10k)over10k.FieldSchema(name:s, type:string, comment:null), (over10k)over10k.FieldSchema(name:ts, type:timestamp, comment:null), (over10k)over10k.FieldSchema(name:dec, type:decimal(4,2), comment:null), (over10k)over10k.FieldSchema(name:bin, type:binary, comment:null), (over10k)over10k.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), (over10k)over10k.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
 Manufacturer#1	1173.15	2	true
 Manufacturer#1	1173.15	2	true
 Manufacturer#1	1414.42	28	true
diff --git a/src/ql/src/test/results/clientpositive/windowing_multipartitioning.q.out b/src/ql/src/test/results/clientpositive/windowing_multipartitioning.q.out
index 8bb1861..6472921 100644
--- a/src/ql/src/test/results/clientpositive/windowing_multipartitioning.q.out
+++ b/src/ql/src/test/results/clientpositive/windowing_multipartitioning.q.out
@@ -12,7 +12,7 @@ PREHOOK: query: create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|'
@@ -27,7 +27,7 @@ POSTHOOK: query: create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|'
diff --git a/src/ql/src/test/results/clientpositive/windowing_navfn.q.out b/src/ql/src/test/results/clientpositive/windowing_navfn.q.out
index aa0c405..4fff8fe 100644
--- a/src/ql/src/test/results/clientpositive/windowing_navfn.q.out
+++ b/src/ql/src/test/results/clientpositive/windowing_navfn.q.out
@@ -11,8 +11,8 @@ PREHOOK: query: create table over10k(
            d double,
            bo boolean,
            s string,
-	   ts timestamp, 
-           dec decimal,  
+           ts timestamp, 
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|'
@@ -26,8 +26,8 @@ POSTHOOK: query: create table over10k(
            d double,
            bo boolean,
            s string,
-	   ts timestamp, 
-           dec decimal,  
+           ts timestamp, 
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|'
diff --git a/src/ql/src/test/results/clientpositive/windowing_ntile.q.out b/src/ql/src/test/results/clientpositive/windowing_ntile.q.out
index fd6f6b0..7d95db7 100644
--- a/src/ql/src/test/results/clientpositive/windowing_ntile.q.out
+++ b/src/ql/src/test/results/clientpositive/windowing_ntile.q.out
@@ -12,7 +12,7 @@ PREHOOK: query: create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|'
@@ -27,7 +27,7 @@ POSTHOOK: query: create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|'
diff --git a/src/ql/src/test/results/clientpositive/windowing_rank.q.out b/src/ql/src/test/results/clientpositive/windowing_rank.q.out
index 39cb4b8..ac11897 100644
--- a/src/ql/src/test/results/clientpositive/windowing_rank.q.out
+++ b/src/ql/src/test/results/clientpositive/windowing_rank.q.out
@@ -12,7 +12,7 @@ PREHOOK: query: create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|'
@@ -27,7 +27,7 @@ POSTHOOK: query: create table over10k(
            bo boolean,
            s string,
 	   ts timestamp, 
-           dec decimal,  
+           dec decimal(4,2),  
            bin binary)
        row format delimited
        fields terminated by '|'
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java
index f2ddc73..6726973 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java
@@ -37,6 +37,7 @@
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.AbstractPrimitiveJavaObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
@@ -231,7 +232,7 @@ public Object deserialize(Writable blob) throws SerDeException {
           Date d;
           d = Date.valueOf(t);
           row.set(c, d);
-        } else if (typeName.equals(serdeConstants.DECIMAL_TYPE_NAME)) {
+        } else if (typeInfo instanceof DecimalTypeInfo) {
           HiveDecimal bd = HiveDecimal.create(t);
           row.set(c, bd);
         } else if (typeInfo instanceof VarcharTypeInfo) {
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/io/HiveDecimalWritable.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/io/HiveDecimalWritable.java
index acab539..008fda3 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/io/HiveDecimalWritable.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/io/HiveDecimalWritable.java
@@ -28,6 +28,7 @@
 import org.apache.hadoop.hive.serde2.ByteStream.Output;
 import org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils;
 import org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils.VInt;
+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;
 import org.apache.hadoop.io.WritableComparable;
 import org.apache.hadoop.io.WritableUtils;
 
@@ -84,6 +85,18 @@ public HiveDecimal getHiveDecimal() {
     return HiveDecimal.create(new BigInteger(internalStorage), scale);
   }
 
+  /**
+   * Get a HiveDecimal instance from the writable and constraint it with maximum precision/scale.
+   *
+   * @param maxPrecision maximum precision
+   * @param maxScale maximum scale
+   * @return HiveDecimal instance
+   */
+  public HiveDecimal getHiveDecimal(int maxPrecision, int maxScale) {
+     return HiveDecimalUtils.enforcePrecisionScale(HiveDecimal.create(new BigInteger(internalStorage), scale),
+         maxPrecision, maxScale);
+  }
+
   @Override
   public void readFields(DataInput in) throws IOException {
     scale = WritableUtils.readVInt(in);
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveDecimal.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveDecimal.java
index 3be28dd..78cc381 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveDecimal.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveDecimal.java
@@ -24,18 +24,32 @@
 import org.apache.hadoop.hive.common.type.HiveDecimal;
 import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
 import org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyHiveDecimalObjectInspector;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;
 import org.apache.hadoop.io.Text;
 
 public class LazyHiveDecimal extends LazyPrimitive<LazyHiveDecimalObjectInspector, HiveDecimalWritable> {
   static final private Log LOG = LogFactory.getLog(LazyHiveDecimal.class);
 
+  private final int precision;
+  private final int scale;
+
   public LazyHiveDecimal(LazyHiveDecimalObjectInspector oi) {
     super(oi);
+    DecimalTypeInfo typeInfo = (DecimalTypeInfo)oi.getTypeInfo();
+    if (typeInfo == null) {
+      throw new RuntimeException("Decimal type used without type params");
+    }
+
+    precision = typeInfo.precision();
+    scale = typeInfo.scale();
     data = new HiveDecimalWritable();
   }
 
   public LazyHiveDecimal(LazyHiveDecimal copy) {
     super(copy);
+    precision = copy.precision;
+    scale = copy.scale;
     data = new HiveDecimalWritable(copy.data);
   }
 
@@ -59,6 +73,7 @@ public void init(ByteArrayRef bytes, int start, int length) {
     }
 
     HiveDecimal dec = HiveDecimal.create(byteData);
+    dec = enforcePrecisionScale(dec);
     if (dec != null) {
       data.set(dec);
       isNull = false;
@@ -69,8 +84,13 @@ public void init(ByteArrayRef bytes, int start, int length) {
     }
   }
 
+  private HiveDecimal enforcePrecisionScale(HiveDecimal dec) {
+    return HiveDecimalUtils.enforcePrecisionScale(dec, precision, scale);
+  }
+
   @Override
   public HiveDecimalWritable getWritableObject() {
     return data;
   }
+
 }
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveDecimalObjectInspector.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveDecimalObjectInspector.java
index 5618d0c..55ab3e6 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveDecimalObjectInspector.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveDecimalObjectInspector.java
@@ -22,14 +22,14 @@
 import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
 import org.apache.hadoop.hive.serde2.lazy.LazyHiveDecimal;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.HiveDecimalObjectInspector;
-import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;
 
-public class LazyHiveDecimalObjectInspector
-    extends AbstractPrimitiveLazyObjectInspector<HiveDecimalWritable>
-    implements HiveDecimalObjectInspector {
+public class LazyHiveDecimalObjectInspector extends AbstractPrimitiveLazyObjectInspector<HiveDecimalWritable>
+implements HiveDecimalObjectInspector {
 
-  protected LazyHiveDecimalObjectInspector() {
-    super(TypeInfoFactory.decimalTypeInfo);
+  protected LazyHiveDecimalObjectInspector(DecimalTypeInfo typeInfo) {
+    super(typeInfo);
   }
 
   @Override
@@ -39,7 +39,12 @@ public Object copyObject(Object o) {
 
   @Override
   public HiveDecimal getPrimitiveJavaObject(Object o) {
-    return o == null ? null : ((LazyHiveDecimal) o).getWritableObject().getHiveDecimal();
+    if (o == null) {
+      return null;
+    }
+
+    HiveDecimal dec = ((LazyHiveDecimal)o).getWritableObject().getHiveDecimal();
+    return HiveDecimalUtils.enforcePrecisionScale(dec, (DecimalTypeInfo) typeInfo);
   }
 
 }
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java
index 6f03979..7cf4e2f 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java
@@ -24,6 +24,7 @@
 
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 import org.apache.hadoop.hive.serde2.typeinfo.VarcharTypeInfo;
@@ -64,8 +65,6 @@
       new LazyTimestampObjectInspector();
   public static final LazyBinaryObjectInspector LAZY_BINARY_OBJECT_INSPECTOR =
       new LazyBinaryObjectInspector();
-  public static final LazyHiveDecimalObjectInspector LAZY_BIG_DECIMAL_OBJECT_INSPECTOR =
-      new LazyHiveDecimalObjectInspector();
 
   private LazyPrimitiveObjectInspectorFactory() {
     // prevent instantiation
@@ -98,8 +97,6 @@ private LazyPrimitiveObjectInspectorFactory() {
         LAZY_DATE_OBJECT_INSPECTOR);
     cachedPrimitiveLazyObjectInspectors.put(TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.TIMESTAMP_TYPE_NAME),
         LAZY_TIMESTAMP_OBJECT_INSPECTOR);
-    cachedPrimitiveLazyObjectInspectors.put(TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DECIMAL_TYPE_NAME),
-        LAZY_BIG_DECIMAL_OBJECT_INSPECTOR);
     cachedPrimitiveLazyObjectInspectors.put(TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BINARY_TYPE_NAME),
         LAZY_BINARY_OBJECT_INSPECTOR);
   }
@@ -128,6 +125,9 @@ private LazyPrimitiveObjectInspectorFactory() {
     case VARCHAR:
       poi = new LazyHiveVarcharObjectInspector((VarcharTypeInfo)typeInfo);
       break;
+    case DECIMAL:
+      poi = new LazyHiveDecimalObjectInspector((DecimalTypeInfo)typeInfo);
+      break;
     default:
       throw new RuntimeException(
           "Primitve type " + typeInfo.getPrimitiveCategory() + " should not take parameters");
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveDecimal.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveDecimal.java
index a1d0e4c..e56e2ca 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveDecimal.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveDecimal.java
@@ -17,15 +17,23 @@
  */
 package org.apache.hadoop.hive.serde2.lazybinary;
 
+import org.apache.hadoop.hive.common.type.HiveDecimal;
 import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
 import org.apache.hadoop.hive.serde2.lazy.ByteArrayRef;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableHiveDecimalObjectInspector;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
 
 public class LazyBinaryHiveDecimal extends
     LazyBinaryPrimitive<WritableHiveDecimalObjectInspector, HiveDecimalWritable> {
+  private int precision;
+  private int scale;
 
   LazyBinaryHiveDecimal(WritableHiveDecimalObjectInspector oi) {
     super(oi);
+
+    DecimalTypeInfo typeInfo = (DecimalTypeInfo) oi.getTypeInfo();
+    this.precision = typeInfo.precision();
+    this.scale = typeInfo.scale();
     data = new HiveDecimalWritable();
   }
 
@@ -37,6 +45,8 @@
   @Override
   public void init(ByteArrayRef bytes, int start, int length) {
     data.setFromBytes(bytes.getData(), start, length);
+    HiveDecimal dec = data.getHiveDecimal(precision, scale);
+    data = dec == null ? null : new HiveDecimalWritable(dec);
   }
 
 }
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java
index ab4eb56..847bd11 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java
@@ -18,8 +18,6 @@
 
 package org.apache.hadoop.hive.serde2.lazybinary;
 
-import java.nio.ByteBuffer;
-import java.nio.charset.CharacterCodingException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -46,8 +44,6 @@
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.StructField;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.HiveVarcharObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.HiveDecimalObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.BinaryObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.BooleanObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.ByteObjectInspector;
@@ -55,6 +51,7 @@
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.FloatObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.HiveDecimalObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.HiveVarcharObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.ShortObjectInspector;
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveDecimalObjectInspector.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveDecimalObjectInspector.java
index 113445e..7d91293 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveDecimalObjectInspector.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveDecimalObjectInspector.java
@@ -21,14 +21,18 @@
 
 import org.apache.hadoop.hive.common.type.HiveDecimal;
 import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
-import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;
 
 public class JavaHiveDecimalObjectInspector
-    extends AbstractPrimitiveJavaObjectInspector
-    implements SettableHiveDecimalObjectInspector {
+extends AbstractPrimitiveJavaObjectInspector
+implements SettableHiveDecimalObjectInspector {
 
-  protected JavaHiveDecimalObjectInspector() {
-    super(TypeInfoFactory.decimalTypeInfo);
+  public JavaHiveDecimalObjectInspector() {
+  }
+
+  public JavaHiveDecimalObjectInspector(DecimalTypeInfo typeInfo) {
+    super(typeInfo);
   }
 
   @Override
@@ -38,33 +42,32 @@ public HiveDecimalWritable getPrimitiveWritableObject(Object o) {
     }
 
     if (o instanceof String) {
-      o = HiveDecimal.create((String)o);
-      if (o == null) {
-        return null;
-      }
+      HiveDecimal dec = enforcePrecisionScale(HiveDecimal.create((String)o));
+      return dec == null ? null : new HiveDecimalWritable(dec);
     }
 
-    return new HiveDecimalWritable((HiveDecimal) o);
+    HiveDecimal dec = enforcePrecisionScale((HiveDecimal)o);
+    return dec == null ? null : new HiveDecimalWritable(dec);
   }
 
   @Override
   public HiveDecimal getPrimitiveJavaObject(Object o) {
-    return o == null ? null : (HiveDecimal) o;
+    return enforcePrecisionScale((HiveDecimal)o);
   }
 
   @Override
   public Object set(Object o, byte[] bytes, int scale) {
-    return HiveDecimal.create(new BigInteger(bytes), scale);
+    return enforcePrecisionScale(HiveDecimal.create(new BigInteger(bytes), scale));
   }
 
   @Override
   public Object set(Object o, HiveDecimal t) {
-    return t;
+    return enforcePrecisionScale(t);
   }
 
   @Override
   public Object set(Object o, HiveDecimalWritable t) {
-    return t == null ? null : t.getHiveDecimal();
+    return t == null ? null : enforcePrecisionScale(t.getHiveDecimal());
   }
 
   @Override
@@ -74,11 +77,11 @@ public Object create(byte[] bytes, int scale) {
 
   @Override
   public Object create(HiveDecimal t) {
-    if (t == null) {
-      return null;
-    }
+    return t;
+  }
 
-    return HiveDecimal.create(t.unscaledValue(), t.scale());
+  private HiveDecimal enforcePrecisionScale(HiveDecimal dec) {
+    return HiveDecimalUtils.enforcePrecisionScale(dec,(DecimalTypeInfo)typeInfo);
   }
 
 }
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java
index fc0cee6..5c99f64 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java
@@ -22,7 +22,6 @@
 import java.util.HashMap;
 import java.util.Map;
 
-import org.apache.hadoop.hive.common.type.HiveVarchar;
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.io.ByteWritable;
 import org.apache.hadoop.hive.serde2.io.DateWritable;
@@ -35,6 +34,7 @@
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils.PrimitiveTypeEntry;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 import org.apache.hadoop.hive.serde2.typeinfo.VarcharTypeInfo;
@@ -82,7 +82,7 @@
   public static final WritableBinaryObjectInspector writableBinaryObjectInspector =
       new WritableBinaryObjectInspector();
   public static final WritableHiveDecimalObjectInspector writableHiveDecimalObjectInspector =
-      new WritableHiveDecimalObjectInspector();
+      new WritableHiveDecimalObjectInspector(TypeInfoFactory.decimalTypeInfo);
 
   // Map from PrimitiveTypeInfo to AbstractPrimitiveWritableObjectInspector.
   private static HashMap<PrimitiveTypeInfo, AbstractPrimitiveWritableObjectInspector> cachedPrimitiveWritableInspectorCache =
@@ -112,8 +112,7 @@
         writableTimestampObjectInspector);
     cachedPrimitiveWritableInspectorCache.put(TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BINARY_TYPE_NAME),
         writableBinaryObjectInspector);
-    cachedPrimitiveWritableInspectorCache.put(TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DECIMAL_TYPE_NAME),
-        writableHiveDecimalObjectInspector);
+    cachedPrimitiveWritableInspectorCache.put(TypeInfoFactory.decimalTypeInfo, writableHiveDecimalObjectInspector);
   }
 
   private static Map<PrimitiveCategory, AbstractPrimitiveWritableObjectInspector> primitiveCategoryToWritableOI =
@@ -159,7 +158,7 @@
   public static final JavaBinaryObjectInspector javaByteArrayObjectInspector =
       new JavaBinaryObjectInspector();
   public static final JavaHiveDecimalObjectInspector javaHiveDecimalObjectInspector =
-      new JavaHiveDecimalObjectInspector();
+      new JavaHiveDecimalObjectInspector(TypeInfoFactory.decimalTypeInfo);
 
   // Map from PrimitiveTypeInfo to AbstractPrimitiveJavaObjectInspector.
   private static HashMap<PrimitiveTypeInfo, AbstractPrimitiveJavaObjectInspector> cachedPrimitiveJavaInspectorCache =
@@ -189,8 +188,7 @@
         javaTimestampObjectInspector);
     cachedPrimitiveJavaInspectorCache.put(TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BINARY_TYPE_NAME),
         javaByteArrayObjectInspector);
-    cachedPrimitiveJavaInspectorCache.put(TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DECIMAL_TYPE_NAME),
-        javaHiveDecimalObjectInspector);
+    cachedPrimitiveJavaInspectorCache.put(TypeInfoFactory.decimalTypeInfo, javaHiveDecimalObjectInspector);
   }
 
   private static Map<PrimitiveCategory, AbstractPrimitiveJavaObjectInspector> primitiveCategoryToJavaOI =
@@ -244,8 +242,11 @@ public static AbstractPrimitiveWritableObjectInspector getPrimitiveWritableObjec
     case VARCHAR:
       result = new WritableHiveVarcharObjectInspector((VarcharTypeInfo)typeInfo);
       break;
-      default:
-        throw new RuntimeException("Failed to create WritableHiveVarcharObjectInspector for " + typeInfo );
+    case DECIMAL:
+      result = new WritableHiveDecimalObjectInspector((DecimalTypeInfo)typeInfo);
+      break;
+    default:
+      throw new RuntimeException("Failed to create object inspector for " + typeInfo );
     }
 
     cachedPrimitiveWritableInspectorCache.put(typeInfo, result);
@@ -286,7 +287,7 @@ public static ConstantObjectInspector getPrimitiveWritableConstantObjectInspecto
     case TIMESTAMP:
       return new WritableConstantTimestampObjectInspector((TimestampWritable)value);
     case DECIMAL:
-      return new WritableConstantHiveDecimalObjectInspector((HiveDecimalWritable)value);
+      return new WritableConstantHiveDecimalObjectInspector((DecimalTypeInfo)typeInfo, (HiveDecimalWritable)value);
     case BINARY:
       return new WritableConstantBinaryObjectInspector((BytesWritable)value);
     case VOID:
@@ -330,6 +331,9 @@ public static AbstractPrimitiveJavaObjectInspector getPrimitiveJavaObjectInspect
     case VARCHAR:
       result = new JavaHiveVarcharObjectInspector((VarcharTypeInfo)typeInfo);
       break;
+    case DECIMAL:
+      result = new JavaHiveDecimalObjectInspector((DecimalTypeInfo)typeInfo);
+      break;
       default:
         throw new RuntimeException("Failed to create JavaHiveVarcharObjectInspector for " + typeInfo );
     }
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveDecimalObjectInspector.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveDecimalObjectInspector.java
index b6cb744..a9ca7bd 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveDecimalObjectInspector.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveDecimalObjectInspector.java
@@ -17,27 +17,43 @@
  */
 package org.apache.hadoop.hive.serde2.objectinspector.primitive;
 
+import org.apache.hadoop.hive.common.type.HiveDecimal;
 import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
 import org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
 
 /**
  * A WritableConstantHiveDecimalObjectInspector is a WritableHiveDecimalObjectInspector
  * that implements ConstantObjectInspector.
  */
 public class WritableConstantHiveDecimalObjectInspector extends WritableHiveDecimalObjectInspector
-    implements ConstantObjectInspector {
+implements ConstantObjectInspector {
 
   private HiveDecimalWritable value;
 
   protected WritableConstantHiveDecimalObjectInspector() {
     super();
   }
-  WritableConstantHiveDecimalObjectInspector(HiveDecimalWritable value) {
+
+  WritableConstantHiveDecimalObjectInspector(DecimalTypeInfo typeInfo,
+      HiveDecimalWritable value) {
+    super(typeInfo);
     this.value = value;
   }
 
   @Override
   public HiveDecimalWritable getWritableConstantValue() {
-    return value;
+    // We need to enforce precision/scale here.
+    // A little inefficiency here as we need to create a HiveDecimal instance from the writable and
+    // recreate a HiveDecimalWritable instance on the HiveDecimal instance. However, we don't know
+    // the precision/scale of the original writable until we get a HiveDecimal instance from it.
+    DecimalTypeInfo decTypeInfo = (DecimalTypeInfo)typeInfo;
+    HiveDecimal dec = value == null ? null :
+      value.getHiveDecimal(decTypeInfo.precision(), decTypeInfo.scale());
+    if (dec == null) {
+      return null;
+    }
+    return new HiveDecimalWritable(dec);
   }
+
 }
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveDecimalObjectInspector.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveDecimalObjectInspector.java
index dc9c8fb..9c36462 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveDecimalObjectInspector.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveDecimalObjectInspector.java
@@ -20,24 +20,27 @@
 
 import org.apache.hadoop.hive.common.type.HiveDecimal;
 import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
-import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;
 
-public class WritableHiveDecimalObjectInspector
-    extends AbstractPrimitiveWritableObjectInspector
-    implements SettableHiveDecimalObjectInspector {
+public class WritableHiveDecimalObjectInspector extends AbstractPrimitiveWritableObjectInspector
+implements SettableHiveDecimalObjectInspector {
 
-  protected WritableHiveDecimalObjectInspector() {
-    super(TypeInfoFactory.decimalTypeInfo);
+  public WritableHiveDecimalObjectInspector() {
+  }
+
+  protected WritableHiveDecimalObjectInspector(DecimalTypeInfo typeInfo) {
+    super(typeInfo);
   }
 
   @Override
   public HiveDecimalWritable getPrimitiveWritableObject(Object o) {
-    return o == null ? null : (HiveDecimalWritable) o;
+    return enforcePrecisionScale(((HiveDecimalWritable) o));
   }
 
   @Override
   public HiveDecimal getPrimitiveJavaObject(Object o) {
-    return o == null ? null : ((HiveDecimalWritable) o).getHiveDecimal();
+    return enforcePrecisionScale(((HiveDecimalWritable)o).getHiveDecimal());
   }
 
   @Override
@@ -47,27 +50,34 @@ public Object copyObject(Object o) {
 
   @Override
   public Object set(Object o, byte[] bytes, int scale) {
-    ((HiveDecimalWritable) o).set(bytes, scale);
-    return o;
+    HiveDecimalWritable writable = (HiveDecimalWritable)create(bytes, scale);
+    if (writable != null) {
+      ((HiveDecimalWritable)o).set(writable);
+      return o;
+    } else {
+      return null;
+    }
   }
 
   @Override
   public Object set(Object o, HiveDecimal t) {
-    if (t == null) {
+    HiveDecimal dec = enforcePrecisionScale(t);
+    if (dec != null) {
+      ((HiveDecimalWritable) o).set(dec);
+      return o;
+    } else {
       return null;
     }
-
-    ((HiveDecimalWritable) o).set(t);
-    return o;
   }
 
   @Override
   public Object set(Object o, HiveDecimalWritable t) {
-    if (t == null) {
+    HiveDecimalWritable writable = enforcePrecisionScale(t);
+    if (writable == null) {
       return null;
     }
 
-    ((HiveDecimalWritable) o).set(t);
+    ((HiveDecimalWritable) o).set(writable);
     return o;
   }
 
@@ -78,11 +88,15 @@ public Object create(byte[] bytes, int scale) {
 
   @Override
   public Object create(HiveDecimal t) {
-    if (t == null) {
-      return null;
-    }
+    return t == null ? null : new HiveDecimalWritable(t);
+  }
+
+  private HiveDecimal enforcePrecisionScale(HiveDecimal dec) {
+    return HiveDecimalUtils.enforcePrecisionScale(dec, (DecimalTypeInfo)typeInfo);
+  }
 
-    return new HiveDecimalWritable(t);
+  private HiveDecimalWritable enforcePrecisionScale(HiveDecimalWritable writable) {
+    return HiveDecimalUtils.enforcePrecisionScale(writable, (DecimalTypeInfo)typeInfo);
   }
 
 }
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/DecimalTypeInfo.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/DecimalTypeInfo.java
new file mode 100644
index 0000000..bd28609
--- /dev/null
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/DecimalTypeInfo.java
@@ -0,0 +1,104 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.serde2.typeinfo;
+
+import org.apache.hadoop.hive.serde.serdeConstants;
+
+public class DecimalTypeInfo extends PrimitiveTypeInfo {
+  private static final long serialVersionUID = 1L;
+
+  private int precision;
+  private int scale;
+
+  // no-arg constructor to make kyro happy.
+  public DecimalTypeInfo() {
+  }
+
+  public DecimalTypeInfo(int precision, int scale) {
+    super(serdeConstants.DECIMAL_TYPE_NAME);
+    HiveDecimalUtils.validateParameter(precision, scale);
+    this.precision = precision;
+    this.scale = scale;
+  }
+
+  @Override
+  public String getTypeName() {
+    return getQualifiedName();
+  }
+
+  @Override
+  public boolean equals(Object other) {
+    if (other == null || !(other instanceof DecimalTypeInfo)) {
+      return false;
+    }
+
+    DecimalTypeInfo dti = (DecimalTypeInfo)other;
+
+    return this.precision() == dti.precision() && this.scale() == dti.scale();
+
+  }
+
+  /**
+   * Generate the hashCode for this TypeInfo.
+   */
+  @Override
+  public int hashCode() {
+    return 31 * (17 + precision) + scale;
+  }
+
+  @Override
+  public String toString() {
+    return getQualifiedName();
+  }
+
+  @Override
+  public String getQualifiedName() {
+    return getQualifiedName(precision, scale);
+  }
+
+  public static String getQualifiedName(int precision, int scale) {
+    StringBuilder sb = new StringBuilder(serdeConstants.DECIMAL_TYPE_NAME);
+    sb.append("(");
+    sb.append(precision);
+    sb.append(",");
+    sb.append(scale);
+    sb.append(")");
+    return sb.toString();
+  }
+
+  public int precision() {
+    return precision;
+  }
+
+  public int scale() {
+    return scale;
+  }
+
+  @Override
+  public boolean accept(TypeInfo other) {
+    if (other == null || !(other instanceof DecimalTypeInfo)) {
+      return false;
+    }
+
+    DecimalTypeInfo dti = (DecimalTypeInfo)other;
+    // Make sure "this" has enough integer room to accomodate other's integer digits.
+    return this.precision() - this.scale() >= dti.precision() - dti.scale();
+  }
+
+}
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/HiveDecimalUtils.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/HiveDecimalUtils.java
new file mode 100644
index 0000000..420509c
--- /dev/null
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/HiveDecimalUtils.java
@@ -0,0 +1,121 @@
+package org.apache.hadoop.hive.serde2.typeinfo;
+
+import java.math.BigDecimal;
+
+import org.apache.hadoop.hive.common.type.HiveDecimal;
+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
+
+public class HiveDecimalUtils {
+
+  public static HiveDecimal enforcePrecisionScale(HiveDecimal dec, DecimalTypeInfo typeInfo) {
+    return enforcePrecisionScale(dec, typeInfo.precision(), typeInfo.scale());
+  }
+
+  public static HiveDecimal enforcePrecisionScale(HiveDecimal dec,int maxPrecision, int maxScale) {
+    if (dec == null) {
+      return null;
+    }
+
+    // Minor optimization, avoiding creating new objects.
+    if (dec.precision() - dec.scale() <= maxPrecision - maxScale && dec.scale() <= maxScale) {
+      return dec;
+    }
+
+    BigDecimal bd = HiveDecimal.enforcePrecisionScale(dec.bigDecimalValue(),
+        maxPrecision, maxScale);
+    if (bd == null) {
+      return null;
+    }
+
+    return HiveDecimal.create(bd);
+  }
+
+  public static HiveDecimalWritable enforcePrecisionScale(HiveDecimalWritable writable,
+      DecimalTypeInfo typeInfo) {
+    if (writable == null) {
+      return null;
+    }
+
+    HiveDecimal dec = enforcePrecisionScale(writable.getHiveDecimal(), typeInfo);
+    return dec == null ? null : new HiveDecimalWritable(dec);
+  }
+
+  public static HiveDecimalWritable enforcePrecisionScale(HiveDecimalWritable writable,
+      int precision, int scale) {
+    if (writable == null) {
+      return null;
+    }
+
+    HiveDecimal dec = enforcePrecisionScale(writable.getHiveDecimal(), precision, scale);
+    return dec == null ? null : new HiveDecimalWritable(dec);
+  }
+
+  public static void validateParameter(int precision, int scale) {
+    if (precision < 1 || precision > HiveDecimal.MAX_PRECISION) {
+      throw new IllegalArgumentException("Decimal precision out of allowed range [1," +
+          HiveDecimal.MAX_PRECISION + "]");
+    }
+
+    if (scale < 0 || scale > HiveDecimal.MAX_SCALE) {
+      throw new IllegalArgumentException("Decimal scale out of allowed range [0," +
+          HiveDecimal.MAX_SCALE + "]");
+    }
+
+    if (precision < scale) {
+      throw new IllegalArgumentException("Decimal scale must be less than or equal to precision");
+    }
+  }
+
+  /**
+   * Get the precision of double type can be tricky. While a double may have more digits than
+   * a HiveDecimal can hold, in reality those numbers are of no practical use. Thus, we assume
+   * that a double can have at most HiveDecimal.MAX_PRECISION, which is generous enough. This
+   * implies that casting a double to a decimal type is always valid.
+   *
+   */
+  public static int getPrecisionForType(PrimitiveTypeInfo typeInfo) {
+    switch (typeInfo.getPrimitiveCategory()) {
+    case DECIMAL:
+      return ((DecimalTypeInfo)typeInfo).precision();
+    case FLOAT:
+      return 23;
+    case BYTE:
+      return 3;
+    case SHORT:
+      return 5;
+    case INT:
+      return 10;
+    case LONG:
+      return 19;
+    default:
+      return HiveDecimal.MAX_PRECISION;
+    }
+  }
+
+  /**
+   * Get the scale of double type can be tricky. While a double may have more decimal digits than
+   * HiveDecimal, in reality those numbers are of no practical use. Thus, we assume that a double
+   * can have at most HiveDecimal.MAX_SCALE, which is generous enough. This implies implies that
+   * casting a double to a decimal type is always valid.
+   *
+   */
+  public static int getScaleForType(PrimitiveTypeInfo typeInfo) {
+    switch (typeInfo.getPrimitiveCategory()) {
+    case DECIMAL:
+      return ((DecimalTypeInfo)typeInfo).scale();
+    case FLOAT:
+      return 7;
+    case BYTE:
+      return 0;
+    case SHORT:
+      return 0;
+    case INT:
+      return 0;
+    case LONG:
+      return 0;
+    default:
+      return HiveDecimal.MAX_SCALE;
+    }
+  }
+
+}
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java
index 36a7008..e7f3f48 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java
@@ -68,4 +68,9 @@ public String toString() {
 
   @Override
   public abstract int hashCode();
+
+  public boolean accept(TypeInfo other) {
+    return this.equals(other);
+  }
+
 }
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java
index 13d1ec0..08a8c8e 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java
@@ -24,6 +24,7 @@
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hive.common.type.HiveDecimal;
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils.PrimitiveTypeEntry;
@@ -54,7 +55,12 @@ private TypeInfoFactory() {
   public static final PrimitiveTypeInfo dateTypeInfo = new PrimitiveTypeInfo(serdeConstants.DATE_TYPE_NAME);
   public static final PrimitiveTypeInfo timestampTypeInfo = new PrimitiveTypeInfo(serdeConstants.TIMESTAMP_TYPE_NAME);
   public static final PrimitiveTypeInfo binaryTypeInfo = new PrimitiveTypeInfo(serdeConstants.BINARY_TYPE_NAME);
-  public static final PrimitiveTypeInfo decimalTypeInfo = new PrimitiveTypeInfo(serdeConstants.DECIMAL_TYPE_NAME);
+
+  /**
+   * A DecimalTypeInfo instance that has max precision and max scale.
+   */
+  public static final DecimalTypeInfo decimalTypeInfo = new DecimalTypeInfo(HiveDecimal.MAX_PRECISION,
+      HiveDecimal.MAX_SCALE);
 
   public static final PrimitiveTypeInfo unknownTypeInfo = new PrimitiveTypeInfo("unknown");
 
@@ -75,7 +81,7 @@ private TypeInfoFactory() {
     cachedPrimitiveTypeInfo.put(serdeConstants.DATE_TYPE_NAME, dateTypeInfo);
     cachedPrimitiveTypeInfo.put(serdeConstants.TIMESTAMP_TYPE_NAME, timestampTypeInfo);
     cachedPrimitiveTypeInfo.put(serdeConstants.BINARY_TYPE_NAME, binaryTypeInfo);
-    cachedPrimitiveTypeInfo.put(serdeConstants.DECIMAL_TYPE_NAME, decimalTypeInfo);
+    cachedPrimitiveTypeInfo.put(decimalTypeInfo.getQualifiedName(), decimalTypeInfo);
     cachedPrimitiveTypeInfo.put("unknown", unknownTypeInfo);
   }
 
@@ -128,6 +134,12 @@ private static PrimitiveTypeInfo createPrimitiveTypeInfo(String fullName) {
           return null;
         }
         return new VarcharTypeInfo(Integer.valueOf(parts.typeParams[0]));
+      case DECIMAL:
+        if (parts.typeParams.length != 2) {
+          return null;
+        }
+        return new DecimalTypeInfo(Integer.valueOf(parts.typeParams[0]),
+            Integer.valueOf(parts.typeParams[1]));
       default:
         return null;
     }
@@ -138,6 +150,11 @@ public static VarcharTypeInfo getVarcharTypeInfo(int length) {
     return (VarcharTypeInfo) getPrimitiveTypeInfo(fullName);
   }
 
+  public static DecimalTypeInfo getDecimalTypeInfo(int precision, int scale) {
+    String fullName = DecimalTypeInfo.getQualifiedName(precision, scale);
+    return (DecimalTypeInfo) getPrimitiveTypeInfo(fullName);
+  };
+
   public static TypeInfo getPrimitiveTypeInfoFromPrimitiveWritable(
       Class<?> clazz) {
     String typeName = PrimitiveObjectInspectorUtils
@@ -207,6 +224,6 @@ public static TypeInfo getMapTypeInfo(TypeInfo keyTypeInfo,
       cachedMapTypeInfo.put(signature, result);
     }
     return result;
-  };
+  }
 
 }
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java
index d21abd4..48aa52c 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java
@@ -395,23 +395,39 @@ private TypeInfo parseType() {
           PrimitiveObjectInspectorUtils.getTypeEntryFromTypeName(t.text);
       if (typeEntry != null && typeEntry.primitiveCategory != PrimitiveCategory.UNKNOWN ) {
         String qualifiedTypeName = typeEntry.typeName;
-        if (typeEntry.primitiveCategory == PrimitiveCategory.VARCHAR) {
-          int length = HiveVarchar.MAX_VARCHAR_LENGTH;
-          
-          String[] params = parseParams();
+        String[] params = parseParams();
+        switch (typeEntry.primitiveCategory) {
+        case VARCHAR:
           if (params == null || params.length == 0) {
-            throw new RuntimeException( "Varchar type is specified without length: " + typeInfoString);
+            throw new IllegalArgumentException( "Varchar type is specified without length: " + typeInfoString);
           }
-          
+
           if (params.length == 1) {
-            length = Integer.valueOf(params[0]);
+            int length = Integer.valueOf(params[0]);
             VarcharUtils.validateParameter(length);
+            qualifiedTypeName = BaseCharTypeInfo.getQualifiedName(typeEntry.typeName, length);
           } else if (params.length > 1) {
-            throw new RuntimeException("Type varchar only takes one parameter, but " +
+            throw new IllegalArgumentException("Type varchar only takes one parameter, but " +
                 params.length + " is seen");
-          } 
+          }
+
+          break;
+        case DECIMAL:
+          if (params == null || params.length == 0) {
+            throw new IllegalArgumentException( "Decimal type is specified without length: " + typeInfoString);
+          }
+
+          if (params.length == 2) {
+            int precision = Integer.valueOf(params[0]);
+            int scale = Integer.valueOf(params[1]);
+            HiveDecimalUtils.validateParameter(precision, scale);
+            qualifiedTypeName = DecimalTypeInfo.getQualifiedName(precision, scale);
+          } else if (params.length > 1) {
+            throw new IllegalArgumentException("Type varchar only takes one parameter, but " +
+                params.length + " is seen");
+          }
 
-          qualifiedTypeName = BaseCharTypeInfo.getQualifiedName(typeEntry.typeName, length);
+          break;
         }
 
         return TypeInfoFactory.getPrimitiveTypeInfo(qualifiedTypeName);
@@ -679,7 +695,7 @@ public static TypeInfo getTypeInfoFromObjectInspector(ObjectInspector oi) {
     switch (oi.getCategory()) {
     case PRIMITIVE: {
       PrimitiveObjectInspector poi = (PrimitiveObjectInspector) oi;
-      result = TypeInfoFactory.getPrimitiveTypeInfo(poi.getTypeName());
+      result = poi.getTypeInfo();
       break;
     }
     case LIST: {
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeInfo.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeInfo.java
index 5d6f3f4..676a1e5 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeInfo.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeInfo.java
@@ -45,7 +45,7 @@ public boolean equals(Object other) {
 
     VarcharTypeInfo pti = (VarcharTypeInfo) other;
 
-    return this.typeName.equals(pti.typeName) && this.getLength() == pti.getLength();
+    return this.getLength() == pti.getLength();
   }
 
   /**
@@ -53,7 +53,7 @@ public boolean equals(Object other) {
    */
   @Override
   public int hashCode() {
-    return getQualifiedName().hashCode();
+    return getLength();
   }
 
   @Override
-- 
1.7.0.4

