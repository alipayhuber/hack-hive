From 8158fb5acd55349fcbdb34cb3b03911c98710742 Mon Sep 17 00:00:00 2001
From: Xuefu Zhang <xzhang@xzlt.(none)>
Date: Fri, 6 Jun 2014 11:27:39 -0700
Subject: [PATCH 351/375] CDH-16309: Backport HIVE-6022: Load statements with incorrect order of partitions put input files to unreadable places

---
 .../hadoop/hive/ql/parse/BaseSemanticAnalyzer.java |   14 ++++--
 ql/src/test/queries/clientpositive/loadpart2.q     |    9 ++++
 ql/src/test/results/clientnegative/dyn_part4.q.out |    2 +-
 ql/src/test/results/clientpositive/loadpart2.q.out |   51 ++++++++++++++++++++
 4 files changed, 71 insertions(+), 5 deletions(-)
 create mode 100644 ql/src/test/queries/clientpositive/loadpart2.q
 create mode 100644 ql/src/test/results/clientpositive/loadpart2.q.out

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
index fd35a51..374afb2 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
@@ -776,7 +776,7 @@ public tableSpec(Hive db, HiveConf conf, ASTNode ast,
         ASTNode partspec = (ASTNode) ast.getChild(1);
         partitions = new ArrayList<Partition>();
         // partSpec is a mapping from partition column name to its value.
-        partSpec = new LinkedHashMap<String, String>(partspec.getChildCount());
+        Map<String, String> tmpPartSpec = new HashMap<String, String>(partspec.getChildCount());
         for (int i = 0; i < partspec.getChildCount(); ++i) {
           ASTNode partspec_val = (ASTNode) partspec.getChild(i);
           String val = null;
@@ -791,15 +791,21 @@ public tableSpec(Hive db, HiveConf conf, ASTNode ast,
           } else { // in the form of T partition (ds="2010-03-03")
             val = stripQuotes(partspec_val.getChild(1).getText());
           }
-          partSpec.put(colName, val);
+          tmpPartSpec.put(colName, val);
         }
 
         // check if the columns specified in the partition() clause are actually partition columns
-        validatePartSpec(tableHandle, partSpec, ast, conf);
+        validatePartSpec(tableHandle, tmpPartSpec, ast, conf);
+
+        List<FieldSchema> parts = tableHandle.getPartitionKeys();
+        partSpec = new LinkedHashMap<String, String>(partspec.getChildCount());
+        for (FieldSchema fs : parts) {
+          String partKey = fs.getName();
+          partSpec.put(partKey, tmpPartSpec.get(partKey));
+        }        
 
         // check if the partition spec is valid
         if (numDynParts > 0) {
-          List<FieldSchema> parts = tableHandle.getPartitionKeys();
           int numStaPart = parts.size() - numDynParts;
           if (numStaPart == 0 &&
               conf.getVar(HiveConf.ConfVars.DYNAMICPARTITIONINGMODE).equalsIgnoreCase("strict")) {
diff --git a/src/ql/src/test/queries/clientpositive/loadpart2.q b/src/ql/src/test/queries/clientpositive/loadpart2.q
new file mode 100644
index 0000000..c69d33e
--- /dev/null
+++ b/src/ql/src/test/queries/clientpositive/loadpart2.q
@@ -0,0 +1,9 @@
+
+create table hive_test ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as textfile;
+load data local inpath '../data/files/test.dat' overwrite into table hive_test partition (pcol1='part1',pcol2='part1') ;
+load data local inpath '../data/files/test.dat' overwrite into table hive_test partition (pcol2='part2',pcol1='part2') ;
+select * from hive_test where pcol1='part1' and pcol2='part1';
+select * from hive_test where pcol1='part2' and pcol2='part2';
+
+
+
diff --git a/src/ql/src/test/results/clientnegative/dyn_part4.q.out b/src/ql/src/test/results/clientnegative/dyn_part4.q.out
index 43f1e4d..862e1b5 100644
--- a/src/ql/src/test/results/clientnegative/dyn_part4.q.out
+++ b/src/ql/src/test/results/clientnegative/dyn_part4.q.out
@@ -3,4 +3,4 @@ PREHOOK: type: CREATETABLE
 POSTHOOK: query: create table nzhang_part4 (key string) partitioned by (ds string, hr string, value string)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@nzhang_part4
-FAILED: SemanticException [Error 10125]: Partition columns in partition specification are not the same as that defined in the table schema. The names and orders have to be exactly the same. Partition columns in the table schema are: (ds, hr, value), while the partitions specified in the query are: (value, ds, hr).
+FAILED: SemanticException [Error 10094]: Line 3:46 Dynamic partition cannot be the parent of a static partition 'hr'
diff --git a/src/ql/src/test/results/clientpositive/loadpart2.q.out b/src/ql/src/test/results/clientpositive/loadpart2.q.out
new file mode 100644
index 0000000..c11d252
--- /dev/null
+++ b/src/ql/src/test/results/clientpositive/loadpart2.q.out
@@ -0,0 +1,51 @@
+PREHOOK: query: create table hive_test ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as textfile
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table hive_test ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as textfile
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@hive_test
+PREHOOK: query: load data local inpath '../data/files/test.dat' overwrite into table hive_test partition (pcol1='part1',pcol2='part1')
+PREHOOK: type: LOAD
+PREHOOK: Output: default@hive_test
+POSTHOOK: query: load data local inpath '../data/files/test.dat' overwrite into table hive_test partition (pcol1='part1',pcol2='part1')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@hive_test
+POSTHOOK: Output: default@hive_test@pcol1=part1/pcol2=part1
+PREHOOK: query: load data local inpath '../data/files/test.dat' overwrite into table hive_test partition (pcol2='part2',pcol1='part2')
+PREHOOK: type: LOAD
+PREHOOK: Output: default@hive_test
+POSTHOOK: query: load data local inpath '../data/files/test.dat' overwrite into table hive_test partition (pcol2='part2',pcol1='part2')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@hive_test
+POSTHOOK: Output: default@hive_test@pcol1=part2/pcol2=part2
+PREHOOK: query: select * from hive_test where pcol1='part1' and pcol2='part1'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@hive_test
+PREHOOK: Input: default@hive_test@pcol1=part1/pcol2=part1
+#### A masked pattern was here ####
+POSTHOOK: query: select * from hive_test where pcol1='part1' and pcol2='part1'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@hive_test
+POSTHOOK: Input: default@hive_test@pcol1=part1/pcol2=part1
+#### A masked pattern was here ####
+1	part1	part1
+2	part1	part1
+3	part1	part1
+4	part1	part1
+5	part1	part1
+6	part1	part1
+PREHOOK: query: select * from hive_test where pcol1='part2' and pcol2='part2'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@hive_test
+PREHOOK: Input: default@hive_test@pcol1=part2/pcol2=part2
+#### A masked pattern was here ####
+POSTHOOK: query: select * from hive_test where pcol1='part2' and pcol2='part2'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@hive_test
+POSTHOOK: Input: default@hive_test@pcol1=part2/pcol2=part2
+#### A masked pattern was here ####
+1	part2	part2
+2	part2	part2
+3	part2	part2
+4	part2	part2
+5	part2	part2
+6	part2	part2
-- 
1.7.0.4

