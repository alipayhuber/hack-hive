From edb5684ee53642976d0e80d2d98ad6a88d741f4a Mon Sep 17 00:00:00 2001
From: Ashutosh Chauhan <hashutosh@apache.org>
Date: Sat, 5 Oct 2013 09:49:54 +0000
Subject: [PATCH 069/375] HIVE-4888 : listPartitionsByFilter doesn't support lt/gt/lte/gte (Sergey Shelukhin via Ashutosh Chauhan)

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1529423 13f79535-47bb-0310-9956-ffa450edef68
---
 .../hadoop/hive/metastore/MetaStoreDirectSql.java  |   61 +-
 .../hive/metastore/parser/ExpressionTree.java      |   25 +-
 .../hadoop/hive/metastore/TestHiveMetaStore.java   |   22 +-
 .../hadoop/hive/metastore/TestMetastoreExpr.java   |  262 +++
 .../test/queries/clientpositive/filter_numeric.q   |   15 +
 .../results/clientpositive/filter_numeric.q.out    | 1712 ++++++++++++++++++++
 serde/if/serde.thrift                              |    1 +
 serde/src/gen/thrift/gen-cpp/serde_constants.cpp   |    5 +
 serde/src/gen/thrift/gen-cpp/serde_constants.h     |    1 +
 .../apache/hadoop/hive/serde/serdeConstants.java   |    8 +
 .../gen-php/org/apache/hadoop/hive/serde/Types.php |    7 +
 .../org_apache_hadoop_hive_serde/constants.py      |    6 +
 serde/src/gen/thrift/gen-rb/serde_constants.rb     |    7 +
 13 files changed, 2088 insertions(+), 44 deletions(-)
 create mode 100644 ql/src/test/org/apache/hadoop/hive/metastore/TestMetastoreExpr.java
 create mode 100644 ql/src/test/queries/clientpositive/filter_numeric.q
 create mode 100644 ql/src/test/results/clientpositive/filter_numeric.q.out

diff --git a/src/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java b/src/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java
index 00dfb76..164b904 100644
--- a/src/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java
+++ b/src/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java
@@ -53,6 +53,7 @@
 import org.apache.hadoop.hive.metastore.parser.ExpressionTree.Operator;
 import org.apache.hadoop.hive.metastore.parser.ExpressionTree.TreeNode;
 import org.apache.hadoop.hive.metastore.parser.ExpressionTree.TreeVisitor;
+import org.apache.hadoop.hive.serde.serdeConstants;
 
 /**
  * This class contains the optimizations for MetaStore that rely on direct SQL access to
@@ -165,7 +166,7 @@ private void trySetAnsiQuotesForMysql() throws SQLException {
     }
     String list = repeat(",?", partNames.size()).substring(1);
     return getPartitionsViaSqlFilterInternal(dbName, tblName, null,
-        "and \"PARTITIONS\".\"PART_NAME\" in (" + list + ")",
+        "\"PARTITIONS\".\"PART_NAME\" in (" + list + ")",
         partNames, new ArrayList<String>(), max);
   }
 
@@ -179,7 +180,8 @@ private void trySetAnsiQuotesForMysql() throws SQLException {
   public List<Partition> getPartitionsViaSqlFilter(
       Table table, ExpressionTree tree, Integer max) throws MetaException {
     assert tree != null;
-    List<String> params = new ArrayList<String>(), joins = new ArrayList<String>();
+    List<Object> params = new ArrayList<Object>();
+    List<String> joins = new ArrayList<String>();
     String sqlFilter = PartitionFilterGenerator.generateSqlFilter(table, tree, params, joins);
     if (sqlFilter == null) {
       return null; // Cannot make SQL filter to push down.
@@ -232,7 +234,7 @@ private boolean isViewTable(String dbName, String tblName) throws MetaException 
    * @return List of partition objects.
    */
   private List<Partition> getPartitionsViaSqlFilterInternal(String dbName, String tblName,
-      Boolean isView, String sqlFilter, List<String> paramsForFilter,
+      Boolean isView, String sqlFilter, List<? extends Object> paramsForFilter,
       List<String> joinsForFilter, Integer max) throws MetaException {
     boolean doTrace = LOG.isDebugEnabled();
     dbName = dbName.toLowerCase();
@@ -255,9 +257,11 @@ private boolean isViewTable(String dbName, String tblName) throws MetaException 
     String queryText =
         "select \"PARTITIONS\".\"PART_ID\" from \"PARTITIONS\""
       + "  inner join \"TBLS\" on \"PARTITIONS\".\"TBL_ID\" = \"TBLS\".\"TBL_ID\" "
+      + "    and \"TBLS\".\"TBL_NAME\" = ? "
       + "  inner join \"DBS\" on \"TBLS\".\"DB_ID\" = \"DBS\".\"DB_ID\" "
-      + join(joinsForFilter, ' ') + " where \"TBLS\".\"TBL_NAME\" = ? and \"DBS\".\"NAME\" = ? "
-      + (sqlFilter == null ? "" : sqlFilter) + orderForFilter;
+      + "     and \"DBS\".\"NAME\" = ? "
+      + join(joinsForFilter, ' ')
+      + (sqlFilter == null ? "" : (" where " + sqlFilter)) + orderForFilter;
     Object[] params = new Object[paramsForFilter.size() + 2];
     params[0] = tblName;
     params[1] = dbName;
@@ -649,11 +653,11 @@ private static String trimCommaList(StringBuilder sb) {
   private static class PartitionFilterGenerator extends TreeVisitor {
     private final Table table;
     private final FilterBuilder filterBuffer;
-    private final List<String> params;
+    private final List<Object> params;
     private final List<String> joins;
 
     private PartitionFilterGenerator(
-        Table table, List<String> params, List<String> joins) {
+        Table table, List<Object> params, List<String> joins) {
       this.table = table;
       this.params = params;
       this.joins = joins;
@@ -668,7 +672,7 @@ private PartitionFilterGenerator(
      * @return the string representation of the expression tree
      */
     public static String generateSqlFilter(Table table,
-        ExpressionTree tree, List<String> params, List<String> joins) throws MetaException {
+        ExpressionTree tree, List<Object> params, List<String> joins) throws MetaException {
       assert table != null;
       if (tree.getRoot() == null) {
         return "";
@@ -685,7 +689,7 @@ public static String generateSqlFilter(Table table,
         if (joins.get(i) != null) continue;
         joins.remove(i--);
       }
-      return "and (" + visitor.filterBuffer.getFilter() + ")";
+      return "(" + visitor.filterBuffer.getFilter() + ")";
     }
 
     @Override
@@ -718,10 +722,28 @@ public void visit(LeafNode node) throws MetaException {
       int partColIndex = node.getPartColIndexForFilter(table, filterBuffer);
       if (filterBuffer.hasError()) return;
 
-      // Add parameters linearly; we are traversing leaf nodes LTR, so they would match correctly.
-      String valueAsString = node.getFilterPushdownParam(table, partColIndex, filterBuffer);
-      if (filterBuffer.hasError()) return;
-      params.add(valueAsString);
+      // We skipped 'like', other ops should all work as long as the types are right.
+      String colType = table.getPartitionKeys().get(partColIndex).getType();
+      boolean isStringCol = colType.equals(serdeConstants.STRING_TYPE_NAME);
+      if (!isStringCol && !serdeConstants.IntegralTypes.contains(colType)) {
+        filterBuffer.setError("Filter pushdown is only supported for string or integral columns");
+        return;
+      }
+
+      boolean isStringVal = node.value instanceof String;
+      if (!isStringVal && !(node.value instanceof Long)) {
+        filterBuffer.setError("Filter pushdown is only supported for string or integral values");
+        return;
+      } else if (isStringCol != isStringVal) {
+        // It's not clear how filtering for e.g. "stringCol > 5" should work (which side is
+        // to be coerced?). Let the expression evaluation sort this one out, not metastore.
+        filterBuffer.setError("Cannot push down filter for "
+            + (isStringCol ? "string" : "integral") + " column and value " + node.value);
+        return;
+      }
+
+      // Force string-based handling in some cases to be compatible with JDO pushdown.
+      boolean forceStringEq = !isStringCol && node.canJdoUseStringsWithIntegral();
 
       if (joins.isEmpty()) {
         // There's a fixed number of partition cols that we might have filters on. To avoid
@@ -738,8 +760,19 @@ public void visit(LeafNode node) throws MetaException {
             + " and \"FILTER" + partColIndex + "\".\"INTEGER_IDX\" = " + partColIndex);
       }
 
+      // Build the filter and add parameters linearly; we are traversing leaf nodes LTR.
       String tableValue = "\"FILTER" + partColIndex + "\".\"PART_KEY_VAL\"";
-      // TODO: need casts here if #doesOperatorSupportIntegral is amended to include lt/gt/etc.
+      if (!isStringCol && !forceStringEq) {
+        // The underlying database field is varchar, we need to compare numbers.
+        tableValue = "cast(" + tableValue + " as decimal(21,0))";
+        // This is a workaround for DERBY-6358; as such, it is pretty horrible.
+        tableValue = "(case when \"TBLS\".\"TBL_NAME\" = ? and \"DBS\".\"NAME\" = ? then "
+          + tableValue + " else null end)";
+        params.add(table.getTableName().toLowerCase());
+        params.add(table.getDbName().toLowerCase());
+      }
+      params.add(forceStringEq ? node.value.toString() : node.value);
+
       filterBuffer.append(node.isReverseOrder
           ? "(? " + node.operator.getSqlOp() + " " + tableValue + ")"
           : "(" + tableValue + " " + node.operator.getSqlOp() + " ?)");
diff --git a/src/metastore/src/java/org/apache/hadoop/hive/metastore/parser/ExpressionTree.java b/src/metastore/src/java/org/apache/hadoop/hive/metastore/parser/ExpressionTree.java
index 4cbe2a3..93e9942 100644
--- a/src/metastore/src/java/org/apache/hadoop/hive/metastore/parser/ExpressionTree.java
+++ b/src/metastore/src/java/org/apache/hadoop/hive/metastore/parser/ExpressionTree.java
@@ -348,7 +348,7 @@ private void generateJDOFilterOverPartitions(Table table, Map<String, Object> pa
       int partitionColumnIndex = getPartColIndexForFilter(table, filterBuilder);
       if (filterBuilder.hasError()) return;
 
-      String valueAsString = getFilterPushdownParam(table, partitionColumnIndex, filterBuilder);
+      String valueAsString = getJdoFilterPushdownParam(table, partitionColumnIndex, filterBuilder);
       if (filterBuilder.hasError()) return;
 
       String paramName = PARAM_PREFIX + params.size();
@@ -394,25 +394,13 @@ private void generateJDOFilterOverPartitions(Table table, Map<String, Object> pa
      * @param operator operator
      * @return true iff filter pushdown for this operator can be done for integral types.
      */
-    private static boolean doesOperatorSupportIntegral(Operator operator) {
-      // TODO: for SQL-based filtering, this could be amended if we added casts.
+    public boolean canJdoUseStringsWithIntegral() {
       return (operator == Operator.EQUALS)
           || (operator == Operator.NOTEQUALS)
           || (operator == Operator.NOTEQUALS2);
     }
 
     /**
-     * @param type type
-     * @return true iff type is an integral type.
-     */
-    private static boolean isIntegralType(String type) {
-      return type.equals(serdeConstants.TINYINT_TYPE_NAME)
-          || type.equals(serdeConstants.SMALLINT_TYPE_NAME)
-          || type.equals(serdeConstants.INT_TYPE_NAME)
-          || type.equals(serdeConstants.BIGINT_TYPE_NAME);
-    }
-
-    /**
      * Get partition column index in the table partition column list that
      * corresponds to the key that is being filtered on by this tree node.
      * @param table The table.
@@ -440,21 +428,20 @@ public int getPartColIndexForFilter(
     }
 
     /**
-     * Validates and gets the query parameter for filter pushdown based on the column
+     * Validates and gets the query parameter for JDO filter pushdown based on the column
      * and the constant stored in this node.
-     * In future this may become different for SQL and JDOQL filter pushdown.
      * @param table The table.
      * @param partColIndex The index of the column to check.
      * @param filterBuilder filter builder used to report error, if any.
      * @return The parameter string.
      */
-    public String getFilterPushdownParam(
+    private String getJdoFilterPushdownParam(
         Table table, int partColIndex, FilterBuilder filterBuilder) throws MetaException {
-      boolean isIntegralSupported = doesOperatorSupportIntegral(operator);
+      boolean isIntegralSupported = canJdoUseStringsWithIntegral();
       String colType = table.getPartitionKeys().get(partColIndex).getType();
       // Can only support partitions whose types are string, or maybe integers
       if (!colType.equals(serdeConstants.STRING_TYPE_NAME)
-          && (!isIntegralSupported || !isIntegralType(colType))) {
+          && (!isIntegralSupported || !serdeConstants.IntegralTypes.contains(colType))) {
         filterBuilder.setError("Filtering is supported only on partition keys of type " +
             "string" + (isIntegralSupported ? ", or integral types" : ""));
         return null;
diff --git a/src/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java b/src/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
index 80fbbac..9c6cb14 100644
--- a/src/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
+++ b/src/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
@@ -2019,6 +2019,17 @@ public void testPartitionFilter() throws Exception {
     checkFilter(client, dbName, tblName, "p1 like \"p1.*\"", 6);
     checkFilter(client, dbName, tblName, "p2 like \"p.*3\"", 1);
 
+    // Test gt/lt/lte/gte for numbers.
+    checkFilter(client, dbName, tblName, "p3 < 0", 1);
+    checkFilter(client, dbName, tblName, "p3 >= -33", 6);
+    checkFilter(client, dbName, tblName, "p3 > -33", 5);
+    checkFilter(client, dbName, tblName, "p3 > 31 and p3 < 32", 0);
+    checkFilter(client, dbName, tblName, "p3 > 31 or p3 < 31", 3);
+    checkFilter(client, dbName, tblName, "p3 > 30 or p3 < 30", 6);
+    checkFilter(client, dbName, tblName, "p3 >= 31 or p3 < -32", 6);
+    checkFilter(client, dbName, tblName, "p3 >= 32", 2);
+    checkFilter(client, dbName, tblName, "p3 > 32", 0);
+
     //Test for setting the maximum partition count
     List<Partition> partitions = client.listPartitionsByFilter(dbName,
         tblName, "p1 >= \"p12\"", (short) 2);
@@ -2037,17 +2048,6 @@ public void testPartitionFilter() throws Exception {
     assertTrue("Filter on int partition key", me.getMessage().contains(
           "Filtering is supported only on partition keys of type string"));
 
-    try {
-      client.listPartitionsByFilter(dbName,
-          tblName, "p3 >= 31", (short) -1);
-    } catch(MetaException e) {
-      me = e;
-    }
-    assertNotNull(me);
-    assertTrue("Filter on int partition key", me.getMessage().contains(
-          "Filtering is supported only on partition keys of type string"));
-
-
     me = null;
     try {
       client.listPartitionsByFilter(dbName,
diff --git a/src/ql/src/test/org/apache/hadoop/hive/metastore/TestMetastoreExpr.java b/src/ql/src/test/org/apache/hadoop/hive/metastore/TestMetastoreExpr.java
new file mode 100644
index 0000000..03492e2
--- /dev/null
+++ b/src/ql/src/test/org/apache/hadoop/hive/metastore/TestMetastoreExpr.java
@@ -0,0 +1,262 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.metastore;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Stack;
+
+import junit.framework.TestCase;
+
+
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.metastore.api.AlreadyExistsException;
+import org.apache.hadoop.hive.metastore.api.Database;
+import org.apache.hadoop.hive.metastore.api.FieldSchema;
+import org.apache.hadoop.hive.metastore.api.InvalidObjectException;
+import org.apache.hadoop.hive.metastore.api.InvalidOperationException;
+import org.apache.hadoop.hive.metastore.api.MetaException;
+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;
+import org.apache.hadoop.hive.metastore.api.Order;
+import org.apache.hadoop.hive.metastore.api.Partition;
+import org.apache.hadoop.hive.metastore.api.SerDeInfo;
+import org.apache.hadoop.hive.metastore.api.StorageDescriptor;
+import org.apache.hadoop.hive.metastore.api.Table;
+import org.apache.hadoop.hive.ql.exec.FunctionRegistry;
+import org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc;
+import org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc;
+import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
+import org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc;
+import org.apache.hadoop.hive.ql.exec.Utilities;
+import org.apache.hadoop.hive.serde.serdeConstants;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.util.StringUtils;
+import org.apache.thrift.TException;
+
+import com.google.common.collect.Lists;
+
+/** 
+ * Tests hive metastore expression support. This should be moved in metastore module
+ * as soon as we are able to use ql from metastore server (requires splitting metastore
+ * server and client).
+ * This is a "companion" test to test to TestHiveMetaStore#testPartitionFilter; thus,
+ * it doesn't test all the edge cases of the filter (if classes were merged, perhaps the
+ * filter test could be rolled into it); assumption is that they use the same path in SQL/JDO.
+ */
+public class TestMetastoreExpr extends TestCase {
+  protected static HiveMetaStoreClient client;
+
+  @Override
+  protected void tearDown() throws Exception {
+    try {
+      super.tearDown();
+      client.close();
+    } catch (Throwable e) {
+      System.err.println("Unable to close metastore");
+      System.err.println(StringUtils.stringifyException(e));
+      throw new Exception(e);
+    }
+  }
+
+  @Override
+  protected void setUp() throws Exception {
+    super.setUp();
+    try {
+      client = new HiveMetaStoreClient(new HiveConf(this.getClass()), null);
+    } catch (Throwable e) {
+      System.err.println("Unable to open the metastore");
+      System.err.println(StringUtils.stringifyException(e));
+      throw new Exception(e);
+    }
+  }
+
+  private static void silentDropDatabase(String dbName) throws MetaException, TException {
+    try {
+      for (String tableName : client.getTables(dbName, "*")) {
+        client.dropTable(dbName, tableName);
+      }
+      client.dropDatabase(dbName);
+    } catch (NoSuchObjectException e) {
+    } catch (InvalidOperationException e) {
+    }
+  }
+
+  public void testPartitionExpr() throws Exception {
+    String dbName = "filterdb";
+    String tblName = "filtertbl";
+
+    silentDropDatabase(dbName);
+    Database db = new Database();
+    db.setName(dbName);
+    client.createDatabase(db);
+
+    ArrayList<FieldSchema> cols = new ArrayList<FieldSchema>(2);
+    cols.add(new FieldSchema("c1", serdeConstants.STRING_TYPE_NAME, ""));
+    cols.add(new FieldSchema("c2", serdeConstants.INT_TYPE_NAME, ""));
+    ArrayList<FieldSchema> partCols = Lists.newArrayList(
+        new FieldSchema("p1", serdeConstants.STRING_TYPE_NAME, ""),
+        new FieldSchema("p2", serdeConstants.INT_TYPE_NAME, ""));
+
+    Table tbl = new Table();
+    tbl.setDbName(dbName);
+    tbl.setTableName(tblName);
+    addSd(cols, tbl);
+
+    tbl.setPartitionKeys(partCols);
+    client.createTable(tbl);
+    tbl = client.getTable(dbName, tblName);
+
+    addPartition(client, tbl, Lists.newArrayList("p11", "32"), "part1");
+    addPartition(client, tbl, Lists.newArrayList("p12", "32"), "part2");
+    addPartition(client, tbl, Lists.newArrayList("p13", "31"), "part3");
+    addPartition(client, tbl, Lists.newArrayList("p14", "-33"), "part4");
+
+    ExprBuilder e = new ExprBuilder(tblName);
+
+    checkExpr(3, dbName, tblName, e.val(0).intCol("p2").pred(">", 2).build());
+    checkExpr(3, dbName, tblName, e.intCol("p2").val(0).pred("<", 2).build());
+    checkExpr(1, dbName, tblName, e.intCol("p2").val(0).pred(">", 2).build());
+    checkExpr(2, dbName, tblName, e.val(31).intCol("p2").pred("<=", 2).build());
+    checkExpr(3, dbName, tblName, e.val("p11").strCol("p1").pred(">", 2).build());
+    checkExpr(1, dbName, tblName, e.val("p11").strCol("p1").pred(">", 2)
+        .intCol("p2").val(31).pred("<", 2).pred("and", 2).build());
+
+    // Apply between, isnull and instr (not supported by pushdown) via name filtering.
+    checkExpr(3, dbName, tblName,
+        e.val(32).val(31).intCol("p2").val(false).pred("between", 4).build());
+    checkExpr(4, dbName, tblName, e.val("p").strCol("p1")
+        .fn("instr", TypeInfoFactory.intTypeInfo, 2).val(0).pred("<=", 2).build());
+    checkExpr(0, dbName, tblName, e.intCol("p2").pred("isnull", 1).build());
+
+    // Cannot deserialize => throw the specific exception.
+    try {
+      client.listPartitionsByExpr(dbName, tblName,
+          new byte[] { 'f', 'o', 'o' }, null, (short)-1, new ArrayList<Partition>());
+      fail("Should have thrown IncompatibleMetastoreException");
+    } catch (IMetaStoreClient.IncompatibleMetastoreException ex) {
+    }
+
+    // Invalid expression => throw some exception, but not incompatible metastore.
+    try {
+      checkExpr(-1, dbName, tblName, e.val(31).intCol("p3").pred(">", 2).build());
+      fail("Should have thrown");
+    } catch (IMetaStoreClient.IncompatibleMetastoreException ex) {
+      fail("Should not have thrown IncompatibleMetastoreException");
+    } catch (Exception ex) {
+    }
+  }
+
+  public void checkExpr(int numParts,
+      String dbName, String tblName, ExprNodeDesc expr) throws Exception {
+    List<Partition> parts = new ArrayList<Partition>();
+    client.listPartitionsByExpr(
+        dbName, tblName, Utilities.serializeExpressionToKryo(expr), null, (short)-1, parts);
+    assertEquals("Partition check failed: " + expr.getExprString(), numParts, parts.size());
+  }
+
+  private static class ExprBuilder {
+    private final String tblName;
+    private final Stack<ExprNodeDesc> stack = new Stack<ExprNodeDesc>();
+
+    public ExprBuilder(String tblName) {
+      this.tblName = tblName;
+    }
+
+    public ExprNodeDesc build() throws Exception {
+      if (stack.size() != 1) throw new Exception("Bad test: " + stack.size());
+      return stack.pop();
+    }
+
+    public ExprBuilder pred(String name, int args) {
+      return fn(name, TypeInfoFactory.booleanTypeInfo, args);
+    }
+
+    private ExprBuilder fn(String name, TypeInfo ti, int args) {
+      List<ExprNodeDesc> children = new ArrayList<ExprNodeDesc>();
+      for (int i = 0; i < args; ++i) {
+        children.add(stack.pop());
+      }
+      stack.push(new ExprNodeGenericFuncDesc(TypeInfoFactory.booleanTypeInfo,
+          FunctionRegistry.getFunctionInfo(name).getGenericUDF(), children));
+      return this;
+    }
+
+    public ExprBuilder strCol(String col) {
+      return colInternal(TypeInfoFactory.stringTypeInfo, col, true);
+    }
+    public ExprBuilder intCol(String col) {
+      return colInternal(TypeInfoFactory.intTypeInfo, col, true);
+    }
+    public ExprBuilder npCol(String col) {
+      return colInternal(TypeInfoFactory.stringTypeInfo, col, false);
+    }
+    private ExprBuilder colInternal(TypeInfo ti, String col, boolean part) {
+      stack.push(new ExprNodeColumnDesc(ti, col, tblName, part));
+      return this;
+    }
+
+    public ExprBuilder val(String val) {
+      return valInternal(TypeInfoFactory.stringTypeInfo, val);
+    }
+    public ExprBuilder val(int val) {
+      return valInternal(TypeInfoFactory.intTypeInfo, val);
+    }
+    public ExprBuilder val(boolean val) {
+      return valInternal(TypeInfoFactory.booleanTypeInfo, val);
+    }
+    private ExprBuilder valInternal(TypeInfo ti, Object val) {
+      stack.push(new ExprNodeConstantDesc(ti, val));
+      return this;
+    }
+  }
+
+  private void addSd(ArrayList<FieldSchema> cols, Table tbl) {
+    StorageDescriptor sd = new StorageDescriptor();
+    sd.setCols(cols);
+    sd.setCompressed(false);
+    sd.setNumBuckets(1);
+    sd.setParameters(new HashMap<String, String>());
+    sd.setBucketCols(new ArrayList<String>());
+    sd.setSerdeInfo(new SerDeInfo());
+    sd.getSerdeInfo().setName(tbl.getTableName());
+    sd.getSerdeInfo().setParameters(new HashMap<String, String>());
+    sd.getSerdeInfo().getParameters()
+        .put(serdeConstants.SERIALIZATION_FORMAT, "1");
+    sd.setSortCols(new ArrayList<Order>());
+    tbl.setSd(sd);
+  }
+
+  private void addPartition(HiveMetaStoreClient client, Table table,
+      List<String> vals, String location) throws InvalidObjectException,
+        AlreadyExistsException, MetaException, TException {
+
+    Partition part = new Partition();
+    part.setDbName(table.getDbName());
+    part.setTableName(table.getTableName());
+    part.setValues(vals);
+    part.setParameters(new HashMap<String, String>());
+    part.setSd(table.getSd());
+    part.getSd().setSerdeInfo(table.getSd().getSerdeInfo());
+    part.getSd().setLocation(table.getSd().getLocation() + location);
+
+    client.add_partition(part);
+  }
+}
diff --git a/src/ql/src/test/queries/clientpositive/filter_numeric.q b/src/ql/src/test/queries/clientpositive/filter_numeric.q
new file mode 100644
index 0000000..192730e
--- /dev/null
+++ b/src/ql/src/test/queries/clientpositive/filter_numeric.q
@@ -0,0 +1,15 @@
+set hive.exec.dynamic.partition.mode=nonstrict;
+
+create table partint(key string, value string) partitioned by (ds string, hr int);
+insert overwrite table partint partition(ds, hr) select * from srcpart where ds = '2008-04-08';
+
+explain select key, value, hr from partint where hr < 11;
+select key, value, hr from partint where hr < 11;
+
+explain select key, value, hr from partint where hr <= 12 and hr > 11;
+select key, value, hr from partint where hr <= 12 and hr > 11;
+
+explain select key, value, hr from partint where hr < 13;
+select key, value, hr from partint where hr < 13;
+
+drop table partint;
\ No newline at end of file
diff --git a/src/ql/src/test/results/clientpositive/filter_numeric.q.out b/src/ql/src/test/results/clientpositive/filter_numeric.q.out
new file mode 100644
index 0000000..7be2ef4
--- /dev/null
+++ b/src/ql/src/test/results/clientpositive/filter_numeric.q.out
@@ -0,0 +1,1712 @@
+PREHOOK: query: create table partint(key string, value string) partitioned by (ds string, hr int)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table partint(key string, value string) partitioned by (ds string, hr int)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@partint
+PREHOOK: query: insert overwrite table partint partition(ds, hr) select * from srcpart where ds = '2008-04-08'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Output: default@partint
+POSTHOOK: query: insert overwrite table partint partition(ds, hr) select * from srcpart where ds = '2008-04-08'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Output: default@partint@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@partint@ds=2008-04-08/hr=12
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain select key, value, hr from partint where hr < 11
+PREHOOK: type: QUERY
+POSTHOOK: query: explain select key, value, hr from partint where hr < 11
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME partint))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL hr))) (TOK_WHERE (< (TOK_TABLE_OR_COL hr) 11))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        partint 
+          TableScan
+            alias: partint
+            Filter Operator
+              predicate:
+                  expr: (hr < 11)
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: string
+                      expr: value
+                      type: string
+                      expr: hr
+                      type: string
+                outputColumnNames: _col0, _col1, _col2
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 0
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+
+PREHOOK: query: select key, value, hr from partint where hr < 11
+PREHOOK: type: QUERY
+PREHOOK: Input: default@partint
+#### A masked pattern was here ####
+POSTHOOK: query: select key, value, hr from partint where hr < 11
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@partint
+#### A masked pattern was here ####
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain select key, value, hr from partint where hr <= 12 and hr > 11
+PREHOOK: type: QUERY
+POSTHOOK: query: explain select key, value, hr from partint where hr <= 12 and hr > 11
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME partint))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL hr))) (TOK_WHERE (and (<= (TOK_TABLE_OR_COL hr) 12) (> (TOK_TABLE_OR_COL hr) 11)))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        partint 
+          TableScan
+            alias: partint
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+                    expr: hr
+                    type: string
+              outputColumnNames: _col0, _col1, _col2
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+
+PREHOOK: query: select key, value, hr from partint where hr <= 12 and hr > 11
+PREHOOK: type: QUERY
+PREHOOK: Input: default@partint
+PREHOOK: Input: default@partint@ds=2008-04-08/hr=12
+#### A masked pattern was here ####
+POSTHOOK: query: select key, value, hr from partint where hr <= 12 and hr > 11
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@partint
+POSTHOOK: Input: default@partint@ds=2008-04-08/hr=12
+#### A masked pattern was here ####
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238	12
+86	val_86	12
+311	val_311	12
+27	val_27	12
+165	val_165	12
+409	val_409	12
+255	val_255	12
+278	val_278	12
+98	val_98	12
+484	val_484	12
+265	val_265	12
+193	val_193	12
+401	val_401	12
+150	val_150	12
+273	val_273	12
+224	val_224	12
+369	val_369	12
+66	val_66	12
+128	val_128	12
+213	val_213	12
+146	val_146	12
+406	val_406	12
+429	val_429	12
+374	val_374	12
+152	val_152	12
+469	val_469	12
+145	val_145	12
+495	val_495	12
+37	val_37	12
+327	val_327	12
+281	val_281	12
+277	val_277	12
+209	val_209	12
+15	val_15	12
+82	val_82	12
+403	val_403	12
+166	val_166	12
+417	val_417	12
+430	val_430	12
+252	val_252	12
+292	val_292	12
+219	val_219	12
+287	val_287	12
+153	val_153	12
+193	val_193	12
+338	val_338	12
+446	val_446	12
+459	val_459	12
+394	val_394	12
+237	val_237	12
+482	val_482	12
+174	val_174	12
+413	val_413	12
+494	val_494	12
+207	val_207	12
+199	val_199	12
+466	val_466	12
+208	val_208	12
+174	val_174	12
+399	val_399	12
+396	val_396	12
+247	val_247	12
+417	val_417	12
+489	val_489	12
+162	val_162	12
+377	val_377	12
+397	val_397	12
+309	val_309	12
+365	val_365	12
+266	val_266	12
+439	val_439	12
+342	val_342	12
+367	val_367	12
+325	val_325	12
+167	val_167	12
+195	val_195	12
+475	val_475	12
+17	val_17	12
+113	val_113	12
+155	val_155	12
+203	val_203	12
+339	val_339	12
+0	val_0	12
+455	val_455	12
+128	val_128	12
+311	val_311	12
+316	val_316	12
+57	val_57	12
+302	val_302	12
+205	val_205	12
+149	val_149	12
+438	val_438	12
+345	val_345	12
+129	val_129	12
+170	val_170	12
+20	val_20	12
+489	val_489	12
+157	val_157	12
+378	val_378	12
+221	val_221	12
+92	val_92	12
+111	val_111	12
+47	val_47	12
+72	val_72	12
+4	val_4	12
+280	val_280	12
+35	val_35	12
+427	val_427	12
+277	val_277	12
+208	val_208	12
+356	val_356	12
+399	val_399	12
+169	val_169	12
+382	val_382	12
+498	val_498	12
+125	val_125	12
+386	val_386	12
+437	val_437	12
+469	val_469	12
+192	val_192	12
+286	val_286	12
+187	val_187	12
+176	val_176	12
+54	val_54	12
+459	val_459	12
+51	val_51	12
+138	val_138	12
+103	val_103	12
+239	val_239	12
+213	val_213	12
+216	val_216	12
+430	val_430	12
+278	val_278	12
+176	val_176	12
+289	val_289	12
+221	val_221	12
+65	val_65	12
+318	val_318	12
+332	val_332	12
+311	val_311	12
+275	val_275	12
+137	val_137	12
+241	val_241	12
+83	val_83	12
+333	val_333	12
+180	val_180	12
+284	val_284	12
+12	val_12	12
+230	val_230	12
+181	val_181	12
+67	val_67	12
+260	val_260	12
+404	val_404	12
+384	val_384	12
+489	val_489	12
+353	val_353	12
+373	val_373	12
+272	val_272	12
+138	val_138	12
+217	val_217	12
+84	val_84	12
+348	val_348	12
+466	val_466	12
+58	val_58	12
+8	val_8	12
+411	val_411	12
+230	val_230	12
+208	val_208	12
+348	val_348	12
+24	val_24	12
+463	val_463	12
+431	val_431	12
+179	val_179	12
+172	val_172	12
+42	val_42	12
+129	val_129	12
+158	val_158	12
+119	val_119	12
+496	val_496	12
+0	val_0	12
+322	val_322	12
+197	val_197	12
+468	val_468	12
+393	val_393	12
+454	val_454	12
+100	val_100	12
+298	val_298	12
+199	val_199	12
+191	val_191	12
+418	val_418	12
+96	val_96	12
+26	val_26	12
+165	val_165	12
+327	val_327	12
+230	val_230	12
+205	val_205	12
+120	val_120	12
+131	val_131	12
+51	val_51	12
+404	val_404	12
+43	val_43	12
+436	val_436	12
+156	val_156	12
+469	val_469	12
+468	val_468	12
+308	val_308	12
+95	val_95	12
+196	val_196	12
+288	val_288	12
+481	val_481	12
+457	val_457	12
+98	val_98	12
+282	val_282	12
+197	val_197	12
+187	val_187	12
+318	val_318	12
+318	val_318	12
+409	val_409	12
+470	val_470	12
+137	val_137	12
+369	val_369	12
+316	val_316	12
+169	val_169	12
+413	val_413	12
+85	val_85	12
+77	val_77	12
+0	val_0	12
+490	val_490	12
+87	val_87	12
+364	val_364	12
+179	val_179	12
+118	val_118	12
+134	val_134	12
+395	val_395	12
+282	val_282	12
+138	val_138	12
+238	val_238	12
+419	val_419	12
+15	val_15	12
+118	val_118	12
+72	val_72	12
+90	val_90	12
+307	val_307	12
+19	val_19	12
+435	val_435	12
+10	val_10	12
+277	val_277	12
+273	val_273	12
+306	val_306	12
+224	val_224	12
+309	val_309	12
+389	val_389	12
+327	val_327	12
+242	val_242	12
+369	val_369	12
+392	val_392	12
+272	val_272	12
+331	val_331	12
+401	val_401	12
+242	val_242	12
+452	val_452	12
+177	val_177	12
+226	val_226	12
+5	val_5	12
+497	val_497	12
+402	val_402	12
+396	val_396	12
+317	val_317	12
+395	val_395	12
+58	val_58	12
+35	val_35	12
+336	val_336	12
+95	val_95	12
+11	val_11	12
+168	val_168	12
+34	val_34	12
+229	val_229	12
+233	val_233	12
+143	val_143	12
+472	val_472	12
+322	val_322	12
+498	val_498	12
+160	val_160	12
+195	val_195	12
+42	val_42	12
+321	val_321	12
+430	val_430	12
+119	val_119	12
+489	val_489	12
+458	val_458	12
+78	val_78	12
+76	val_76	12
+41	val_41	12
+223	val_223	12
+492	val_492	12
+149	val_149	12
+449	val_449	12
+218	val_218	12
+228	val_228	12
+138	val_138	12
+453	val_453	12
+30	val_30	12
+209	val_209	12
+64	val_64	12
+468	val_468	12
+76	val_76	12
+74	val_74	12
+342	val_342	12
+69	val_69	12
+230	val_230	12
+33	val_33	12
+368	val_368	12
+103	val_103	12
+296	val_296	12
+113	val_113	12
+216	val_216	12
+367	val_367	12
+344	val_344	12
+167	val_167	12
+274	val_274	12
+219	val_219	12
+239	val_239	12
+485	val_485	12
+116	val_116	12
+223	val_223	12
+256	val_256	12
+263	val_263	12
+70	val_70	12
+487	val_487	12
+480	val_480	12
+401	val_401	12
+288	val_288	12
+191	val_191	12
+5	val_5	12
+244	val_244	12
+438	val_438	12
+128	val_128	12
+467	val_467	12
+432	val_432	12
+202	val_202	12
+316	val_316	12
+229	val_229	12
+469	val_469	12
+463	val_463	12
+280	val_280	12
+2	val_2	12
+35	val_35	12
+283	val_283	12
+331	val_331	12
+235	val_235	12
+80	val_80	12
+44	val_44	12
+193	val_193	12
+321	val_321	12
+335	val_335	12
+104	val_104	12
+466	val_466	12
+366	val_366	12
+175	val_175	12
+403	val_403	12
+483	val_483	12
+53	val_53	12
+105	val_105	12
+257	val_257	12
+406	val_406	12
+409	val_409	12
+190	val_190	12
+406	val_406	12
+401	val_401	12
+114	val_114	12
+258	val_258	12
+90	val_90	12
+203	val_203	12
+262	val_262	12
+348	val_348	12
+424	val_424	12
+12	val_12	12
+396	val_396	12
+201	val_201	12
+217	val_217	12
+164	val_164	12
+431	val_431	12
+454	val_454	12
+478	val_478	12
+298	val_298	12
+125	val_125	12
+431	val_431	12
+164	val_164	12
+424	val_424	12
+187	val_187	12
+382	val_382	12
+5	val_5	12
+70	val_70	12
+397	val_397	12
+480	val_480	12
+291	val_291	12
+24	val_24	12
+351	val_351	12
+255	val_255	12
+104	val_104	12
+70	val_70	12
+163	val_163	12
+438	val_438	12
+119	val_119	12
+414	val_414	12
+200	val_200	12
+491	val_491	12
+237	val_237	12
+439	val_439	12
+360	val_360	12
+248	val_248	12
+479	val_479	12
+305	val_305	12
+417	val_417	12
+199	val_199	12
+444	val_444	12
+120	val_120	12
+429	val_429	12
+169	val_169	12
+443	val_443	12
+323	val_323	12
+325	val_325	12
+277	val_277	12
+230	val_230	12
+478	val_478	12
+178	val_178	12
+468	val_468	12
+310	val_310	12
+317	val_317	12
+333	val_333	12
+493	val_493	12
+460	val_460	12
+207	val_207	12
+249	val_249	12
+265	val_265	12
+480	val_480	12
+83	val_83	12
+136	val_136	12
+353	val_353	12
+172	val_172	12
+214	val_214	12
+462	val_462	12
+233	val_233	12
+406	val_406	12
+133	val_133	12
+175	val_175	12
+189	val_189	12
+454	val_454	12
+375	val_375	12
+401	val_401	12
+421	val_421	12
+407	val_407	12
+384	val_384	12
+256	val_256	12
+26	val_26	12
+134	val_134	12
+67	val_67	12
+384	val_384	12
+379	val_379	12
+18	val_18	12
+462	val_462	12
+492	val_492	12
+100	val_100	12
+298	val_298	12
+9	val_9	12
+341	val_341	12
+498	val_498	12
+146	val_146	12
+458	val_458	12
+362	val_362	12
+186	val_186	12
+285	val_285	12
+348	val_348	12
+167	val_167	12
+18	val_18	12
+273	val_273	12
+183	val_183	12
+281	val_281	12
+344	val_344	12
+97	val_97	12
+469	val_469	12
+315	val_315	12
+84	val_84	12
+28	val_28	12
+37	val_37	12
+448	val_448	12
+152	val_152	12
+348	val_348	12
+307	val_307	12
+194	val_194	12
+414	val_414	12
+477	val_477	12
+222	val_222	12
+126	val_126	12
+90	val_90	12
+169	val_169	12
+403	val_403	12
+400	val_400	12
+200	val_200	12
+97	val_97	12
+PREHOOK: query: explain select key, value, hr from partint where hr < 13
+PREHOOK: type: QUERY
+POSTHOOK: query: explain select key, value, hr from partint where hr < 13
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME partint))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL hr))) (TOK_WHERE (< (TOK_TABLE_OR_COL hr) 13))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        partint 
+          TableScan
+            alias: partint
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+                    expr: hr
+                    type: string
+              outputColumnNames: _col0, _col1, _col2
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+
+PREHOOK: query: select key, value, hr from partint where hr < 13
+PREHOOK: type: QUERY
+PREHOOK: Input: default@partint
+PREHOOK: Input: default@partint@ds=2008-04-08/hr=11
+PREHOOK: Input: default@partint@ds=2008-04-08/hr=12
+#### A masked pattern was here ####
+POSTHOOK: query: select key, value, hr from partint where hr < 13
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@partint
+POSTHOOK: Input: default@partint@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@partint@ds=2008-04-08/hr=12
+#### A masked pattern was here ####
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238	11
+86	val_86	11
+311	val_311	11
+27	val_27	11
+165	val_165	11
+409	val_409	11
+255	val_255	11
+278	val_278	11
+98	val_98	11
+484	val_484	11
+265	val_265	11
+193	val_193	11
+401	val_401	11
+150	val_150	11
+273	val_273	11
+224	val_224	11
+369	val_369	11
+66	val_66	11
+128	val_128	11
+213	val_213	11
+146	val_146	11
+406	val_406	11
+429	val_429	11
+374	val_374	11
+152	val_152	11
+469	val_469	11
+145	val_145	11
+495	val_495	11
+37	val_37	11
+327	val_327	11
+281	val_281	11
+277	val_277	11
+209	val_209	11
+15	val_15	11
+82	val_82	11
+403	val_403	11
+166	val_166	11
+417	val_417	11
+430	val_430	11
+252	val_252	11
+292	val_292	11
+219	val_219	11
+287	val_287	11
+153	val_153	11
+193	val_193	11
+338	val_338	11
+446	val_446	11
+459	val_459	11
+394	val_394	11
+237	val_237	11
+482	val_482	11
+174	val_174	11
+413	val_413	11
+494	val_494	11
+207	val_207	11
+199	val_199	11
+466	val_466	11
+208	val_208	11
+174	val_174	11
+399	val_399	11
+396	val_396	11
+247	val_247	11
+417	val_417	11
+489	val_489	11
+162	val_162	11
+377	val_377	11
+397	val_397	11
+309	val_309	11
+365	val_365	11
+266	val_266	11
+439	val_439	11
+342	val_342	11
+367	val_367	11
+325	val_325	11
+167	val_167	11
+195	val_195	11
+475	val_475	11
+17	val_17	11
+113	val_113	11
+155	val_155	11
+203	val_203	11
+339	val_339	11
+0	val_0	11
+455	val_455	11
+128	val_128	11
+311	val_311	11
+316	val_316	11
+57	val_57	11
+302	val_302	11
+205	val_205	11
+149	val_149	11
+438	val_438	11
+345	val_345	11
+129	val_129	11
+170	val_170	11
+20	val_20	11
+489	val_489	11
+157	val_157	11
+378	val_378	11
+221	val_221	11
+92	val_92	11
+111	val_111	11
+47	val_47	11
+72	val_72	11
+4	val_4	11
+280	val_280	11
+35	val_35	11
+427	val_427	11
+277	val_277	11
+208	val_208	11
+356	val_356	11
+399	val_399	11
+169	val_169	11
+382	val_382	11
+498	val_498	11
+125	val_125	11
+386	val_386	11
+437	val_437	11
+469	val_469	11
+192	val_192	11
+286	val_286	11
+187	val_187	11
+176	val_176	11
+54	val_54	11
+459	val_459	11
+51	val_51	11
+138	val_138	11
+103	val_103	11
+239	val_239	11
+213	val_213	11
+216	val_216	11
+430	val_430	11
+278	val_278	11
+176	val_176	11
+289	val_289	11
+221	val_221	11
+65	val_65	11
+318	val_318	11
+332	val_332	11
+311	val_311	11
+275	val_275	11
+137	val_137	11
+241	val_241	11
+83	val_83	11
+333	val_333	11
+180	val_180	11
+284	val_284	11
+12	val_12	11
+230	val_230	11
+181	val_181	11
+67	val_67	11
+260	val_260	11
+404	val_404	11
+384	val_384	11
+489	val_489	11
+353	val_353	11
+373	val_373	11
+272	val_272	11
+138	val_138	11
+217	val_217	11
+84	val_84	11
+348	val_348	11
+466	val_466	11
+58	val_58	11
+8	val_8	11
+411	val_411	11
+230	val_230	11
+208	val_208	11
+348	val_348	11
+24	val_24	11
+463	val_463	11
+431	val_431	11
+179	val_179	11
+172	val_172	11
+42	val_42	11
+129	val_129	11
+158	val_158	11
+119	val_119	11
+496	val_496	11
+0	val_0	11
+322	val_322	11
+197	val_197	11
+468	val_468	11
+393	val_393	11
+454	val_454	11
+100	val_100	11
+298	val_298	11
+199	val_199	11
+191	val_191	11
+418	val_418	11
+96	val_96	11
+26	val_26	11
+165	val_165	11
+327	val_327	11
+230	val_230	11
+205	val_205	11
+120	val_120	11
+131	val_131	11
+51	val_51	11
+404	val_404	11
+43	val_43	11
+436	val_436	11
+156	val_156	11
+469	val_469	11
+468	val_468	11
+308	val_308	11
+95	val_95	11
+196	val_196	11
+288	val_288	11
+481	val_481	11
+457	val_457	11
+98	val_98	11
+282	val_282	11
+197	val_197	11
+187	val_187	11
+318	val_318	11
+318	val_318	11
+409	val_409	11
+470	val_470	11
+137	val_137	11
+369	val_369	11
+316	val_316	11
+169	val_169	11
+413	val_413	11
+85	val_85	11
+77	val_77	11
+0	val_0	11
+490	val_490	11
+87	val_87	11
+364	val_364	11
+179	val_179	11
+118	val_118	11
+134	val_134	11
+395	val_395	11
+282	val_282	11
+138	val_138	11
+238	val_238	11
+419	val_419	11
+15	val_15	11
+118	val_118	11
+72	val_72	11
+90	val_90	11
+307	val_307	11
+19	val_19	11
+435	val_435	11
+10	val_10	11
+277	val_277	11
+273	val_273	11
+306	val_306	11
+224	val_224	11
+309	val_309	11
+389	val_389	11
+327	val_327	11
+242	val_242	11
+369	val_369	11
+392	val_392	11
+272	val_272	11
+331	val_331	11
+401	val_401	11
+242	val_242	11
+452	val_452	11
+177	val_177	11
+226	val_226	11
+5	val_5	11
+497	val_497	11
+402	val_402	11
+396	val_396	11
+317	val_317	11
+395	val_395	11
+58	val_58	11
+35	val_35	11
+336	val_336	11
+95	val_95	11
+11	val_11	11
+168	val_168	11
+34	val_34	11
+229	val_229	11
+233	val_233	11
+143	val_143	11
+472	val_472	11
+322	val_322	11
+498	val_498	11
+160	val_160	11
+195	val_195	11
+42	val_42	11
+321	val_321	11
+430	val_430	11
+119	val_119	11
+489	val_489	11
+458	val_458	11
+78	val_78	11
+76	val_76	11
+41	val_41	11
+223	val_223	11
+492	val_492	11
+149	val_149	11
+449	val_449	11
+218	val_218	11
+228	val_228	11
+138	val_138	11
+453	val_453	11
+30	val_30	11
+209	val_209	11
+64	val_64	11
+468	val_468	11
+76	val_76	11
+74	val_74	11
+342	val_342	11
+69	val_69	11
+230	val_230	11
+33	val_33	11
+368	val_368	11
+103	val_103	11
+296	val_296	11
+113	val_113	11
+216	val_216	11
+367	val_367	11
+344	val_344	11
+167	val_167	11
+274	val_274	11
+219	val_219	11
+239	val_239	11
+485	val_485	11
+116	val_116	11
+223	val_223	11
+256	val_256	11
+263	val_263	11
+70	val_70	11
+487	val_487	11
+480	val_480	11
+401	val_401	11
+288	val_288	11
+191	val_191	11
+5	val_5	11
+244	val_244	11
+438	val_438	11
+128	val_128	11
+467	val_467	11
+432	val_432	11
+202	val_202	11
+316	val_316	11
+229	val_229	11
+469	val_469	11
+463	val_463	11
+280	val_280	11
+2	val_2	11
+35	val_35	11
+283	val_283	11
+331	val_331	11
+235	val_235	11
+80	val_80	11
+44	val_44	11
+193	val_193	11
+321	val_321	11
+335	val_335	11
+104	val_104	11
+466	val_466	11
+366	val_366	11
+175	val_175	11
+403	val_403	11
+483	val_483	11
+53	val_53	11
+105	val_105	11
+257	val_257	11
+406	val_406	11
+409	val_409	11
+190	val_190	11
+406	val_406	11
+401	val_401	11
+114	val_114	11
+258	val_258	11
+90	val_90	11
+203	val_203	11
+262	val_262	11
+348	val_348	11
+424	val_424	11
+12	val_12	11
+396	val_396	11
+201	val_201	11
+217	val_217	11
+164	val_164	11
+431	val_431	11
+454	val_454	11
+478	val_478	11
+298	val_298	11
+125	val_125	11
+431	val_431	11
+164	val_164	11
+424	val_424	11
+187	val_187	11
+382	val_382	11
+5	val_5	11
+70	val_70	11
+397	val_397	11
+480	val_480	11
+291	val_291	11
+24	val_24	11
+351	val_351	11
+255	val_255	11
+104	val_104	11
+70	val_70	11
+163	val_163	11
+438	val_438	11
+119	val_119	11
+414	val_414	11
+200	val_200	11
+491	val_491	11
+237	val_237	11
+439	val_439	11
+360	val_360	11
+248	val_248	11
+479	val_479	11
+305	val_305	11
+417	val_417	11
+199	val_199	11
+444	val_444	11
+120	val_120	11
+429	val_429	11
+169	val_169	11
+443	val_443	11
+323	val_323	11
+325	val_325	11
+277	val_277	11
+230	val_230	11
+478	val_478	11
+178	val_178	11
+468	val_468	11
+310	val_310	11
+317	val_317	11
+333	val_333	11
+493	val_493	11
+460	val_460	11
+207	val_207	11
+249	val_249	11
+265	val_265	11
+480	val_480	11
+83	val_83	11
+136	val_136	11
+353	val_353	11
+172	val_172	11
+214	val_214	11
+462	val_462	11
+233	val_233	11
+406	val_406	11
+133	val_133	11
+175	val_175	11
+189	val_189	11
+454	val_454	11
+375	val_375	11
+401	val_401	11
+421	val_421	11
+407	val_407	11
+384	val_384	11
+256	val_256	11
+26	val_26	11
+134	val_134	11
+67	val_67	11
+384	val_384	11
+379	val_379	11
+18	val_18	11
+462	val_462	11
+492	val_492	11
+100	val_100	11
+298	val_298	11
+9	val_9	11
+341	val_341	11
+498	val_498	11
+146	val_146	11
+458	val_458	11
+362	val_362	11
+186	val_186	11
+285	val_285	11
+348	val_348	11
+167	val_167	11
+18	val_18	11
+273	val_273	11
+183	val_183	11
+281	val_281	11
+344	val_344	11
+97	val_97	11
+469	val_469	11
+315	val_315	11
+84	val_84	11
+28	val_28	11
+37	val_37	11
+448	val_448	11
+152	val_152	11
+348	val_348	11
+307	val_307	11
+194	val_194	11
+414	val_414	11
+477	val_477	11
+222	val_222	11
+126	val_126	11
+90	val_90	11
+169	val_169	11
+403	val_403	11
+400	val_400	11
+200	val_200	11
+97	val_97	11
+238	val_238	12
+86	val_86	12
+311	val_311	12
+27	val_27	12
+165	val_165	12
+409	val_409	12
+255	val_255	12
+278	val_278	12
+98	val_98	12
+484	val_484	12
+265	val_265	12
+193	val_193	12
+401	val_401	12
+150	val_150	12
+273	val_273	12
+224	val_224	12
+369	val_369	12
+66	val_66	12
+128	val_128	12
+213	val_213	12
+146	val_146	12
+406	val_406	12
+429	val_429	12
+374	val_374	12
+152	val_152	12
+469	val_469	12
+145	val_145	12
+495	val_495	12
+37	val_37	12
+327	val_327	12
+281	val_281	12
+277	val_277	12
+209	val_209	12
+15	val_15	12
+82	val_82	12
+403	val_403	12
+166	val_166	12
+417	val_417	12
+430	val_430	12
+252	val_252	12
+292	val_292	12
+219	val_219	12
+287	val_287	12
+153	val_153	12
+193	val_193	12
+338	val_338	12
+446	val_446	12
+459	val_459	12
+394	val_394	12
+237	val_237	12
+482	val_482	12
+174	val_174	12
+413	val_413	12
+494	val_494	12
+207	val_207	12
+199	val_199	12
+466	val_466	12
+208	val_208	12
+174	val_174	12
+399	val_399	12
+396	val_396	12
+247	val_247	12
+417	val_417	12
+489	val_489	12
+162	val_162	12
+377	val_377	12
+397	val_397	12
+309	val_309	12
+365	val_365	12
+266	val_266	12
+439	val_439	12
+342	val_342	12
+367	val_367	12
+325	val_325	12
+167	val_167	12
+195	val_195	12
+475	val_475	12
+17	val_17	12
+113	val_113	12
+155	val_155	12
+203	val_203	12
+339	val_339	12
+0	val_0	12
+455	val_455	12
+128	val_128	12
+311	val_311	12
+316	val_316	12
+57	val_57	12
+302	val_302	12
+205	val_205	12
+149	val_149	12
+438	val_438	12
+345	val_345	12
+129	val_129	12
+170	val_170	12
+20	val_20	12
+489	val_489	12
+157	val_157	12
+378	val_378	12
+221	val_221	12
+92	val_92	12
+111	val_111	12
+47	val_47	12
+72	val_72	12
+4	val_4	12
+280	val_280	12
+35	val_35	12
+427	val_427	12
+277	val_277	12
+208	val_208	12
+356	val_356	12
+399	val_399	12
+169	val_169	12
+382	val_382	12
+498	val_498	12
+125	val_125	12
+386	val_386	12
+437	val_437	12
+469	val_469	12
+192	val_192	12
+286	val_286	12
+187	val_187	12
+176	val_176	12
+54	val_54	12
+459	val_459	12
+51	val_51	12
+138	val_138	12
+103	val_103	12
+239	val_239	12
+213	val_213	12
+216	val_216	12
+430	val_430	12
+278	val_278	12
+176	val_176	12
+289	val_289	12
+221	val_221	12
+65	val_65	12
+318	val_318	12
+332	val_332	12
+311	val_311	12
+275	val_275	12
+137	val_137	12
+241	val_241	12
+83	val_83	12
+333	val_333	12
+180	val_180	12
+284	val_284	12
+12	val_12	12
+230	val_230	12
+181	val_181	12
+67	val_67	12
+260	val_260	12
+404	val_404	12
+384	val_384	12
+489	val_489	12
+353	val_353	12
+373	val_373	12
+272	val_272	12
+138	val_138	12
+217	val_217	12
+84	val_84	12
+348	val_348	12
+466	val_466	12
+58	val_58	12
+8	val_8	12
+411	val_411	12
+230	val_230	12
+208	val_208	12
+348	val_348	12
+24	val_24	12
+463	val_463	12
+431	val_431	12
+179	val_179	12
+172	val_172	12
+42	val_42	12
+129	val_129	12
+158	val_158	12
+119	val_119	12
+496	val_496	12
+0	val_0	12
+322	val_322	12
+197	val_197	12
+468	val_468	12
+393	val_393	12
+454	val_454	12
+100	val_100	12
+298	val_298	12
+199	val_199	12
+191	val_191	12
+418	val_418	12
+96	val_96	12
+26	val_26	12
+165	val_165	12
+327	val_327	12
+230	val_230	12
+205	val_205	12
+120	val_120	12
+131	val_131	12
+51	val_51	12
+404	val_404	12
+43	val_43	12
+436	val_436	12
+156	val_156	12
+469	val_469	12
+468	val_468	12
+308	val_308	12
+95	val_95	12
+196	val_196	12
+288	val_288	12
+481	val_481	12
+457	val_457	12
+98	val_98	12
+282	val_282	12
+197	val_197	12
+187	val_187	12
+318	val_318	12
+318	val_318	12
+409	val_409	12
+470	val_470	12
+137	val_137	12
+369	val_369	12
+316	val_316	12
+169	val_169	12
+413	val_413	12
+85	val_85	12
+77	val_77	12
+0	val_0	12
+490	val_490	12
+87	val_87	12
+364	val_364	12
+179	val_179	12
+118	val_118	12
+134	val_134	12
+395	val_395	12
+282	val_282	12
+138	val_138	12
+238	val_238	12
+419	val_419	12
+15	val_15	12
+118	val_118	12
+72	val_72	12
+90	val_90	12
+307	val_307	12
+19	val_19	12
+435	val_435	12
+10	val_10	12
+277	val_277	12
+273	val_273	12
+306	val_306	12
+224	val_224	12
+309	val_309	12
+389	val_389	12
+327	val_327	12
+242	val_242	12
+369	val_369	12
+392	val_392	12
+272	val_272	12
+331	val_331	12
+401	val_401	12
+242	val_242	12
+452	val_452	12
+177	val_177	12
+226	val_226	12
+5	val_5	12
+497	val_497	12
+402	val_402	12
+396	val_396	12
+317	val_317	12
+395	val_395	12
+58	val_58	12
+35	val_35	12
+336	val_336	12
+95	val_95	12
+11	val_11	12
+168	val_168	12
+34	val_34	12
+229	val_229	12
+233	val_233	12
+143	val_143	12
+472	val_472	12
+322	val_322	12
+498	val_498	12
+160	val_160	12
+195	val_195	12
+42	val_42	12
+321	val_321	12
+430	val_430	12
+119	val_119	12
+489	val_489	12
+458	val_458	12
+78	val_78	12
+76	val_76	12
+41	val_41	12
+223	val_223	12
+492	val_492	12
+149	val_149	12
+449	val_449	12
+218	val_218	12
+228	val_228	12
+138	val_138	12
+453	val_453	12
+30	val_30	12
+209	val_209	12
+64	val_64	12
+468	val_468	12
+76	val_76	12
+74	val_74	12
+342	val_342	12
+69	val_69	12
+230	val_230	12
+33	val_33	12
+368	val_368	12
+103	val_103	12
+296	val_296	12
+113	val_113	12
+216	val_216	12
+367	val_367	12
+344	val_344	12
+167	val_167	12
+274	val_274	12
+219	val_219	12
+239	val_239	12
+485	val_485	12
+116	val_116	12
+223	val_223	12
+256	val_256	12
+263	val_263	12
+70	val_70	12
+487	val_487	12
+480	val_480	12
+401	val_401	12
+288	val_288	12
+191	val_191	12
+5	val_5	12
+244	val_244	12
+438	val_438	12
+128	val_128	12
+467	val_467	12
+432	val_432	12
+202	val_202	12
+316	val_316	12
+229	val_229	12
+469	val_469	12
+463	val_463	12
+280	val_280	12
+2	val_2	12
+35	val_35	12
+283	val_283	12
+331	val_331	12
+235	val_235	12
+80	val_80	12
+44	val_44	12
+193	val_193	12
+321	val_321	12
+335	val_335	12
+104	val_104	12
+466	val_466	12
+366	val_366	12
+175	val_175	12
+403	val_403	12
+483	val_483	12
+53	val_53	12
+105	val_105	12
+257	val_257	12
+406	val_406	12
+409	val_409	12
+190	val_190	12
+406	val_406	12
+401	val_401	12
+114	val_114	12
+258	val_258	12
+90	val_90	12
+203	val_203	12
+262	val_262	12
+348	val_348	12
+424	val_424	12
+12	val_12	12
+396	val_396	12
+201	val_201	12
+217	val_217	12
+164	val_164	12
+431	val_431	12
+454	val_454	12
+478	val_478	12
+298	val_298	12
+125	val_125	12
+431	val_431	12
+164	val_164	12
+424	val_424	12
+187	val_187	12
+382	val_382	12
+5	val_5	12
+70	val_70	12
+397	val_397	12
+480	val_480	12
+291	val_291	12
+24	val_24	12
+351	val_351	12
+255	val_255	12
+104	val_104	12
+70	val_70	12
+163	val_163	12
+438	val_438	12
+119	val_119	12
+414	val_414	12
+200	val_200	12
+491	val_491	12
+237	val_237	12
+439	val_439	12
+360	val_360	12
+248	val_248	12
+479	val_479	12
+305	val_305	12
+417	val_417	12
+199	val_199	12
+444	val_444	12
+120	val_120	12
+429	val_429	12
+169	val_169	12
+443	val_443	12
+323	val_323	12
+325	val_325	12
+277	val_277	12
+230	val_230	12
+478	val_478	12
+178	val_178	12
+468	val_468	12
+310	val_310	12
+317	val_317	12
+333	val_333	12
+493	val_493	12
+460	val_460	12
+207	val_207	12
+249	val_249	12
+265	val_265	12
+480	val_480	12
+83	val_83	12
+136	val_136	12
+353	val_353	12
+172	val_172	12
+214	val_214	12
+462	val_462	12
+233	val_233	12
+406	val_406	12
+133	val_133	12
+175	val_175	12
+189	val_189	12
+454	val_454	12
+375	val_375	12
+401	val_401	12
+421	val_421	12
+407	val_407	12
+384	val_384	12
+256	val_256	12
+26	val_26	12
+134	val_134	12
+67	val_67	12
+384	val_384	12
+379	val_379	12
+18	val_18	12
+462	val_462	12
+492	val_492	12
+100	val_100	12
+298	val_298	12
+9	val_9	12
+341	val_341	12
+498	val_498	12
+146	val_146	12
+458	val_458	12
+362	val_362	12
+186	val_186	12
+285	val_285	12
+348	val_348	12
+167	val_167	12
+18	val_18	12
+273	val_273	12
+183	val_183	12
+281	val_281	12
+344	val_344	12
+97	val_97	12
+469	val_469	12
+315	val_315	12
+84	val_84	12
+28	val_28	12
+37	val_37	12
+448	val_448	12
+152	val_152	12
+348	val_348	12
+307	val_307	12
+194	val_194	12
+414	val_414	12
+477	val_477	12
+222	val_222	12
+126	val_126	12
+90	val_90	12
+169	val_169	12
+403	val_403	12
+400	val_400	12
+200	val_200	12
+97	val_97	12
+PREHOOK: query: drop table partint
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@partint
+PREHOOK: Output: default@partint
+POSTHOOK: query: drop table partint
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@partint
+POSTHOOK: Output: default@partint
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: partint PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
diff --git a/src/serde/if/serde.thrift b/src/serde/if/serde.thrift
index f1a6802..2ceb572 100644
--- a/src/serde/if/serde.thrift
+++ b/src/serde/if/serde.thrift
@@ -68,5 +68,6 @@ const string LIST_COLUMN_TYPES = "columns.types";
 
 const set<string> PrimitiveTypes  = [ VOID_TYPE_NAME BOOLEAN_TYPE_NAME TINYINT_TYPE_NAME SMALLINT_TYPE_NAME INT_TYPE_NAME BIGINT_TYPE_NAME FLOAT_TYPE_NAME DOUBLE_TYPE_NAME STRING_TYPE_NAME  VARCHAR_TYPE_NAME CHAR_TYPE_NAME DATE_TYPE_NAME DATETIME_TYPE_NAME TIMESTAMP_TYPE_NAME DECIMAL_TYPE_NAME BINARY_TYPE_NAME],
 const set<string> CollectionTypes = [ LIST_TYPE_NAME MAP_TYPE_NAME ],
+const set<string> IntegralTypes = [ TINYINT_TYPE_NAME SMALLINT_TYPE_NAME INT_TYPE_NAME BIGINT_TYPE_NAME ],
 
 
diff --git a/src/serde/src/gen/thrift/gen-cpp/serde_constants.cpp b/src/serde/src/gen/thrift/gen-cpp/serde_constants.cpp
index 86a24af..3ead1fd 100644
--- a/src/serde/src/gen/thrift/gen-cpp/serde_constants.cpp
+++ b/src/serde/src/gen/thrift/gen-cpp/serde_constants.cpp
@@ -103,6 +103,11 @@ serdeConstants::serdeConstants() {
   CollectionTypes.insert("array");
   CollectionTypes.insert("map");
 
+  IntegralTypes.insert("tinyint");
+  IntegralTypes.insert("smallint");
+  IntegralTypes.insert("int");
+  IntegralTypes.insert("bigint");
+
 }
 
 } // namespace
diff --git a/src/serde/src/gen/thrift/gen-cpp/serde_constants.h b/src/serde/src/gen/thrift/gen-cpp/serde_constants.h
index 117d6c6..37f0b8f 100644
--- a/src/serde/src/gen/thrift/gen-cpp/serde_constants.h
+++ b/src/serde/src/gen/thrift/gen-cpp/serde_constants.h
@@ -53,6 +53,7 @@ class serdeConstants {
   std::string LIST_COLUMN_TYPES;
   std::set<std::string>  PrimitiveTypes;
   std::set<std::string>  CollectionTypes;
+  std::set<std::string>  IntegralTypes;
 };
 
 extern const serdeConstants g_serde_constants;
diff --git a/src/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java b/src/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java
index 096f881..22a6168 100644
--- a/src/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java
+++ b/src/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java
@@ -131,4 +131,12 @@
     CollectionTypes.add("map");
   }
 
+  public static final Set<String> IntegralTypes = new HashSet<String>();
+  static {
+    IntegralTypes.add("tinyint");
+    IntegralTypes.add("smallint");
+    IntegralTypes.add("int");
+    IntegralTypes.add("bigint");
+  }
+
 }
diff --git a/src/serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php b/src/serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php
index 8a0b415..ecbee27 100644
--- a/src/serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php
+++ b/src/serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php
@@ -112,4 +112,11 @@ $GLOBALS['serde_CONSTANTS']['CollectionTypes'] = array(
   "map" => true,
 );
 
+$GLOBALS['serde_CONSTANTS']['IntegralTypes'] = array(
+  "tinyint" => true,
+  "smallint" => true,
+  "int" => true,
+  "bigint" => true,
+);
+
 
diff --git a/src/serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py b/src/serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py
index 47aab22..474b775 100644
--- a/src/serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py
+++ b/src/serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py
@@ -67,3 +67,9 @@
   "array",
   "map",
 ])
+IntegralTypes = set([
+  "tinyint",
+  "smallint",
+  "int",
+  "bigint",
+])
diff --git a/src/serde/src/gen/thrift/gen-rb/serde_constants.rb b/src/serde/src/gen/thrift/gen-rb/serde_constants.rb
index 200cefd..248418d 100644
--- a/src/serde/src/gen/thrift/gen-rb/serde_constants.rb
+++ b/src/serde/src/gen/thrift/gen-rb/serde_constants.rb
@@ -103,3 +103,10 @@ CollectionTypes = Set.new([
   %q"map",
 ])
 
+IntegralTypes = Set.new([
+  %q"tinyint",
+  %q"smallint",
+  %q"int",
+  %q"bigint",
+])
+
-- 
1.7.0.4

