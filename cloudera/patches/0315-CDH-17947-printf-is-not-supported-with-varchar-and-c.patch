From 97f24fca70eb137b963ee8dd9c265be6281fcb47 Mon Sep 17 00:00:00 2001
From: xzhang <xzhang@xzdt.(none)>
Date: Mon, 24 Mar 2014 12:15:54 -0700
Subject: [PATCH 315/375] CDH-17947: printf is not supported with varchar and char

---
 .../hive/ql/udf/generic/GenericUDFPrintf.java      |   76 +++++------
 .../hive/ql/udf/generic/TestGenericUDFPrintf.java  |  140 ++++++++++++++++++++
 2 files changed, 177 insertions(+), 39 deletions(-)
 create mode 100644 ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFPrintf.java

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java
index 505cf07..e9c0cc4 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java
@@ -29,18 +29,13 @@
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.Converter;
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.BooleanObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.ByteObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.FloatObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.ShortObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.TimestampObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableHiveDecimalObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableStringObjectInspector;
 import org.apache.hadoop.io.Text;
 
 /**
@@ -58,6 +53,8 @@
     + "  \"Hello World 100 days\"")
 public class GenericUDFPrintf extends GenericUDF {
   private transient ObjectInspector[] argumentOIs;
+  protected transient Converter converterFormat;
+
   private final Text resultText = new Text();
 
   @Override
@@ -67,12 +64,25 @@ public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumen
           "The function PRINTF(String format, Obj... args) needs at least one arguments.");
     }
 
-    if (arguments[0].getTypeName() != serdeConstants.STRING_TYPE_NAME
-      && arguments[0].getTypeName() != serdeConstants.VOID_TYPE_NAME) {
+    WritableStringObjectInspector resultOI = PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+
+    if (arguments[0].getCategory() == ObjectInspector.Category.PRIMITIVE) {
+      PrimitiveObjectInspector poi = ((PrimitiveObjectInspector) arguments[0]);
+      if (poi.getPrimitiveCategory() == PrimitiveObjectInspector.PrimitiveCategory.STRING ||
+          poi.getPrimitiveCategory() == PrimitiveObjectInspector.PrimitiveCategory.CHAR ||
+          poi.getPrimitiveCategory() == PrimitiveObjectInspector.PrimitiveCategory.VARCHAR ||
+          poi.getPrimitiveCategory() == PrimitiveObjectInspector.PrimitiveCategory.VOID) {
+        converterFormat = ObjectInspectorConverters.getConverter(arguments[0], resultOI);
+      } else {
         throw new UDFArgumentTypeException(0, "Argument 1"
-        + " of function PRINTF must be \"" + serdeConstants.STRING_TYPE_NAME
-        + "\", but \"" + arguments[0].getTypeName() + "\" was found.");
+            + " of function PRINTF must be \"" + serdeConstants.STRING_TYPE_NAME
+            + "\", but \"" + arguments[0].getTypeName() + "\" was found.");
       }
+    } else {
+      throw new UDFArgumentTypeException(0, "Argument 1"
+          + " of function PRINTF must be \"" + serdeConstants.STRING_TYPE_NAME
+          + "\", but \"" + arguments[0].getTypeName() + "\" was found.");
+    }
 
     for (int i = 1; i < arguments.length; i++) {
       if (!arguments[i].getCategory().equals(Category.PRIMITIVE)){
@@ -83,58 +93,46 @@ public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumen
     }
 
     argumentOIs = arguments;
-    return PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+    return resultOI;
   }
 
   @Override
   public Object evaluate(DeferredObject[] arguments) throws HiveException {
+    // If the first argument is null, return null. (It's okay for other arguments to be null, in
+    // which case, "null" will be printed.)
+    if (arguments[0].get() == null) {
+      return null;
+    }
+
     StringBuilder sb = new StringBuilder();
     Formatter formatter = new Formatter(sb, Locale.US);
 
-    String pattern = ((StringObjectInspector) argumentOIs[0])
-        .getPrimitiveJavaObject(arguments[0].get());
+    Text pattern = (Text)converterFormat.convert(arguments[0].get());
 
-    ArrayList argumentList = new ArrayList();
+    ArrayList<Object> argumentList = new ArrayList<Object>();
     for (int i = 1; i < arguments.length; i++) {
       switch (((PrimitiveObjectInspector)argumentOIs[i]).getPrimitiveCategory()) {
         case BOOLEAN:
-          argumentList.add(((BooleanObjectInspector)argumentOIs[i]).get(arguments[i].get()));
-          break;
         case BYTE:
-          argumentList.add(((ByteObjectInspector)argumentOIs[i]).get(arguments[i].get()));
-          break;
         case SHORT:
-          argumentList.add(((ShortObjectInspector)argumentOIs[i]).get(arguments[i].get()));
-          break;
         case INT:
-          argumentList.add(((IntObjectInspector)argumentOIs[i]).get(arguments[i].get()));
-          break;
         case LONG:
-          argumentList.add(((LongObjectInspector)argumentOIs[i]).get(arguments[i].get()));
-          break;
         case FLOAT:
-          argumentList.add(((FloatObjectInspector)argumentOIs[i]).get(arguments[i].get()));
-          break;
         case DOUBLE:
-          argumentList.add(((DoubleObjectInspector)argumentOIs[i]).get(arguments[i].get()));
-          break;
+        case CHAR:
+        case VARCHAR:
         case STRING:
-          argumentList.add(((StringObjectInspector)argumentOIs[i])
-            .getPrimitiveJavaObject(arguments[i].get()));
-          break;
         case TIMESTAMP:
-          argumentList.add(((TimestampObjectInspector)argumentOIs[i])
+        case DECIMAL:
+          argumentList.add(((PrimitiveObjectInspector)argumentOIs[i])
             .getPrimitiveJavaObject(arguments[i].get()));
           break;
-        case BINARY:
-          argumentList.add(arguments[i].get());
-          break;
         default:
           argumentList.add(arguments[i].get());
           break;
       }
     }
-    formatter.format(pattern, argumentList.toArray());
+    formatter.format(pattern.toString(), argumentList.toArray());
 
     resultText.set(sb.toString());
     return resultText;
diff --git a/src/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFPrintf.java b/src/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFPrintf.java
new file mode 100644
index 0000000..1d52435
--- /dev/null
+++ b/src/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFPrintf.java
@@ -0,0 +1,140 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.udf.generic;
+
+import org.apache.hadoop.hive.common.type.HiveDecimal;
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredJavaObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredObject;
+import org.apache.hadoop.hive.serde2.io.HiveCharWritable;
+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
+import org.apache.hadoop.hive.serde2.io.HiveVarcharWritable;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.io.Text;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+public class TestGenericUDFPrintf {
+
+  @Test
+  public void testCharVarcharArgs() throws HiveException {
+    GenericUDFPrintf udf = new GenericUDFPrintf();
+
+    ObjectInspector[] inputOIs = {
+        PrimitiveObjectInspectorFactory.writableStringObjectInspector,
+        PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector(TypeInfoFactory.getCharTypeInfo(5)),
+        PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector(TypeInfoFactory.getVarcharTypeInfo(7))
+    };
+
+    HiveCharWritable argChar = new HiveCharWritable();
+    argChar.set("hello");
+    HiveVarcharWritable argVarchar = new HiveVarcharWritable();
+    argVarchar.set("world");
+    DeferredObject[] args = {
+        new DeferredJavaObject(new Text("1st: %s, 2nd: %s")),
+        new DeferredJavaObject(argChar),
+        new DeferredJavaObject(argVarchar)
+    };
+
+    PrimitiveObjectInspector oi = (PrimitiveObjectInspector) udf.initialize(inputOIs);
+    Assert.assertEquals(PrimitiveObjectInspectorFactory.writableStringObjectInspector, oi);
+    Text res = (Text) udf.evaluate(args);
+    Assert.assertEquals("1st: hello, 2nd: world", res.toString());
+  }
+
+  @Test
+  public void testCharFormat() throws HiveException {
+    GenericUDFPrintf udf = new GenericUDFPrintf();
+
+    ObjectInspector[] inputOIs = {
+        PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector(TypeInfoFactory.getCharTypeInfo(10)),
+        PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector(TypeInfoFactory.getVarcharTypeInfo(7))
+    };
+
+    HiveCharWritable formatChar = new HiveCharWritable();
+    formatChar.set("arg1=%s");
+    HiveVarcharWritable argVarchar = new HiveVarcharWritable();
+    argVarchar.set("world");
+    DeferredObject[] args = {
+        new DeferredJavaObject(formatChar),
+        new DeferredJavaObject(argVarchar)
+    };
+
+    PrimitiveObjectInspector oi = (PrimitiveObjectInspector) udf.initialize(inputOIs);
+    Assert.assertEquals(PrimitiveObjectInspectorFactory.writableStringObjectInspector, oi);
+    Text res = (Text) udf.evaluate(args);
+    Assert.assertEquals("arg1=world", res.toString());
+  }
+
+  @Test
+  public void testVarcharFormat() throws HiveException {
+    GenericUDFPrintf udf = new GenericUDFPrintf();
+
+    ObjectInspector[] inputOIs = {
+        PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector(TypeInfoFactory.getVarcharTypeInfo(7)),
+        PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector(TypeInfoFactory.getCharTypeInfo(5))
+    };
+
+    HiveCharWritable argChar = new HiveCharWritable();
+    argChar.set("hello");
+    HiveVarcharWritable formatVarchar = new HiveVarcharWritable();
+    formatVarchar.set("arg1=%s");
+    DeferredObject[] args = {
+        new DeferredJavaObject(formatVarchar),
+        new DeferredJavaObject(argChar)
+    };
+
+    PrimitiveObjectInspector oi = (PrimitiveObjectInspector) udf.initialize(inputOIs);
+    Assert.assertEquals(PrimitiveObjectInspectorFactory.writableStringObjectInspector, oi);
+    Text res = (Text) udf.evaluate(args);
+    Assert.assertEquals("arg1=hello", res.toString());
+  }
+
+  @Test
+  public void testDecimalArgs() throws HiveException {
+    GenericUDFPrintf udf = new GenericUDFPrintf();
+
+    ObjectInspector[] inputOIs = {
+        PrimitiveObjectInspectorFactory.writableStringObjectInspector,
+        PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector(TypeInfoFactory.getDecimalTypeInfo(5, 2)),
+        PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector(TypeInfoFactory.getDecimalTypeInfo(3, 2))
+    };
+
+    HiveDecimalWritable argDec1 = new HiveDecimalWritable();
+    argDec1.set(HiveDecimal.create("234.789"));
+    HiveDecimalWritable argDec2 = new HiveDecimalWritable();
+    argDec2.set(HiveDecimal.create("3.5"));
+
+    DeferredObject[] args = {
+        new DeferredJavaObject(new Text("1st: %s, 2nd: %s")),
+        new DeferredJavaObject(argDec1),
+        new DeferredJavaObject(argDec2)
+    };
+
+    PrimitiveObjectInspector oi = (PrimitiveObjectInspector) udf.initialize(inputOIs);
+    Assert.assertEquals(PrimitiveObjectInspectorFactory.writableStringObjectInspector, oi);
+    Text res = (Text) udf.evaluate(args);
+    Assert.assertEquals("1st: 234.79, 2nd: 3.5", res.toString());
+  }
+
+}
-- 
1.7.0.4

