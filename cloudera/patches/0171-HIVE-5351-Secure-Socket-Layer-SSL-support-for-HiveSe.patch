From 514e9767cd4ad9d240d4b28bfb8bc1feb1bad811 Mon Sep 17 00:00:00 2001
From: Brock Noland <brock@apache.org>
Date: Thu, 7 Nov 2013 20:24:33 +0000
Subject: [PATCH 171/375] HIVE-5351 - Secure-Socket-Layer (SSL) support for HiveServer2 (Prasad Mujumdar via Brock Noland)

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1539799 13f79535-47bb-0310-9956-ffa450edef68
---
 .../java/org/apache/hadoop/hive/conf/HiveConf.java |    3 +
 data/files/keystore.jks                            |  Bin 0 -> 2248 bytes
 data/files/truststore.jks                          |  Bin 0 -> 958 bytes
 .../org/apache/hive/jdbc/TestJdbcWithMiniHS2.java  |   86 ++++++++
 .../test/java/org/apache/hive/jdbc/TestSSL.java    |  221 ++++++++++++++++++++
 .../hive/jdbc/miniHS2/AbstarctHiveService.java     |  129 ++++++++++++
 .../java/org/apache/hive/jdbc/miniHS2/MiniHS2.java |  119 +++++++++++
 .../apache/hive/jdbc/miniHS2/TestHiveServer2.java  |   69 ++++++
 .../java/org/apache/hive/jdbc/HiveConnection.java  |   49 ++++-
 .../hadoop/hive/metastore/HiveMetaStore.java       |    5 +-
 .../apache/hive/service/auth/HiveAuthFactory.java  |   54 +++++-
 .../service/cli/thrift/ThriftBinaryCLIService.java |   14 ++-
 .../apache/hadoop/hive/shims/Hadoop20Shims.java    |    4 +
 .../hadoop/hive/shims/HadoopShimsSecure.java       |    1 -
 14 files changed, 735 insertions(+), 19 deletions(-)
 create mode 100644 data/files/keystore.jks
 create mode 100644 data/files/truststore.jks
 create mode 100644 itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
 create mode 100644 itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestSSL.java
 create mode 100644 itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/AbstarctHiveService.java
 create mode 100644 itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java
 create mode 100644 itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/TestHiveServer2.java

diff --git a/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index ec55251..aab0812 100644
--- a/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -768,6 +768,9 @@
     HIVE_SERVER2_ENABLE_DOAS("hive.server2.enable.doAs", true),
     HIVE_SERVER2_TABLE_TYPE_MAPPING("hive.server2.table.type.mapping", "CLASSIC"),
     HIVE_SERVER2_SESSION_HOOK("hive.server2.session.hook", ""),
+    HIVE_SERVER2_USE_SSL("hive.server2.use.SSL", false),
+    HIVE_SERVER2_SSL_KEYSTORE_PATH("hive.server2.keystore.path", ""),
+    HIVE_SERVER2_SSL_KEYSTORE_PASSWORD("hive.server2.keystore.password", ""),
 
     HIVE_SECURITY_COMMAND_WHITELIST("hive.security.command.whitelist", "set,reset,dfs,add,delete"),
 
diff --git a/src/data/files/keystore.jks b/src/data/files/keystore.jks
new file mode 100644
index 0000000000000000000000000000000000000000..469d8a543a4d2a94535996ceee2a24891699b1cc
GIT binary patch
literal 2248
zcmchYc|6qn8pmhGSSK8N#uk#D-xzBsOBlPcWJ%eYvKt!9bZ>*9AskZ?hGZ*ZEJK!L
zJ+ft=bdIU1kg`T0##XM*z4vv`>vjJ>e>{IY@9*n*UeD|EeO{mE$Lfz&5C{Z03h<x7
z6&MtQ3BK$fa0E=}-jKvWAa)2qg#G~dICxY!z)-LXL;wtC2SJI@<&;Dm`c6D9JBc*5
zua8T8U1bW3!T0b@BV`)0dahYKcx|0#vw;n=n#&;9O?^YjTaiC%PWxMglu9~o>9p}+
z(#5${Qlrizjd*Qt=3Y;+F6i8J>X;dp-8O4&ppIWly63Y$Su+~i$j^H_U7hsxzU@}*
z#OCn(Z<E$&J9ct8SK=Ke$IJ0PZtK?((+vw=Jqna-ebMQPbG;M0_Vx(`7o@dC;*R`>
zU{7sNAB~VRuL8JrNrK~q#6rAJ*<RY<IlP_?1YDv)F*i8mS#j7ynAvtP^OoaYTPvl?
z+Uo1c(;dt84noK~<)?i|{AS;<c;5=Hl$P~kmCT)t1j8|?$;clh{jz!2wF<LHC%ZfO
z4L!A813sY)k5eq8wrGUsB7+&cM272!K@!W)oO-n3B9`^4vNIfcMVYX6ceHz~htj6F
z66PMXfX7xoJC>ICkuE4NSp!WkpieK#@#EAOc2TU%3KH%WqHY>Iw)QG#c#aThm7Tvs
zW9V+`^31@As*EJH_$HMiqL7iy`dENe#S6DgSk3P=pqM<h+96}~VV`MN<)G~<6tiiz
z6N2XYm==)~?P;)$cdcP|b$rtsDcqo;bo-GVsv3i1XB)WS%SCS5o6d`?B_^AS$1uh1
zYu;Mo?qglEUDXjMZI$U}t|PgW*4p2EFlc`&KmKO^#Y4B~jP&z9@^+qt4_WGkSuor7
zjH#FNE0QB`>IW_vBXe3MFMW-sg}Jzi)+Xrw6Hc-|R%_>A>}c53Q2M2@-qHKlPY7a<
zlJzoLawdWFprzUu>){rvT(HZuXmzU9x}>RMw&QPcdPRv0RGr+2+>V&VwTT7m5JFJj
zy@C>A71mRU-lD0d+?tZzIt(5$<KViK2xW;NXqjw&0Y+pB849wa4v%Q<F)DI-hn}LL
zpT#W&G(DkNjkxVCF;{iBQ&+D>*4CIS$d<iOou09O<f$X)Nr)}i&})Arz&Po&Z9&BK
ziQtWP`7HP4UKUNSG1}X#gm`YOPqIoj8nrKT`GwGmp5($4T)&od0csDQ44>F4R##Tb
z8;&bvn8cM6q7GJ}_mx9**jK)X=oJNxFy|VpsQD#Qb$7Rll4gw0hb`t;n^YetCe(6<
zz@F1x%oip3Pxnfq+%K^L^Lq9oIHlutMfigC9=iArL7IeVJGDS^y8%WP>C=MA8k*pl
zZO3S88Z@F4d@RoDQhZ#bWY%Zod+l?Y2M!FavmNeByx%Y6De9#eSYYN=*Ct%jKkhb7
z7!L^ALZ?H2oycfg{#3~Movg?CI)4_u<SuN3{)3)*o7UJIJKs4dTe-Vd`&}ZEUCz$k
zpSe##h<1lL76IbI70nPQAjMaLr&C?4-y?Z++DlR4d5iSLdwqjWDM5{>FQ&(bJE^7S
z!p`?Kr<~zrICUyg`2dJE6tuapVuU6n*g!|I#g4{t8=AICj!c#7QE^))msIFV8eRdN
zb$&0v$VEz2j=%^NAthnEepOgNAVTum$$HBxgUMvytWkID#jx5riKo_E;xY@dvrc|f
zq{ipCQf}W$I1DMdki!{zxf%1FY45A{HZ!eHqbPDwb<qpz|2c4eMURim_IC<QWdBP`
zjg<NI!;3AYvQ)B3h@t9&sH@3)IQ_V9>Z(=s9~U~Za~}D;om--oLZN3J|MW(74-Fl_
z00d&Y0T9{n01@I>%mx8NAW)AkU2cGvgIk4!BC&YEU>G|H2u1vIWSMMkP!1tZxA2hg
zh}iJ|60ZLvoc|;IM~#lEc!W4iv3>!87z8f>`w3t|P}Gq%BZL9LpDCLV?BDMvep29s
z7%u{e0JM;Rj<y~W;dPu}3xPla23iLH0e|y6M6ldn1v$DGY(y|W2q1!aAVe@2)PC2F
z98<{B3ndhJwYSP`*tnc>h7X7i@K!LlA3&*^ut`zIhhEmbe33oAAK3c%)f)!n!lvCC
z)@~Z5e0Fc6pwaU1a+zb9u&ZgZdBT;tw@;L44^i;spji3A8R=Y=HgK;Oe>LL;^H`w$
zV`6;**W~093NhZ{Wky#Om+zSyecGaoZF@wf9c-fKvT|LYDKvemB%Hfe{a(G=!(r#y
zC<A}>%i(;zO=}f9HT-rD@jU-*RV!kCHDhEYl`ZaDtG7hb85hWHU+E=n7pwME%H#E4
z48oiGvoGg886I})=dH$psxr{a-C@tS&DgT}(M*Jbj}hF@=A=nxGWLoTgbfS=m&pP$
zfYi}%O7THOp~Cv>`L|#e+4|*qBy#!)?VWN9d&yr#Jld)w5y2p#JskQtuCO@9R;D*<
zh|m@29h@W{q_REwfrDj?r&9uKjv*9#lPxZ+pJtubxw&mJAFuY-&rSVva9edbtL^a`
zVC<cHPFu7~|Im?SNhZtK-Ma6u8$A?5>#wxGu$k0QvPtYF=s(WS2IqRkJJ|3lm;_~Z
z4D~zPz5hq}zMH7D3D)rDrvl5fhMj@$a;}$*ALPC~b%wQ+J+q%DsH`B3ntZpOqPQ~l
z`HgUjJvs7SlUI2_yz)VFX2b=_v1m%>-M%Z+83QV}6oQgs&wZhaV=d1~TPwW~u?lQG
z(N<|lUq}mHz1uBT^Xj@`%d(M6ZFgv>=~%lllQ15KC90j(5|wDa!{FY(SAs`3qvi|_
Js_3iE{{opy;Gh5i

literal 0
HcmV?d00001

diff --git a/src/data/files/truststore.jks b/src/data/files/truststore.jks
new file mode 100644
index 0000000000000000000000000000000000000000..9c5d703fba6c8c23bf6ee8f431d6d0fc35bf9ee1
GIT binary patch
literal 958
zcmezO_TO6u1_mY|W(3n58JT6NSt&`$Kmo_cw>h&JSR?dI4J;WLm}?E1m@5sMm=YH-
zGchtTu|(`Q<22x9<J4;NX#38~$jHsgV31=dV8F-59LmBb%pRJTotIyp2NU7I5Mf7%
z@B<A3>f#b+b1X<q&PX-nHQ)vba0|0|03Bo~Vju+KG7ED<<P|`o1`6W5hQ@{lM#cuF
zCg#S5Q4;({hK9xlmPVFP0Xn;<iBSnTKp0sWn41{+84Q{jxtN+585#CW^64*|``tXJ
zZhq9Bol2j)g4Kegj*A`VU4Hx9JeJk^+?T~}JUa4y>MYS;eE$kI*1xT_?4P^!=i2W-
zyJjwX`0LZ`EpGo)7W*$232|(3Zb(~yXS2qJB_2{OndQnS9>`7C+Rb<*ihs?Glec*?
zd{;DWY~Z+j`K5>9`Mpt27qumo4?RA+W4mU-?xp=3{(KI6Jb8M^F4e71SJt@{ueqnY
zCc^K>uCq5P)8GGpw$W?nD%RC`6Am?n@jqO()9~5bo-?mIm@B^QjFE1(3uc;-AotQF
z*nLmO%oQI6Ec3P=o02kP^Xb!}$9UJ2Fs$kce03oA@HZ#sDg1%A4OQc9q!PVU9Qs-c
z(qx&K85tNCD;mff$O2<imXAe@Ma1IctWIv%DHh9SwDotN*>G2LJL^K^Km?{LU?4Iw
z2>&Vxlqi|Ipv+tTNYSaf{TVS?&61f~-_AZ_`)*r#ab~g?kD>aJ7T4&HR^P2mTfaFx
ztJk@c7^?dwYxkOE-*>NgXJ8vM-Ni&~zr}z5Hn;wMd7sWXNoJ*|$~GKZ=^OpIdDFtr
zO$X{MR?M2hI6bP~&x=>pA+vAqsbfJt_p0-Lhl<HL6j--Do$Y3Cy)WbLw5o;Y|4hH6
zX7~N&ln1|O2x+Ryd0f8xv0eT3xi_~&+I{;A?{1A+mRzs-XIo!>w9L8EnSGOvrrqy3
zuGOiU*<9}OezjzQn~R*M#z|54jGYR*S6W|u-j(%s(gE?cSE{VHzp@ElcOWOn@!THU
i+jZwF3Yv86jpP{Duj5kx`QB$`i><QrQ7dtWk9z<h!)<^7

literal 0
HcmV?d00001

diff --git a/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
new file mode 100644
index 0000000..6c25736
--- /dev/null
+++ b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
@@ -0,0 +1,86 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.jdbc;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.ResultSet;
+import java.sql.Statement;
+
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hive.jdbc.miniHS2.MiniHS2;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+  public class TestJdbcWithMiniHS2 {
+    private static MiniHS2 miniHS2 = null;
+    private static Path dataFilePath;
+
+    private Connection hs2Conn = null;
+
+    @BeforeClass
+    public static void beforeTest() throws Exception {
+      Class.forName(MiniHS2.getJdbcDriverName());
+      HiveConf conf = new HiveConf();
+      miniHS2 = new MiniHS2(conf);
+      String dataFileDir = conf.get("test.data.files").replace('\\', '/')
+          .replace("c:", "");
+      dataFilePath = new Path(dataFileDir, "kv1.txt");
+    }
+
+    @Before
+    public void setUp() throws Exception {
+      miniHS2.start();
+      hs2Conn = DriverManager.getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
+      hs2Conn.createStatement().execute("set hive.support.concurrency = false");
+    }
+
+    @After
+    public void tearDown() throws Exception {
+      hs2Conn.close();
+      miniHS2.stop();
+    }
+
+    @Test
+    public void testConnection() throws Exception {
+      String tableName = "testTab1";
+      Statement stmt = hs2Conn.createStatement();
+
+      // create table
+      stmt.execute("DROP TABLE IF EXISTS " + tableName);
+      stmt.execute("CREATE TABLE " + tableName
+          + " (under_col INT COMMENT 'the under column', value STRING) COMMENT ' test table'");
+
+      // load data
+      stmt.execute("load data local inpath '"
+          + dataFilePath.toString() + "' into table " + tableName);
+
+      ResultSet res = stmt.executeQuery("SELECT * FROM " + tableName);
+      assertTrue(res.next());
+      assertEquals("val_238", res.getString(2));
+      res.close();
+      stmt.close();
+    }
+}
diff --git a/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestSSL.java b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestSSL.java
new file mode 100644
index 0000000..d0c4fc2
--- /dev/null
+++ b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestSSL.java
@@ -0,0 +1,221 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.jdbc;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.fail;
+
+import java.io.File;
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.Statement;
+
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
+import org.apache.hive.jdbc.miniHS2.MiniHS2;
+//import org.apache.hive.service.miniHS2.MiniHS2;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+public class TestSSL {
+  private static final String KEY_STORE_NAME = "keystore.jks";
+  private static final String TRUST_STORE_NAME = "truststore.jks";
+  private static final String KEY_STORE_PASSWORD = "HiveJdbc";
+  private static final String JAVA_TRUST_STORE_PROP = "javax.net.ssl.trustStore";
+  private static final String JAVA_TRUST_STORE_PASS_PROP = "javax.net.ssl.trustStorePassword";
+
+  private MiniHS2 miniHS2 = null;
+  private static HiveConf conf = new HiveConf();
+  private Connection hs2Conn = null;
+  private String dataFileDir = conf.get("test.data.files");
+
+  @BeforeClass
+  public static void beforeTest() throws Exception {
+    Class.forName(MiniHS2.getJdbcDriverName());
+  }
+
+  @Before
+  public void setUp() throws Exception {
+    DriverManager.setLoginTimeout(0);
+    if (!System.getProperty("test.data.files", "").isEmpty()) {
+      dataFileDir = System.getProperty("test.data.files");
+    }
+    dataFileDir = dataFileDir.replace('\\', '/').replace("c:", "");
+    miniHS2 = new MiniHS2(conf);
+  }
+
+  @After
+  public void tearDown() throws Exception {
+    if (hs2Conn != null) {
+      hs2Conn.close();
+    }
+    if (miniHS2 != null && miniHS2.isStarted()) {
+      miniHS2.stop();
+    }
+    System.clearProperty(JAVA_TRUST_STORE_PROP);
+    System.clearProperty(JAVA_TRUST_STORE_PASS_PROP);
+  }
+
+  /***
+   * Test SSL client with non-SSL server fails
+   * @throws Exception
+   */
+  @Test
+  public void testInvalidConfig() throws Exception {
+    miniHS2.start();
+    DriverManager.setLoginTimeout(4);
+    try {
+      hs2Conn = DriverManager.getConnection(miniHS2.getJdbcURL() + ";ssl=true;sslTrustStore=" +
+          dataFileDir + File.separator + TRUST_STORE_NAME + ";trustStorePassword=" +
+          KEY_STORE_PASSWORD, System.getProperty("user.name"), "bar");
+      fail("SSL connection should fail with NON-SSL server");
+    } catch (SQLException e) {
+      // expected error
+      assertEquals("08S01", e.getSQLState().trim());
+    }
+
+    System.setProperty(JAVA_TRUST_STORE_PROP, dataFileDir + File.separator + TRUST_STORE_NAME );
+    System.setProperty(JAVA_TRUST_STORE_PASS_PROP, KEY_STORE_PASSWORD);
+    try {
+      hs2Conn = DriverManager.getConnection(miniHS2.getJdbcURL() + ";ssl=true",
+          System.getProperty("user.name"), "bar");
+      fail("SSL connection should fail with NON-SSL server");
+    } catch (SQLException e) {
+      // expected error
+      assertEquals("08S01", e.getSQLState().trim());
+    }
+
+  }
+
+  /***
+   * Test non-SSL client with SSL server fails
+   * @throws Exception
+   */
+  @Test
+  public void testConnectionMismatch() throws Exception {
+    miniHS2.setConfProperty(ConfVars.HIVE_SERVER2_USE_SSL.varname, "true");
+    miniHS2.setConfProperty(ConfVars.HIVE_SERVER2_SSL_KEYSTORE_PASSWORD.varname, "");
+    miniHS2.start();
+    try {
+      hs2Conn = DriverManager.getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
+      fail("NON SSL connection should fail with SSL server");
+    } catch (SQLException e) {
+      // expected error
+      assertEquals("08S01", e.getSQLState().trim());
+    }
+
+    try {
+      hs2Conn = DriverManager.getConnection(miniHS2.getJdbcURL()+ ";ssl=false",
+          System.getProperty("user.name"), "bar");
+      fail("NON SSL connection should fail with SSL server");
+    } catch (SQLException e) {
+      // expected error
+      assertEquals("08S01", e.getSQLState().trim());
+    }
+
+  }
+
+  /***
+   * Test SSL client connection to SSL server
+   * @throws Exception
+   */
+  @Test
+  public void testSSLConnectionWithURL() throws Exception {
+    // Start HS2 with SSL
+    startSslSever();
+
+    // make SSL connection
+    hs2Conn = DriverManager.getConnection(miniHS2.getJdbcURL() + ";ssl=true;sslTrustStore=" +
+        dataFileDir + File.separator + TRUST_STORE_NAME + ";trustStorePassword=" +
+        KEY_STORE_PASSWORD, System.getProperty("user.name"), "bar");
+
+    hs2Conn.close();
+  }
+
+  /***
+   * Test SSL client connection to SSL server
+   * @throws Exception
+   */
+  @Test
+  public void testSSLConnectionWithProperty() throws Exception {
+    // Start HS2 with SSL
+    startSslSever();
+
+    System.setProperty(JAVA_TRUST_STORE_PROP, dataFileDir + File.separator + TRUST_STORE_NAME );
+    System.setProperty(JAVA_TRUST_STORE_PASS_PROP, KEY_STORE_PASSWORD);
+    // make SSL connection
+    hs2Conn = DriverManager.getConnection(miniHS2.getJdbcURL() + ";ssl=true",
+        System.getProperty("user.name"), "bar");
+
+    hs2Conn.close();
+  }
+
+  /**
+   * Start HS2 in SSL mode, open a SSL connection and fetch data
+   * @throws Exception
+   */
+  @Test
+  public void testSSLFetch() throws Exception {
+    // Start HS2 with SSL
+    startSslSever();
+
+    // make SSL connection
+    hs2Conn = DriverManager.getConnection(miniHS2.getJdbcURL() + ";ssl=true;sslTrustStore=" +
+        dataFileDir + File.separator + TRUST_STORE_NAME + ";trustStorePassword=" +
+        KEY_STORE_PASSWORD, System.getProperty("user.name"), "bar");
+
+    String tableName = "sslTab";
+    Statement stmt = hs2Conn.createStatement();
+    Path dataFilePath = new Path(dataFileDir, "kv1.txt");
+
+    stmt.execute("set hive.support.concurrency = false");
+
+    stmt.execute("drop table if exists " + tableName);
+    stmt.execute("create table " + tableName
+        + " (under_col int comment 'the under column', value string)");
+
+    // load data
+    stmt.execute("load data local inpath '"
+        + dataFilePath.toString() + "' into table " + tableName);
+
+    ResultSet res = stmt.executeQuery("SELECT * FROM " + tableName);
+    int rowCount = 0;
+    while (res.next()) {
+      ++rowCount;
+      assertEquals("val_" + res.getInt(1), res.getString(2));
+    }
+
+    // read result over SSL
+    assertEquals(500, rowCount);
+  }
+
+  private void startSslSever () throws Exception {
+    miniHS2.setConfProperty(ConfVars.HIVE_SERVER2_USE_SSL.varname, "true");
+    miniHS2.setConfProperty(ConfVars.HIVE_SERVER2_SSL_KEYSTORE_PATH.varname,
+        dataFileDir + File.separator +  KEY_STORE_NAME);
+    miniHS2.setConfProperty(ConfVars.HIVE_SERVER2_SSL_KEYSTORE_PASSWORD.varname,
+        KEY_STORE_PASSWORD);
+    miniHS2.start();
+  }
+
+}
diff --git a/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/AbstarctHiveService.java b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/AbstarctHiveService.java
new file mode 100644
index 0000000..5ecd156
--- /dev/null
+++ b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/AbstarctHiveService.java
@@ -0,0 +1,129 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.jdbc.miniHS2;
+
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
+
+/***
+ * Base class for Hive service
+ * AbstarctHiveService.
+ *
+ */
+public abstract class AbstarctHiveService {
+  private HiveConf hiveConf = null;
+  private String hostname;
+  private int port;
+  private boolean startedHiveService = false;
+
+  public AbstarctHiveService(HiveConf hiveConf, String hostname, int port) {
+    this.hiveConf = hiveConf;
+    this.hostname = hostname;
+    this.port = port;
+  }
+
+  /**
+   * Get Hive conf
+   * @return
+   */
+  public HiveConf getHiveConf() {
+    return hiveConf;
+  }
+
+  /**
+   * Get config property
+   * @param propertyKey
+   * @return
+   */
+  public String getConfProperty(String propertyKey) {
+    return hiveConf.get(propertyKey);
+  }
+
+  /**
+   * Set config property
+   * @param propertyKey
+   * @param propertyValue
+   */
+  public void setConfProperty(String propertyKey, String propertyValue) {
+    System.setProperty(propertyKey, propertyValue);
+    hiveConf.set(propertyKey, propertyValue);
+  }
+
+  /**
+   * Retrieve warehouse directory
+   * @return
+   */
+  public Path getWareHouseDir() {
+    return new Path(hiveConf.getVar(ConfVars.METASTOREWAREHOUSE));
+  }
+
+  public void setWareHouseDir(String wareHouseURI) {
+    verifyNotStarted();
+    System.setProperty(ConfVars.METASTOREWAREHOUSE.varname, wareHouseURI);
+    hiveConf.setVar(ConfVars.METASTOREWAREHOUSE, wareHouseURI);
+  }
+
+  /**
+   * Set service host
+   * @param hostName
+   */
+  public void setHost(String hostName) {
+    this.hostname = hostName;
+  }
+
+  // get service host
+  protected String getHost() {
+    return hostname;
+  }
+
+  /**
+   * Set service port #
+   * @param portNum
+   */
+  public void setPort(int portNum) {
+    this.port = portNum;
+  }
+
+  // get service port#
+  protected int getPort() {
+    return port;
+  }
+
+  public boolean isStarted() {
+    return startedHiveService;
+  }
+
+  protected void setStarted(boolean hiveServiceStatus) {
+    this.startedHiveService =  hiveServiceStatus;
+  }
+
+  protected void verifyStarted() {
+    if (!isStarted()) {
+      throw new IllegalStateException("HS2 is not running");
+    }
+  }
+
+  protected void verifyNotStarted() {
+    if (isStarted()) {
+      throw new IllegalStateException("HS2 alreadyrunning");
+    }
+  }
+
+}
diff --git a/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java
new file mode 100644
index 0000000..a65e678
--- /dev/null
+++ b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java
@@ -0,0 +1,119 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.jdbc.miniHS2;
+
+import java.io.File;
+import java.io.IOException;
+import java.util.concurrent.TimeoutException;
+import java.util.concurrent.atomic.AtomicLong;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
+import org.apache.hadoop.hive.metastore.HiveMetaStore;
+import org.apache.hadoop.hive.metastore.MetaStoreUtils;
+import org.apache.hive.service.Service;
+import org.apache.hive.service.cli.CLIServiceClient;
+import org.apache.hive.service.cli.SessionHandle;
+import org.apache.hive.service.cli.thrift.ThriftBinaryCLIService;
+import org.apache.hive.service.cli.thrift.ThriftCLIServiceClient;
+import org.apache.hive.service.server.HiveServer2;
+
+import com.google.common.io.Files;
+
+public class MiniHS2 extends AbstarctHiveService {
+  private static final String driverName = "org.apache.hive.jdbc.HiveDriver";
+  private HiveServer2 hiveServer2 = null;
+  private final File baseDir;
+  private static final AtomicLong hs2Counter = new AtomicLong();
+
+  public MiniHS2(HiveConf hiveConf) throws IOException {
+    super(hiveConf, "localhost", MetaStoreUtils.findFreePort());
+    baseDir =  Files.createTempDir();
+    setWareHouseDir("file://" + baseDir.getPath() + File.separator + "warehouse");
+    String metaStoreURL =  "jdbc:derby:" + baseDir.getAbsolutePath() + File.separator + "test_metastore-" +
+        hs2Counter.incrementAndGet() + ";create=true";
+
+    System.setProperty(HiveConf.ConfVars.METASTORECONNECTURLKEY.varname, metaStoreURL);
+    hiveConf.setVar(HiveConf.ConfVars.METASTORECONNECTURLKEY, metaStoreURL);
+    hiveConf.setVar(ConfVars.HIVE_SERVER2_THRIFT_BIND_HOST, getHost());
+    hiveConf.setIntVar(ConfVars.HIVE_SERVER2_THRIFT_PORT, getPort());
+    HiveMetaStore.HMSHandler.resetDefaultDBFlag();
+  }
+
+  public void start() throws Exception {
+    hiveServer2 = new HiveServer2();
+    hiveServer2.init(getHiveConf());
+    hiveServer2.start();
+    waitForStartup();
+    setStarted(true);
+  }
+
+  public void stop() {
+    verifyStarted();
+    hiveServer2.stop();
+    setStarted(false);
+    FileUtils.deleteQuietly(baseDir);
+  }
+
+  public CLIServiceClient getServiceClient() {
+    verifyStarted();
+    return getServiceClientInternal();
+  }
+
+  public CLIServiceClient getServiceClientInternal() {
+    for (Service service : hiveServer2.getServices()) {
+      if (service instanceof ThriftBinaryCLIService) {
+        return new ThriftCLIServiceClient((ThriftBinaryCLIService)service);
+      }
+    }
+    throw new IllegalStateException("HS2 not running Thrift service");
+  }
+
+  public String getJdbcURL() {
+    return "jdbc:hive2://" + getHost() + ":" + getPort() + "/default";
+  }
+
+  public static String getJdbcDriverName() {
+    return driverName;
+  }
+
+  private void waitForStartup() throws Exception {
+    int waitTime = 0;
+    long startupTimeout = 1000L * 1000000000L;
+    CLIServiceClient hs2Client = getServiceClientInternal();
+    SessionHandle sessionHandle = null;
+    do {
+      Thread.sleep(500L);
+      waitTime += 500L;
+      if (waitTime > startupTimeout) {
+        throw new TimeoutException("Couldn't access new HiveServer: " + getJdbcURL());
+      }
+      try {
+        sessionHandle = hs2Client.openSession("foo", "bar");
+      } catch (Exception e) {
+        // service not started yet
+        continue;
+      }
+      hs2Client.closeSession(sessionHandle);
+      break;
+    } while (true);
+  }
+
+}
diff --git a/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/TestHiveServer2.java b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/TestHiveServer2.java
new file mode 100644
index 0000000..eb08628
--- /dev/null
+++ b/src/itests/hive-unit/src/test/java/org/apache/hive/jdbc/miniHS2/TestHiveServer2.java
@@ -0,0 +1,69 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.jdbc.miniHS2;
+
+import static org.junit.Assert.assertFalse;
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hive.service.cli.CLIServiceClient;
+import org.apache.hive.service.cli.OperationHandle;
+import org.apache.hive.service.cli.RowSet;
+import org.apache.hive.service.cli.SessionHandle;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+public class TestHiveServer2 {
+
+  private static MiniHS2 miniHS2 = null;
+  private Map<String, String> confOverlay;
+
+  @BeforeClass
+  public static void beforeTest() throws IOException {
+    miniHS2 = new MiniHS2(new HiveConf());
+  }
+
+  @Before
+  public void setUp() throws Exception {
+    miniHS2.start();
+    confOverlay = new HashMap<String, String>();
+  }
+
+  @After
+  public void tearDown() {
+    miniHS2.stop();
+  }
+
+  @Test
+  public void testConnection() throws Exception {
+    String tabName = "testTab1";
+    CLIServiceClient serviceClient = miniHS2.getServiceClient();
+    SessionHandle sessHandle = serviceClient.openSession("foo", "bar");
+    serviceClient.executeStatement(sessHandle, "DROP TABLE IF EXISTS tab", confOverlay);
+    serviceClient.executeStatement(sessHandle, "CREATE TABLE " + tabName + " (id INT)", confOverlay);
+    OperationHandle opHandle = serviceClient.executeStatement(sessHandle, "SHOW TABLES", confOverlay);
+    RowSet rowSet = serviceClient.fetchResults(opHandle);
+    assertFalse(rowSet.getSize() == 0);
+  }
+}
diff --git a/src/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java b/src/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java
index bb82a6e..ef39573 100644
--- a/src/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java
+++ b/src/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java
@@ -24,6 +24,7 @@
 import java.sql.Clob;
 import java.sql.Connection;
 import java.sql.DatabaseMetaData;
+import java.sql.DriverManager;
 import java.sql.NClob;
 import java.sql.PreparedStatement;
 import java.sql.SQLClientInfoException;
@@ -46,6 +47,7 @@
 
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.session.SessionState;
+import org.apache.hive.service.auth.HiveAuthFactory;
 import org.apache.hive.service.auth.KerberosSaslHelper;
 import org.apache.hive.service.auth.PlainSaslHelper;
 import org.apache.hive.service.auth.SaslQOP;
@@ -61,7 +63,6 @@
 import org.apache.thrift.protocol.TBinaryProtocol;
 import org.apache.thrift.protocol.TProtocol;
 import org.apache.thrift.transport.THttpClient;
-import org.apache.thrift.transport.TSocket;
 import org.apache.thrift.transport.TTransport;
 import org.apache.thrift.transport.TTransportException;
 
@@ -78,6 +79,10 @@
   private static final String HIVE_AUTH_PASSWD = "password";
   private static final String HIVE_ANONYMOUS_USER = "anonymous";
   private static final String HIVE_ANONYMOUS_PASSWD = "anonymous";
+  private static final String HIVE_USE_SSL = "ssl";
+  private static final String HIVE_SSL_TRUST_STORE = "sslTrustStore";
+  private static final String HIVE_SSL_TRUST_STORE_PASSWORD = "trustStorePassword";
+
   private final String jdbcURI;
   private final String host;
   private final int port;
@@ -91,8 +96,10 @@
   private SQLWarning warningChain = null;
   private TSessionHandle sessHandle = null;
   private final List<TProtocolVersion> supportedProtocols = new LinkedList<TProtocolVersion>();
+  private int loginTimeout = 0;
 
   public HiveConnection(String uri, Properties info) throws SQLException {
+    loginTimeout = DriverManager.getLoginTimeout();
     jdbcURI = uri;
     // parse the connection uri
     Utils.JdbcConnectionParams connParams = Utils.parseURL(jdbcURI);
@@ -178,26 +185,26 @@ private TTransport createHttpTransport() throws SQLException {
   }
 
   private TTransport createBinaryTransport() throws SQLException {
-    transport = new TSocket(host, port);
-    // handle secure connection if specified
-    if (!sessConfMap.containsKey(HIVE_AUTH_TYPE)
-        || !sessConfMap.get(HIVE_AUTH_TYPE).equals(HIVE_AUTH_SIMPLE)) {
-      try {
+    try {
+      // handle secure connection if specified
+      if (!HIVE_AUTH_SIMPLE.equals(sessConfMap.get(HIVE_AUTH_TYPE))) {
         // If Kerberos
         if (sessConfMap.containsKey(HIVE_AUTH_PRINCIPAL)) {
           Map<String, String> saslProps = new HashMap<String, String>();
           SaslQOP saslQOP = SaslQOP.AUTH;
-          if(sessConfMap.containsKey(HIVE_AUTH_QOP)) {
+          if (sessConfMap.containsKey(HIVE_AUTH_QOP)) {
             try {
               saslQOP = SaslQOP.fromString(sessConfMap.get(HIVE_AUTH_QOP));
             } catch (IllegalArgumentException e) {
-              throw new SQLException("Invalid " + HIVE_AUTH_QOP + " parameter. " + e.getMessage(), "42000", e);
+              throw new SQLException("Invalid " + HIVE_AUTH_QOP + " parameter. " + e.getMessage(),
+                  "42000", e);
             }
           }
           saslProps.put(Sasl.QOP, saslQOP.toString());
           saslProps.put(Sasl.SERVER_AUTH, "true");
           transport = KerberosSaslHelper.getKerberosTransport(
-              sessConfMap.get(HIVE_AUTH_PRINCIPAL), host, transport, saslProps);
+              sessConfMap.get(HIVE_AUTH_PRINCIPAL), host,
+              HiveAuthFactory.getSocketTransport(host, port, loginTimeout), saslProps);
         } else {
           String userName = sessConfMap.get(HIVE_AUTH_USER);
           if ((userName == null) || userName.isEmpty()) {
@@ -207,12 +214,30 @@ private TTransport createBinaryTransport() throws SQLException {
           if ((passwd == null) || passwd.isEmpty()) {
             passwd = HIVE_ANONYMOUS_PASSWD;
           }
+          String useSslStr = sessConfMap.get(HIVE_USE_SSL);
+          if ("true".equalsIgnoreCase(useSslStr)) {
+            String sslTrustStore = sessConfMap.get(HIVE_SSL_TRUST_STORE);
+            String sslTrustStorePassword = sessConfMap.get(HIVE_SSL_TRUST_STORE_PASSWORD);
+            if (sslTrustStore == null || sslTrustStore.isEmpty()) {
+              transport = HiveAuthFactory.getSSLSocket(host, port, loginTimeout);
+            } else {
+              transport = HiveAuthFactory.getSSLSocket(host, port, loginTimeout,
+                  sslTrustStore, sslTrustStorePassword);
+            }
+          } else {
+            transport = HiveAuthFactory.getSocketTransport(host, port, loginTimeout);
+          }
           transport = PlainSaslHelper.getPlainTransport(userName, passwd, transport);
         }
-      } catch (SaslException e) {
-        throw new SQLException("Could not create secure connection to "
-            + jdbcURI + ": " + e.getMessage(), " 08S01", e);
+      } else {
+        transport = HiveAuthFactory.getSocketTransport(host, port, loginTimeout);
       }
+    } catch (SaslException e) {
+      throw new SQLException("Could not create secure connection to "
+          + jdbcURI + ": " + e.getMessage(), " 08S01", e);
+    } catch (TTransportException e) {
+      throw new SQLException("Could not create connection to "
+          + jdbcURI + ": " + e.getMessage(), " 08S01", e);
     }
     return transport;
   }
diff --git a/src/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java b/src/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
index 23c272f..eeb00ef 100644
--- a/src/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
+++ b/src/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
@@ -277,6 +277,10 @@ public static Integer get() {
       return threadLocalId.get();
     }
 
+    public static void resetDefaultDBFlag() {
+      createDefaultDB = false;
+    }
+
     public HMSHandler(String name) throws MetaException {
       super(name);
       hiveConf = new HiveConf(this.getClass());
@@ -4082,7 +4086,6 @@ public static IHMSHandler newHMSHandler(String name, HiveConf hiveConf) throws M
   }
 
 
-
   /**
    * Discard a current delegation token.
    *
diff --git a/src/service/src/java/org/apache/hive/service/auth/HiveAuthFactory.java b/src/service/src/java/org/apache/hive/service/auth/HiveAuthFactory.java
index e7930d9..5235ba9 100644
--- a/src/service/src/java/org/apache/hive/service/auth/HiveAuthFactory.java
+++ b/src/service/src/java/org/apache/hive/service/auth/HiveAuthFactory.java
@@ -18,6 +18,12 @@
 package org.apache.hive.service.auth;
 
 import java.io.IOException;
+import java.net.InetAddress;
+import java.net.InetSocketAddress;
+import java.net.UnknownHostException;
+import java.text.MessageFormat;
+import java.util.HashMap;
+import java.util.Map;
 
 import javax.security.auth.login.LoginException;
 import javax.security.sasl.Sasl;
@@ -28,15 +34,15 @@
 import org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge;
 import org.apache.hive.service.cli.thrift.ThriftCLIService;
 import org.apache.thrift.TProcessorFactory;
+import org.apache.thrift.transport.TSSLTransportFactory;
+import org.apache.thrift.transport.TServerSocket;
+import org.apache.thrift.transport.TSocket;
+import org.apache.thrift.transport.TTransport;
 import org.apache.thrift.transport.TTransportException;
 import org.apache.thrift.transport.TTransportFactory;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.text.MessageFormat;
-import java.util.HashMap;
-import java.util.Map;
-
 public class HiveAuthFactory {
   private static final Logger LOG = LoggerFactory.getLogger(HiveAuthFactory.class);
 
@@ -157,4 +163,44 @@ public static void loginFromKeytab(HiveConf hiveConf) throws IOException {
     }
   }
 
+  public static TTransport getSocketTransport(String host, int port, int loginTimeout)
+      throws TTransportException {
+    return new TSocket(host, port, loginTimeout);
+  }
+
+  public static TTransport getSSLSocket(String host, int port, int loginTimeout)
+      throws TTransportException {
+    return TSSLTransportFactory.getClientSocket(host, port, loginTimeout);
+  }
+
+  public static TTransport getSSLSocket(String host, int port, int loginTimeout,
+      String trustStorePath, String trustStorePassWord) throws TTransportException {
+    TSSLTransportFactory.TSSLTransportParameters params =
+        new TSSLTransportFactory.TSSLTransportParameters();
+    params.setTrustStore(trustStorePath, trustStorePassWord);
+    params.requireClientAuth(true);
+    return TSSLTransportFactory.getClientSocket(host, port, loginTimeout, params);
+  }
+
+  public static TServerSocket getServerSocket(String hiveHost, int portNum)
+      throws TTransportException {
+    InetSocketAddress serverAddress = null;
+    if (hiveHost != null && !hiveHost.isEmpty()) {
+      serverAddress = new InetSocketAddress(hiveHost, portNum);
+    } else {
+      serverAddress = new  InetSocketAddress(portNum);
+    }
+    return new TServerSocket(serverAddress );
+  }
+
+  public static TServerSocket getServerSSLSocket(String hiveHost, int portNum,
+      String keyStorePath, String keyStorePassWord) throws TTransportException, UnknownHostException {
+    TSSLTransportFactory.TSSLTransportParameters params =
+        new TSSLTransportFactory.TSSLTransportParameters();
+    params.setKeyStore(keyStorePath, keyStorePassWord);
+
+    return TSSLTransportFactory.getServerSocket(portNum, 10000,
+        InetAddress.getByName(hiveHost), params);
+  }
+
 }
diff --git a/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftBinaryCLIService.java b/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftBinaryCLIService.java
index 5f255b2..6ffc795 100644
--- a/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftBinaryCLIService.java
+++ b/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftBinaryCLIService.java
@@ -67,7 +67,19 @@ public void run() {
       maxWorkerThreads = hiveConf.getIntVar(ConfVars.HIVE_SERVER2_THRIFT_MAX_WORKER_THREADS);
       requestTimeout = hiveConf.getIntVar(ConfVars.HIVE_SERVER2_THRIFT_LOGIN_TIMEOUT);
 
-      TThreadPoolServer.Args sargs = new TThreadPoolServer.Args(new TServerSocket(serverAddress))
+      TServerSocket serverSocket = null;
+      if (!hiveConf.getBoolVar(ConfVars.HIVE_SERVER2_USE_SSL)) {
+        serverSocket = HiveAuthFactory.getServerSocket(hiveHost, portNum);
+      } else {
+        String keyStorePath = hiveConf.getVar(ConfVars.HIVE_SERVER2_SSL_KEYSTORE_PATH).trim();
+        if (keyStorePath.isEmpty()) {
+          throw new IllegalArgumentException(ConfVars.HIVE_SERVER2_SSL_KEYSTORE_PATH.varname +
+              " Not configured for SSL connection");
+        }
+        serverSocket = HiveAuthFactory.getServerSSLSocket(hiveHost, portNum,
+            keyStorePath, hiveConf.getVar(ConfVars.HIVE_SERVER2_SSL_KEYSTORE_PASSWORD));
+      }
+      TThreadPoolServer.Args sargs = new TThreadPoolServer.Args(serverSocket)
       .processorFactory(processorFactory)
       .transportFactory(transportFactory)
       .protocolFactory(new TBinaryProtocol.Factory())
diff --git a/src/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java b/src/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java
index 7bf5293..83d0fbb 100644
--- a/src/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java
+++ b/src/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java
@@ -614,6 +614,10 @@ public Path createDelegationTokenFile(Configuration conf) throws IOException {
 
   @Override
   public UserGroupInformation createRemoteUser(String userName, List<String> groupNames) {
+    if (groupNames.isEmpty()) {
+      groupNames = new ArrayList<String>();
+      groupNames.add(userName);
+    }
     return new UnixUserGroupInformation(userName, groupNames.toArray(new String[0]));
   }
 
diff --git a/src/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java b/src/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java
index faa3334..c97659b 100644
--- a/src/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java
+++ b/src/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java
@@ -545,7 +545,6 @@ public Path createDelegationTokenFile(Configuration conf) throws IOException {
     return tokenPath;
   }
 
-
   @Override
   public UserGroupInformation createProxyUser(String userName) throws IOException {
     return UserGroupInformation.createProxyUser(
-- 
1.7.0.4

