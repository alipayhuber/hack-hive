From 83d2bd886ae35e5a3731dd244a3b89ada626ba93 Mon Sep 17 00:00:00 2001
From: Brock Noland <brock@apache.org>
Date: Tue, 8 Oct 2013 19:10:22 +0000
Subject: [PATCH 077/375] HIVE-5460: invalid offsets in lag lead should return an exception (per ISO-SQL) (Edward Capriolo via Brock Noland)

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1530393 13f79535-47bb-0310-9956-ffa450edef68
---
 .../hadoop/hive/ql/exec/FunctionRegistry.java      |    2 -
 .../parse/WindowingExprNodeEvaluatorFactory.java   |    4 +-
 .../hive/ql/udf/generic/GenericUDAFLeadLag.java    |   73 +++----
 .../hadoop/hive/ql/udf/generic/GenericUDFLag.java  |   23 ++
 .../hadoop/hive/ql/udf/generic/GenericUDFLead.java |   24 ++
 .../hive/ql/udf/generic/GenericUDFLeadLag.java     |  239 +++++++------------
 .../hadoop/hive/ql/udf/generic/LeadLagBuffer.java  |   12 +
 .../queries/clientnegative/windowing_ll_no_neg.q   |   26 ++
 .../clientnegative/windowing_ll_no_neg.q.out       |   39 ++++
 9 files changed, 243 insertions(+), 199 deletions(-)
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLag.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLead.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/udf/generic/LeadLagBuffer.java
 create mode 100644 ql/src/test/queries/clientnegative/windowing_ll_no_neg.q
 create mode 100644 ql/src/test/results/clientnegative/windowing_ll_no_neg.q.out

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
index ab23a9a..6c05959 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
@@ -128,8 +128,6 @@
 import org.apache.hadoop.hive.ql.udf.UDFWeekOfYear;
 import org.apache.hadoop.hive.ql.udf.UDFYear;
 import org.apache.hadoop.hive.ql.udf.generic.*;
-import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLeadLag.GenericUDFLag;
-import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLeadLag.GenericUDFLead;
 import org.apache.hadoop.hive.ql.udf.ptf.MatchPath.MatchPathResolver;
 import org.apache.hadoop.hive.ql.udf.ptf.Noop.NoopResolver;
 import org.apache.hadoop.hive.ql.udf.ptf.NoopWithMap.NoopWithMapResolver;
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/WindowingExprNodeEvaluatorFactory.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/WindowingExprNodeEvaluatorFactory.java
index 81039cf..e851f90 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/WindowingExprNodeEvaluatorFactory.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/WindowingExprNodeEvaluatorFactory.java
@@ -26,8 +26,8 @@
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;
-import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLeadLag.GenericUDFLag;
-import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLeadLag.GenericUDFLead;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLag;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLead;
 
 /*
  * When constructing the Evaluator Tree from an ExprNode Tree
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFLeadLag.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFLeadLag.java
index 084bf2f..295cd2e 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFLeadLag.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFLeadLag.java
@@ -23,7 +23,6 @@
 import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.parse.SemanticException;
-import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.AggregationBuffer;
 import org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters;
@@ -34,8 +33,7 @@
 import org.apache.hadoop.io.IntWritable;
 
 /**
- * abstract class for Lead & lag UDAFs
- * GenericUDAFLeadLag.
+ * abstract class for Lead & lag UDAFs GenericUDAFLeadLag.
  *
  */
 public abstract class GenericUDAFLeadLag extends AbstractGenericUDAFResolver {
@@ -44,32 +42,31 @@
 
   @Override
   public GenericUDAFEvaluator getEvaluator(GenericUDAFParameterInfo parameters)
-      throws SemanticException {
+          throws SemanticException {
 
     ObjectInspector[] paramOIs = parameters.getParameterObjectInspectors();
     String fNm = functionName();
 
-    if (!(paramOIs.length >= 1 && paramOIs.length <= 3) ) {
-      throw new UDFArgumentTypeException(paramOIs.length - 1,
-          "Incorrect invocation of " + fNm + ": _FUNC_(expr, amt, default)");
+    if (!(paramOIs.length >= 1 && paramOIs.length <= 3)) {
+      throw new UDFArgumentTypeException(paramOIs.length - 1, "Incorrect invocation of " + fNm
+              + ": _FUNC_(expr, amt, default)");
     }
 
     int amt = 1;
-    if ( paramOIs.length > 1 ) {
+    if (paramOIs.length > 1) {
       ObjectInspector amtOI = paramOIs[1];
 
-      if ( !ObjectInspectorUtils.isConstantObjectInspector(amtOI) ||
-          (amtOI.getCategory() != ObjectInspector.Category.PRIMITIVE) ||
-          ((PrimitiveObjectInspector)amtOI).getPrimitiveCategory() !=
-          PrimitiveObjectInspector.PrimitiveCategory.INT )
-      {
-        throw new UDFArgumentTypeException(0,
-            fNm + " amount must be a integer value "
-            + amtOI.getTypeName() + " was passed as parameter 1.");
+      if (!ObjectInspectorUtils.isConstantObjectInspector(amtOI)
+              || (amtOI.getCategory() != ObjectInspector.Category.PRIMITIVE)
+              || ((PrimitiveObjectInspector) amtOI).getPrimitiveCategory() != PrimitiveObjectInspector.PrimitiveCategory.INT) {
+        throw new UDFArgumentTypeException(1, fNm + " amount must be a integer value "
+                + amtOI.getTypeName() + " was passed as parameter 1.");
+      }
+      Object o = ((ConstantObjectInspector) amtOI).getWritableConstantValue();
+      amt = ((IntWritable) o).get();
+      if (amt < 0) {
+        throw new UDFArgumentTypeException(1, fNm + " amount can not be nagative. Specified: " + amt );
       }
-      Object o = ((ConstantObjectInspector)amtOI).
-          getWritableConstantValue();
-      amt = ((IntWritable)o).get();
     }
 
     if (paramOIs.length == 3) {
@@ -85,13 +82,6 @@ public GenericUDAFEvaluator getEvaluator(GenericUDAFParameterInfo parameters)
 
   protected abstract GenericUDAFLeadLagEvaluator createLLEvaluator();
 
-  static interface LeadLagBuffer extends AggregationBuffer {
-    void initialize(int leadAmt);
-    void addRow(Object leadExprValue, Object defaultValue) ;
-    Object terminate();
-
-  }
-
   public static abstract class GenericUDAFLeadLagEvaluator extends GenericUDAFEvaluator {
 
     private transient ObjectInspector[] inputOI;
@@ -100,24 +90,21 @@ public GenericUDAFEvaluator getEvaluator(GenericUDAFParameterInfo parameters)
     private transient Converter defaultValueConverter;
 
     @Override
-    public ObjectInspector init(Mode m, ObjectInspector[] parameters) throws HiveException
-    {
+    public ObjectInspector init(Mode m, ObjectInspector[] parameters) throws HiveException {
       super.init(m, parameters);
-      if (m != Mode.COMPLETE)
-      {
-        throw new HiveException(
-            "Only COMPLETE mode supported for " + fnName + " function");
+      if (m != Mode.COMPLETE) {
+        throw new HiveException("Only COMPLETE mode supported for " + fnName + " function");
       }
 
       inputOI = parameters;
 
       if (parameters.length == 3) {
-        defaultValueConverter = ObjectInspectorConverters.getConverter(parameters[2], parameters[0]);
+        defaultValueConverter = ObjectInspectorConverters
+                .getConverter(parameters[2], parameters[0]);
       }
 
-      return ObjectInspectorFactory.getStandardListObjectInspector(
-          ObjectInspectorUtils
-          .getStandardObjectInspector(parameters[0]));
+      return ObjectInspectorFactory.getStandardListObjectInspector(ObjectInspectorUtils
+              .getStandardObjectInspector(parameters[0]));
     }
 
     public int getAmt() {
@@ -140,24 +127,22 @@ public void setFnName(String fnName) {
 
     @Override
     public AggregationBuffer getNewAggregationBuffer() throws HiveException {
-      LeadLagBuffer lb =  getNewLLBuffer();
+      LeadLagBuffer lb = getNewLLBuffer();
       lb.initialize(amt);
       return lb;
     }
 
     @Override
     public void reset(AggregationBuffer agg) throws HiveException {
-      ((LeadLagBuffer)agg).initialize(amt);
+      ((LeadLagBuffer) agg).initialize(amt);
     }
 
     @Override
     public void iterate(AggregationBuffer agg, Object[] parameters) throws HiveException {
-      Object rowExprVal = ObjectInspectorUtils.copyToStandardObject(parameters[0],
-          inputOI[0]);
+      Object rowExprVal = ObjectInspectorUtils.copyToStandardObject(parameters[0], inputOI[0]);
       Object defaultVal = parameters.length > 2 ? ObjectInspectorUtils.copyToStandardObject(
-          defaultValueConverter.convert(parameters[2]),
-          inputOI[0]) : null;
-      ((LeadLagBuffer)agg).addRow(rowExprVal, defaultVal);
+              defaultValueConverter.convert(parameters[2]), inputOI[0]) : null;
+      ((LeadLagBuffer) agg).addRow(rowExprVal, defaultVal);
     }
 
     @Override
@@ -172,7 +157,7 @@ public void merge(AggregationBuffer agg, Object partial) throws HiveException {
 
     @Override
     public Object terminate(AggregationBuffer agg) throws HiveException {
-      return ((LeadLagBuffer)agg).terminate();
+      return ((LeadLagBuffer) agg).terminate();
     }
 
   }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLag.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLag.java
new file mode 100644
index 0000000..594f61e
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLag.java
@@ -0,0 +1,23 @@
+package org.apache.hadoop.hive.ql.udf.generic;
+
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.udf.UDFType;
+
+@UDFType(impliesOrder = true)
+public class GenericUDFLag extends GenericUDFLeadLag {
+  @Override
+  protected String _getFnName() {
+    return "lag";
+  }
+
+  @Override
+  protected int getIndex(int amt) {
+    return pItr.getIndex() - 1 - amt;
+  }
+
+  @Override
+  protected Object getRow(int amt) throws HiveException {
+    return pItr.lag(amt + 1);
+  }
+
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLead.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLead.java
new file mode 100644
index 0000000..6240887
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLead.java
@@ -0,0 +1,24 @@
+package org.apache.hadoop.hive.ql.udf.generic;
+
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.udf.UDFType;
+
+@UDFType(impliesOrder = true)
+public class GenericUDFLead extends GenericUDFLeadLag {
+
+  @Override
+  protected String _getFnName() {
+    return "lead";
+  }
+
+  @Override
+  protected int getIndex(int amt) {
+    return pItr.getIndex() - 1 + amt;
+  }
+
+  @Override
+  protected Object getRow(int amt) throws HiveException {
+    return pItr.lead(amt - 1);
+  }
+
+}
\ No newline at end of file
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLeadLag.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLeadLag.java
index ea269f4..ec49f05 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLeadLag.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLeadLag.java
@@ -24,7 +24,6 @@
 import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
-import org.apache.hadoop.hive.ql.udf.UDFType;
 import org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters;
@@ -34,84 +33,73 @@
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
 import org.apache.hadoop.io.IntWritable;
 
-public abstract class GenericUDFLeadLag extends GenericUDF
-{
-	transient ExprNodeEvaluator exprEvaluator;
-	transient PTFPartitionIterator<Object> pItr;
-	transient ObjectInspector firstArgOI;
-	transient ObjectInspector defaultArgOI;
-	transient Converter defaultValueConverter;
-	int amt;
-
-	static{
-		PTFUtils.makeTransient(GenericUDFLeadLag.class, "exprEvaluator", "pItr",
-        "firstArgOI", "defaultArgOI", "defaultValueConverter");
-	}
-
-	@Override
-	public Object evaluate(DeferredObject[] arguments) throws HiveException
-	{
+public abstract class GenericUDFLeadLag extends GenericUDF {
+  transient ExprNodeEvaluator exprEvaluator;
+  transient PTFPartitionIterator<Object> pItr;
+  transient ObjectInspector firstArgOI;
+  transient ObjectInspector defaultArgOI;
+  transient Converter defaultValueConverter;
+  int amt;
+
+  static {
+    PTFUtils.makeTransient(GenericUDFLeadLag.class, "exprEvaluator", "pItr", "firstArgOI",
+            "defaultArgOI", "defaultValueConverter");
+  }
+
+  @Override
+  public Object evaluate(DeferredObject[] arguments) throws HiveException {
     Object defaultVal = null;
-    if(arguments.length == 3){
-      defaultVal =  ObjectInspectorUtils.copyToStandardObject(
-          defaultValueConverter.convert(arguments[2].get()),
-          defaultArgOI);
+    if (arguments.length == 3) {
+      defaultVal = ObjectInspectorUtils.copyToStandardObject(
+              defaultValueConverter.convert(arguments[2].get()), defaultArgOI);
     }
 
-		int idx = pItr.getIndex() - 1;
-		int start = 0;
-		int end = pItr.getPartition().size();
-		try
-		{
-		  Object ret = null;
-		  int newIdx = getIndex(amt);
+    int idx = pItr.getIndex() - 1;
+    int start = 0;
+    int end = pItr.getPartition().size();
+    try {
+      Object ret = null;
+      int newIdx = getIndex(amt);
 
-		  if(newIdx >= end || newIdx < start) {
+      if (newIdx >= end || newIdx < start) {
         ret = defaultVal;
-		  }
-		  else {
+      } else {
         Object row = getRow(amt);
         ret = exprEvaluator.evaluate(row);
-        ret = ObjectInspectorUtils.copyToStandardObject(ret,
-            firstArgOI, ObjectInspectorCopyOption.WRITABLE);
-		  }
-			return ret;
-		}
-		finally
-		{
-			Object currRow = pItr.resetToIndex(idx);
-			// reevaluate expression on current Row, to trigger the Lazy object
-			// caches to be reset to the current row.
-			exprEvaluator.evaluate(currRow);
-		}
-
-	}
-
-	@Override
-	public ObjectInspector initialize(ObjectInspector[] arguments)
-			throws UDFArgumentException
-	{
+        ret = ObjectInspectorUtils.copyToStandardObject(ret, firstArgOI,
+                ObjectInspectorCopyOption.WRITABLE);
+      }
+      return ret;
+    } finally {
+      Object currRow = pItr.resetToIndex(idx);
+      // reevaluate expression on current Row, to trigger the Lazy object
+      // caches to be reset to the current row.
+      exprEvaluator.evaluate(currRow);
+    }
+
+  }
+
+  @Override
+  public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException {
     if (!(arguments.length >= 1 && arguments.length <= 3)) {
-      throw new UDFArgumentTypeException(arguments.length - 1,
-          "Incorrect invocation of " + _getFnName() + ": _FUNC_(expr, amt, default)");
+      throw new UDFArgumentTypeException(arguments.length - 1, "Incorrect invocation of "
+              + _getFnName() + ": _FUNC_(expr, amt, default)");
     }
 
     amt = 1;
-
     if (arguments.length > 1) {
       ObjectInspector amtOI = arguments[1];
-      if ( !ObjectInspectorUtils.isConstantObjectInspector(amtOI) ||
-          (amtOI.getCategory() != ObjectInspector.Category.PRIMITIVE) ||
-          ((PrimitiveObjectInspector)amtOI).getPrimitiveCategory() !=
-          PrimitiveObjectInspector.PrimitiveCategory.INT )
-      {
-        throw new UDFArgumentTypeException(0,
-            _getFnName() + " amount must be a integer value "
-            + amtOI.getTypeName() + " was passed as parameter 1.");
+      if (!ObjectInspectorUtils.isConstantObjectInspector(amtOI)
+              || (amtOI.getCategory() != ObjectInspector.Category.PRIMITIVE)
+              || ((PrimitiveObjectInspector) amtOI).getPrimitiveCategory() != PrimitiveObjectInspector.PrimitiveCategory.INT) {
+        throw new UDFArgumentTypeException(1, _getFnName() + " amount must be a integer value "
+                + amtOI.getTypeName() + " was passed as parameter 1.");
+      }
+      Object o = ((ConstantObjectInspector) amtOI).getWritableConstantValue();
+      amt = ((IntWritable) o).get();
+      if (amt < 0) {
+        throw new UDFArgumentTypeException(1,  " amount can not be nagative. Specified: " + amt);
       }
-      Object o = ((ConstantObjectInspector)amtOI).
-          getWritableConstantValue();
-      amt = ((IntWritable)o).get();
     }
 
     if (arguments.length == 3) {
@@ -123,30 +111,26 @@ public ObjectInspector initialize(ObjectInspector[] arguments)
 
     firstArgOI = arguments[0];
     return ObjectInspectorUtils.getStandardObjectInspector(firstArgOI,
-        ObjectInspectorCopyOption.WRITABLE);
-	}
-
-	public ExprNodeEvaluator getExprEvaluator()
-	{
-		return exprEvaluator;
-	}
-
-	public void setExprEvaluator(ExprNodeEvaluator exprEvaluator)
-	{
-		this.exprEvaluator = exprEvaluator;
-	}
-
-	public PTFPartitionIterator<Object> getpItr()
-	{
-		return pItr;
-	}
-
-	public void setpItr(PTFPartitionIterator<Object> pItr)
-	{
-		this.pItr = pItr;
-	}
-
-	public ObjectInspector getFirstArgOI() {
+            ObjectInspectorCopyOption.WRITABLE);
+  }
+
+  public ExprNodeEvaluator getExprEvaluator() {
+    return exprEvaluator;
+  }
+
+  public void setExprEvaluator(ExprNodeEvaluator exprEvaluator) {
+    this.exprEvaluator = exprEvaluator;
+  }
+
+  public PTFPartitionIterator<Object> getpItr() {
+    return pItr;
+  }
+
+  public void setpItr(PTFPartitionIterator<Object> pItr) {
+    this.pItr = pItr;
+  }
+
+  public ObjectInspector getFirstArgOI() {
     return firstArgOI;
   }
 
@@ -179,69 +163,22 @@ public void setAmt(int amt) {
   }
 
   @Override
-	public String getDisplayString(String[] children)
-	{
-		assert (children.length == 2);
-		StringBuilder sb = new StringBuilder();
-		sb.append(_getFnName());
-		sb.append("(");
-		sb.append(children[0]);
-		sb.append(", ");
-		sb.append(children[1]);
-		sb.append(")");
-		return sb.toString();
-	}
-
-	protected abstract String _getFnName();
-
-	protected abstract Object getRow(int amt) throws HiveException;
-
-	protected abstract int getIndex(int amt);
-
-	@UDFType(impliesOrder = true)
-	public static class GenericUDFLead extends GenericUDFLeadLag
-	{
-
-		@Override
-		protected String _getFnName()
-		{
-			return "lead";
-		}
-
-		@Override
-		protected int getIndex(int amt) {
-		  return pItr.getIndex() - 1 + amt;
-		}
-
-		@Override
-		protected Object getRow(int amt) throws HiveException
-		{
-			return pItr.lead(amt - 1);
-		}
-
-	}
-
-	@UDFType(impliesOrder = true)
-	public static class GenericUDFLag extends GenericUDFLeadLag
-	{
-		@Override
-		protected String _getFnName()
-		{
-			return "lag";
-		}
-
-		@Override
-    protected int getIndex(int amt) {
-      return pItr.getIndex() - 1 - amt;
-    }
+  public String getDisplayString(String[] children) {
+    assert (children.length == 2);
+    StringBuilder sb = new StringBuilder();
+    sb.append(_getFnName());
+    sb.append("(");
+    sb.append(children[0]);
+    sb.append(", ");
+    sb.append(children[1]);
+    sb.append(")");
+    return sb.toString();
+  }
 
-		@Override
-		protected Object getRow(int amt) throws HiveException
-		{
-			return pItr.lag(amt + 1);
-		}
+  protected abstract String _getFnName();
 
-	}
+  protected abstract Object getRow(int amt) throws HiveException;
 
-}
+  protected abstract int getIndex(int amt);
 
+}
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/LeadLagBuffer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/LeadLagBuffer.java
new file mode 100644
index 0000000..5edcfb3
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/LeadLagBuffer.java
@@ -0,0 +1,12 @@
+package org.apache.hadoop.hive.ql.udf.generic;
+
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.AggregationBuffer;
+
+interface LeadLagBuffer extends AggregationBuffer {
+  void initialize(int leadAmt);
+
+  void addRow(Object leadExprValue, Object defaultValue);
+
+  Object terminate();
+
+}
\ No newline at end of file
diff --git a/src/ql/src/test/queries/clientnegative/windowing_ll_no_neg.q b/src/ql/src/test/queries/clientnegative/windowing_ll_no_neg.q
new file mode 100644
index 0000000..46bca37
--- /dev/null
+++ b/src/ql/src/test/queries/clientnegative/windowing_ll_no_neg.q
@@ -0,0 +1,26 @@
+DROP TABLE IF EXISTS part;
+
+-- data setup
+CREATE TABLE part(
+    p_partkey INT,
+    p_name STRING,
+    p_mfgr STRING,
+    p_brand STRING,
+    p_type STRING,
+    p_size INT,
+    p_container STRING,
+    p_retailprice DOUBLE,
+    p_comment STRING
+);
+
+LOAD DATA LOCAL INPATH '../data/files/part_tiny.txt' overwrite into table part;
+
+
+select p_mfgr, p_name, p_size,
+min(p_retailprice),
+rank() over(distribute by p_mfgr sort by p_name)as r,
+dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
+p_size, p_size - lag(p_size,-1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
+from part
+group by p_mfgr, p_name, p_size
+;
diff --git a/src/ql/src/test/results/clientnegative/windowing_ll_no_neg.q.out b/src/ql/src/test/results/clientnegative/windowing_ll_no_neg.q.out
new file mode 100644
index 0000000..bde437d
--- /dev/null
+++ b/src/ql/src/test/results/clientnegative/windowing_ll_no_neg.q.out
@@ -0,0 +1,39 @@
+PREHOOK: query: DROP TABLE IF EXISTS part
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE IF EXISTS part
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: -- data setup
+CREATE TABLE part(
+    p_partkey INT,
+    p_name STRING,
+    p_mfgr STRING,
+    p_brand STRING,
+    p_type STRING,
+    p_size INT,
+    p_container STRING,
+    p_retailprice DOUBLE,
+    p_comment STRING
+)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: -- data setup
+CREATE TABLE part(
+    p_partkey INT,
+    p_name STRING,
+    p_mfgr STRING,
+    p_brand STRING,
+    p_type STRING,
+    p_size INT,
+    p_container STRING,
+    p_retailprice DOUBLE,
+    p_comment STRING
+)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@part
+PREHOOK: query: LOAD DATA LOCAL INPATH '../data/files/part_tiny.txt' overwrite into table part
+PREHOOK: type: LOAD
+PREHOOK: Output: default@part
+POSTHOOK: query: LOAD DATA LOCAL INPATH '../data/files/part_tiny.txt' overwrite into table part
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@part
+FAILED: SemanticException Failed to breakup Windowing invocations into Groups. At least 1 group must only depend on input columns. Also check for circular dependencies.
+Underlying error: org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException: Lag amount can not be nagative. Specified: -1
-- 
1.7.0.4

